I0314 15:38:49.914387 29479 caffe.cpp:116] Use GPU with device ID 2
I0314 15:38:50.893061 29479 caffe.cpp:124] Starting Optimization
I0314 15:38:50.893180 29479 solver.cpp:32] Initializing solver from parameters: 
base_lr: 1e-08
display: 20
max_iter: 200000
lr_policy: "poly"
power: 0.9
momentum: 0.9
weight_decay: 0.0005
snapshot: 10000
snapshot_prefix: "models/pnet/VGG_VOC2012ext"
debug_info: false
net: "models/pnet/VGG_VOC2012ext.prototxt"
test_initialization: false
average_loss: 20
iter_size: 8
eval_type: "segmentation"
I0314 15:38:50.893210 29479 solver.cpp:70] Creating training net from net file: models/pnet/VGG_VOC2012ext.prototxt
I0314 15:38:51.462448 29479 net.cpp:42] Initializing net from parameters: 
name: "VGG_VOC2012ext"
state {
  phase: TRAIN
}
layer {
  name: "loaddata"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/home/valada/datasets/OFFROAD_OWN_MEAN_RSC/aug_deformed_v46.txt"
    batch_size: 1
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    engine: CAFFE
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    engine: CAFFE
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    engine: CAFFE
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    engine: CAFFE
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    engine: CAFFE
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    engine: CAFFE
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    engine: CAFFE
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    engine: CAFFE
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    engine: CAFFE
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    engine: CAFFE
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    engine: CAFFE
    filter_stride: 2
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    engine: CAFFE
    filter_stride: 2
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    engine: CAFFE
    filter_stride: 2
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "fc6"
  type: "Convolution"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 12
    kernel_size: 3
    engine: CAFFE
    filter_stride: 12
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "Convolution"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
    engine: CAFFE
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_norm"
  type: "Normalize"
  bottom: "fc7"
  top: "fc7_norm"
  norm_param {
    across_spatial: false
    scale_filler {
      type: "constant"
      value: 10
    }
    channel_shared: false
    fix_scale: false
  }
}
layer {
  name: "pool6_1x1"
  type: "Pooling"
  bottom: "fc7"
  top: "pool6_1x1"
  pooling_param {
    pool: AVE
    bin_size: 1
  }
}
layer {
  name: "pool6_1x1_norm"
  type: "Normalize"
  bottom: "pool6_1x1"
  top: "pool6_1x1_norm"
  norm_param {
    across_spatial: false
    scale_filler {
      type: "constant"
      value: 10
    }
    channel_shared: false
    fix_scale: false
  }
}
layer {
  name: "pool6_1x1_norm_drop"
  type: "Dropout"
  bottom: "pool6_1x1_norm"
  top: "pool6_1x1_norm"
  dropout_param {
    dropout_ratio: 0.3
  }
}
layer {
  name: "fc7_norm_score21"
  type: "Convolution"
  bottom: "fc7_norm"
  top: "fc7_norm_score21"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  convolution_param {
    num_output: 6
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
  }
}
layer {
  name: "pool6_1x1_norm_score21"
  type: "Convolution"
  bottom: "pool6_1x1_norm"
  top: "pool6_1x1_norm_score21"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  convolution_param {
    num_output: 6
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
  }
}
layer {
  name: "pool6_1x1_norm_upscore21"
  type: "UnPooling"
  bottom: "pool6_1x1_norm_score21"
  bottom: "fc7_norm_score21"
  top: "pool6_1x1_norm_upscore21"
  unpooling_param {
    unpool: REP
    out_kernel_size: 0
    out_stride: 0
  }
}
layer {
  name: "score21"
  type: "Eltwise"
  bottom: "pool6_1x1_norm_upscore21"
  bottom: "fc7_norm_score21"
  top: "score21"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "upscore21"
  type: "Deconvolution"
  bottom: "score21"
  top: "upscore21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 6
    pad: 4
    kernel_size: 16
    group: 6
    stride: 8
    weight_filler {
      type: "bilinear_upsampling"
    }
  }
}
layer {
  name: "score"
  type: "Crop"
  bottom: "upscore21"
  bottom: "data"
  top: "score"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
  include {
    phase: TRAIN
  }
  loss_param {
    ignore_label: 255
    normalize: false
  }
}
I0314 15:38:51.462779 29479 layer_factory.hpp:74] Creating layer loaddata
I0314 15:38:51.462806 29479 net.cpp:91] Creating Layer loaddata
I0314 15:38:51.462817 29479 net.cpp:369] loaddata -> data
I0314 15:38:51.462846 29479 net.cpp:369] loaddata -> label
I0314 15:38:51.462862 29479 net.cpp:121] Setting up loaddata
I0314 15:38:51.462869 29479 hdf5_data_layer.cpp:80] Loading list of HDF5 filenames from: /home/valada/datasets/OFFROAD_OWN_MEAN_RSC/aug_deformed_v46.txt
I0314 15:38:52.369917 29479 hdf5_data_layer.cpp:94] Number of HDF5 files: 60
I0314 15:39:09.591245 29479 net.cpp:128] Top shape: 1 3 300 300 (270000)
I0314 15:39:09.591280 29479 net.cpp:128] Top shape: 1 1 300 300 (90000)
I0314 15:39:09.591292 29479 layer_factory.hpp:74] Creating layer data_loaddata_0_split
I0314 15:39:09.591315 29479 net.cpp:91] Creating Layer data_loaddata_0_split
I0314 15:39:09.591323 29479 net.cpp:411] data_loaddata_0_split <- data
I0314 15:39:09.591339 29479 net.cpp:369] data_loaddata_0_split -> data_loaddata_0_split_0
I0314 15:39:09.591354 29479 net.cpp:369] data_loaddata_0_split -> data_loaddata_0_split_1
I0314 15:39:09.591362 29479 net.cpp:121] Setting up data_loaddata_0_split
I0314 15:39:09.591373 29479 net.cpp:128] Top shape: 1 3 300 300 (270000)
I0314 15:39:09.591380 29479 net.cpp:128] Top shape: 1 3 300 300 (270000)
I0314 15:39:09.591387 29479 layer_factory.hpp:74] Creating layer conv1_1
I0314 15:39:09.591401 29479 net.cpp:91] Creating Layer conv1_1
I0314 15:39:09.591408 29479 net.cpp:411] conv1_1 <- data_loaddata_0_split_0
I0314 15:39:09.591414 29479 net.cpp:369] conv1_1 -> conv1_1
I0314 15:39:09.591425 29479 net.cpp:121] Setting up conv1_1
I0314 15:39:09.591521 29479 net.cpp:128] Top shape: 1 64 300 300 (5760000)
I0314 15:39:09.591541 29479 layer_factory.hpp:74] Creating layer relu1_1
I0314 15:39:09.591553 29479 net.cpp:91] Creating Layer relu1_1
I0314 15:39:09.591559 29479 net.cpp:411] relu1_1 <- conv1_1
I0314 15:39:09.591567 29479 net.cpp:358] relu1_1 -> conv1_1 (in-place)
I0314 15:39:09.591573 29479 net.cpp:121] Setting up relu1_1
I0314 15:39:09.591583 29479 net.cpp:128] Top shape: 1 64 300 300 (5760000)
I0314 15:39:09.591589 29479 layer_factory.hpp:74] Creating layer conv1_2
I0314 15:39:09.591598 29479 net.cpp:91] Creating Layer conv1_2
I0314 15:39:09.591603 29479 net.cpp:411] conv1_2 <- conv1_1
I0314 15:39:09.591611 29479 net.cpp:369] conv1_2 -> conv1_2
I0314 15:39:09.591656 29479 net.cpp:121] Setting up conv1_2
I0314 15:39:09.592006 29479 net.cpp:128] Top shape: 1 64 300 300 (5760000)
I0314 15:39:09.592020 29479 layer_factory.hpp:74] Creating layer relu1_2
I0314 15:39:09.592041 29479 net.cpp:91] Creating Layer relu1_2
I0314 15:39:09.592046 29479 net.cpp:411] relu1_2 <- conv1_2
I0314 15:39:09.592052 29479 net.cpp:358] relu1_2 -> conv1_2 (in-place)
I0314 15:39:09.592059 29479 net.cpp:121] Setting up relu1_2
I0314 15:39:09.592067 29479 net.cpp:128] Top shape: 1 64 300 300 (5760000)
I0314 15:39:09.592072 29479 layer_factory.hpp:74] Creating layer pool1
I0314 15:39:09.592083 29479 net.cpp:91] Creating Layer pool1
I0314 15:39:09.592089 29479 net.cpp:411] pool1 <- conv1_2
I0314 15:39:09.592095 29479 net.cpp:369] pool1 -> pool1
I0314 15:39:09.592104 29479 net.cpp:121] Setting up pool1
I0314 15:39:09.592128 29479 net.cpp:128] Top shape: 1 64 150 150 (1440000)
I0314 15:39:09.592134 29479 layer_factory.hpp:74] Creating layer conv2_1
I0314 15:39:09.592144 29479 net.cpp:91] Creating Layer conv2_1
I0314 15:39:09.592149 29479 net.cpp:411] conv2_1 <- pool1
I0314 15:39:09.592154 29479 net.cpp:369] conv2_1 -> conv2_1
I0314 15:39:09.592161 29479 net.cpp:121] Setting up conv2_1
I0314 15:39:09.592375 29479 net.cpp:128] Top shape: 1 128 150 150 (2880000)
I0314 15:39:09.592387 29479 layer_factory.hpp:74] Creating layer relu2_1
I0314 15:39:09.592397 29479 net.cpp:91] Creating Layer relu2_1
I0314 15:39:09.592402 29479 net.cpp:411] relu2_1 <- conv2_1
I0314 15:39:09.592408 29479 net.cpp:358] relu2_1 -> conv2_1 (in-place)
I0314 15:39:09.592416 29479 net.cpp:121] Setting up relu2_1
I0314 15:39:09.592422 29479 net.cpp:128] Top shape: 1 128 150 150 (2880000)
I0314 15:39:09.592428 29479 layer_factory.hpp:74] Creating layer conv2_2
I0314 15:39:09.592437 29479 net.cpp:91] Creating Layer conv2_2
I0314 15:39:09.592440 29479 net.cpp:411] conv2_2 <- conv2_1
I0314 15:39:09.592447 29479 net.cpp:369] conv2_2 -> conv2_2
I0314 15:39:09.592455 29479 net.cpp:121] Setting up conv2_2
I0314 15:39:09.592913 29479 net.cpp:128] Top shape: 1 128 150 150 (2880000)
I0314 15:39:09.592927 29479 layer_factory.hpp:74] Creating layer relu2_2
I0314 15:39:09.592936 29479 net.cpp:91] Creating Layer relu2_2
I0314 15:39:09.592941 29479 net.cpp:411] relu2_2 <- conv2_2
I0314 15:39:09.592959 29479 net.cpp:358] relu2_2 -> conv2_2 (in-place)
I0314 15:39:09.592967 29479 net.cpp:121] Setting up relu2_2
I0314 15:39:09.592973 29479 net.cpp:128] Top shape: 1 128 150 150 (2880000)
I0314 15:39:09.592979 29479 layer_factory.hpp:74] Creating layer pool2
I0314 15:39:09.592985 29479 net.cpp:91] Creating Layer pool2
I0314 15:39:09.592989 29479 net.cpp:411] pool2 <- conv2_2
I0314 15:39:09.592995 29479 net.cpp:369] pool2 -> pool2
I0314 15:39:09.593001 29479 net.cpp:121] Setting up pool2
I0314 15:39:09.593009 29479 net.cpp:128] Top shape: 1 128 75 75 (720000)
I0314 15:39:09.593014 29479 layer_factory.hpp:74] Creating layer conv3_1
I0314 15:39:09.593020 29479 net.cpp:91] Creating Layer conv3_1
I0314 15:39:09.593025 29479 net.cpp:411] conv3_1 <- pool2
I0314 15:39:09.593031 29479 net.cpp:369] conv3_1 -> conv3_1
I0314 15:39:09.593039 29479 net.cpp:121] Setting up conv3_1
I0314 15:39:09.593762 29479 net.cpp:128] Top shape: 1 256 75 75 (1440000)
I0314 15:39:09.593775 29479 layer_factory.hpp:74] Creating layer relu3_1
I0314 15:39:09.593783 29479 net.cpp:91] Creating Layer relu3_1
I0314 15:39:09.593789 29479 net.cpp:411] relu3_1 <- conv3_1
I0314 15:39:09.593796 29479 net.cpp:358] relu3_1 -> conv3_1 (in-place)
I0314 15:39:09.593802 29479 net.cpp:121] Setting up relu3_1
I0314 15:39:09.593808 29479 net.cpp:128] Top shape: 1 256 75 75 (1440000)
I0314 15:39:09.593816 29479 layer_factory.hpp:74] Creating layer conv3_2
I0314 15:39:09.593824 29479 net.cpp:91] Creating Layer conv3_2
I0314 15:39:09.593829 29479 net.cpp:411] conv3_2 <- conv3_1
I0314 15:39:09.593835 29479 net.cpp:369] conv3_2 -> conv3_2
I0314 15:39:09.593843 29479 net.cpp:121] Setting up conv3_2
I0314 15:39:09.595232 29479 net.cpp:128] Top shape: 1 256 75 75 (1440000)
I0314 15:39:09.595244 29479 layer_factory.hpp:74] Creating layer relu3_2
I0314 15:39:09.595264 29479 net.cpp:91] Creating Layer relu3_2
I0314 15:39:09.595270 29479 net.cpp:411] relu3_2 <- conv3_2
I0314 15:39:09.595276 29479 net.cpp:358] relu3_2 -> conv3_2 (in-place)
I0314 15:39:09.595283 29479 net.cpp:121] Setting up relu3_2
I0314 15:39:09.595290 29479 net.cpp:128] Top shape: 1 256 75 75 (1440000)
I0314 15:39:09.595295 29479 layer_factory.hpp:74] Creating layer conv3_3
I0314 15:39:09.595306 29479 net.cpp:91] Creating Layer conv3_3
I0314 15:39:09.595310 29479 net.cpp:411] conv3_3 <- conv3_2
I0314 15:39:09.595316 29479 net.cpp:369] conv3_3 -> conv3_3
I0314 15:39:09.595324 29479 net.cpp:121] Setting up conv3_3
I0314 15:39:09.596560 29479 net.cpp:128] Top shape: 1 256 75 75 (1440000)
I0314 15:39:09.596582 29479 layer_factory.hpp:74] Creating layer relu3_3
I0314 15:39:09.596588 29479 net.cpp:91] Creating Layer relu3_3
I0314 15:39:09.596593 29479 net.cpp:411] relu3_3 <- conv3_3
I0314 15:39:09.596598 29479 net.cpp:358] relu3_3 -> conv3_3 (in-place)
I0314 15:39:09.596604 29479 net.cpp:121] Setting up relu3_3
I0314 15:39:09.596609 29479 net.cpp:128] Top shape: 1 256 75 75 (1440000)
I0314 15:39:09.596616 29479 layer_factory.hpp:74] Creating layer pool3
I0314 15:39:09.596623 29479 net.cpp:91] Creating Layer pool3
I0314 15:39:09.596627 29479 net.cpp:411] pool3 <- conv3_3
I0314 15:39:09.596633 29479 net.cpp:369] pool3 -> pool3
I0314 15:39:09.596640 29479 net.cpp:121] Setting up pool3
I0314 15:39:09.596649 29479 net.cpp:128] Top shape: 1 256 38 38 (369664)
I0314 15:39:09.596667 29479 layer_factory.hpp:74] Creating layer conv4_1
I0314 15:39:09.596674 29479 net.cpp:91] Creating Layer conv4_1
I0314 15:39:09.596680 29479 net.cpp:411] conv4_1 <- pool3
I0314 15:39:09.596689 29479 net.cpp:369] conv4_1 -> conv4_1
I0314 15:39:09.596698 29479 net.cpp:121] Setting up conv4_1
I0314 15:39:09.598953 29479 net.cpp:128] Top shape: 1 512 38 38 (739328)
I0314 15:39:09.598965 29479 layer_factory.hpp:74] Creating layer relu4_1
I0314 15:39:09.598984 29479 net.cpp:91] Creating Layer relu4_1
I0314 15:39:09.598990 29479 net.cpp:411] relu4_1 <- conv4_1
I0314 15:39:09.599000 29479 net.cpp:358] relu4_1 -> conv4_1 (in-place)
I0314 15:39:09.599006 29479 net.cpp:121] Setting up relu4_1
I0314 15:39:09.599012 29479 net.cpp:128] Top shape: 1 512 38 38 (739328)
I0314 15:39:09.599015 29479 layer_factory.hpp:74] Creating layer conv4_2
I0314 15:39:09.599023 29479 net.cpp:91] Creating Layer conv4_2
I0314 15:39:09.599027 29479 net.cpp:411] conv4_2 <- conv4_1
I0314 15:39:09.599033 29479 net.cpp:369] conv4_2 -> conv4_2
I0314 15:39:09.599041 29479 net.cpp:121] Setting up conv4_2
I0314 15:39:09.603235 29479 net.cpp:128] Top shape: 1 512 38 38 (739328)
I0314 15:39:09.603263 29479 layer_factory.hpp:74] Creating layer relu4_2
I0314 15:39:09.603271 29479 net.cpp:91] Creating Layer relu4_2
I0314 15:39:09.603274 29479 net.cpp:411] relu4_2 <- conv4_2
I0314 15:39:09.603283 29479 net.cpp:358] relu4_2 -> conv4_2 (in-place)
I0314 15:39:09.603289 29479 net.cpp:121] Setting up relu4_2
I0314 15:39:09.603294 29479 net.cpp:128] Top shape: 1 512 38 38 (739328)
I0314 15:39:09.603299 29479 layer_factory.hpp:74] Creating layer conv4_3
I0314 15:39:09.603305 29479 net.cpp:91] Creating Layer conv4_3
I0314 15:39:09.603320 29479 net.cpp:411] conv4_3 <- conv4_2
I0314 15:39:09.603327 29479 net.cpp:369] conv4_3 -> conv4_3
I0314 15:39:09.603334 29479 net.cpp:121] Setting up conv4_3
I0314 15:39:09.608393 29479 net.cpp:128] Top shape: 1 512 38 38 (739328)
I0314 15:39:09.608420 29479 layer_factory.hpp:74] Creating layer relu4_3
I0314 15:39:09.608428 29479 net.cpp:91] Creating Layer relu4_3
I0314 15:39:09.608431 29479 net.cpp:411] relu4_3 <- conv4_3
I0314 15:39:09.608436 29479 net.cpp:358] relu4_3 -> conv4_3 (in-place)
I0314 15:39:09.608443 29479 net.cpp:121] Setting up relu4_3
I0314 15:39:09.608446 29479 net.cpp:128] Top shape: 1 512 38 38 (739328)
I0314 15:39:09.608450 29479 layer_factory.hpp:74] Creating layer pool4
I0314 15:39:09.608459 29479 net.cpp:91] Creating Layer pool4
I0314 15:39:09.608464 29479 net.cpp:411] pool4 <- conv4_3
I0314 15:39:09.608510 29479 net.cpp:369] pool4 -> pool4
I0314 15:39:09.608516 29479 net.cpp:121] Setting up pool4
I0314 15:39:09.608528 29479 net.cpp:128] Top shape: 1 512 38 38 (739328)
I0314 15:39:09.608533 29479 layer_factory.hpp:74] Creating layer conv5_1
I0314 15:39:09.608544 29479 net.cpp:91] Creating Layer conv5_1
I0314 15:39:09.608551 29479 net.cpp:411] conv5_1 <- pool4
I0314 15:39:09.608556 29479 net.cpp:369] conv5_1 -> conv5_1
I0314 15:39:09.608564 29479 net.cpp:121] Setting up conv5_1
I0314 15:39:09.614002 29479 net.cpp:128] Top shape: 1 512 38 38 (739328)
I0314 15:39:09.614029 29479 layer_factory.hpp:74] Creating layer relu5_1
I0314 15:39:09.614037 29479 net.cpp:91] Creating Layer relu5_1
I0314 15:39:09.614040 29479 net.cpp:411] relu5_1 <- conv5_1
I0314 15:39:09.614047 29479 net.cpp:358] relu5_1 -> conv5_1 (in-place)
I0314 15:39:09.614051 29479 net.cpp:121] Setting up relu5_1
I0314 15:39:09.614056 29479 net.cpp:128] Top shape: 1 512 38 38 (739328)
I0314 15:39:09.614065 29479 layer_factory.hpp:74] Creating layer conv5_2
I0314 15:39:09.614073 29479 net.cpp:91] Creating Layer conv5_2
I0314 15:39:09.614078 29479 net.cpp:411] conv5_2 <- conv5_1
I0314 15:39:09.614099 29479 net.cpp:369] conv5_2 -> conv5_2
I0314 15:39:09.614105 29479 net.cpp:121] Setting up conv5_2
I0314 15:39:09.619421 29479 net.cpp:128] Top shape: 1 512 38 38 (739328)
I0314 15:39:09.619434 29479 layer_factory.hpp:74] Creating layer relu5_2
I0314 15:39:09.619441 29479 net.cpp:91] Creating Layer relu5_2
I0314 15:39:09.619446 29479 net.cpp:411] relu5_2 <- conv5_2
I0314 15:39:09.619451 29479 net.cpp:358] relu5_2 -> conv5_2 (in-place)
I0314 15:39:09.619457 29479 net.cpp:121] Setting up relu5_2
I0314 15:39:09.619462 29479 net.cpp:128] Top shape: 1 512 38 38 (739328)
I0314 15:39:09.619464 29479 layer_factory.hpp:74] Creating layer conv5_3
I0314 15:39:09.619484 29479 net.cpp:91] Creating Layer conv5_3
I0314 15:39:09.619488 29479 net.cpp:411] conv5_3 <- conv5_2
I0314 15:39:09.619498 29479 net.cpp:369] conv5_3 -> conv5_3
I0314 15:39:09.619503 29479 net.cpp:121] Setting up conv5_3
I0314 15:39:09.623842 29479 net.cpp:128] Top shape: 1 512 38 38 (739328)
I0314 15:39:09.623867 29479 layer_factory.hpp:74] Creating layer relu5_3
I0314 15:39:09.623873 29479 net.cpp:91] Creating Layer relu5_3
I0314 15:39:09.623878 29479 net.cpp:411] relu5_3 <- conv5_3
I0314 15:39:09.623885 29479 net.cpp:358] relu5_3 -> conv5_3 (in-place)
I0314 15:39:09.623890 29479 net.cpp:121] Setting up relu5_3
I0314 15:39:09.623895 29479 net.cpp:128] Top shape: 1 512 38 38 (739328)
I0314 15:39:09.623901 29479 layer_factory.hpp:74] Creating layer pool5
I0314 15:39:09.623915 29479 net.cpp:91] Creating Layer pool5
I0314 15:39:09.623931 29479 net.cpp:411] pool5 <- conv5_3
I0314 15:39:09.623940 29479 net.cpp:369] pool5 -> pool5
I0314 15:39:09.623947 29479 net.cpp:121] Setting up pool5
I0314 15:39:09.623956 29479 net.cpp:128] Top shape: 1 512 38 38 (739328)
I0314 15:39:09.623965 29479 layer_factory.hpp:74] Creating layer fc6
I0314 15:39:09.623971 29479 net.cpp:91] Creating Layer fc6
I0314 15:39:09.623977 29479 net.cpp:411] fc6 <- pool5
I0314 15:39:09.623983 29479 net.cpp:369] fc6 -> fc6
I0314 15:39:09.623991 29479 net.cpp:121] Setting up fc6
I0314 15:39:09.634047 29479 net.cpp:128] Top shape: 1 1024 38 38 (1478656)
I0314 15:39:09.634086 29479 layer_factory.hpp:74] Creating layer relu6
I0314 15:39:09.634098 29479 net.cpp:91] Creating Layer relu6
I0314 15:39:09.634104 29479 net.cpp:411] relu6 <- fc6
I0314 15:39:09.634110 29479 net.cpp:358] relu6 -> fc6 (in-place)
I0314 15:39:09.634119 29479 net.cpp:121] Setting up relu6
I0314 15:39:09.634124 29479 net.cpp:128] Top shape: 1 1024 38 38 (1478656)
I0314 15:39:09.634131 29479 layer_factory.hpp:74] Creating layer drop6
I0314 15:39:09.634160 29479 net.cpp:91] Creating Layer drop6
I0314 15:39:09.634163 29479 net.cpp:411] drop6 <- fc6
I0314 15:39:09.634168 29479 net.cpp:358] drop6 -> fc6 (in-place)
I0314 15:39:09.634178 29479 net.cpp:121] Setting up drop6
I0314 15:39:09.634189 29479 net.cpp:128] Top shape: 1 1024 38 38 (1478656)
I0314 15:39:09.634193 29479 layer_factory.hpp:74] Creating layer fc7
I0314 15:39:09.634253 29479 net.cpp:91] Creating Layer fc7
I0314 15:39:09.634259 29479 net.cpp:411] fc7 <- fc6
I0314 15:39:09.634265 29479 net.cpp:369] fc7 -> fc7
I0314 15:39:09.634274 29479 net.cpp:121] Setting up fc7
I0314 15:39:09.636848 29479 net.cpp:128] Top shape: 1 1024 38 38 (1478656)
I0314 15:39:09.636875 29479 layer_factory.hpp:74] Creating layer relu7
I0314 15:39:09.636884 29479 net.cpp:91] Creating Layer relu7
I0314 15:39:09.636889 29479 net.cpp:411] relu7 <- fc7
I0314 15:39:09.636895 29479 net.cpp:358] relu7 -> fc7 (in-place)
I0314 15:39:09.636900 29479 net.cpp:121] Setting up relu7
I0314 15:39:09.636907 29479 net.cpp:128] Top shape: 1 1024 38 38 (1478656)
I0314 15:39:09.636911 29479 layer_factory.hpp:74] Creating layer drop7
I0314 15:39:09.636917 29479 net.cpp:91] Creating Layer drop7
I0314 15:39:09.636921 29479 net.cpp:411] drop7 <- fc7
I0314 15:39:09.636940 29479 net.cpp:358] drop7 -> fc7 (in-place)
I0314 15:39:09.636945 29479 net.cpp:121] Setting up drop7
I0314 15:39:09.636951 29479 net.cpp:128] Top shape: 1 1024 38 38 (1478656)
I0314 15:39:09.636955 29479 layer_factory.hpp:74] Creating layer fc7_drop7_0_split
I0314 15:39:09.636962 29479 net.cpp:91] Creating Layer fc7_drop7_0_split
I0314 15:39:09.636965 29479 net.cpp:411] fc7_drop7_0_split <- fc7
I0314 15:39:09.636975 29479 net.cpp:369] fc7_drop7_0_split -> fc7_drop7_0_split_0
I0314 15:39:09.636984 29479 net.cpp:369] fc7_drop7_0_split -> fc7_drop7_0_split_1
I0314 15:39:09.636992 29479 net.cpp:121] Setting up fc7_drop7_0_split
I0314 15:39:09.637001 29479 net.cpp:128] Top shape: 1 1024 38 38 (1478656)
I0314 15:39:09.637007 29479 net.cpp:128] Top shape: 1 1024 38 38 (1478656)
I0314 15:39:09.637012 29479 layer_factory.hpp:74] Creating layer fc7_norm
I0314 15:39:09.637024 29479 net.cpp:91] Creating Layer fc7_norm
I0314 15:39:09.637032 29479 net.cpp:411] fc7_norm <- fc7_drop7_0_split_0
I0314 15:39:09.637048 29479 net.cpp:369] fc7_norm -> fc7_norm
I0314 15:39:09.637058 29479 net.cpp:121] Setting up fc7_norm
I0314 15:39:09.637084 29479 net.cpp:128] Top shape: 1 1024 38 38 (1478656)
I0314 15:39:09.637092 29479 layer_factory.hpp:74] Creating layer pool6_1x1
I0314 15:39:09.637104 29479 net.cpp:91] Creating Layer pool6_1x1
I0314 15:39:09.637109 29479 net.cpp:411] pool6_1x1 <- fc7_drop7_0_split_1
I0314 15:39:09.637115 29479 net.cpp:369] pool6_1x1 -> pool6_1x1
I0314 15:39:09.637122 29479 net.cpp:121] Setting up pool6_1x1
I0314 15:39:09.637140 29479 net.cpp:128] Top shape: 1 1024 1 1 (1024)
I0314 15:39:09.637147 29479 layer_factory.hpp:74] Creating layer pool6_1x1_norm
I0314 15:39:09.637158 29479 net.cpp:91] Creating Layer pool6_1x1_norm
I0314 15:39:09.637163 29479 net.cpp:411] pool6_1x1_norm <- pool6_1x1
I0314 15:39:09.637171 29479 net.cpp:369] pool6_1x1_norm -> pool6_1x1_norm
I0314 15:39:09.637177 29479 net.cpp:121] Setting up pool6_1x1_norm
I0314 15:39:09.637195 29479 net.cpp:128] Top shape: 1 1024 1 1 (1024)
I0314 15:39:09.637202 29479 layer_factory.hpp:74] Creating layer pool6_1x1_norm_drop
I0314 15:39:09.637212 29479 net.cpp:91] Creating Layer pool6_1x1_norm_drop
I0314 15:39:09.637217 29479 net.cpp:411] pool6_1x1_norm_drop <- pool6_1x1_norm
I0314 15:39:09.637225 29479 net.cpp:358] pool6_1x1_norm_drop -> pool6_1x1_norm (in-place)
I0314 15:39:09.637233 29479 net.cpp:121] Setting up pool6_1x1_norm_drop
I0314 15:39:09.637239 29479 net.cpp:128] Top shape: 1 1024 1 1 (1024)
I0314 15:39:09.637245 29479 layer_factory.hpp:74] Creating layer fc7_norm_score21
I0314 15:39:09.637253 29479 net.cpp:91] Creating Layer fc7_norm_score21
I0314 15:39:09.637259 29479 net.cpp:411] fc7_norm_score21 <- fc7_norm
I0314 15:39:09.637267 29479 net.cpp:369] fc7_norm_score21 -> fc7_norm_score21
I0314 15:39:09.637275 29479 net.cpp:121] Setting up fc7_norm_score21
I0314 15:39:09.637778 29479 net.cpp:128] Top shape: 1 6 38 38 (8664)
I0314 15:39:09.637797 29479 layer_factory.hpp:74] Creating layer fc7_norm_score21_fc7_norm_score21_0_split
I0314 15:39:09.637806 29479 net.cpp:91] Creating Layer fc7_norm_score21_fc7_norm_score21_0_split
I0314 15:39:09.637814 29479 net.cpp:411] fc7_norm_score21_fc7_norm_score21_0_split <- fc7_norm_score21
I0314 15:39:09.637835 29479 net.cpp:369] fc7_norm_score21_fc7_norm_score21_0_split -> fc7_norm_score21_fc7_norm_score21_0_split_0
I0314 15:39:09.637845 29479 net.cpp:369] fc7_norm_score21_fc7_norm_score21_0_split -> fc7_norm_score21_fc7_norm_score21_0_split_1
I0314 15:39:09.637852 29479 net.cpp:121] Setting up fc7_norm_score21_fc7_norm_score21_0_split
I0314 15:39:09.637861 29479 net.cpp:128] Top shape: 1 6 38 38 (8664)
I0314 15:39:09.637866 29479 net.cpp:128] Top shape: 1 6 38 38 (8664)
I0314 15:39:09.637871 29479 layer_factory.hpp:74] Creating layer pool6_1x1_norm_score21
I0314 15:39:09.637881 29479 net.cpp:91] Creating Layer pool6_1x1_norm_score21
I0314 15:39:09.637887 29479 net.cpp:411] pool6_1x1_norm_score21 <- pool6_1x1_norm
I0314 15:39:09.637895 29479 net.cpp:369] pool6_1x1_norm_score21 -> pool6_1x1_norm_score21
I0314 15:39:09.637907 29479 net.cpp:121] Setting up pool6_1x1_norm_score21
I0314 15:39:09.637981 29479 net.cpp:128] Top shape: 1 6 1 1 (6)
I0314 15:39:09.637991 29479 layer_factory.hpp:74] Creating layer pool6_1x1_norm_upscore21
I0314 15:39:09.638003 29479 net.cpp:91] Creating Layer pool6_1x1_norm_upscore21
I0314 15:39:09.638008 29479 net.cpp:411] pool6_1x1_norm_upscore21 <- pool6_1x1_norm_score21
I0314 15:39:09.638015 29479 net.cpp:411] pool6_1x1_norm_upscore21 <- fc7_norm_score21_fc7_norm_score21_0_split_0
I0314 15:39:09.638021 29479 net.cpp:369] pool6_1x1_norm_upscore21 -> pool6_1x1_norm_upscore21
I0314 15:39:09.638031 29479 net.cpp:121] Setting up pool6_1x1_norm_upscore21
I0314 15:39:09.638056 29479 net.cpp:128] Top shape: 1 6 38 38 (8664)
I0314 15:39:09.638062 29479 layer_factory.hpp:74] Creating layer score21
I0314 15:39:09.638072 29479 net.cpp:91] Creating Layer score21
I0314 15:39:09.638077 29479 net.cpp:411] score21 <- pool6_1x1_norm_upscore21
I0314 15:39:09.638082 29479 net.cpp:411] score21 <- fc7_norm_score21_fc7_norm_score21_0_split_1
I0314 15:39:09.638088 29479 net.cpp:369] score21 -> score21
I0314 15:39:09.638098 29479 net.cpp:121] Setting up score21
I0314 15:39:09.638109 29479 net.cpp:128] Top shape: 1 6 38 38 (8664)
I0314 15:39:09.638114 29479 layer_factory.hpp:74] Creating layer upscore21
I0314 15:39:09.638128 29479 net.cpp:91] Creating Layer upscore21
I0314 15:39:09.638133 29479 net.cpp:411] upscore21 <- score21
I0314 15:39:09.638139 29479 net.cpp:369] upscore21 -> upscore21
I0314 15:39:09.638146 29479 net.cpp:121] Setting up upscore21
I0314 15:39:09.638444 29479 net.cpp:128] Top shape: 1 6 304 304 (554496)
I0314 15:39:09.638456 29479 layer_factory.hpp:74] Creating layer score
I0314 15:39:09.638468 29479 net.cpp:91] Creating Layer score
I0314 15:39:09.638474 29479 net.cpp:411] score <- upscore21
I0314 15:39:09.638479 29479 net.cpp:411] score <- data_loaddata_0_split_1
I0314 15:39:09.638486 29479 net.cpp:369] score -> score
I0314 15:39:09.638494 29479 net.cpp:121] Setting up score
I0314 15:39:09.638577 29479 net.cpp:128] Top shape: 1 6 300 300 (540000)
I0314 15:39:09.638584 29479 layer_factory.hpp:74] Creating layer loss
I0314 15:39:09.638597 29479 net.cpp:91] Creating Layer loss
I0314 15:39:09.638602 29479 net.cpp:411] loss <- score
I0314 15:39:09.638607 29479 net.cpp:411] loss <- label
I0314 15:39:09.638615 29479 net.cpp:369] loss -> loss
I0314 15:39:09.638628 29479 net.cpp:121] Setting up loss
I0314 15:39:09.638643 29479 layer_factory.hpp:74] Creating layer loss
I0314 15:39:09.639966 29479 net.cpp:128] Top shape: (1)
I0314 15:39:09.639974 29479 net.cpp:130]     with loss weight 1
I0314 15:39:09.640002 29479 net.cpp:193] loss needs backward computation.
I0314 15:39:09.640008 29479 net.cpp:193] score needs backward computation.
I0314 15:39:09.640012 29479 net.cpp:193] upscore21 needs backward computation.
I0314 15:39:09.640018 29479 net.cpp:193] score21 needs backward computation.
I0314 15:39:09.640022 29479 net.cpp:193] pool6_1x1_norm_upscore21 needs backward computation.
I0314 15:39:09.640028 29479 net.cpp:193] pool6_1x1_norm_score21 needs backward computation.
I0314 15:39:09.640032 29479 net.cpp:193] fc7_norm_score21_fc7_norm_score21_0_split needs backward computation.
I0314 15:39:09.640048 29479 net.cpp:193] fc7_norm_score21 needs backward computation.
I0314 15:39:09.640058 29479 net.cpp:193] pool6_1x1_norm_drop needs backward computation.
I0314 15:39:09.640064 29479 net.cpp:193] pool6_1x1_norm needs backward computation.
I0314 15:39:09.640067 29479 net.cpp:193] pool6_1x1 needs backward computation.
I0314 15:39:09.640072 29479 net.cpp:193] fc7_norm needs backward computation.
I0314 15:39:09.640076 29479 net.cpp:193] fc7_drop7_0_split needs backward computation.
I0314 15:39:09.640081 29479 net.cpp:193] drop7 needs backward computation.
I0314 15:39:09.640085 29479 net.cpp:193] relu7 needs backward computation.
I0314 15:39:09.640089 29479 net.cpp:193] fc7 needs backward computation.
I0314 15:39:09.640094 29479 net.cpp:193] drop6 needs backward computation.
I0314 15:39:09.640097 29479 net.cpp:193] relu6 needs backward computation.
I0314 15:39:09.640100 29479 net.cpp:193] fc6 needs backward computation.
I0314 15:39:09.640105 29479 net.cpp:193] pool5 needs backward computation.
I0314 15:39:09.640110 29479 net.cpp:193] relu5_3 needs backward computation.
I0314 15:39:09.640115 29479 net.cpp:193] conv5_3 needs backward computation.
I0314 15:39:09.640118 29479 net.cpp:193] relu5_2 needs backward computation.
I0314 15:39:09.640123 29479 net.cpp:193] conv5_2 needs backward computation.
I0314 15:39:09.640127 29479 net.cpp:193] relu5_1 needs backward computation.
I0314 15:39:09.640133 29479 net.cpp:193] conv5_1 needs backward computation.
I0314 15:39:09.640137 29479 net.cpp:193] pool4 needs backward computation.
I0314 15:39:09.640142 29479 net.cpp:193] relu4_3 needs backward computation.
I0314 15:39:09.640146 29479 net.cpp:193] conv4_3 needs backward computation.
I0314 15:39:09.640149 29479 net.cpp:193] relu4_2 needs backward computation.
I0314 15:39:09.640154 29479 net.cpp:193] conv4_2 needs backward computation.
I0314 15:39:09.640158 29479 net.cpp:193] relu4_1 needs backward computation.
I0314 15:39:09.640161 29479 net.cpp:193] conv4_1 needs backward computation.
I0314 15:39:09.640166 29479 net.cpp:193] pool3 needs backward computation.
I0314 15:39:09.640171 29479 net.cpp:193] relu3_3 needs backward computation.
I0314 15:39:09.640175 29479 net.cpp:193] conv3_3 needs backward computation.
I0314 15:39:09.640179 29479 net.cpp:193] relu3_2 needs backward computation.
I0314 15:39:09.640184 29479 net.cpp:193] conv3_2 needs backward computation.
I0314 15:39:09.640188 29479 net.cpp:193] relu3_1 needs backward computation.
I0314 15:39:09.640192 29479 net.cpp:193] conv3_1 needs backward computation.
I0314 15:39:09.640197 29479 net.cpp:193] pool2 needs backward computation.
I0314 15:39:09.640200 29479 net.cpp:193] relu2_2 needs backward computation.
I0314 15:39:09.640205 29479 net.cpp:193] conv2_2 needs backward computation.
I0314 15:39:09.640209 29479 net.cpp:193] relu2_1 needs backward computation.
I0314 15:39:09.640214 29479 net.cpp:193] conv2_1 needs backward computation.
I0314 15:39:09.640218 29479 net.cpp:193] pool1 needs backward computation.
I0314 15:39:09.640223 29479 net.cpp:193] relu1_2 needs backward computation.
I0314 15:39:09.640228 29479 net.cpp:193] conv1_2 needs backward computation.
I0314 15:39:09.640230 29479 net.cpp:193] relu1_1 needs backward computation.
I0314 15:39:09.640236 29479 net.cpp:193] conv1_1 needs backward computation.
I0314 15:39:09.640240 29479 net.cpp:195] data_loaddata_0_split does not need backward computation.
I0314 15:39:09.640246 29479 net.cpp:195] loaddata does not need backward computation.
I0314 15:39:09.640249 29479 net.cpp:236] This network produces output loss
I0314 15:39:09.640286 29479 net.cpp:483] Collecting Learning Rate and Weight Decay.
I0314 15:39:09.640300 29479 net.cpp:248] Network initialization done.
I0314 15:39:09.640305 29479 net.cpp:249] Memory required for data: 285716220
I0314 15:39:09.640471 29479 solver.cpp:42] Solver scaffolding done.
I0314 15:39:09.640553 29479 caffe.cpp:89] Finetuning from models/pnet/VGG_ILSVRC_16_layers_fc_reduced.caffemodel
I0314 15:39:11.072324 29479 solver.cpp:251] Solving VGG_VOC2012ext
I0314 15:39:11.072399 29479 solver.cpp:252] Learning Rate Policy: poly
I0314 15:39:12.211494 29479 solver.cpp:214] Iteration 0, loss = 166298
I0314 15:39:12.211561 29479 solver.cpp:229]     Train net output #0: loss = 169983 (* 1 = 169983 loss)
I0314 15:39:12.315114 29479 solver.cpp:610] Iteration 0, lr = 1e-08
I0314 15:39:12.315132 29479 solver.cpp:613] Iteration 0, avg_grad_norm = 4.61798e+06
I0314 15:39:35.558323 29479 solver.cpp:214] Iteration 20, loss = 130350
I0314 15:39:35.558516 29479 solver.cpp:229]     Train net output #0: loss = 106902 (* 1 = 106902 loss)
I0314 15:39:35.662875 29479 solver.cpp:610] Iteration 20, lr = 9.9991e-09
I0314 15:39:35.662888 29479 solver.cpp:613] Iteration 20, avg_grad_norm = 2.42432e+06
I0314 15:39:58.973187 29479 solver.cpp:214] Iteration 40, loss = 79659.9
I0314 15:39:58.973261 29479 solver.cpp:229]     Train net output #0: loss = 50216.8 (* 1 = 50216.8 loss)
I0314 15:39:59.077747 29479 solver.cpp:610] Iteration 40, lr = 9.9982e-09
I0314 15:39:59.077760 29479 solver.cpp:613] Iteration 40, avg_grad_norm = 3.79327e+06
I0314 15:40:22.393010 29479 solver.cpp:214] Iteration 60, loss = 51058.9
I0314 15:40:22.393151 29479 solver.cpp:229]     Train net output #0: loss = 33723.6 (* 1 = 33723.6 loss)
I0314 15:40:22.497648 29479 solver.cpp:610] Iteration 60, lr = 9.9973e-09
I0314 15:40:22.497660 29479 solver.cpp:613] Iteration 60, avg_grad_norm = 3.62204e+06
I0314 15:40:45.931301 29479 solver.cpp:214] Iteration 80, loss = 36158.4
I0314 15:40:45.931383 29479 solver.cpp:229]     Train net output #0: loss = 60549.4 (* 1 = 60549.4 loss)
I0314 15:40:46.035962 29479 solver.cpp:610] Iteration 80, lr = 9.9964e-09
I0314 15:40:46.035976 29479 solver.cpp:613] Iteration 80, avg_grad_norm = 2.45408e+06
I0314 15:41:09.423755 29479 solver.cpp:214] Iteration 100, loss = 30478.4
I0314 15:41:09.423950 29479 solver.cpp:229]     Train net output #0: loss = 17195.9 (* 1 = 17195.9 loss)
I0314 15:41:09.529356 29479 solver.cpp:610] Iteration 100, lr = 9.9955e-09
I0314 15:41:09.529369 29479 solver.cpp:613] Iteration 100, avg_grad_norm = 2.53566e+06
I0314 15:41:32.995477 29479 solver.cpp:214] Iteration 120, loss = 25146.8
I0314 15:41:32.995537 29479 solver.cpp:229]     Train net output #0: loss = 18755.5 (* 1 = 18755.5 loss)
I0314 15:41:33.100286 29479 solver.cpp:610] Iteration 120, lr = 9.9946e-09
I0314 15:41:33.100297 29479 solver.cpp:613] Iteration 120, avg_grad_norm = 2.07002e+06
I0314 15:42:11.132292 29479 solver.cpp:214] Iteration 140, loss = 23048.1
I0314 15:42:11.132441 29479 solver.cpp:229]     Train net output #0: loss = 22847.2 (* 1 = 22847.2 loss)
I0314 15:42:11.237840 29479 solver.cpp:610] Iteration 140, lr = 9.9937e-09
I0314 15:42:11.237854 29479 solver.cpp:613] Iteration 140, avg_grad_norm = 1.91197e+06
I0314 15:42:34.720368 29479 solver.cpp:214] Iteration 160, loss = 22666.1
I0314 15:42:34.720437 29479 solver.cpp:229]     Train net output #0: loss = 20891.8 (* 1 = 20891.8 loss)
I0314 15:42:34.824352 29479 solver.cpp:610] Iteration 160, lr = 9.9928e-09
I0314 15:42:34.824364 29479 solver.cpp:613] Iteration 160, avg_grad_norm = 1.98622e+06
I0314 15:42:58.721145 29479 solver.cpp:214] Iteration 180, loss = 20202.4
I0314 15:42:58.721371 29479 solver.cpp:229]     Train net output #0: loss = 24916.4 (* 1 = 24916.4 loss)
I0314 15:42:58.832871 29479 solver.cpp:610] Iteration 180, lr = 9.9919e-09
I0314 15:42:58.832886 29479 solver.cpp:613] Iteration 180, avg_grad_norm = 1.31219e+06
I0314 15:43:23.782574 29479 solver.cpp:214] Iteration 200, loss = 19729.8
I0314 15:43:23.782644 29479 solver.cpp:229]     Train net output #0: loss = 14298.8 (* 1 = 14298.8 loss)
I0314 15:43:23.894351 29479 solver.cpp:610] Iteration 200, lr = 9.991e-09
I0314 15:43:23.894363 29479 solver.cpp:613] Iteration 200, avg_grad_norm = 1.33088e+06
I0314 15:43:48.830029 29479 solver.cpp:214] Iteration 220, loss = 18443.7
I0314 15:43:48.830202 29479 solver.cpp:229]     Train net output #0: loss = 23511.2 (* 1 = 23511.2 loss)
I0314 15:43:48.941840 29479 solver.cpp:610] Iteration 220, lr = 9.9901e-09
I0314 15:43:48.941854 29479 solver.cpp:613] Iteration 220, avg_grad_norm = 1.35694e+06
I0314 15:44:14.223744 29479 solver.cpp:214] Iteration 240, loss = 18274.9
I0314 15:44:14.223809 29479 solver.cpp:229]     Train net output #0: loss = 10518 (* 1 = 10518 loss)
I0314 15:44:14.338592 29479 solver.cpp:610] Iteration 240, lr = 9.9892e-09
I0314 15:44:14.338604 29479 solver.cpp:613] Iteration 240, avg_grad_norm = 1.54208e+06
I0314 15:44:53.270552 29479 solver.cpp:214] Iteration 260, loss = 18685.2
I0314 15:44:53.270670 29479 solver.cpp:229]     Train net output #0: loss = 21564.3 (* 1 = 21564.3 loss)
I0314 15:44:53.374490 29479 solver.cpp:610] Iteration 260, lr = 9.9883e-09
I0314 15:44:53.374505 29479 solver.cpp:613] Iteration 260, avg_grad_norm = 1.49175e+06
I0314 15:45:16.845432 29479 solver.cpp:214] Iteration 280, loss = 17349.3
I0314 15:45:16.845489 29479 solver.cpp:229]     Train net output #0: loss = 10359.4 (* 1 = 10359.4 loss)
I0314 15:45:16.950690 29479 solver.cpp:610] Iteration 280, lr = 9.9874e-09
I0314 15:45:16.950703 29479 solver.cpp:613] Iteration 280, avg_grad_norm = 1.36363e+06
I0314 15:45:41.798647 29479 solver.cpp:214] Iteration 300, loss = 17283
I0314 15:45:41.798779 29479 solver.cpp:229]     Train net output #0: loss = 19858.5 (* 1 = 19858.5 loss)
I0314 15:45:41.911789 29479 solver.cpp:610] Iteration 300, lr = 9.9865e-09
I0314 15:45:41.911803 29479 solver.cpp:613] Iteration 300, avg_grad_norm = 1.45973e+06
I0314 15:46:07.449183 29479 solver.cpp:214] Iteration 320, loss = 17094.3
I0314 15:46:07.449246 29479 solver.cpp:229]     Train net output #0: loss = 18411.1 (* 1 = 18411.1 loss)
I0314 15:46:07.564237 29479 solver.cpp:610] Iteration 320, lr = 9.9856e-09
I0314 15:46:07.564249 29479 solver.cpp:613] Iteration 320, avg_grad_norm = 1.40852e+06
I0314 15:46:33.136631 29479 solver.cpp:214] Iteration 340, loss = 16712.1
I0314 15:46:33.136772 29479 solver.cpp:229]     Train net output #0: loss = 20434 (* 1 = 20434 loss)
I0314 15:46:33.249680 29479 solver.cpp:610] Iteration 340, lr = 9.9847e-09
I0314 15:46:33.249693 29479 solver.cpp:613] Iteration 340, avg_grad_norm = 1.22274e+06
I0314 15:46:58.500062 29479 solver.cpp:214] Iteration 360, loss = 16584.7
I0314 15:46:58.500128 29479 solver.cpp:229]     Train net output #0: loss = 18942.8 (* 1 = 18942.8 loss)
I0314 15:46:58.613293 29479 solver.cpp:610] Iteration 360, lr = 9.9838e-09
I0314 15:46:58.613306 29479 solver.cpp:613] Iteration 360, avg_grad_norm = 1.29454e+06
I0314 15:47:23.844485 29479 solver.cpp:214] Iteration 380, loss = 15903.3
I0314 15:47:23.844607 29479 solver.cpp:229]     Train net output #0: loss = 11411 (* 1 = 11411 loss)
I0314 15:47:23.957509 29479 solver.cpp:610] Iteration 380, lr = 9.9829e-09
I0314 15:47:23.957520 29479 solver.cpp:613] Iteration 380, avg_grad_norm = 1.27063e+06
I0314 15:48:04.000681 29479 solver.cpp:214] Iteration 400, loss = 16076.8
I0314 15:48:04.000771 29479 solver.cpp:229]     Train net output #0: loss = 21136.9 (* 1 = 21136.9 loss)
I0314 15:48:04.105926 29479 solver.cpp:610] Iteration 400, lr = 9.982e-09
I0314 15:48:04.105939 29479 solver.cpp:613] Iteration 400, avg_grad_norm = 1.44715e+06
I0314 15:48:28.190992 29479 solver.cpp:214] Iteration 420, loss = 15583.8
I0314 15:48:28.191061 29479 solver.cpp:229]     Train net output #0: loss = 16250.7 (* 1 = 16250.7 loss)
I0314 15:48:28.304152 29479 solver.cpp:610] Iteration 420, lr = 9.9811e-09
I0314 15:48:28.304167 29479 solver.cpp:613] Iteration 420, avg_grad_norm = 1.31968e+06
I0314 15:48:53.750084 29479 solver.cpp:214] Iteration 440, loss = 15813.3
I0314 15:48:53.750304 29479 solver.cpp:229]     Train net output #0: loss = 17099.3 (* 1 = 17099.3 loss)
I0314 15:48:53.864699 29479 solver.cpp:610] Iteration 440, lr = 9.9802e-09
I0314 15:48:53.864712 29479 solver.cpp:613] Iteration 440, avg_grad_norm = 1.65338e+06
I0314 15:49:19.458156 29479 solver.cpp:214] Iteration 460, loss = 15534.1
I0314 15:49:19.458219 29479 solver.cpp:229]     Train net output #0: loss = 10943.1 (* 1 = 10943.1 loss)
I0314 15:49:19.572842 29479 solver.cpp:610] Iteration 460, lr = 9.9793e-09
I0314 15:49:19.572855 29479 solver.cpp:613] Iteration 460, avg_grad_norm = 1.44548e+06
I0314 15:49:45.120139 29479 solver.cpp:214] Iteration 480, loss = 15349.5
I0314 15:49:45.120290 29479 solver.cpp:229]     Train net output #0: loss = 26378.8 (* 1 = 26378.8 loss)
I0314 15:49:45.233196 29479 solver.cpp:610] Iteration 480, lr = 9.9784e-09
I0314 15:49:45.233208 29479 solver.cpp:613] Iteration 480, avg_grad_norm = 1.3108e+06
I0314 15:50:10.480612 29479 solver.cpp:214] Iteration 500, loss = 14980.4
I0314 15:50:10.480666 29479 solver.cpp:229]     Train net output #0: loss = 25360.8 (* 1 = 25360.8 loss)
I0314 15:50:10.593617 29479 solver.cpp:610] Iteration 500, lr = 9.9775e-09
I0314 15:50:10.593629 29479 solver.cpp:613] Iteration 500, avg_grad_norm = 1.07505e+06
I0314 15:50:48.603487 29479 solver.cpp:214] Iteration 520, loss = 14801.5
I0314 15:50:48.603631 29479 solver.cpp:229]     Train net output #0: loss = 21357.6 (* 1 = 21357.6 loss)
I0314 15:50:48.708763 29479 solver.cpp:610] Iteration 520, lr = 9.9766e-09
I0314 15:50:48.708778 29479 solver.cpp:613] Iteration 520, avg_grad_norm = 1.20103e+06
I0314 15:51:12.558809 29479 solver.cpp:214] Iteration 540, loss = 15007.7
I0314 15:51:12.558864 29479 solver.cpp:229]     Train net output #0: loss = 15702.4 (* 1 = 15702.4 loss)
I0314 15:51:12.671859 29479 solver.cpp:610] Iteration 540, lr = 9.9757e-09
I0314 15:51:12.671892 29479 solver.cpp:613] Iteration 540, avg_grad_norm = 1.42773e+06
I0314 15:51:38.223603 29479 solver.cpp:214] Iteration 560, loss = 14516
I0314 15:51:38.223706 29479 solver.cpp:229]     Train net output #0: loss = 19984.1 (* 1 = 19984.1 loss)
I0314 15:51:38.338129 29479 solver.cpp:610] Iteration 560, lr = 9.9748e-09
I0314 15:51:38.338142 29479 solver.cpp:613] Iteration 560, avg_grad_norm = 1.35831e+06
I0314 15:52:03.894958 29479 solver.cpp:214] Iteration 580, loss = 14156.5
I0314 15:52:03.895022 29479 solver.cpp:229]     Train net output #0: loss = 16366.8 (* 1 = 16366.8 loss)
I0314 15:52:04.007946 29479 solver.cpp:610] Iteration 580, lr = 9.9739e-09
I0314 15:52:04.007958 29479 solver.cpp:613] Iteration 580, avg_grad_norm = 1.13685e+06
I0314 15:52:29.214959 29479 solver.cpp:214] Iteration 600, loss = 13956.2
I0314 15:52:29.215057 29479 solver.cpp:229]     Train net output #0: loss = 10378.8 (* 1 = 10378.8 loss)
I0314 15:52:29.327927 29479 solver.cpp:610] Iteration 600, lr = 9.973e-09
I0314 15:52:29.327940 29479 solver.cpp:613] Iteration 600, avg_grad_norm = 998888
I0314 15:52:54.818675 29479 solver.cpp:214] Iteration 620, loss = 13651
I0314 15:52:54.818733 29479 solver.cpp:229]     Train net output #0: loss = 10840 (* 1 = 10840 loss)
I0314 15:52:54.933459 29479 solver.cpp:610] Iteration 620, lr = 9.9721e-09
I0314 15:52:54.933470 29479 solver.cpp:613] Iteration 620, avg_grad_norm = 940890
I0314 15:53:35.031316 29479 solver.cpp:214] Iteration 640, loss = 14034.9
I0314 15:53:35.031415 29479 solver.cpp:229]     Train net output #0: loss = 12903.8 (* 1 = 12903.8 loss)
I0314 15:53:35.136513 29479 solver.cpp:610] Iteration 640, lr = 9.9712e-09
I0314 15:53:35.136525 29479 solver.cpp:613] Iteration 640, avg_grad_norm = 1.17388e+06
I0314 15:53:58.582474 29479 solver.cpp:214] Iteration 660, loss = 14165.7
I0314 15:53:58.582530 29479 solver.cpp:229]     Train net output #0: loss = 5770.09 (* 1 = 5770.09 loss)
I0314 15:53:58.687795 29479 solver.cpp:610] Iteration 660, lr = 9.97029e-09
I0314 15:53:58.687808 29479 solver.cpp:613] Iteration 660, avg_grad_norm = 1.21942e+06
I0314 15:54:23.559492 29479 solver.cpp:214] Iteration 680, loss = 13754
I0314 15:54:23.559587 29479 solver.cpp:229]     Train net output #0: loss = 16748.8 (* 1 = 16748.8 loss)
I0314 15:54:23.674257 29479 solver.cpp:610] Iteration 680, lr = 9.96939e-09
I0314 15:54:23.674269 29479 solver.cpp:613] Iteration 680, avg_grad_norm = 1.11153e+06
I0314 15:54:49.227244 29479 solver.cpp:214] Iteration 700, loss = 14076.5
I0314 15:54:49.227310 29479 solver.cpp:229]     Train net output #0: loss = 15543.9 (* 1 = 15543.9 loss)
I0314 15:54:49.341917 29479 solver.cpp:610] Iteration 700, lr = 9.96849e-09
I0314 15:54:49.341930 29479 solver.cpp:613] Iteration 700, avg_grad_norm = 1.43949e+06
I0314 15:55:14.916008 29479 solver.cpp:214] Iteration 720, loss = 13560.6
I0314 15:55:14.916193 29479 solver.cpp:229]     Train net output #0: loss = 14086.2 (* 1 = 14086.2 loss)
I0314 15:55:15.030699 29479 solver.cpp:610] Iteration 720, lr = 9.96759e-09
I0314 15:55:15.030712 29479 solver.cpp:613] Iteration 720, avg_grad_norm = 1.39762e+06
I0314 15:55:40.280143 29479 solver.cpp:214] Iteration 740, loss = 13495
I0314 15:55:40.280185 29479 solver.cpp:229]     Train net output #0: loss = 12108.5 (* 1 = 12108.5 loss)
I0314 15:55:40.393074 29479 solver.cpp:610] Iteration 740, lr = 9.96669e-09
I0314 15:55:40.393086 29479 solver.cpp:613] Iteration 740, avg_grad_norm = 1.11914e+06
I0314 15:56:05.818306 29479 solver.cpp:214] Iteration 760, loss = 13093.9
I0314 15:56:05.818398 29479 solver.cpp:229]     Train net output #0: loss = 15677.8 (* 1 = 15677.8 loss)
I0314 15:56:05.933118 29479 solver.cpp:610] Iteration 760, lr = 9.96579e-09
I0314 15:56:05.933131 29479 solver.cpp:613] Iteration 760, avg_grad_norm = 1.01779e+06
I0314 15:56:43.376001 29479 solver.cpp:214] Iteration 780, loss = 13023.5
I0314 15:56:43.376097 29479 solver.cpp:229]     Train net output #0: loss = 16460.9 (* 1 = 16460.9 loss)
I0314 15:56:43.481350 29479 solver.cpp:610] Iteration 780, lr = 9.96489e-09
I0314 15:56:43.481364 29479 solver.cpp:613] Iteration 780, avg_grad_norm = 1.10516e+06
I0314 15:57:07.923044 29479 solver.cpp:214] Iteration 800, loss = 13486.5
I0314 15:57:07.923102 29479 solver.cpp:229]     Train net output #0: loss = 14536.3 (* 1 = 14536.3 loss)
I0314 15:57:08.036204 29479 solver.cpp:610] Iteration 800, lr = 9.96399e-09
I0314 15:57:08.036217 29479 solver.cpp:613] Iteration 800, avg_grad_norm = 1.11881e+06
I0314 15:57:33.580358 29479 solver.cpp:214] Iteration 820, loss = 12867.3
I0314 15:57:33.580495 29479 solver.cpp:229]     Train net output #0: loss = 15961.5 (* 1 = 15961.5 loss)
I0314 15:57:33.695055 29479 solver.cpp:610] Iteration 820, lr = 9.96309e-09
I0314 15:57:33.695068 29479 solver.cpp:613] Iteration 820, avg_grad_norm = 1.17828e+06
I0314 15:57:59.259325 29479 solver.cpp:214] Iteration 840, loss = 12525.8
I0314 15:57:59.259366 29479 solver.cpp:229]     Train net output #0: loss = 14722.3 (* 1 = 14722.3 loss)
I0314 15:57:59.373973 29479 solver.cpp:610] Iteration 840, lr = 9.96219e-09
I0314 15:57:59.373986 29479 solver.cpp:613] Iteration 840, avg_grad_norm = 1.26635e+06
I0314 15:58:24.671766 29479 solver.cpp:214] Iteration 860, loss = 12954.1
I0314 15:58:24.671862 29479 solver.cpp:229]     Train net output #0: loss = 15300.7 (* 1 = 15300.7 loss)
I0314 15:58:24.784710 29479 solver.cpp:610] Iteration 860, lr = 9.96129e-09
I0314 15:58:24.784737 29479 solver.cpp:613] Iteration 860, avg_grad_norm = 1.43816e+06
I0314 15:58:49.998556 29479 solver.cpp:214] Iteration 880, loss = 13016.6
I0314 15:58:49.998615 29479 solver.cpp:229]     Train net output #0: loss = 18893.1 (* 1 = 18893.1 loss)
I0314 15:58:50.111644 29479 solver.cpp:610] Iteration 880, lr = 9.96039e-09
I0314 15:58:50.111655 29479 solver.cpp:613] Iteration 880, avg_grad_norm = 1.32199e+06
I0314 15:59:34.085904 29479 solver.cpp:214] Iteration 900, loss = 12879
I0314 15:59:34.086031 29479 solver.cpp:229]     Train net output #0: loss = 22215.5 (* 1 = 22215.5 loss)
I0314 15:59:34.191220 29479 solver.cpp:610] Iteration 900, lr = 9.95949e-09
I0314 15:59:34.191233 29479 solver.cpp:613] Iteration 900, avg_grad_norm = 1.08435e+06
I0314 15:59:57.662467 29479 solver.cpp:214] Iteration 920, loss = 12710.6
I0314 15:59:57.662524 29479 solver.cpp:229]     Train net output #0: loss = 19312.3 (* 1 = 19312.3 loss)
I0314 15:59:57.767771 29479 solver.cpp:610] Iteration 920, lr = 9.95859e-09
I0314 15:59:57.767787 29479 solver.cpp:613] Iteration 920, avg_grad_norm = 1.01859e+06
I0314 16:00:22.519861 29479 solver.cpp:214] Iteration 940, loss = 12737.2
I0314 16:00:22.519954 29479 solver.cpp:229]     Train net output #0: loss = 10080.9 (* 1 = 10080.9 loss)
I0314 16:00:22.634474 29479 solver.cpp:610] Iteration 940, lr = 9.95769e-09
I0314 16:00:22.634486 29479 solver.cpp:613] Iteration 940, avg_grad_norm = 1.04157e+06
I0314 16:00:48.202854 29479 solver.cpp:214] Iteration 960, loss = 12475.5
I0314 16:00:48.202921 29479 solver.cpp:229]     Train net output #0: loss = 13114.2 (* 1 = 13114.2 loss)
I0314 16:00:48.317497 29479 solver.cpp:610] Iteration 960, lr = 9.95679e-09
I0314 16:00:48.317509 29479 solver.cpp:613] Iteration 960, avg_grad_norm = 973024
I0314 16:01:13.893134 29479 solver.cpp:214] Iteration 980, loss = 12990.6
I0314 16:01:13.893381 29479 solver.cpp:229]     Train net output #0: loss = 11232.6 (* 1 = 11232.6 loss)
I0314 16:01:14.007779 29479 solver.cpp:610] Iteration 980, lr = 9.95589e-09
I0314 16:01:14.007798 29479 solver.cpp:613] Iteration 980, avg_grad_norm = 1.14712e+06
I0314 16:01:39.280416 29479 solver.cpp:214] Iteration 1000, loss = 12374.5
I0314 16:01:39.280478 29479 solver.cpp:229]     Train net output #0: loss = 8748.53 (* 1 = 8748.53 loss)
I0314 16:01:39.393705 29479 solver.cpp:610] Iteration 1000, lr = 9.95499e-09
I0314 16:01:39.393719 29479 solver.cpp:613] Iteration 1000, avg_grad_norm = 1.18005e+06
I0314 16:02:38.203629 29479 solver.cpp:214] Iteration 1020, loss = 12520
I0314 16:02:38.203759 29479 solver.cpp:229]     Train net output #0: loss = 14556.7 (* 1 = 14556.7 loss)
I0314 16:02:38.308079 29479 solver.cpp:610] Iteration 1020, lr = 9.95409e-09
I0314 16:02:38.308092 29479 solver.cpp:613] Iteration 1020, avg_grad_norm = 1.16578e+06
I0314 16:03:01.714460 29479 solver.cpp:214] Iteration 1040, loss = 12425.3
I0314 16:03:01.714520 29479 solver.cpp:229]     Train net output #0: loss = 9722.29 (* 1 = 9722.29 loss)
I0314 16:03:01.819754 29479 solver.cpp:610] Iteration 1040, lr = 9.95319e-09
I0314 16:03:01.819766 29479 solver.cpp:613] Iteration 1040, avg_grad_norm = 1.25077e+06
I0314 16:03:25.267892 29479 solver.cpp:214] Iteration 1060, loss = 12335.9
I0314 16:03:25.268024 29479 solver.cpp:229]     Train net output #0: loss = 11714.9 (* 1 = 11714.9 loss)
I0314 16:03:25.373313 29479 solver.cpp:610] Iteration 1060, lr = 9.95229e-09
I0314 16:03:25.373327 29479 solver.cpp:613] Iteration 1060, avg_grad_norm = 1.08023e+06
I0314 16:03:49.426316 29479 solver.cpp:214] Iteration 1080, loss = 12373.5
I0314 16:03:49.426383 29479 solver.cpp:229]     Train net output #0: loss = 11583.2 (* 1 = 11583.2 loss)
I0314 16:03:49.538055 29479 solver.cpp:610] Iteration 1080, lr = 9.95139e-09
I0314 16:03:49.538069 29479 solver.cpp:613] Iteration 1080, avg_grad_norm = 993324
I0314 16:04:14.711120 29479 solver.cpp:214] Iteration 1100, loss = 12682.3
I0314 16:04:14.711205 29479 solver.cpp:229]     Train net output #0: loss = 12948.8 (* 1 = 12948.8 loss)
I0314 16:04:14.824481 29479 solver.cpp:610] Iteration 1100, lr = 9.95049e-09
I0314 16:04:14.824494 29479 solver.cpp:613] Iteration 1100, avg_grad_norm = 1.17097e+06
I0314 16:04:40.079593 29479 solver.cpp:214] Iteration 1120, loss = 11729.7
I0314 16:04:40.079659 29479 solver.cpp:229]     Train net output #0: loss = 14970.6 (* 1 = 14970.6 loss)
I0314 16:04:40.194272 29479 solver.cpp:610] Iteration 1120, lr = 9.94959e-09
I0314 16:04:40.194285 29479 solver.cpp:613] Iteration 1120, avg_grad_norm = 1.09546e+06
I0314 16:05:05.782888 29479 solver.cpp:214] Iteration 1140, loss = 11713.3
I0314 16:05:05.783021 29479 solver.cpp:229]     Train net output #0: loss = 10887.5 (* 1 = 10887.5 loss)
I0314 16:05:05.897717 29479 solver.cpp:610] Iteration 1140, lr = 9.94869e-09
I0314 16:05:05.897730 29479 solver.cpp:613] Iteration 1140, avg_grad_norm = 913778
I0314 16:05:43.513567 29479 solver.cpp:214] Iteration 1160, loss = 11810.2
I0314 16:05:43.513690 29479 solver.cpp:229]     Train net output #0: loss = 10995.4 (* 1 = 10995.4 loss)
I0314 16:05:43.618826 29479 solver.cpp:610] Iteration 1160, lr = 9.94778e-09
I0314 16:05:43.618839 29479 solver.cpp:613] Iteration 1160, avg_grad_norm = 931667
I0314 16:06:07.726740 29479 solver.cpp:214] Iteration 1180, loss = 12315.2
I0314 16:06:07.726788 29479 solver.cpp:229]     Train net output #0: loss = 19527.7 (* 1 = 19527.7 loss)
I0314 16:06:07.838371 29479 solver.cpp:610] Iteration 1180, lr = 9.94688e-09
I0314 16:06:07.838383 29479 solver.cpp:613] Iteration 1180, avg_grad_norm = 1.12467e+06
I0314 16:06:33.202869 29479 solver.cpp:214] Iteration 1200, loss = 11901.1
I0314 16:06:33.203095 29479 solver.cpp:229]     Train net output #0: loss = 13328.3 (* 1 = 13328.3 loss)
I0314 16:06:33.317939 29479 solver.cpp:610] Iteration 1200, lr = 9.94598e-09
I0314 16:06:33.317951 29479 solver.cpp:613] Iteration 1200, avg_grad_norm = 1.08432e+06
I0314 16:06:58.869588 29479 solver.cpp:214] Iteration 1220, loss = 11518.5
I0314 16:06:58.869644 29479 solver.cpp:229]     Train net output #0: loss = 12097.8 (* 1 = 12097.8 loss)
I0314 16:06:58.984225 29479 solver.cpp:610] Iteration 1220, lr = 9.94508e-09
I0314 16:06:58.984238 29479 solver.cpp:613] Iteration 1220, avg_grad_norm = 1.1383e+06
I0314 16:07:24.143990 29479 solver.cpp:214] Iteration 1240, loss = 12008.2
I0314 16:07:24.144125 29479 solver.cpp:229]     Train net output #0: loss = 15276.6 (* 1 = 15276.6 loss)
I0314 16:07:24.254304 29479 solver.cpp:610] Iteration 1240, lr = 9.94418e-09
I0314 16:07:24.254317 29479 solver.cpp:613] Iteration 1240, avg_grad_norm = 965015
I0314 16:07:49.652789 29479 solver.cpp:214] Iteration 1260, loss = 11708
I0314 16:07:49.652847 29479 solver.cpp:229]     Train net output #0: loss = 14047.6 (* 1 = 14047.6 loss)
I0314 16:07:49.767477 29479 solver.cpp:610] Iteration 1260, lr = 9.94328e-09
I0314 16:07:49.767488 29479 solver.cpp:613] Iteration 1260, avg_grad_norm = 911678
I0314 16:08:28.018013 29479 solver.cpp:214] Iteration 1280, loss = 11736
I0314 16:08:28.018118 29479 solver.cpp:229]     Train net output #0: loss = 14969 (* 1 = 14969 loss)
I0314 16:08:28.123224 29479 solver.cpp:610] Iteration 1280, lr = 9.94238e-09
I0314 16:08:28.123237 29479 solver.cpp:613] Iteration 1280, avg_grad_norm = 1.09833e+06
I0314 16:08:51.773568 29479 solver.cpp:214] Iteration 1300, loss = 11866.2
I0314 16:08:51.773623 29479 solver.cpp:229]     Train net output #0: loss = 10362.2 (* 1 = 10362.2 loss)
I0314 16:08:51.888221 29479 solver.cpp:610] Iteration 1300, lr = 9.94148e-09
I0314 16:08:51.888233 29479 solver.cpp:613] Iteration 1300, avg_grad_norm = 1.19689e+06
I0314 16:09:17.432988 29479 solver.cpp:214] Iteration 1320, loss = 11406
I0314 16:09:17.433109 29479 solver.cpp:229]     Train net output #0: loss = 12148.1 (* 1 = 12148.1 loss)
I0314 16:09:17.547729 29479 solver.cpp:610] Iteration 1320, lr = 9.94058e-09
I0314 16:09:17.547742 29479 solver.cpp:613] Iteration 1320, avg_grad_norm = 1.02342e+06
I0314 16:09:42.898211 29479 solver.cpp:214] Iteration 1340, loss = 11949.3
I0314 16:09:42.898268 29479 solver.cpp:229]     Train net output #0: loss = 9212.14 (* 1 = 9212.14 loss)
I0314 16:09:43.011230 29479 solver.cpp:610] Iteration 1340, lr = 9.93968e-09
I0314 16:09:43.011243 29479 solver.cpp:613] Iteration 1340, avg_grad_norm = 915180
I0314 16:10:08.217386 29479 solver.cpp:214] Iteration 1360, loss = 11282.7
I0314 16:10:08.217479 29479 solver.cpp:229]     Train net output #0: loss = 15316.6 (* 1 = 15316.6 loss)
I0314 16:10:08.330451 29479 solver.cpp:610] Iteration 1360, lr = 9.93878e-09
I0314 16:10:08.330463 29479 solver.cpp:613] Iteration 1360, avg_grad_norm = 986900
I0314 16:10:33.793905 29479 solver.cpp:214] Iteration 1380, loss = 11495
I0314 16:10:33.793951 29479 solver.cpp:229]     Train net output #0: loss = 11090 (* 1 = 11090 loss)
I0314 16:10:33.908617 29479 solver.cpp:610] Iteration 1380, lr = 9.93788e-09
I0314 16:10:33.908628 29479 solver.cpp:613] Iteration 1380, avg_grad_norm = 875308
I0314 16:11:13.162768 29479 solver.cpp:214] Iteration 1400, loss = 11194.7
I0314 16:11:13.162894 29479 solver.cpp:229]     Train net output #0: loss = 10974.1 (* 1 = 10974.1 loss)
I0314 16:11:13.267344 29479 solver.cpp:610] Iteration 1400, lr = 9.93698e-09
I0314 16:11:13.267356 29479 solver.cpp:613] Iteration 1400, avg_grad_norm = 1.08794e+06
I0314 16:11:36.725015 29479 solver.cpp:214] Iteration 1420, loss = 11692.2
I0314 16:11:36.725074 29479 solver.cpp:229]     Train net output #0: loss = 12050.6 (* 1 = 12050.6 loss)
I0314 16:11:36.830291 29479 solver.cpp:610] Iteration 1420, lr = 9.93608e-09
I0314 16:11:36.830304 29479 solver.cpp:613] Iteration 1420, avg_grad_norm = 1.00583e+06
I0314 16:12:01.779574 29479 solver.cpp:214] Iteration 1440, loss = 11763
I0314 16:12:01.779801 29479 solver.cpp:229]     Train net output #0: loss = 10501.5 (* 1 = 10501.5 loss)
I0314 16:12:01.894340 29479 solver.cpp:610] Iteration 1440, lr = 9.93518e-09
I0314 16:12:01.894352 29479 solver.cpp:613] Iteration 1440, avg_grad_norm = 951677
I0314 16:12:27.439550 29479 solver.cpp:214] Iteration 1460, loss = 11128.4
I0314 16:12:27.439611 29479 solver.cpp:229]     Train net output #0: loss = 11073.9 (* 1 = 11073.9 loss)
I0314 16:12:27.554193 29479 solver.cpp:610] Iteration 1460, lr = 9.93428e-09
I0314 16:12:27.554204 29479 solver.cpp:613] Iteration 1460, avg_grad_norm = 989386
I0314 16:12:53.005667 29479 solver.cpp:214] Iteration 1480, loss = 11126
I0314 16:12:53.005769 29479 solver.cpp:229]     Train net output #0: loss = 10360.9 (* 1 = 10360.9 loss)
I0314 16:12:53.118752 29479 solver.cpp:610] Iteration 1480, lr = 9.93338e-09
I0314 16:12:53.118764 29479 solver.cpp:613] Iteration 1480, avg_grad_norm = 1.13204e+06
I0314 16:13:18.317646 29479 solver.cpp:214] Iteration 1500, loss = 11849.3
I0314 16:13:18.317706 29479 solver.cpp:229]     Train net output #0: loss = 5598.07 (* 1 = 5598.07 loss)
I0314 16:13:18.430490 29479 solver.cpp:610] Iteration 1500, lr = 9.93247e-09
I0314 16:13:18.430503 29479 solver.cpp:613] Iteration 1500, avg_grad_norm = 1.19245e+06
I0314 16:13:43.966053 29479 solver.cpp:214] Iteration 1520, loss = 11330.6
I0314 16:13:43.966202 29479 solver.cpp:229]     Train net output #0: loss = 11025.9 (* 1 = 11025.9 loss)
I0314 16:13:44.082069 29479 solver.cpp:610] Iteration 1520, lr = 9.93157e-09
I0314 16:13:44.082084 29479 solver.cpp:613] Iteration 1520, avg_grad_norm = 911884
I0314 16:14:29.005345 29479 solver.cpp:214] Iteration 1540, loss = 11436.6
I0314 16:14:29.005450 29479 solver.cpp:229]     Train net output #0: loss = 8179.9 (* 1 = 8179.9 loss)
I0314 16:14:29.109645 29479 solver.cpp:610] Iteration 1540, lr = 9.93067e-09
I0314 16:14:29.109658 29479 solver.cpp:613] Iteration 1540, avg_grad_norm = 985984
I0314 16:14:52.578183 29479 solver.cpp:214] Iteration 1560, loss = 11694.2
I0314 16:14:52.578229 29479 solver.cpp:229]     Train net output #0: loss = 6869.84 (* 1 = 6869.84 loss)
I0314 16:14:52.683828 29479 solver.cpp:610] Iteration 1560, lr = 9.92977e-09
I0314 16:14:52.683841 29479 solver.cpp:613] Iteration 1560, avg_grad_norm = 1.25761e+06
I0314 16:15:17.861788 29479 solver.cpp:214] Iteration 1580, loss = 11226.6
I0314 16:15:17.861939 29479 solver.cpp:229]     Train net output #0: loss = 12035 (* 1 = 12035 loss)
I0314 16:15:17.976174 29479 solver.cpp:610] Iteration 1580, lr = 9.92887e-09
I0314 16:15:17.976187 29479 solver.cpp:613] Iteration 1580, avg_grad_norm = 984636
I0314 16:15:43.398643 29479 solver.cpp:214] Iteration 1600, loss = 11244
I0314 16:15:43.398699 29479 solver.cpp:229]     Train net output #0: loss = 12723.7 (* 1 = 12723.7 loss)
I0314 16:15:43.512032 29479 solver.cpp:610] Iteration 1600, lr = 9.92797e-09
I0314 16:15:43.512045 29479 solver.cpp:613] Iteration 1600, avg_grad_norm = 930491
I0314 16:16:08.724210 29479 solver.cpp:214] Iteration 1620, loss = 10971.1
I0314 16:16:08.724385 29479 solver.cpp:229]     Train net output #0: loss = 8818.6 (* 1 = 8818.6 loss)
I0314 16:16:08.837143 29479 solver.cpp:610] Iteration 1620, lr = 9.92707e-09
I0314 16:16:08.837157 29479 solver.cpp:613] Iteration 1620, avg_grad_norm = 863451
I0314 16:16:34.278741 29479 solver.cpp:214] Iteration 1640, loss = 10914.3
I0314 16:16:34.278813 29479 solver.cpp:229]     Train net output #0: loss = 7879.99 (* 1 = 7879.99 loss)
I0314 16:16:34.393348 29479 solver.cpp:610] Iteration 1640, lr = 9.92617e-09
I0314 16:16:34.393362 29479 solver.cpp:613] Iteration 1640, avg_grad_norm = 927586
I0314 16:17:20.417984 29479 solver.cpp:214] Iteration 1660, loss = 11224.3
I0314 16:17:20.418112 29479 solver.cpp:229]     Train net output #0: loss = 15294.6 (* 1 = 15294.6 loss)
I0314 16:17:20.523313 29479 solver.cpp:610] Iteration 1660, lr = 9.92527e-09
I0314 16:17:20.523326 29479 solver.cpp:613] Iteration 1660, avg_grad_norm = 849350
I0314 16:17:43.975056 29479 solver.cpp:214] Iteration 1680, loss = 11121.5
I0314 16:17:43.975116 29479 solver.cpp:229]     Train net output #0: loss = 14116 (* 1 = 14116 loss)
I0314 16:17:44.080364 29479 solver.cpp:610] Iteration 1680, lr = 9.92437e-09
I0314 16:17:44.080377 29479 solver.cpp:613] Iteration 1680, avg_grad_norm = 940950
I0314 16:18:08.697227 29479 solver.cpp:214] Iteration 1700, loss = 11045.4
I0314 16:18:08.697479 29479 solver.cpp:229]     Train net output #0: loss = 11981.4 (* 1 = 11981.4 loss)
I0314 16:18:08.812006 29479 solver.cpp:610] Iteration 1700, lr = 9.92347e-09
I0314 16:18:08.812019 29479 solver.cpp:613] Iteration 1700, avg_grad_norm = 945787
I0314 16:18:34.359304 29479 solver.cpp:214] Iteration 1720, loss = 11200.4
I0314 16:18:34.359369 29479 solver.cpp:229]     Train net output #0: loss = 10780.3 (* 1 = 10780.3 loss)
I0314 16:18:34.472323 29479 solver.cpp:610] Iteration 1720, lr = 9.92257e-09
I0314 16:18:34.472338 29479 solver.cpp:613] Iteration 1720, avg_grad_norm = 960593
I0314 16:18:59.680150 29479 solver.cpp:214] Iteration 1740, loss = 11417.9
I0314 16:18:59.680305 29479 solver.cpp:229]     Train net output #0: loss = 10864.5 (* 1 = 10864.5 loss)
I0314 16:18:59.793258 29479 solver.cpp:610] Iteration 1740, lr = 9.92167e-09
I0314 16:18:59.793272 29479 solver.cpp:613] Iteration 1740, avg_grad_norm = 1.08701e+06
I0314 16:19:25.010352 29479 solver.cpp:214] Iteration 1760, loss = 10891.6
I0314 16:19:25.010412 29479 solver.cpp:229]     Train net output #0: loss = 12006.8 (* 1 = 12006.8 loss)
I0314 16:19:25.123291 29479 solver.cpp:610] Iteration 1760, lr = 9.92076e-09
I0314 16:19:25.123304 29479 solver.cpp:613] Iteration 1760, avg_grad_norm = 958808
I0314 16:20:05.697088 29479 solver.cpp:214] Iteration 1780, loss = 11175.9
I0314 16:20:05.697221 29479 solver.cpp:229]     Train net output #0: loss = 10470.1 (* 1 = 10470.1 loss)
I0314 16:20:05.802381 29479 solver.cpp:610] Iteration 1780, lr = 9.91986e-09
I0314 16:20:05.802394 29479 solver.cpp:613] Iteration 1780, avg_grad_norm = 880272
I0314 16:20:29.246263 29479 solver.cpp:214] Iteration 1800, loss = 10946.2
I0314 16:20:29.246325 29479 solver.cpp:229]     Train net output #0: loss = 10203.1 (* 1 = 10203.1 loss)
I0314 16:20:29.351418 29479 solver.cpp:610] Iteration 1800, lr = 9.91896e-09
I0314 16:20:29.351431 29479 solver.cpp:613] Iteration 1800, avg_grad_norm = 1.17082e+06
I0314 16:20:53.825197 29479 solver.cpp:214] Iteration 1820, loss = 11074.8
I0314 16:20:53.825395 29479 solver.cpp:229]     Train net output #0: loss = 10468.8 (* 1 = 10468.8 loss)
I0314 16:20:53.939759 29479 solver.cpp:610] Iteration 1820, lr = 9.91806e-09
I0314 16:20:53.939772 29479 solver.cpp:613] Iteration 1820, avg_grad_norm = 1.10209e+06
I0314 16:21:19.484617 29479 solver.cpp:214] Iteration 1840, loss = 10880.8
I0314 16:21:19.484679 29479 solver.cpp:229]     Train net output #0: loss = 11752.9 (* 1 = 11752.9 loss)
I0314 16:21:19.599180 29479 solver.cpp:610] Iteration 1840, lr = 9.91716e-09
I0314 16:21:19.599194 29479 solver.cpp:613] Iteration 1840, avg_grad_norm = 1.12835e+06
I0314 16:21:44.838068 29479 solver.cpp:214] Iteration 1860, loss = 11230
I0314 16:21:44.838193 29479 solver.cpp:229]     Train net output #0: loss = 15558 (* 1 = 15558 loss)
I0314 16:21:44.950891 29479 solver.cpp:610] Iteration 1860, lr = 9.91626e-09
I0314 16:21:44.950903 29479 solver.cpp:613] Iteration 1860, avg_grad_norm = 1.25494e+06
I0314 16:22:10.165333 29479 solver.cpp:214] Iteration 1880, loss = 11124.2
I0314 16:22:10.165392 29479 solver.cpp:229]     Train net output #0: loss = 11850.7 (* 1 = 11850.7 loss)
I0314 16:22:10.278455 29479 solver.cpp:610] Iteration 1880, lr = 9.91536e-09
I0314 16:22:10.278467 29479 solver.cpp:613] Iteration 1880, avg_grad_norm = 1.05558e+06
I0314 16:22:35.484951 29479 solver.cpp:214] Iteration 1900, loss = 10613.5
I0314 16:22:35.485170 29479 solver.cpp:229]     Train net output #0: loss = 16112.3 (* 1 = 16112.3 loss)
I0314 16:22:35.597861 29479 solver.cpp:610] Iteration 1900, lr = 9.91446e-09
I0314 16:22:35.597883 29479 solver.cpp:613] Iteration 1900, avg_grad_norm = 984887
I0314 16:23:21.470330 29479 solver.cpp:214] Iteration 1920, loss = 10816.6
I0314 16:23:21.470475 29479 solver.cpp:229]     Train net output #0: loss = 10160.3 (* 1 = 10160.3 loss)
I0314 16:23:21.575559 29479 solver.cpp:610] Iteration 1920, lr = 9.91356e-09
I0314 16:23:21.575572 29479 solver.cpp:613] Iteration 1920, avg_grad_norm = 1.27974e+06
I0314 16:23:45.010021 29479 solver.cpp:214] Iteration 1940, loss = 10514.4
I0314 16:23:45.010088 29479 solver.cpp:229]     Train net output #0: loss = 8136.96 (* 1 = 8136.96 loss)
I0314 16:23:45.115186 29479 solver.cpp:610] Iteration 1940, lr = 9.91266e-09
I0314 16:23:45.115200 29479 solver.cpp:613] Iteration 1940, avg_grad_norm = 917584
I0314 16:24:10.148567 29479 solver.cpp:214] Iteration 1960, loss = 10720.5
I0314 16:24:10.148705 29479 solver.cpp:229]     Train net output #0: loss = 8530.14 (* 1 = 8530.14 loss)
I0314 16:24:10.263211 29479 solver.cpp:610] Iteration 1960, lr = 9.91176e-09
I0314 16:24:10.263223 29479 solver.cpp:613] Iteration 1960, avg_grad_norm = 843105
I0314 16:24:35.499117 29479 solver.cpp:214] Iteration 1980, loss = 10919.6
I0314 16:24:35.499178 29479 solver.cpp:229]     Train net output #0: loss = 6244.24 (* 1 = 6244.24 loss)
I0314 16:24:35.612284 29479 solver.cpp:610] Iteration 1980, lr = 9.91086e-09
I0314 16:24:35.612298 29479 solver.cpp:613] Iteration 1980, avg_grad_norm = 774413
I0314 16:25:00.820425 29479 solver.cpp:214] Iteration 2000, loss = 10414.1
I0314 16:25:00.820530 29479 solver.cpp:229]     Train net output #0: loss = 8587.97 (* 1 = 8587.97 loss)
I0314 16:25:00.933411 29479 solver.cpp:610] Iteration 2000, lr = 9.90995e-09
I0314 16:25:00.933423 29479 solver.cpp:613] Iteration 2000, avg_grad_norm = 758116
I0314 16:25:26.148445 29479 solver.cpp:214] Iteration 2020, loss = 10821.2
I0314 16:25:26.148504 29479 solver.cpp:229]     Train net output #0: loss = 9399.89 (* 1 = 9399.89 loss)
I0314 16:25:26.261412 29479 solver.cpp:610] Iteration 2020, lr = 9.90905e-09
I0314 16:25:26.261425 29479 solver.cpp:613] Iteration 2020, avg_grad_norm = 879469
I0314 16:26:06.413830 29479 solver.cpp:214] Iteration 2040, loss = 10900.1
I0314 16:26:06.413944 29479 solver.cpp:229]     Train net output #0: loss = 16349.9 (* 1 = 16349.9 loss)
I0314 16:26:06.519114 29479 solver.cpp:610] Iteration 2040, lr = 9.90815e-09
I0314 16:26:06.519127 29479 solver.cpp:613] Iteration 2040, avg_grad_norm = 885063
I0314 16:26:29.939818 29479 solver.cpp:214] Iteration 2060, loss = 10123.1
I0314 16:26:29.939887 29479 solver.cpp:229]     Train net output #0: loss = 11479.3 (* 1 = 11479.3 loss)
I0314 16:26:30.044421 29479 solver.cpp:610] Iteration 2060, lr = 9.90725e-09
I0314 16:26:30.044435 29479 solver.cpp:613] Iteration 2060, avg_grad_norm = 775780
I0314 16:26:55.008435 29479 solver.cpp:214] Iteration 2080, loss = 10561.3
I0314 16:26:55.008651 29479 solver.cpp:229]     Train net output #0: loss = 6294.47 (* 1 = 6294.47 loss)
I0314 16:26:55.121466 29479 solver.cpp:610] Iteration 2080, lr = 9.90635e-09
I0314 16:26:55.121479 29479 solver.cpp:613] Iteration 2080, avg_grad_norm = 896556
I0314 16:27:20.294728 29479 solver.cpp:214] Iteration 2100, loss = 10870.4
I0314 16:27:20.294777 29479 solver.cpp:229]     Train net output #0: loss = 9125.41 (* 1 = 9125.41 loss)
I0314 16:27:20.407740 29479 solver.cpp:610] Iteration 2100, lr = 9.90545e-09
I0314 16:27:20.407753 29479 solver.cpp:613] Iteration 2100, avg_grad_norm = 1.11918e+06
I0314 16:27:45.589058 29479 solver.cpp:214] Iteration 2120, loss = 10826.9
I0314 16:27:45.589169 29479 solver.cpp:229]     Train net output #0: loss = 11771.7 (* 1 = 11771.7 loss)
I0314 16:27:45.702234 29479 solver.cpp:610] Iteration 2120, lr = 9.90455e-09
I0314 16:27:45.702247 29479 solver.cpp:613] Iteration 2120, avg_grad_norm = 798086
I0314 16:28:11.244536 29479 solver.cpp:214] Iteration 2140, loss = 10387.5
I0314 16:28:11.244597 29479 solver.cpp:229]     Train net output #0: loss = 10072 (* 1 = 10072 loss)
I0314 16:28:11.359091 29479 solver.cpp:610] Iteration 2140, lr = 9.90365e-09
I0314 16:28:11.359103 29479 solver.cpp:613] Iteration 2140, avg_grad_norm = 902573
I0314 16:28:53.842952 29479 solver.cpp:214] Iteration 2160, loss = 10450.5
I0314 16:28:53.843099 29479 solver.cpp:229]     Train net output #0: loss = 11827.8 (* 1 = 11827.8 loss)
I0314 16:28:53.946578 29479 solver.cpp:610] Iteration 2160, lr = 9.90275e-09
I0314 16:28:53.946590 29479 solver.cpp:613] Iteration 2160, avg_grad_norm = 907839
I0314 16:29:17.356987 29479 solver.cpp:214] Iteration 2180, loss = 10627.7
I0314 16:29:17.357048 29479 solver.cpp:229]     Train net output #0: loss = 7533.9 (* 1 = 7533.9 loss)
I0314 16:29:17.462306 29479 solver.cpp:610] Iteration 2180, lr = 9.90185e-09
I0314 16:29:17.462318 29479 solver.cpp:613] Iteration 2180, avg_grad_norm = 975722
I0314 16:29:41.611793 29479 solver.cpp:214] Iteration 2200, loss = 10034.9
I0314 16:29:41.611932 29479 solver.cpp:229]     Train net output #0: loss = 8934.04 (* 1 = 8934.04 loss)
I0314 16:29:41.726399 29479 solver.cpp:610] Iteration 2200, lr = 9.90095e-09
I0314 16:29:41.726413 29479 solver.cpp:613] Iteration 2200, avg_grad_norm = 786993
I0314 16:30:07.252300 29479 solver.cpp:214] Iteration 2220, loss = 10551
I0314 16:30:07.252390 29479 solver.cpp:229]     Train net output #0: loss = 5274.25 (* 1 = 5274.25 loss)
I0314 16:30:07.365118 29479 solver.cpp:610] Iteration 2220, lr = 9.90004e-09
I0314 16:30:07.365180 29479 solver.cpp:613] Iteration 2220, avg_grad_norm = 816352
I0314 16:30:37.285883 29479 solver.cpp:214] Iteration 2240, loss = 10408
I0314 16:30:37.286027 29479 solver.cpp:229]     Train net output #0: loss = 7053.49 (* 1 = 7053.49 loss)
I0314 16:30:37.472800 29479 solver.cpp:610] Iteration 2240, lr = 9.89914e-09
I0314 16:30:37.472815 29479 solver.cpp:613] Iteration 2240, avg_grad_norm = 981015
I0314 16:31:14.150785 29479 solver.cpp:214] Iteration 2260, loss = 10145.6
I0314 16:31:14.150912 29479 solver.cpp:229]     Train net output #0: loss = 9924.5 (* 1 = 9924.5 loss)
I0314 16:31:14.263669 29479 solver.cpp:610] Iteration 2260, lr = 9.89824e-09
I0314 16:31:14.263681 29479 solver.cpp:613] Iteration 2260, avg_grad_norm = 858668
I0314 16:31:39.786626 29479 solver.cpp:214] Iteration 2280, loss = 10547.5
I0314 16:31:39.786684 29479 solver.cpp:229]     Train net output #0: loss = 13327 (* 1 = 13327 loss)
I0314 16:31:39.901334 29479 solver.cpp:610] Iteration 2280, lr = 9.89734e-09
I0314 16:31:39.901346 29479 solver.cpp:613] Iteration 2280, avg_grad_norm = 868866
I0314 16:32:39.623388 29479 solver.cpp:214] Iteration 2300, loss = 10692.7
I0314 16:32:39.623510 29479 solver.cpp:229]     Train net output #0: loss = 6148.74 (* 1 = 6148.74 loss)
I0314 16:32:39.987448 29479 solver.cpp:610] Iteration 2300, lr = 9.89644e-09
I0314 16:32:39.987462 29479 solver.cpp:613] Iteration 2300, avg_grad_norm = 821381
I0314 16:33:41.994588 29479 solver.cpp:214] Iteration 2320, loss = 10384.1
I0314 16:33:41.994716 29479 solver.cpp:229]     Train net output #0: loss = 10146.8 (* 1 = 10146.8 loss)
I0314 16:33:42.382081 29479 solver.cpp:610] Iteration 2320, lr = 9.89554e-09
I0314 16:33:42.382094 29479 solver.cpp:613] Iteration 2320, avg_grad_norm = 802738
I0314 16:34:44.922078 29479 solver.cpp:214] Iteration 2340, loss = 10668.1
I0314 16:34:44.922279 29479 solver.cpp:229]     Train net output #0: loss = 11416.3 (* 1 = 11416.3 loss)
I0314 16:34:45.279500 29479 solver.cpp:610] Iteration 2340, lr = 9.89464e-09
I0314 16:34:45.279513 29479 solver.cpp:613] Iteration 2340, avg_grad_norm = 875951
I0314 16:35:48.203922 29479 solver.cpp:214] Iteration 2360, loss = 10361.7
I0314 16:35:48.204079 29479 solver.cpp:229]     Train net output #0: loss = 7735.24 (* 1 = 7735.24 loss)
I0314 16:35:48.562968 29479 solver.cpp:610] Iteration 2360, lr = 9.89374e-09
I0314 16:35:48.562986 29479 solver.cpp:613] Iteration 2360, avg_grad_norm = 882816
I0314 16:36:52.200826 29479 solver.cpp:214] Iteration 2380, loss = 10112.5
I0314 16:36:52.200942 29479 solver.cpp:229]     Train net output #0: loss = 10612.5 (* 1 = 10612.5 loss)
I0314 16:36:52.365236 29479 solver.cpp:610] Iteration 2380, lr = 9.89284e-09
I0314 16:36:52.365264 29479 solver.cpp:613] Iteration 2380, avg_grad_norm = 855396
I0314 16:37:55.258939 29479 solver.cpp:214] Iteration 2400, loss = 10507.9
I0314 16:37:55.259093 29479 solver.cpp:229]     Train net output #0: loss = 9171.07 (* 1 = 9171.07 loss)
I0314 16:37:55.616822 29479 solver.cpp:610] Iteration 2400, lr = 9.89193e-09
I0314 16:37:55.616837 29479 solver.cpp:613] Iteration 2400, avg_grad_norm = 1.04164e+06
I0314 16:39:14.735745 29479 solver.cpp:214] Iteration 2420, loss = 10110.4
I0314 16:39:14.735863 29479 solver.cpp:229]     Train net output #0: loss = 17032.7 (* 1 = 17032.7 loss)
I0314 16:39:15.094730 29479 solver.cpp:610] Iteration 2420, lr = 9.89103e-09
I0314 16:39:15.094744 29479 solver.cpp:613] Iteration 2420, avg_grad_norm = 1.15726e+06
I0314 16:39:57.896555 29479 solver.cpp:214] Iteration 2440, loss = 10313.4
I0314 16:39:57.896750 29479 solver.cpp:229]     Train net output #0: loss = 8445.2 (* 1 = 8445.2 loss)
I0314 16:39:58.011205 29479 solver.cpp:610] Iteration 2440, lr = 9.89013e-09
I0314 16:39:58.011255 29479 solver.cpp:613] Iteration 2440, avg_grad_norm = 1.13539e+06
I0314 16:40:56.324666 29479 solver.cpp:214] Iteration 2460, loss = 10416.3
I0314 16:40:56.324885 29479 solver.cpp:229]     Train net output #0: loss = 13495.4 (* 1 = 13495.4 loss)
I0314 16:40:56.537094 29479 solver.cpp:610] Iteration 2460, lr = 9.88923e-09
I0314 16:40:56.537108 29479 solver.cpp:613] Iteration 2460, avg_grad_norm = 868621
I0314 16:41:59.891135 29479 solver.cpp:214] Iteration 2480, loss = 10310.4
I0314 16:41:59.891266 29479 solver.cpp:229]     Train net output #0: loss = 10136.6 (* 1 = 10136.6 loss)
I0314 16:42:00.262833 29479 solver.cpp:610] Iteration 2480, lr = 9.88833e-09
I0314 16:42:00.262847 29479 solver.cpp:613] Iteration 2480, avg_grad_norm = 995581
I0314 16:43:03.568814 29479 solver.cpp:214] Iteration 2500, loss = 10006.4
I0314 16:43:03.568928 29479 solver.cpp:229]     Train net output #0: loss = 10250.3 (* 1 = 10250.3 loss)
I0314 16:43:03.928153 29479 solver.cpp:610] Iteration 2500, lr = 9.88743e-09
I0314 16:43:03.928167 29479 solver.cpp:613] Iteration 2500, avg_grad_norm = 880982
I0314 16:44:07.370795 29479 solver.cpp:214] Iteration 2520, loss = 9963.67
I0314 16:44:07.371009 29479 solver.cpp:229]     Train net output #0: loss = 10326.7 (* 1 = 10326.7 loss)
I0314 16:44:07.733805 29479 solver.cpp:610] Iteration 2520, lr = 9.88653e-09
I0314 16:44:07.733819 29479 solver.cpp:613] Iteration 2520, avg_grad_norm = 957365
I0314 16:45:42.392786 29479 solver.cpp:214] Iteration 2540, loss = 10123.3
I0314 16:45:42.392936 29479 solver.cpp:229]     Train net output #0: loss = 9617.66 (* 1 = 9617.66 loss)
I0314 16:45:42.709939 29479 solver.cpp:610] Iteration 2540, lr = 9.88563e-09
I0314 16:45:42.709992 29479 solver.cpp:613] Iteration 2540, avg_grad_norm = 916474
I0314 16:46:45.818580 29479 solver.cpp:214] Iteration 2560, loss = 9658.7
I0314 16:46:45.818706 29479 solver.cpp:229]     Train net output #0: loss = 9925.98 (* 1 = 9925.98 loss)
I0314 16:46:46.017788 29479 solver.cpp:610] Iteration 2560, lr = 9.88473e-09
I0314 16:46:46.017802 29479 solver.cpp:613] Iteration 2560, avg_grad_norm = 855755
I0314 16:47:34.500756 29479 solver.cpp:214] Iteration 2580, loss = 9926.88
I0314 16:47:34.500880 29479 solver.cpp:229]     Train net output #0: loss = 8143.93 (* 1 = 8143.93 loss)
I0314 16:47:34.616857 29479 solver.cpp:610] Iteration 2580, lr = 9.88382e-09
I0314 16:47:34.616870 29479 solver.cpp:613] Iteration 2580, avg_grad_norm = 869327
I0314 16:48:23.739740 29479 solver.cpp:214] Iteration 2600, loss = 9824.04
I0314 16:48:23.739938 29479 solver.cpp:229]     Train net output #0: loss = 7706.8 (* 1 = 7706.8 loss)
I0314 16:48:24.105249 29479 solver.cpp:610] Iteration 2600, lr = 9.88292e-09
I0314 16:48:24.105263 29479 solver.cpp:613] Iteration 2600, avg_grad_norm = 901228
I0314 16:49:28.260598 29479 solver.cpp:214] Iteration 2620, loss = 9870.54
I0314 16:49:28.260753 29479 solver.cpp:229]     Train net output #0: loss = 9364.6 (* 1 = 9364.6 loss)
I0314 16:49:28.473830 29479 solver.cpp:610] Iteration 2620, lr = 9.88202e-09
I0314 16:49:28.473845 29479 solver.cpp:613] Iteration 2620, avg_grad_norm = 844601
I0314 16:50:32.300837 29479 solver.cpp:214] Iteration 2640, loss = 9971.64
I0314 16:50:32.300992 29479 solver.cpp:229]     Train net output #0: loss = 9144.01 (* 1 = 9144.01 loss)
I0314 16:50:32.502337 29479 solver.cpp:610] Iteration 2640, lr = 9.88112e-09
I0314 16:50:32.502351 29479 solver.cpp:613] Iteration 2640, avg_grad_norm = 794836
I0314 16:51:37.360039 29479 solver.cpp:214] Iteration 2660, loss = 9881.11
I0314 16:51:37.360219 29479 solver.cpp:229]     Train net output #0: loss = 8173.2 (* 1 = 8173.2 loss)
I0314 16:51:37.719717 29479 solver.cpp:610] Iteration 2660, lr = 9.88022e-09
I0314 16:51:37.719729 29479 solver.cpp:613] Iteration 2660, avg_grad_norm = 726376
I0314 16:52:56.773061 29479 solver.cpp:214] Iteration 2680, loss = 9801.74
I0314 16:52:56.773196 29479 solver.cpp:229]     Train net output #0: loss = 8207.08 (* 1 = 8207.08 loss)
I0314 16:52:57.130533 29479 solver.cpp:610] Iteration 2680, lr = 9.87932e-09
I0314 16:52:57.130548 29479 solver.cpp:613] Iteration 2680, avg_grad_norm = 787318
I0314 16:54:00.559530 29479 solver.cpp:214] Iteration 2700, loss = 9858.88
I0314 16:54:00.559684 29479 solver.cpp:229]     Train net output #0: loss = 10460 (* 1 = 10460 loss)
I0314 16:54:00.928179 29479 solver.cpp:610] Iteration 2700, lr = 9.87842e-09
I0314 16:54:00.928191 29479 solver.cpp:613] Iteration 2700, avg_grad_norm = 754625
I0314 16:55:04.425151 29479 solver.cpp:214] Iteration 2720, loss = 9816.44
I0314 16:55:04.425304 29479 solver.cpp:229]     Train net output #0: loss = 8945.97 (* 1 = 8945.97 loss)
I0314 16:55:04.784134 29479 solver.cpp:610] Iteration 2720, lr = 9.87752e-09
I0314 16:55:04.784147 29479 solver.cpp:613] Iteration 2720, avg_grad_norm = 895288
I0314 16:55:44.264641 29479 solver.cpp:214] Iteration 2740, loss = 9860.78
I0314 16:55:44.264753 29479 solver.cpp:229]     Train net output #0: loss = 13589.3 (* 1 = 13589.3 loss)
I0314 16:55:44.628546 29479 solver.cpp:610] Iteration 2740, lr = 9.87662e-09
I0314 16:55:44.628559 29479 solver.cpp:613] Iteration 2740, avg_grad_norm = 774708
I0314 16:56:48.062134 29479 solver.cpp:214] Iteration 2760, loss = 9820.34
I0314 16:56:48.062307 29479 solver.cpp:229]     Train net output #0: loss = 10312.9 (* 1 = 10312.9 loss)
I0314 16:56:48.426839 29479 solver.cpp:610] Iteration 2760, lr = 9.87571e-09
I0314 16:56:48.426852 29479 solver.cpp:613] Iteration 2760, avg_grad_norm = 829537
I0314 16:57:51.932307 29479 solver.cpp:214] Iteration 2780, loss = 10243
I0314 16:57:51.932471 29479 solver.cpp:229]     Train net output #0: loss = 14713.6 (* 1 = 14713.6 loss)
I0314 16:57:52.128115 29479 solver.cpp:610] Iteration 2780, lr = 9.87481e-09
I0314 16:57:52.128129 29479 solver.cpp:613] Iteration 2780, avg_grad_norm = 789715
I0314 16:59:16.690460 29479 solver.cpp:214] Iteration 2800, loss = 9951.35
I0314 16:59:16.690640 29479 solver.cpp:229]     Train net output #0: loss = 9330.34 (* 1 = 9330.34 loss)
I0314 16:59:17.056982 29479 solver.cpp:610] Iteration 2800, lr = 9.87391e-09
I0314 16:59:17.056996 29479 solver.cpp:613] Iteration 2800, avg_grad_norm = 771502
I0314 17:00:20.494320 29479 solver.cpp:214] Iteration 2820, loss = 9456.05
I0314 17:00:20.494456 29479 solver.cpp:229]     Train net output #0: loss = 6618.88 (* 1 = 6618.88 loss)
I0314 17:00:20.852849 29479 solver.cpp:610] Iteration 2820, lr = 9.87301e-09
I0314 17:00:20.852864 29479 solver.cpp:613] Iteration 2820, avg_grad_norm = 750138
I0314 17:01:24.350538 29479 solver.cpp:214] Iteration 2840, loss = 10418.5
I0314 17:01:24.350679 29479 solver.cpp:229]     Train net output #0: loss = 7225.96 (* 1 = 7225.96 loss)
I0314 17:01:24.717124 29479 solver.cpp:610] Iteration 2840, lr = 9.87211e-09
I0314 17:01:24.717138 29479 solver.cpp:613] Iteration 2840, avg_grad_norm = 863597
I0314 17:02:31.100906 29479 solver.cpp:214] Iteration 2860, loss = 10004.4
I0314 17:02:31.101075 29479 solver.cpp:229]     Train net output #0: loss = 7687.25 (* 1 = 7687.25 loss)
I0314 17:02:31.296114 29479 solver.cpp:610] Iteration 2860, lr = 9.87121e-09
I0314 17:02:31.296128 29479 solver.cpp:613] Iteration 2860, avg_grad_norm = 864985
I0314 17:03:14.989639 29479 solver.cpp:214] Iteration 2880, loss = 9399.21
I0314 17:03:14.989814 29479 solver.cpp:229]     Train net output #0: loss = 10059.6 (* 1 = 10059.6 loss)
I0314 17:03:15.107574 29479 solver.cpp:610] Iteration 2880, lr = 9.87031e-09
I0314 17:03:15.107588 29479 solver.cpp:613] Iteration 2880, avg_grad_norm = 872417
I0314 17:04:03.672451 29479 solver.cpp:214] Iteration 2900, loss = 10048.6
I0314 17:04:03.672596 29479 solver.cpp:229]     Train net output #0: loss = 8566.58 (* 1 = 8566.58 loss)
I0314 17:04:03.874439 29479 solver.cpp:610] Iteration 2900, lr = 9.8694e-09
I0314 17:04:03.874452 29479 solver.cpp:613] Iteration 2900, avg_grad_norm = 902832
I0314 17:05:26.464411 29479 solver.cpp:214] Iteration 2920, loss = 9786.69
I0314 17:05:26.464530 29479 solver.cpp:229]     Train net output #0: loss = 8667.89 (* 1 = 8667.89 loss)
I0314 17:05:26.793081 29479 solver.cpp:610] Iteration 2920, lr = 9.8685e-09
I0314 17:05:26.793125 29479 solver.cpp:613] Iteration 2920, avg_grad_norm = 732118
I0314 17:06:29.647136 29479 solver.cpp:214] Iteration 2940, loss = 10092.9
I0314 17:06:29.647263 29479 solver.cpp:229]     Train net output #0: loss = 9317.68 (* 1 = 9317.68 loss)
I0314 17:06:30.022688 29479 solver.cpp:610] Iteration 2940, lr = 9.8676e-09
I0314 17:06:30.022703 29479 solver.cpp:613] Iteration 2940, avg_grad_norm = 875973
I0314 17:07:33.139387 29479 solver.cpp:214] Iteration 2960, loss = 9634.78
I0314 17:07:33.139515 29479 solver.cpp:229]     Train net output #0: loss = 9954.59 (* 1 = 9954.59 loss)
I0314 17:07:33.503188 29479 solver.cpp:610] Iteration 2960, lr = 9.8667e-09
I0314 17:07:33.503202 29479 solver.cpp:613] Iteration 2960, avg_grad_norm = 844980
I0314 17:08:37.055577 29479 solver.cpp:214] Iteration 2980, loss = 9540.54
I0314 17:08:37.055693 29479 solver.cpp:229]     Train net output #0: loss = 7250.7 (* 1 = 7250.7 loss)
I0314 17:08:37.419926 29479 solver.cpp:610] Iteration 2980, lr = 9.8658e-09
I0314 17:08:37.419942 29479 solver.cpp:613] Iteration 2980, avg_grad_norm = 953980
I0314 17:09:40.806573 29479 solver.cpp:214] Iteration 3000, loss = 9426.98
I0314 17:09:40.806690 29479 solver.cpp:229]     Train net output #0: loss = 10136.4 (* 1 = 10136.4 loss)
I0314 17:09:41.170485 29479 solver.cpp:610] Iteration 3000, lr = 9.8649e-09
I0314 17:09:41.170498 29479 solver.cpp:613] Iteration 3000, avg_grad_norm = 909271
I0314 17:10:45.932327 29479 solver.cpp:214] Iteration 3020, loss = 9731.27
I0314 17:10:45.932473 29479 solver.cpp:229]     Train net output #0: loss = 7645.48 (* 1 = 7645.48 loss)
I0314 17:10:46.144953 29479 solver.cpp:610] Iteration 3020, lr = 9.864e-09
I0314 17:10:46.144968 29479 solver.cpp:613] Iteration 3020, avg_grad_norm = 950661
I0314 17:11:30.373431 29479 solver.cpp:214] Iteration 3040, loss = 9550.85
I0314 17:11:30.373581 29479 solver.cpp:229]     Train net output #0: loss = 13286.3 (* 1 = 13286.3 loss)
I0314 17:11:30.585731 29479 solver.cpp:610] Iteration 3040, lr = 9.8631e-09
I0314 17:11:30.585744 29479 solver.cpp:613] Iteration 3040, avg_grad_norm = 873234
I0314 17:12:49.280755 29479 solver.cpp:214] Iteration 3060, loss = 9421.46
I0314 17:12:49.280901 29479 solver.cpp:229]     Train net output #0: loss = 12188.2 (* 1 = 12188.2 loss)
I0314 17:12:49.638620 29479 solver.cpp:610] Iteration 3060, lr = 9.86219e-09
I0314 17:12:49.638634 29479 solver.cpp:613] Iteration 3060, avg_grad_norm = 869355
I0314 17:13:53.032667 29479 solver.cpp:214] Iteration 3080, loss = 9490.58
I0314 17:13:53.032845 29479 solver.cpp:229]     Train net output #0: loss = 5089.51 (* 1 = 5089.51 loss)
I0314 17:13:53.398839 29479 solver.cpp:610] Iteration 3080, lr = 9.86129e-09
I0314 17:13:53.398854 29479 solver.cpp:613] Iteration 3080, avg_grad_norm = 829183
I0314 17:14:56.918081 29479 solver.cpp:214] Iteration 3100, loss = 9515.14
I0314 17:14:56.918220 29479 solver.cpp:229]     Train net output #0: loss = 7354.54 (* 1 = 7354.54 loss)
I0314 17:14:57.276762 29479 solver.cpp:610] Iteration 3100, lr = 9.86039e-09
I0314 17:14:57.276777 29479 solver.cpp:613] Iteration 3100, avg_grad_norm = 767892
I0314 17:16:00.801337 29479 solver.cpp:214] Iteration 3120, loss = 9760.62
I0314 17:16:00.801511 29479 solver.cpp:229]     Train net output #0: loss = 16393.6 (* 1 = 16393.6 loss)
I0314 17:16:01.158567 29479 solver.cpp:610] Iteration 3120, lr = 9.85949e-09
I0314 17:16:01.158581 29479 solver.cpp:613] Iteration 3120, avg_grad_norm = 874982
I0314 17:17:04.605096 29479 solver.cpp:214] Iteration 3140, loss = 9756.99
I0314 17:17:04.605229 29479 solver.cpp:229]     Train net output #0: loss = 11405.7 (* 1 = 11405.7 loss)
I0314 17:17:04.798686 29479 solver.cpp:610] Iteration 3140, lr = 9.85859e-09
I0314 17:17:04.798701 29479 solver.cpp:613] Iteration 3140, avg_grad_norm = 752360
I0314 17:18:08.869604 29479 solver.cpp:214] Iteration 3160, loss = 9972.92
I0314 17:18:08.869729 29479 solver.cpp:229]     Train net output #0: loss = 14451.3 (* 1 = 14451.3 loss)
I0314 17:18:09.063071 29479 solver.cpp:610] Iteration 3160, lr = 9.85769e-09
I0314 17:18:09.063083 29479 solver.cpp:613] Iteration 3160, avg_grad_norm = 854721
I0314 17:19:43.883507 29479 solver.cpp:214] Iteration 3180, loss = 9283.2
I0314 17:19:43.883705 29479 solver.cpp:229]     Train net output #0: loss = 8436.45 (* 1 = 8436.45 loss)
I0314 17:19:44.246304 29479 solver.cpp:610] Iteration 3180, lr = 9.85679e-09
I0314 17:19:44.246317 29479 solver.cpp:613] Iteration 3180, avg_grad_norm = 729428
I0314 17:20:46.402071 29479 solver.cpp:214] Iteration 3200, loss = 9943.78
I0314 17:20:46.402210 29479 solver.cpp:229]     Train net output #0: loss = 10715.7 (* 1 = 10715.7 loss)
I0314 17:20:46.757257 29479 solver.cpp:610] Iteration 3200, lr = 9.85588e-09
I0314 17:20:46.757272 29479 solver.cpp:613] Iteration 3200, avg_grad_norm = 893713
I0314 17:21:48.952652 29479 solver.cpp:214] Iteration 3220, loss = 9506.07
I0314 17:21:48.952810 29479 solver.cpp:229]     Train net output #0: loss = 6676.74 (* 1 = 6676.74 loss)
I0314 17:21:49.336139 29479 solver.cpp:610] Iteration 3220, lr = 9.85498e-09
I0314 17:21:49.336154 29479 solver.cpp:613] Iteration 3220, avg_grad_norm = 825680
I0314 17:22:51.984392 29479 solver.cpp:214] Iteration 3240, loss = 9570.61
I0314 17:22:51.984519 29479 solver.cpp:229]     Train net output #0: loss = 6581.3 (* 1 = 6581.3 loss)
I0314 17:22:52.197103 29479 solver.cpp:610] Iteration 3240, lr = 9.85408e-09
I0314 17:22:52.197116 29479 solver.cpp:613] Iteration 3240, avg_grad_norm = 857294
I0314 17:23:54.979249 29479 solver.cpp:214] Iteration 3260, loss = 9776.44
I0314 17:23:54.979383 29479 solver.cpp:229]     Train net output #0: loss = 12960.7 (* 1 = 12960.7 loss)
I0314 17:23:55.333143 29479 solver.cpp:610] Iteration 3260, lr = 9.85318e-09
I0314 17:23:55.333158 29479 solver.cpp:613] Iteration 3260, avg_grad_norm = 776919
I0314 17:24:58.356106 29479 solver.cpp:214] Iteration 3280, loss = 9808.03
I0314 17:24:58.356295 29479 solver.cpp:229]     Train net output #0: loss = 7263.49 (* 1 = 7263.49 loss)
I0314 17:24:58.567200 29479 solver.cpp:610] Iteration 3280, lr = 9.85228e-09
I0314 17:24:58.567214 29479 solver.cpp:613] Iteration 3280, avg_grad_norm = 888486
I0314 17:26:01.624407 29479 solver.cpp:214] Iteration 3300, loss = 9414.03
I0314 17:26:01.624531 29479 solver.cpp:229]     Train net output #0: loss = 5843.74 (* 1 = 5843.74 loss)
I0314 17:26:01.815474 29479 solver.cpp:610] Iteration 3300, lr = 9.85138e-09
I0314 17:26:01.815486 29479 solver.cpp:613] Iteration 3300, avg_grad_norm = 943014
I0314 17:26:58.783763 29479 solver.cpp:214] Iteration 3320, loss = 9902.11
I0314 17:26:58.783905 29479 solver.cpp:229]     Train net output #0: loss = 14974.5 (* 1 = 14974.5 loss)
I0314 17:26:58.895448 29479 solver.cpp:610] Iteration 3320, lr = 9.85048e-09
I0314 17:26:58.895462 29479 solver.cpp:613] Iteration 3320, avg_grad_norm = 804863
I0314 17:27:58.401995 29479 solver.cpp:214] Iteration 3340, loss = 9180.31
I0314 17:27:58.402139 29479 solver.cpp:229]     Train net output #0: loss = 12916 (* 1 = 12916 loss)
I0314 17:27:58.615115 29479 solver.cpp:610] Iteration 3340, lr = 9.84957e-09
I0314 17:27:58.615128 29479 solver.cpp:613] Iteration 3340, avg_grad_norm = 716560
I0314 17:29:01.741981 29479 solver.cpp:214] Iteration 3360, loss = 9511.17
I0314 17:29:01.742158 29479 solver.cpp:229]     Train net output #0: loss = 9153.09 (* 1 = 9153.09 loss)
I0314 17:29:01.936496 29479 solver.cpp:610] Iteration 3360, lr = 9.84867e-09
I0314 17:29:01.936509 29479 solver.cpp:613] Iteration 3360, avg_grad_norm = 754909
I0314 17:30:05.226372 29479 solver.cpp:214] Iteration 3380, loss = 9569.95
I0314 17:30:05.226495 29479 solver.cpp:229]     Train net output #0: loss = 13923.4 (* 1 = 13923.4 loss)
I0314 17:30:05.439383 29479 solver.cpp:610] Iteration 3380, lr = 9.84777e-09
I0314 17:30:05.439398 29479 solver.cpp:613] Iteration 3380, avg_grad_norm = 748662
I0314 17:31:08.722551 29479 solver.cpp:214] Iteration 3400, loss = 9357.53
I0314 17:31:08.722724 29479 solver.cpp:229]     Train net output #0: loss = 6998.04 (* 1 = 6998.04 loss)
I0314 17:31:09.082737 29479 solver.cpp:610] Iteration 3400, lr = 9.84687e-09
I0314 17:31:09.082751 29479 solver.cpp:613] Iteration 3400, avg_grad_norm = 783026
I0314 17:32:12.485059 29479 solver.cpp:214] Iteration 3420, loss = 9423.58
I0314 17:32:12.485234 29479 solver.cpp:229]     Train net output #0: loss = 6371.52 (* 1 = 6371.52 loss)
I0314 17:32:12.842761 29479 solver.cpp:610] Iteration 3420, lr = 9.84597e-09
I0314 17:32:12.842775 29479 solver.cpp:613] Iteration 3420, avg_grad_norm = 794263
I0314 17:33:44.914202 29479 solver.cpp:214] Iteration 3440, loss = 9330
I0314 17:33:44.914397 29479 solver.cpp:229]     Train net output #0: loss = 11233.9 (* 1 = 11233.9 loss)
I0314 17:33:45.271447 29479 solver.cpp:610] Iteration 3440, lr = 9.84507e-09
I0314 17:33:45.271461 29479 solver.cpp:613] Iteration 3440, avg_grad_norm = 755925
I0314 17:34:33.847153 29479 solver.cpp:214] Iteration 3460, loss = 8937.6
I0314 17:34:33.847287 29479 solver.cpp:229]     Train net output #0: loss = 7221.69 (* 1 = 7221.69 loss)
I0314 17:34:33.961796 29479 solver.cpp:610] Iteration 3460, lr = 9.84416e-09
I0314 17:34:33.961833 29479 solver.cpp:613] Iteration 3460, avg_grad_norm = 772340
I0314 17:35:29.447628 29479 solver.cpp:214] Iteration 3480, loss = 9384.32
I0314 17:35:29.447811 29479 solver.cpp:229]     Train net output #0: loss = 8931.07 (* 1 = 8931.07 loss)
I0314 17:35:29.810847 29479 solver.cpp:610] Iteration 3480, lr = 9.84326e-09
I0314 17:35:29.810861 29479 solver.cpp:613] Iteration 3480, avg_grad_norm = 878198
I0314 17:36:33.136579 29479 solver.cpp:214] Iteration 3500, loss = 9517.75
I0314 17:36:33.136718 29479 solver.cpp:229]     Train net output #0: loss = 7634.96 (* 1 = 7634.96 loss)
I0314 17:36:33.496417 29479 solver.cpp:610] Iteration 3500, lr = 9.84236e-09
I0314 17:36:33.496431 29479 solver.cpp:613] Iteration 3500, avg_grad_norm = 1.177e+06
I0314 17:37:37.041573 29479 solver.cpp:214] Iteration 3520, loss = 9672.24
I0314 17:37:37.041697 29479 solver.cpp:229]     Train net output #0: loss = 12500.3 (* 1 = 12500.3 loss)
I0314 17:37:37.399715 29479 solver.cpp:610] Iteration 3520, lr = 9.84146e-09
I0314 17:37:37.399729 29479 solver.cpp:613] Iteration 3520, avg_grad_norm = 1.03354e+06
I0314 17:38:40.977041 29479 solver.cpp:214] Iteration 3540, loss = 9548.7
I0314 17:38:40.977257 29479 solver.cpp:229]     Train net output #0: loss = 8557.92 (* 1 = 8557.92 loss)
I0314 17:38:41.340416 29479 solver.cpp:610] Iteration 3540, lr = 9.84056e-09
I0314 17:38:41.340440 29479 solver.cpp:613] Iteration 3540, avg_grad_norm = 816760
I0314 17:39:59.026778 29479 solver.cpp:214] Iteration 3560, loss = 9536.44
I0314 17:39:59.026993 29479 solver.cpp:229]     Train net output #0: loss = 11180.8 (* 1 = 11180.8 loss)
I0314 17:39:59.214351 29479 solver.cpp:610] Iteration 3560, lr = 9.83966e-09
I0314 17:39:59.214365 29479 solver.cpp:613] Iteration 3560, avg_grad_norm = 740971
I0314 17:41:02.902159 29479 solver.cpp:214] Iteration 3580, loss = 9296.66
I0314 17:41:02.902279 29479 solver.cpp:229]     Train net output #0: loss = 6193.8 (* 1 = 6193.8 loss)
I0314 17:41:03.095837 29479 solver.cpp:610] Iteration 3580, lr = 9.83875e-09
I0314 17:41:03.095851 29479 solver.cpp:613] Iteration 3580, avg_grad_norm = 683255
I0314 17:42:06.516785 29479 solver.cpp:214] Iteration 3600, loss = 9496.12
I0314 17:42:06.516954 29479 solver.cpp:229]     Train net output #0: loss = 8984.48 (* 1 = 8984.48 loss)
I0314 17:42:06.890625 29479 solver.cpp:610] Iteration 3600, lr = 9.83785e-09
I0314 17:42:06.890638 29479 solver.cpp:613] Iteration 3600, avg_grad_norm = 781271
I0314 17:42:46.236320 29479 solver.cpp:214] Iteration 3620, loss = 9086.34
I0314 17:42:46.236482 29479 solver.cpp:229]     Train net output #0: loss = 7977.29 (* 1 = 7977.29 loss)
I0314 17:42:46.596822 29479 solver.cpp:610] Iteration 3620, lr = 9.83695e-09
I0314 17:42:46.596837 29479 solver.cpp:613] Iteration 3620, avg_grad_norm = 825425
I0314 17:43:50.212769 29479 solver.cpp:214] Iteration 3640, loss = 9461.65
I0314 17:43:50.212970 29479 solver.cpp:229]     Train net output #0: loss = 13966 (* 1 = 13966 loss)
I0314 17:43:50.425959 29479 solver.cpp:610] Iteration 3640, lr = 9.83605e-09
I0314 17:43:50.425972 29479 solver.cpp:613] Iteration 3640, avg_grad_norm = 830199
I0314 17:44:53.999936 29479 solver.cpp:214] Iteration 3660, loss = 9327.68
I0314 17:44:54.000128 29479 solver.cpp:229]     Train net output #0: loss = 7310.82 (* 1 = 7310.82 loss)
I0314 17:44:54.368584 29479 solver.cpp:610] Iteration 3660, lr = 9.83515e-09
I0314 17:44:54.368598 29479 solver.cpp:613] Iteration 3660, avg_grad_norm = 763005
I0314 17:45:58.295361 29479 solver.cpp:214] Iteration 3680, loss = 9439.5
I0314 17:45:58.295557 29479 solver.cpp:229]     Train net output #0: loss = 14286 (* 1 = 14286 loss)
I0314 17:45:58.498616 29479 solver.cpp:610] Iteration 3680, lr = 9.83425e-09
I0314 17:45:58.498630 29479 solver.cpp:613] Iteration 3680, avg_grad_norm = 792709
I0314 17:47:21.003654 29479 solver.cpp:214] Iteration 3700, loss = 9362.5
I0314 17:47:21.003852 29479 solver.cpp:229]     Train net output #0: loss = 7349.4 (* 1 = 7349.4 loss)
I0314 17:47:21.368232 29479 solver.cpp:610] Iteration 3700, lr = 9.83334e-09
I0314 17:47:21.368247 29479 solver.cpp:613] Iteration 3700, avg_grad_norm = 871945
I0314 17:48:25.221459 29479 solver.cpp:214] Iteration 3720, loss = 8985.67
I0314 17:48:25.221678 29479 solver.cpp:229]     Train net output #0: loss = 6791.35 (* 1 = 6791.35 loss)
I0314 17:48:25.579910 29479 solver.cpp:610] Iteration 3720, lr = 9.83244e-09
I0314 17:48:25.579924 29479 solver.cpp:613] Iteration 3720, avg_grad_norm = 751082
I0314 17:49:25.125962 29479 solver.cpp:214] Iteration 3740, loss = 9321.29
I0314 17:49:25.126096 29479 solver.cpp:229]     Train net output #0: loss = 6653.4 (* 1 = 6653.4 loss)
I0314 17:49:25.517321 29479 solver.cpp:610] Iteration 3740, lr = 9.83154e-09
I0314 17:49:25.517334 29479 solver.cpp:613] Iteration 3740, avg_grad_norm = 926318
I0314 17:50:14.631867 29479 solver.cpp:214] Iteration 3760, loss = 9954.82
I0314 17:50:14.631992 29479 solver.cpp:229]     Train net output #0: loss = 6984 (* 1 = 6984 loss)
I0314 17:50:14.748051 29479 solver.cpp:610] Iteration 3760, lr = 9.83064e-09
I0314 17:50:14.748065 29479 solver.cpp:613] Iteration 3760, avg_grad_norm = 868051
I0314 17:51:10.474179 29479 solver.cpp:214] Iteration 3780, loss = 9043.99
I0314 17:51:10.474318 29479 solver.cpp:229]     Train net output #0: loss = 11809 (* 1 = 11809 loss)
I0314 17:51:10.676626 29479 solver.cpp:610] Iteration 3780, lr = 9.82974e-09
I0314 17:51:10.676643 29479 solver.cpp:613] Iteration 3780, avg_grad_norm = 793692
I0314 17:52:14.345711 29479 solver.cpp:214] Iteration 3800, loss = 9180.65
I0314 17:52:14.345856 29479 solver.cpp:229]     Train net output #0: loss = 7868.27 (* 1 = 7868.27 loss)
I0314 17:52:14.712535 29479 solver.cpp:610] Iteration 3800, lr = 9.82884e-09
I0314 17:52:14.712549 29479 solver.cpp:613] Iteration 3800, avg_grad_norm = 823646
I0314 17:53:32.411900 29479 solver.cpp:214] Iteration 3820, loss = 9502.93
I0314 17:53:32.412039 29479 solver.cpp:229]     Train net output #0: loss = 6229.84 (* 1 = 6229.84 loss)
I0314 17:53:32.780199 29479 solver.cpp:610] Iteration 3820, lr = 9.82793e-09
I0314 17:53:32.780211 29479 solver.cpp:613] Iteration 3820, avg_grad_norm = 777611
I0314 17:54:36.393446 29479 solver.cpp:214] Iteration 3840, loss = 8922.37
I0314 17:54:36.393610 29479 solver.cpp:229]     Train net output #0: loss = 7949.55 (* 1 = 7949.55 loss)
I0314 17:54:36.759965 29479 solver.cpp:610] Iteration 3840, lr = 9.82703e-09
I0314 17:54:36.759979 29479 solver.cpp:613] Iteration 3840, avg_grad_norm = 779666
I0314 17:55:40.186851 29479 solver.cpp:214] Iteration 3860, loss = 9163.8
I0314 17:55:40.187039 29479 solver.cpp:229]     Train net output #0: loss = 8888.24 (* 1 = 8888.24 loss)
I0314 17:55:40.545382 29479 solver.cpp:610] Iteration 3860, lr = 9.82613e-09
I0314 17:55:40.545394 29479 solver.cpp:613] Iteration 3860, avg_grad_norm = 783058
I0314 17:56:44.145206 29479 solver.cpp:214] Iteration 3880, loss = 9248.67
I0314 17:56:44.145331 29479 solver.cpp:229]     Train net output #0: loss = 10523.5 (* 1 = 10523.5 loss)
I0314 17:56:44.509042 29479 solver.cpp:610] Iteration 3880, lr = 9.82523e-09
I0314 17:56:44.509057 29479 solver.cpp:613] Iteration 3880, avg_grad_norm = 740080
I0314 17:57:48.322237 29479 solver.cpp:214] Iteration 3900, loss = 9188.5
I0314 17:57:48.322392 29479 solver.cpp:229]     Train net output #0: loss = 7426.1 (* 1 = 7426.1 loss)
I0314 17:57:48.515743 29479 solver.cpp:610] Iteration 3900, lr = 9.82433e-09
I0314 17:57:48.515755 29479 solver.cpp:613] Iteration 3900, avg_grad_norm = 781145
I0314 17:58:29.389772 29479 solver.cpp:214] Iteration 3920, loss = 9402.14
I0314 17:58:29.389881 29479 solver.cpp:229]     Train net output #0: loss = 5172.72 (* 1 = 5172.72 loss)
I0314 17:58:29.747145 29479 solver.cpp:610] Iteration 3920, lr = 9.82343e-09
I0314 17:58:29.747158 29479 solver.cpp:613] Iteration 3920, avg_grad_norm = 846840
I0314 17:59:57.569761 29479 solver.cpp:214] Iteration 3940, loss = 9084.14
I0314 17:59:57.569908 29479 solver.cpp:229]     Train net output #0: loss = 10366.2 (* 1 = 10366.2 loss)
I0314 17:59:57.927335 29479 solver.cpp:610] Iteration 3940, lr = 9.82252e-09
I0314 17:59:57.927347 29479 solver.cpp:613] Iteration 3940, avg_grad_norm = 747338
I0314 18:01:01.569104 29479 solver.cpp:214] Iteration 3960, loss = 9160.21
I0314 18:01:01.569273 29479 solver.cpp:229]     Train net output #0: loss = 6806.1 (* 1 = 6806.1 loss)
I0314 18:01:01.938163 29479 solver.cpp:610] Iteration 3960, lr = 9.82162e-09
I0314 18:01:01.938175 29479 solver.cpp:613] Iteration 3960, avg_grad_norm = 669630
I0314 18:02:05.641186 29479 solver.cpp:214] Iteration 3980, loss = 9249.61
I0314 18:02:05.641291 29479 solver.cpp:229]     Train net output #0: loss = 4802.41 (* 1 = 4802.41 loss)
I0314 18:02:05.857146 29479 solver.cpp:610] Iteration 3980, lr = 9.82072e-09
I0314 18:02:05.857158 29479 solver.cpp:613] Iteration 3980, avg_grad_norm = 778625
I0314 18:03:09.414918 29479 solver.cpp:214] Iteration 4000, loss = 9451.41
I0314 18:03:09.415038 29479 solver.cpp:229]     Train net output #0: loss = 9504.53 (* 1 = 9504.53 loss)
I0314 18:03:09.627151 29479 solver.cpp:610] Iteration 4000, lr = 9.81982e-09
I0314 18:03:09.627163 29479 solver.cpp:613] Iteration 4000, avg_grad_norm = 963179
I0314 18:04:13.278218 29479 solver.cpp:214] Iteration 4020, loss = 9056.13
I0314 18:04:13.278327 29479 solver.cpp:229]     Train net output #0: loss = 8377.38 (* 1 = 8377.38 loss)
I0314 18:04:13.639029 29479 solver.cpp:610] Iteration 4020, lr = 9.81892e-09
I0314 18:04:13.639042 29479 solver.cpp:613] Iteration 4020, avg_grad_norm = 808859
I0314 18:05:17.366544 29479 solver.cpp:214] Iteration 4040, loss = 9202.86
I0314 18:05:17.366648 29479 solver.cpp:229]     Train net output #0: loss = 6095.43 (* 1 = 6095.43 loss)
I0314 18:05:17.582569 29479 solver.cpp:610] Iteration 4040, lr = 9.81801e-09
I0314 18:05:17.582582 29479 solver.cpp:613] Iteration 4040, avg_grad_norm = 890836
I0314 18:05:58.439091 29479 solver.cpp:214] Iteration 4060, loss = 9340.5
I0314 18:05:58.439219 29479 solver.cpp:229]     Train net output #0: loss = 5032.69 (* 1 = 5032.69 loss)
I0314 18:05:58.636126 29479 solver.cpp:610] Iteration 4060, lr = 9.81711e-09
I0314 18:05:58.636138 29479 solver.cpp:613] Iteration 4060, avg_grad_norm = 938055
I0314 18:07:16.406424 29479 solver.cpp:214] Iteration 4080, loss = 8902.14
I0314 18:07:16.406672 29479 solver.cpp:229]     Train net output #0: loss = 7835.28 (* 1 = 7835.28 loss)
I0314 18:07:16.766830 29479 solver.cpp:610] Iteration 4080, lr = 9.81621e-09
I0314 18:07:16.766844 29479 solver.cpp:613] Iteration 4080, avg_grad_norm = 682110
I0314 18:08:20.409528 29479 solver.cpp:214] Iteration 4100, loss = 9063.71
I0314 18:08:20.409693 29479 solver.cpp:229]     Train net output #0: loss = 5240.3 (* 1 = 5240.3 loss)
I0314 18:08:20.625538 29479 solver.cpp:610] Iteration 4100, lr = 9.81531e-09
I0314 18:08:20.625552 29479 solver.cpp:613] Iteration 4100, avg_grad_norm = 695573
I0314 18:09:24.080711 29479 solver.cpp:214] Iteration 4120, loss = 9010.83
I0314 18:09:24.080870 29479 solver.cpp:229]     Train net output #0: loss = 10764.5 (* 1 = 10764.5 loss)
I0314 18:09:24.444852 29479 solver.cpp:610] Iteration 4120, lr = 9.81441e-09
I0314 18:09:24.444866 29479 solver.cpp:613] Iteration 4120, avg_grad_norm = 672664
I0314 18:10:28.155407 29479 solver.cpp:214] Iteration 4140, loss = 8911.59
I0314 18:10:28.155555 29479 solver.cpp:229]     Train net output #0: loss = 16476.3 (* 1 = 16476.3 loss)
I0314 18:10:28.352144 29479 solver.cpp:610] Iteration 4140, lr = 9.81351e-09
I0314 18:10:28.352157 29479 solver.cpp:613] Iteration 4140, avg_grad_norm = 754167
I0314 18:11:32.032758 29479 solver.cpp:214] Iteration 4160, loss = 9100.49
I0314 18:11:32.032862 29479 solver.cpp:229]     Train net output #0: loss = 17137 (* 1 = 17137 loss)
I0314 18:11:32.248661 29479 solver.cpp:610] Iteration 4160, lr = 9.8126e-09
I0314 18:11:32.248675 29479 solver.cpp:613] Iteration 4160, avg_grad_norm = 821426
I0314 18:12:35.949918 29479 solver.cpp:214] Iteration 4180, loss = 9028.76
I0314 18:12:35.950059 29479 solver.cpp:229]     Train net output #0: loss = 8203.46 (* 1 = 8203.46 loss)
I0314 18:12:36.315331 29479 solver.cpp:610] Iteration 4180, lr = 9.8117e-09
I0314 18:12:36.315345 29479 solver.cpp:613] Iteration 4180, avg_grad_norm = 739914
I0314 18:13:35.238800 29479 solver.cpp:214] Iteration 4200, loss = 9046.18
I0314 18:13:35.239020 29479 solver.cpp:229]     Train net output #0: loss = 4466.97 (* 1 = 4466.97 loss)
I0314 18:13:35.353557 29479 solver.cpp:610] Iteration 4200, lr = 9.8108e-09
I0314 18:13:35.353570 29479 solver.cpp:613] Iteration 4200, avg_grad_norm = 776074
I0314 18:14:36.020526 29479 solver.cpp:214] Iteration 4220, loss = 9047.47
I0314 18:14:36.020643 29479 solver.cpp:229]     Train net output #0: loss = 11485 (* 1 = 11485 loss)
I0314 18:14:36.380338 29479 solver.cpp:610] Iteration 4220, lr = 9.8099e-09
I0314 18:14:36.380359 29479 solver.cpp:613] Iteration 4220, avg_grad_norm = 792081
I0314 18:15:39.915001 29479 solver.cpp:214] Iteration 4240, loss = 9100.12
I0314 18:15:39.915195 29479 solver.cpp:229]     Train net output #0: loss = 12298.2 (* 1 = 12298.2 loss)
I0314 18:15:40.278035 29479 solver.cpp:610] Iteration 4240, lr = 9.809e-09
I0314 18:15:40.278049 29479 solver.cpp:613] Iteration 4240, avg_grad_norm = 869388
I0314 18:16:44.018260 29479 solver.cpp:214] Iteration 4260, loss = 8967.8
I0314 18:16:44.018453 29479 solver.cpp:229]     Train net output #0: loss = 10744.2 (* 1 = 10744.2 loss)
I0314 18:16:44.212014 29479 solver.cpp:610] Iteration 4260, lr = 9.80809e-09
I0314 18:16:44.212028 29479 solver.cpp:613] Iteration 4260, avg_grad_norm = 797980
I0314 18:17:47.967797 29479 solver.cpp:214] Iteration 4280, loss = 9482.73
I0314 18:17:47.967921 29479 solver.cpp:229]     Train net output #0: loss = 8613.88 (* 1 = 8613.88 loss)
I0314 18:17:48.327308 29479 solver.cpp:610] Iteration 4280, lr = 9.80719e-09
I0314 18:17:48.327322 29479 solver.cpp:613] Iteration 4280, avg_grad_norm = 837904
I0314 18:18:51.783563 29479 solver.cpp:214] Iteration 4300, loss = 8957.01
I0314 18:18:51.783710 29479 solver.cpp:229]     Train net output #0: loss = 8270.23 (* 1 = 8270.23 loss)
I0314 18:18:52.147858 29479 solver.cpp:610] Iteration 4300, lr = 9.80629e-09
I0314 18:18:52.147871 29479 solver.cpp:613] Iteration 4300, avg_grad_norm = 808628
I0314 18:20:10.166267 29479 solver.cpp:214] Iteration 4320, loss = 9062.46
I0314 18:20:10.166452 29479 solver.cpp:229]     Train net output #0: loss = 9122.27 (* 1 = 9122.27 loss)
I0314 18:20:10.524195 29479 solver.cpp:610] Iteration 4320, lr = 9.80539e-09
I0314 18:20:10.524210 29479 solver.cpp:613] Iteration 4320, avg_grad_norm = 729068
I0314 18:21:13.307803 29479 solver.cpp:214] Iteration 4340, loss = 8967.24
I0314 18:21:13.307991 29479 solver.cpp:229]     Train net output #0: loss = 9202.65 (* 1 = 9202.65 loss)
I0314 18:21:13.413194 29479 solver.cpp:610] Iteration 4340, lr = 9.80449e-09
I0314 18:21:13.413257 29479 solver.cpp:613] Iteration 4340, avg_grad_norm = 778447
I0314 18:21:55.067909 29479 solver.cpp:214] Iteration 4360, loss = 9517.31
I0314 18:21:55.068019 29479 solver.cpp:229]     Train net output #0: loss = 7417.97 (* 1 = 7417.97 loss)
I0314 18:21:55.432021 29479 solver.cpp:610] Iteration 4360, lr = 9.80358e-09
I0314 18:21:55.432062 29479 solver.cpp:613] Iteration 4360, avg_grad_norm = 756820
I0314 18:22:58.992213 29479 solver.cpp:214] Iteration 4380, loss = 9151.01
I0314 18:22:58.992388 29479 solver.cpp:229]     Train net output #0: loss = 8411.78 (* 1 = 8411.78 loss)
I0314 18:22:59.352463 29479 solver.cpp:610] Iteration 4380, lr = 9.80268e-09
I0314 18:22:59.352475 29479 solver.cpp:613] Iteration 4380, avg_grad_norm = 868344
I0314 18:24:03.045084 29479 solver.cpp:214] Iteration 4400, loss = 9317.23
I0314 18:24:03.045203 29479 solver.cpp:229]     Train net output #0: loss = 6367.31 (* 1 = 6367.31 loss)
I0314 18:24:03.409814 29479 solver.cpp:610] Iteration 4400, lr = 9.80178e-09
I0314 18:24:03.409827 29479 solver.cpp:613] Iteration 4400, avg_grad_norm = 925344
I0314 18:25:06.915899 29479 solver.cpp:214] Iteration 4420, loss = 9503.74
I0314 18:25:06.916082 29479 solver.cpp:229]     Train net output #0: loss = 6779.51 (* 1 = 6779.51 loss)
I0314 18:25:07.275442 29479 solver.cpp:610] Iteration 4420, lr = 9.80088e-09
I0314 18:25:07.275455 29479 solver.cpp:613] Iteration 4420, avg_grad_norm = 808300
I0314 18:26:10.971060 29479 solver.cpp:214] Iteration 4440, loss = 8938.71
I0314 18:26:10.971166 29479 solver.cpp:229]     Train net output #0: loss = 6259.64 (* 1 = 6259.64 loss)
I0314 18:26:11.337054 29479 solver.cpp:610] Iteration 4440, lr = 9.79998e-09
I0314 18:26:11.337066 29479 solver.cpp:613] Iteration 4440, avg_grad_norm = 798041
I0314 18:27:30.009614 29479 solver.cpp:214] Iteration 4460, loss = 9193.09
I0314 18:27:30.009724 29479 solver.cpp:229]     Train net output #0: loss = 9938.77 (* 1 = 9938.77 loss)
I0314 18:27:30.341953 29479 solver.cpp:610] Iteration 4460, lr = 9.79907e-09
I0314 18:27:30.341966 29479 solver.cpp:613] Iteration 4460, avg_grad_norm = 843849
I0314 18:28:33.831941 29479 solver.cpp:214] Iteration 4480, loss = 8762.66
I0314 18:28:33.832054 29479 solver.cpp:229]     Train net output #0: loss = 9822.86 (* 1 = 9822.86 loss)
I0314 18:28:34.048135 29479 solver.cpp:610] Iteration 4480, lr = 9.79817e-09
I0314 18:28:34.048147 29479 solver.cpp:613] Iteration 4480, avg_grad_norm = 774380
I0314 18:29:16.530083 29479 solver.cpp:214] Iteration 4500, loss = 8757.13
I0314 18:29:16.530226 29479 solver.cpp:229]     Train net output #0: loss = 9357.63 (* 1 = 9357.63 loss)
I0314 18:29:16.646284 29479 solver.cpp:610] Iteration 4500, lr = 9.79727e-09
I0314 18:29:16.646337 29479 solver.cpp:613] Iteration 4500, avg_grad_norm = 904047
I0314 18:30:18.605408 29479 solver.cpp:214] Iteration 4520, loss = 8861.74
I0314 18:30:18.605550 29479 solver.cpp:229]     Train net output #0: loss = 14796.3 (* 1 = 14796.3 loss)
I0314 18:30:18.963130 29479 solver.cpp:610] Iteration 4520, lr = 9.79637e-09
I0314 18:30:18.963143 29479 solver.cpp:613] Iteration 4520, avg_grad_norm = 847773
I0314 18:31:22.656635 29479 solver.cpp:214] Iteration 4540, loss = 8841.28
I0314 18:31:22.656771 29479 solver.cpp:229]     Train net output #0: loss = 8306.7 (* 1 = 8306.7 loss)
I0314 18:31:22.852416 29479 solver.cpp:610] Iteration 4540, lr = 9.79547e-09
I0314 18:31:22.852429 29479 solver.cpp:613] Iteration 4540, avg_grad_norm = 824914
I0314 18:32:26.628906 29479 solver.cpp:214] Iteration 4560, loss = 8686.44
I0314 18:32:26.629047 29479 solver.cpp:229]     Train net output #0: loss = 6581.24 (* 1 = 6581.24 loss)
I0314 18:32:26.824568 29479 solver.cpp:610] Iteration 4560, lr = 9.79456e-09
I0314 18:32:26.824580 29479 solver.cpp:613] Iteration 4560, avg_grad_norm = 803385
I0314 18:33:51.993661 29479 solver.cpp:214] Iteration 4580, loss = 9111.46
I0314 18:33:51.993784 29479 solver.cpp:229]     Train net output #0: loss = 8548.55 (* 1 = 8548.55 loss)
I0314 18:33:52.352103 29479 solver.cpp:610] Iteration 4580, lr = 9.79366e-09
I0314 18:33:52.352118 29479 solver.cpp:613] Iteration 4580, avg_grad_norm = 862461
I0314 18:34:58.893867 29479 solver.cpp:214] Iteration 4600, loss = 8785.56
I0314 18:34:58.893995 29479 solver.cpp:229]     Train net output #0: loss = 8318.5 (* 1 = 8318.5 loss)
I0314 18:34:59.284490 29479 solver.cpp:610] Iteration 4600, lr = 9.79276e-09
I0314 18:34:59.284505 29479 solver.cpp:613] Iteration 4600, avg_grad_norm = 807559
I0314 18:36:03.272416 29479 solver.cpp:214] Iteration 4620, loss = 8851.08
I0314 18:36:03.272624 29479 solver.cpp:229]     Train net output #0: loss = 8582.48 (* 1 = 8582.48 loss)
I0314 18:36:03.639209 29479 solver.cpp:610] Iteration 4620, lr = 9.79186e-09
I0314 18:36:03.639221 29479 solver.cpp:613] Iteration 4620, avg_grad_norm = 820534
I0314 18:36:54.549075 29479 solver.cpp:214] Iteration 4640, loss = 8893.77
I0314 18:36:54.549195 29479 solver.cpp:229]     Train net output #0: loss = 7931.53 (* 1 = 7931.53 loss)
I0314 18:36:54.663530 29479 solver.cpp:610] Iteration 4640, lr = 9.79096e-09
I0314 18:36:54.663569 29479 solver.cpp:613] Iteration 4640, avg_grad_norm = 825659
I0314 18:37:48.584934 29479 solver.cpp:214] Iteration 4660, loss = 9155.59
I0314 18:37:48.585086 29479 solver.cpp:229]     Train net output #0: loss = 9683.86 (* 1 = 9683.86 loss)
I0314 18:37:48.941993 29479 solver.cpp:610] Iteration 4660, lr = 9.79005e-09
I0314 18:37:48.942006 29479 solver.cpp:613] Iteration 4660, avg_grad_norm = 808240
I0314 18:38:52.704118 29479 solver.cpp:214] Iteration 4680, loss = 9192.02
I0314 18:38:52.704274 29479 solver.cpp:229]     Train net output #0: loss = 8599.9 (* 1 = 8599.9 loss)
I0314 18:38:53.064173 29479 solver.cpp:610] Iteration 4680, lr = 9.78915e-09
I0314 18:38:53.064187 29479 solver.cpp:613] Iteration 4680, avg_grad_norm = 681950
I0314 18:40:10.435571 29479 solver.cpp:214] Iteration 4700, loss = 9067.17
I0314 18:40:10.435672 29479 solver.cpp:229]     Train net output #0: loss = 8431.46 (* 1 = 8431.46 loss)
I0314 18:40:10.793476 29479 solver.cpp:610] Iteration 4700, lr = 9.78825e-09
I0314 18:40:10.793489 29479 solver.cpp:613] Iteration 4700, avg_grad_norm = 703048
I0314 18:41:14.448987 29479 solver.cpp:214] Iteration 4720, loss = 8532.12
I0314 18:41:14.449142 29479 solver.cpp:229]     Train net output #0: loss = 7019.6 (* 1 = 7019.6 loss)
I0314 18:41:14.664455 29479 solver.cpp:610] Iteration 4720, lr = 9.78735e-09
I0314 18:41:14.664469 29479 solver.cpp:613] Iteration 4720, avg_grad_norm = 676874
I0314 18:42:18.381265 29479 solver.cpp:214] Iteration 4740, loss = 8900.02
I0314 18:42:18.381383 29479 solver.cpp:229]     Train net output #0: loss = 12804.8 (* 1 = 12804.8 loss)
I0314 18:42:18.739125 29479 solver.cpp:610] Iteration 4740, lr = 9.78644e-09
I0314 18:42:18.739138 29479 solver.cpp:613] Iteration 4740, avg_grad_norm = 778296
I0314 18:43:22.438185 29479 solver.cpp:214] Iteration 4760, loss = 8802.11
I0314 18:43:22.438375 29479 solver.cpp:229]     Train net output #0: loss = 12426.4 (* 1 = 12426.4 loss)
I0314 18:43:22.805018 29479 solver.cpp:610] Iteration 4760, lr = 9.78554e-09
I0314 18:43:22.805044 29479 solver.cpp:613] Iteration 4760, avg_grad_norm = 813553
I0314 18:44:26.645413 29479 solver.cpp:214] Iteration 4780, loss = 9033.26
I0314 18:44:26.645593 29479 solver.cpp:229]     Train net output #0: loss = 6982.66 (* 1 = 6982.66 loss)
I0314 18:44:26.838829 29479 solver.cpp:610] Iteration 4780, lr = 9.78464e-09
I0314 18:44:26.838841 29479 solver.cpp:613] Iteration 4780, avg_grad_norm = 898651
I0314 18:45:08.176233 29479 solver.cpp:214] Iteration 4800, loss = 9038.51
I0314 18:45:08.176411 29479 solver.cpp:229]     Train net output #0: loss = 9803.31 (* 1 = 9803.31 loss)
I0314 18:45:08.389082 29479 solver.cpp:610] Iteration 4800, lr = 9.78374e-09
I0314 18:45:08.389096 29479 solver.cpp:613] Iteration 4800, avg_grad_norm = 811184
I0314 18:46:12.243156 29479 solver.cpp:214] Iteration 4820, loss = 8914.77
I0314 18:46:12.243341 29479 solver.cpp:229]     Train net output #0: loss = 8713.19 (* 1 = 8713.19 loss)
I0314 18:46:12.437023 29479 solver.cpp:610] Iteration 4820, lr = 9.78284e-09
I0314 18:46:12.437049 29479 solver.cpp:613] Iteration 4820, avg_grad_norm = 740248
I0314 18:47:49.285444 29479 solver.cpp:214] Iteration 4840, loss = 8934.7
I0314 18:47:49.285698 29479 solver.cpp:229]     Train net output #0: loss = 7131.65 (* 1 = 7131.65 loss)
I0314 18:47:49.462793 29479 solver.cpp:610] Iteration 4840, lr = 9.78193e-09
I0314 18:47:49.462810 29479 solver.cpp:613] Iteration 4840, avg_grad_norm = 711698
I0314 18:48:53.197340 29479 solver.cpp:214] Iteration 4860, loss = 9322.8
I0314 18:48:53.197528 29479 solver.cpp:229]     Train net output #0: loss = 8653.33 (* 1 = 8653.33 loss)
I0314 18:48:53.561039 29479 solver.cpp:610] Iteration 4860, lr = 9.78103e-09
I0314 18:48:53.561053 29479 solver.cpp:613] Iteration 4860, avg_grad_norm = 780294
I0314 18:49:57.280869 29479 solver.cpp:214] Iteration 4880, loss = 9012.93
I0314 18:49:57.281107 29479 solver.cpp:229]     Train net output #0: loss = 7248.27 (* 1 = 7248.27 loss)
I0314 18:49:57.644278 29479 solver.cpp:610] Iteration 4880, lr = 9.78013e-09
I0314 18:49:57.644299 29479 solver.cpp:613] Iteration 4880, avg_grad_norm = 734663
I0314 18:51:01.212936 29479 solver.cpp:214] Iteration 4900, loss = 9141.68
I0314 18:51:01.213132 29479 solver.cpp:229]     Train net output #0: loss = 6362.79 (* 1 = 6362.79 loss)
I0314 18:51:01.581195 29479 solver.cpp:610] Iteration 4900, lr = 9.77923e-09
I0314 18:51:01.581208 29479 solver.cpp:613] Iteration 4900, avg_grad_norm = 773201
I0314 18:52:05.086009 29479 solver.cpp:214] Iteration 4920, loss = 8553.35
I0314 18:52:05.086233 29479 solver.cpp:229]     Train net output #0: loss = 7755.96 (* 1 = 7755.96 loss)
I0314 18:52:05.458045 29479 solver.cpp:610] Iteration 4920, lr = 9.77832e-09
I0314 18:52:05.458058 29479 solver.cpp:613] Iteration 4920, avg_grad_norm = 717082
I0314 18:52:37.160982 29479 solver.cpp:214] Iteration 4940, loss = 8706.04
I0314 18:52:37.161151 29479 solver.cpp:229]     Train net output #0: loss = 11079.6 (* 1 = 11079.6 loss)
I0314 18:52:37.277195 29479 solver.cpp:610] Iteration 4940, lr = 9.77742e-09
I0314 18:52:37.277209 29479 solver.cpp:613] Iteration 4940, avg_grad_norm = 681889
I0314 18:53:53.268966 29479 solver.cpp:214] Iteration 4960, loss = 8518.32
I0314 18:53:53.269172 29479 solver.cpp:229]     Train net output #0: loss = 8812.4 (* 1 = 8812.4 loss)
I0314 18:53:53.484902 29479 solver.cpp:610] Iteration 4960, lr = 9.77652e-09
I0314 18:53:53.484916 29479 solver.cpp:613] Iteration 4960, avg_grad_norm = 740326
I0314 18:54:57.291571 29479 solver.cpp:214] Iteration 4980, loss = 8746.04
I0314 18:54:57.291780 29479 solver.cpp:229]     Train net output #0: loss = 8794.15 (* 1 = 8794.15 loss)
I0314 18:54:57.495509 29479 solver.cpp:610] Iteration 4980, lr = 9.77562e-09
I0314 18:54:57.495522 29479 solver.cpp:613] Iteration 4980, avg_grad_norm = 665709
I0314 18:56:01.053504 29479 solver.cpp:214] Iteration 5000, loss = 9026.08
I0314 18:56:01.053647 29479 solver.cpp:229]     Train net output #0: loss = 11373.9 (* 1 = 11373.9 loss)
I0314 18:56:01.417917 29479 solver.cpp:610] Iteration 5000, lr = 9.77472e-09
I0314 18:56:01.417930 29479 solver.cpp:613] Iteration 5000, avg_grad_norm = 804757
I0314 18:57:05.084050 29479 solver.cpp:214] Iteration 5020, loss = 8379.91
I0314 18:57:05.084239 29479 solver.cpp:229]     Train net output #0: loss = 11659 (* 1 = 11659 loss)
I0314 18:57:05.289669 29479 solver.cpp:610] Iteration 5020, lr = 9.77381e-09
I0314 18:57:05.289682 29479 solver.cpp:613] Iteration 5020, avg_grad_norm = 753498
I0314 18:58:08.964690 29479 solver.cpp:214] Iteration 5040, loss = 8673.12
I0314 18:58:08.964957 29479 solver.cpp:229]     Train net output #0: loss = 8520.17 (* 1 = 8520.17 loss)
I0314 18:58:09.322880 29479 solver.cpp:610] Iteration 5040, lr = 9.77291e-09
I0314 18:58:09.322897 29479 solver.cpp:613] Iteration 5040, avg_grad_norm = 775283
I0314 18:59:12.791772 29479 solver.cpp:214] Iteration 5060, loss = 9061.94
I0314 18:59:12.791985 29479 solver.cpp:229]     Train net output #0: loss = 11108.1 (* 1 = 11108.1 loss)
I0314 18:59:13.150127 29479 solver.cpp:610] Iteration 5060, lr = 9.77201e-09
I0314 18:59:13.150141 29479 solver.cpp:613] Iteration 5060, avg_grad_norm = 805847
I0314 19:00:42.488279 29479 solver.cpp:214] Iteration 5080, loss = 8926.23
I0314 19:00:42.488500 29479 solver.cpp:229]     Train net output #0: loss = 7209.88 (* 1 = 7209.88 loss)
I0314 19:00:42.592850 29479 solver.cpp:610] Iteration 5080, lr = 9.77111e-09
I0314 19:00:42.592864 29479 solver.cpp:613] Iteration 5080, avg_grad_norm = 679748
I0314 19:01:44.516463 29479 solver.cpp:214] Iteration 5100, loss = 8693.72
I0314 19:01:44.516607 29479 solver.cpp:229]     Train net output #0: loss = 6097.39 (* 1 = 6097.39 loss)
I0314 19:01:44.873234 29479 solver.cpp:610] Iteration 5100, lr = 9.7702e-09
I0314 19:01:44.873246 29479 solver.cpp:613] Iteration 5100, avg_grad_norm = 775628
I0314 19:02:47.171990 29479 solver.cpp:214] Iteration 5120, loss = 8924.15
I0314 19:02:47.172135 29479 solver.cpp:229]     Train net output #0: loss = 7645.75 (* 1 = 7645.75 loss)
I0314 19:02:47.530369 29479 solver.cpp:610] Iteration 5120, lr = 9.7693e-09
I0314 19:02:47.530380 29479 solver.cpp:613] Iteration 5120, avg_grad_norm = 715179
I0314 19:03:50.338704 29479 solver.cpp:214] Iteration 5140, loss = 8515.29
I0314 19:03:50.338840 29479 solver.cpp:229]     Train net output #0: loss = 12357.3 (* 1 = 12357.3 loss)
I0314 19:03:50.695466 29479 solver.cpp:610] Iteration 5140, lr = 9.7684e-09
I0314 19:03:50.695478 29479 solver.cpp:613] Iteration 5140, avg_grad_norm = 778074
I0314 19:04:53.690153 29479 solver.cpp:214] Iteration 5160, loss = 8359.3
I0314 19:04:53.690268 29479 solver.cpp:229]     Train net output #0: loss = 8901.94 (* 1 = 8901.94 loss)
I0314 19:04:53.887480 29479 solver.cpp:610] Iteration 5160, lr = 9.7675e-09
I0314 19:04:53.887491 29479 solver.cpp:613] Iteration 5160, avg_grad_norm = 705233
I0314 19:05:56.381327 29479 solver.cpp:214] Iteration 5180, loss = 8355.97
I0314 19:05:56.381467 29479 solver.cpp:229]     Train net output #0: loss = 7577.96 (* 1 = 7577.96 loss)
I0314 19:05:56.486387 29479 solver.cpp:610] Iteration 5180, lr = 9.7666e-09
I0314 19:05:56.486400 29479 solver.cpp:613] Iteration 5180, avg_grad_norm = 680859
I0314 19:06:56.864404 29479 solver.cpp:214] Iteration 5200, loss = 8845.29
I0314 19:06:56.864509 29479 solver.cpp:229]     Train net output #0: loss = 7723.96 (* 1 = 7723.96 loss)
I0314 19:06:57.067308 29479 solver.cpp:610] Iteration 5200, lr = 9.76569e-09
I0314 19:06:57.067322 29479 solver.cpp:613] Iteration 5200, avg_grad_norm = 750475
I0314 19:08:13.443275 29479 solver.cpp:214] Iteration 5220, loss = 8562.21
I0314 19:08:13.443483 29479 solver.cpp:229]     Train net output #0: loss = 9515.12 (* 1 = 9515.12 loss)
I0314 19:08:13.548408 29479 solver.cpp:610] Iteration 5220, lr = 9.76479e-09
I0314 19:08:13.548421 29479 solver.cpp:613] Iteration 5220, avg_grad_norm = 847343
I0314 19:08:58.866520 29479 solver.cpp:214] Iteration 5240, loss = 8587.27
I0314 19:08:58.866704 29479 solver.cpp:229]     Train net output #0: loss = 9572.85 (* 1 = 9572.85 loss)
I0314 19:08:59.224195 29479 solver.cpp:610] Iteration 5240, lr = 9.76389e-09
I0314 19:08:59.224208 29479 solver.cpp:613] Iteration 5240, avg_grad_norm = 964042
I0314 19:10:02.299984 29479 solver.cpp:214] Iteration 5260, loss = 8589.52
I0314 19:10:02.300195 29479 solver.cpp:229]     Train net output #0: loss = 6060.91 (* 1 = 6060.91 loss)
I0314 19:10:02.669751 29479 solver.cpp:610] Iteration 5260, lr = 9.76299e-09
I0314 19:10:02.669764 29479 solver.cpp:613] Iteration 5260, avg_grad_norm = 701574
I0314 19:11:05.688451 29479 solver.cpp:214] Iteration 5280, loss = 8724.62
I0314 19:11:05.688694 29479 solver.cpp:229]     Train net output #0: loss = 9652.23 (* 1 = 9652.23 loss)
I0314 19:11:06.047814 29479 solver.cpp:610] Iteration 5280, lr = 9.76208e-09
I0314 19:11:06.047828 29479 solver.cpp:613] Iteration 5280, avg_grad_norm = 663849
I0314 19:12:09.265856 29479 solver.cpp:214] Iteration 5300, loss = 8283.44
I0314 19:12:09.266140 29479 solver.cpp:229]     Train net output #0: loss = 13466.4 (* 1 = 13466.4 loss)
I0314 19:12:09.639164 29479 solver.cpp:610] Iteration 5300, lr = 9.76118e-09
I0314 19:12:09.639204 29479 solver.cpp:613] Iteration 5300, avg_grad_norm = 756808
I0314 19:13:12.982287 29479 solver.cpp:214] Iteration 5320, loss = 8630.68
I0314 19:13:12.982425 29479 solver.cpp:229]     Train net output #0: loss = 4555.49 (* 1 = 4555.49 loss)
I0314 19:13:13.339978 29479 solver.cpp:610] Iteration 5320, lr = 9.76028e-09
I0314 19:13:13.339992 29479 solver.cpp:613] Iteration 5320, avg_grad_norm = 798322
I0314 19:14:29.014359 29479 solver.cpp:214] Iteration 5340, loss = 8697.91
I0314 19:14:29.014572 29479 solver.cpp:229]     Train net output #0: loss = 11649.1 (* 1 = 11649.1 loss)
I0314 19:14:29.379261 29479 solver.cpp:610] Iteration 5340, lr = 9.75938e-09
I0314 19:14:29.379276 29479 solver.cpp:613] Iteration 5340, avg_grad_norm = 766242
I0314 19:15:32.845863 29479 solver.cpp:214] Iteration 5360, loss = 8821.04
I0314 19:15:32.845994 29479 solver.cpp:229]     Train net output #0: loss = 11515.2 (* 1 = 11515.2 loss)
I0314 19:15:33.204077 29479 solver.cpp:610] Iteration 5360, lr = 9.75847e-09
I0314 19:15:33.204089 29479 solver.cpp:613] Iteration 5360, avg_grad_norm = 772586
I0314 19:16:13.688026 29479 solver.cpp:214] Iteration 5380, loss = 8335.88
I0314 19:16:13.688217 29479 solver.cpp:229]     Train net output #0: loss = 6839.66 (* 1 = 6839.66 loss)
I0314 19:16:13.805991 29479 solver.cpp:610] Iteration 5380, lr = 9.75757e-09
I0314 19:16:13.806004 29479 solver.cpp:613] Iteration 5380, avg_grad_norm = 708964
I0314 19:17:13.027323 29479 solver.cpp:214] Iteration 5400, loss = 8591.05
I0314 19:17:13.027454 29479 solver.cpp:229]     Train net output #0: loss = 9901.21 (* 1 = 9901.21 loss)
I0314 19:17:13.240460 29479 solver.cpp:610] Iteration 5400, lr = 9.75667e-09
I0314 19:17:13.240474 29479 solver.cpp:613] Iteration 5400, avg_grad_norm = 843676
I0314 19:18:17.028141 29479 solver.cpp:214] Iteration 5420, loss = 8793.83
I0314 19:18:17.028282 29479 solver.cpp:229]     Train net output #0: loss = 15184 (* 1 = 15184 loss)
I0314 19:18:17.225949 29479 solver.cpp:610] Iteration 5420, lr = 9.75577e-09
I0314 19:18:17.225961 29479 solver.cpp:613] Iteration 5420, avg_grad_norm = 678074
I0314 19:19:20.554183 29479 solver.cpp:214] Iteration 5440, loss = 9060.56
I0314 19:19:20.554365 29479 solver.cpp:229]     Train net output #0: loss = 11028.9 (* 1 = 11028.9 loss)
I0314 19:19:20.923764 29479 solver.cpp:610] Iteration 5440, lr = 9.75486e-09
I0314 19:19:20.923779 29479 solver.cpp:613] Iteration 5440, avg_grad_norm = 736718
I0314 19:20:38.377416 29479 solver.cpp:214] Iteration 5460, loss = 8660.67
I0314 19:20:38.377593 29479 solver.cpp:229]     Train net output #0: loss = 6782.99 (* 1 = 6782.99 loss)
I0314 19:20:38.576659 29479 solver.cpp:610] Iteration 5460, lr = 9.75396e-09
I0314 19:20:38.576673 29479 solver.cpp:613] Iteration 5460, avg_grad_norm = 695258
I0314 19:21:42.394747 29479 solver.cpp:214] Iteration 5480, loss = 8440.16
I0314 19:21:42.394896 29479 solver.cpp:229]     Train net output #0: loss = 5980.46 (* 1 = 5980.46 loss)
I0314 19:21:42.603126 29479 solver.cpp:610] Iteration 5480, lr = 9.75306e-09
I0314 19:21:42.603138 29479 solver.cpp:613] Iteration 5480, avg_grad_norm = 789828
I0314 19:22:46.309224 29479 solver.cpp:214] Iteration 5500, loss = 8559.59
I0314 19:22:46.309347 29479 solver.cpp:229]     Train net output #0: loss = 10919.7 (* 1 = 10919.7 loss)
I0314 19:22:46.666422 29479 solver.cpp:610] Iteration 5500, lr = 9.75216e-09
I0314 19:22:46.666435 29479 solver.cpp:613] Iteration 5500, avg_grad_norm = 898709
I0314 19:23:50.290215 29479 solver.cpp:214] Iteration 5520, loss = 8648.03
I0314 19:23:50.290377 29479 solver.cpp:229]     Train net output #0: loss = 7575.34 (* 1 = 7575.34 loss)
I0314 19:23:50.651057 29479 solver.cpp:610] Iteration 5520, lr = 9.75125e-09
I0314 19:23:50.651068 29479 solver.cpp:613] Iteration 5520, avg_grad_norm = 933915
I0314 19:24:32.574568 29479 solver.cpp:214] Iteration 5540, loss = 8516.32
I0314 19:24:32.574741 29479 solver.cpp:229]     Train net output #0: loss = 9098.2 (* 1 = 9098.2 loss)
I0314 19:24:32.940740 29479 solver.cpp:610] Iteration 5540, lr = 9.75035e-09
I0314 19:24:32.940754 29479 solver.cpp:613] Iteration 5540, avg_grad_norm = 770417
I0314 19:25:36.663885 29479 solver.cpp:214] Iteration 5560, loss = 8363.8
I0314 19:25:36.664026 29479 solver.cpp:229]     Train net output #0: loss = 10935.9 (* 1 = 10935.9 loss)
I0314 19:25:37.028133 29479 solver.cpp:610] Iteration 5560, lr = 9.74945e-09
I0314 19:25:37.028148 29479 solver.cpp:613] Iteration 5560, avg_grad_norm = 679610
I0314 19:26:40.691560 29479 solver.cpp:214] Iteration 5580, loss = 8539.01
I0314 19:26:40.691701 29479 solver.cpp:229]     Train net output #0: loss = 7757.27 (* 1 = 7757.27 loss)
I0314 19:26:40.892280 29479 solver.cpp:610] Iteration 5580, lr = 9.74855e-09
I0314 19:26:40.892294 29479 solver.cpp:613] Iteration 5580, avg_grad_norm = 732911
I0314 19:28:19.133507 29479 solver.cpp:214] Iteration 5600, loss = 8629.01
I0314 19:28:19.133692 29479 solver.cpp:229]     Train net output #0: loss = 7733.51 (* 1 = 7733.51 loss)
I0314 19:28:19.518456 29479 solver.cpp:610] Iteration 5600, lr = 9.74764e-09
I0314 19:28:19.518476 29479 solver.cpp:613] Iteration 5600, avg_grad_norm = 777542
I0314 19:29:23.319527 29479 solver.cpp:214] Iteration 5620, loss = 8554.48
I0314 19:29:23.319670 29479 solver.cpp:229]     Train net output #0: loss = 10686.1 (* 1 = 10686.1 loss)
I0314 19:29:23.683382 29479 solver.cpp:610] Iteration 5620, lr = 9.74674e-09
I0314 19:29:23.683396 29479 solver.cpp:613] Iteration 5620, avg_grad_norm = 710043
I0314 19:30:27.245412 29479 solver.cpp:214] Iteration 5640, loss = 8310.61
I0314 19:30:27.245571 29479 solver.cpp:229]     Train net output #0: loss = 8604.23 (* 1 = 8604.23 loss)
I0314 19:30:27.603852 29479 solver.cpp:610] Iteration 5640, lr = 9.74584e-09
I0314 19:30:27.603868 29479 solver.cpp:613] Iteration 5640, avg_grad_norm = 668553
I0314 19:31:28.278961 29479 solver.cpp:214] Iteration 5660, loss = 8150.31
I0314 19:31:28.279194 29479 solver.cpp:229]     Train net output #0: loss = 8003.96 (* 1 = 8003.96 loss)
I0314 19:31:28.390640 29479 solver.cpp:610] Iteration 5660, lr = 9.74494e-09
I0314 19:31:28.390655 29479 solver.cpp:613] Iteration 5660, avg_grad_norm = 684977
I0314 19:32:10.361544 29479 solver.cpp:214] Iteration 5680, loss = 8420.58
I0314 19:32:10.361753 29479 solver.cpp:229]     Train net output #0: loss = 7341.76 (* 1 = 7341.76 loss)
I0314 19:32:10.736829 29479 solver.cpp:610] Iteration 5680, lr = 9.74403e-09
I0314 19:32:10.736845 29479 solver.cpp:613] Iteration 5680, avg_grad_norm = 624740
I0314 19:33:14.631080 29479 solver.cpp:214] Iteration 5700, loss = 8674.4
I0314 19:33:14.631288 29479 solver.cpp:229]     Train net output #0: loss = 5904.42 (* 1 = 5904.42 loss)
I0314 19:33:14.839542 29479 solver.cpp:610] Iteration 5700, lr = 9.74313e-09
I0314 19:33:14.839556 29479 solver.cpp:613] Iteration 5700, avg_grad_norm = 727525
I0314 19:34:31.743393 29479 solver.cpp:214] Iteration 5720, loss = 8427.38
I0314 19:34:31.743535 29479 solver.cpp:229]     Train net output #0: loss = 6229.39 (* 1 = 6229.39 loss)
I0314 19:34:32.107381 29479 solver.cpp:610] Iteration 5720, lr = 9.74223e-09
I0314 19:34:32.107394 29479 solver.cpp:613] Iteration 5720, avg_grad_norm = 715996
I0314 19:35:35.978202 29479 solver.cpp:214] Iteration 5740, loss = 8557.52
I0314 19:35:35.978361 29479 solver.cpp:229]     Train net output #0: loss = 6637.87 (* 1 = 6637.87 loss)
I0314 19:35:36.191196 29479 solver.cpp:610] Iteration 5740, lr = 9.74133e-09
I0314 19:35:36.191208 29479 solver.cpp:613] Iteration 5740, avg_grad_norm = 624380
I0314 19:36:39.715361 29479 solver.cpp:214] Iteration 5760, loss = 8645.37
I0314 19:36:39.715561 29479 solver.cpp:229]     Train net output #0: loss = 7087.04 (* 1 = 7087.04 loss)
I0314 19:36:40.081818 29479 solver.cpp:610] Iteration 5760, lr = 9.74042e-09
I0314 19:36:40.081832 29479 solver.cpp:613] Iteration 5760, avg_grad_norm = 773672
I0314 19:37:43.806396 29479 solver.cpp:214] Iteration 5780, loss = 8166.93
I0314 19:37:43.806552 29479 solver.cpp:229]     Train net output #0: loss = 12329.9 (* 1 = 12329.9 loss)
I0314 19:37:44.011872 29479 solver.cpp:610] Iteration 5780, lr = 9.73952e-09
I0314 19:37:44.011884 29479 solver.cpp:613] Iteration 5780, avg_grad_norm = 732713
I0314 19:38:47.623550 29479 solver.cpp:214] Iteration 5800, loss = 8560.56
I0314 19:38:47.623678 29479 solver.cpp:229]     Train net output #0: loss = 9738.37 (* 1 = 9738.37 loss)
I0314 19:38:47.987126 29479 solver.cpp:610] Iteration 5800, lr = 9.73862e-09
I0314 19:38:47.987139 29479 solver.cpp:613] Iteration 5800, avg_grad_norm = 673205
I0314 19:39:32.305477 29479 solver.cpp:214] Iteration 5820, loss = 8387.87
I0314 19:39:32.305621 29479 solver.cpp:229]     Train net output #0: loss = 6941.45 (* 1 = 6941.45 loss)
I0314 19:39:32.423311 29479 solver.cpp:610] Iteration 5820, lr = 9.73771e-09
I0314 19:39:32.423324 29479 solver.cpp:613] Iteration 5820, avg_grad_norm = 716138
I0314 19:40:34.746351 29479 solver.cpp:214] Iteration 5840, loss = 8544.4
I0314 19:40:34.746558 29479 solver.cpp:229]     Train net output #0: loss = 7982.48 (* 1 = 7982.48 loss)
I0314 19:40:35.110785 29479 solver.cpp:610] Iteration 5840, lr = 9.73681e-09
I0314 19:40:35.110798 29479 solver.cpp:613] Iteration 5840, avg_grad_norm = 737049
I0314 19:41:51.147161 29479 solver.cpp:214] Iteration 5860, loss = 8203
I0314 19:41:51.147336 29479 solver.cpp:229]     Train net output #0: loss = 6956.67 (* 1 = 6956.67 loss)
I0314 19:41:51.511061 29479 solver.cpp:610] Iteration 5860, lr = 9.73591e-09
I0314 19:41:51.511075 29479 solver.cpp:613] Iteration 5860, avg_grad_norm = 678135
I0314 19:42:55.192394 29479 solver.cpp:214] Iteration 5880, loss = 8370.43
I0314 19:42:55.192551 29479 solver.cpp:229]     Train net output #0: loss = 11618.4 (* 1 = 11618.4 loss)
I0314 19:42:55.557013 29479 solver.cpp:610] Iteration 5880, lr = 9.73501e-09
I0314 19:42:55.557026 29479 solver.cpp:613] Iteration 5880, avg_grad_norm = 858721
I0314 19:43:59.137819 29479 solver.cpp:214] Iteration 5900, loss = 8945.92
I0314 19:43:59.137938 29479 solver.cpp:229]     Train net output #0: loss = 11774.4 (* 1 = 11774.4 loss)
I0314 19:43:59.500790 29479 solver.cpp:610] Iteration 5900, lr = 9.7341e-09
I0314 19:43:59.500803 29479 solver.cpp:613] Iteration 5900, avg_grad_norm = 915783
I0314 19:45:03.058835 29479 solver.cpp:214] Iteration 5920, loss = 8505.76
I0314 19:45:03.058974 29479 solver.cpp:229]     Train net output #0: loss = 9124.03 (* 1 = 9124.03 loss)
I0314 19:45:03.417099 29479 solver.cpp:610] Iteration 5920, lr = 9.7332e-09
I0314 19:45:03.417112 29479 solver.cpp:613] Iteration 5920, avg_grad_norm = 787132
I0314 19:46:06.845791 29479 solver.cpp:214] Iteration 5940, loss = 8399.42
I0314 19:46:06.845976 29479 solver.cpp:229]     Train net output #0: loss = 7863 (* 1 = 7863 loss)
I0314 19:46:07.204388 29479 solver.cpp:610] Iteration 5940, lr = 9.7323e-09
I0314 19:46:07.204401 29479 solver.cpp:613] Iteration 5940, avg_grad_norm = 795152
I0314 19:47:10.172986 29479 solver.cpp:214] Iteration 5960, loss = 8778.59
I0314 19:47:10.173153 29479 solver.cpp:229]     Train net output #0: loss = 12871.4 (* 1 = 12871.4 loss)
I0314 19:47:10.278184 29479 solver.cpp:610] Iteration 5960, lr = 9.7314e-09
I0314 19:47:10.278198 29479 solver.cpp:613] Iteration 5960, avg_grad_norm = 752729
I0314 19:48:46.107264 29479 solver.cpp:214] Iteration 5980, loss = 8640.88
I0314 19:48:46.107393 29479 solver.cpp:229]     Train net output #0: loss = 14458.1 (* 1 = 14458.1 loss)
I0314 19:48:46.463843 29479 solver.cpp:610] Iteration 5980, lr = 9.73049e-09
I0314 19:48:46.463856 29479 solver.cpp:613] Iteration 5980, avg_grad_norm = 772521
I0314 19:49:48.671418 29479 solver.cpp:214] Iteration 6000, loss = 8391.28
I0314 19:49:48.671556 29479 solver.cpp:229]     Train net output #0: loss = 7009.33 (* 1 = 7009.33 loss)
I0314 19:49:49.025754 29479 solver.cpp:610] Iteration 6000, lr = 9.72959e-09
I0314 19:49:49.025768 29479 solver.cpp:613] Iteration 6000, avg_grad_norm = 702889
I0314 19:50:51.547703 29479 solver.cpp:214] Iteration 6020, loss = 8410.58
I0314 19:50:51.547899 29479 solver.cpp:229]     Train net output #0: loss = 8052.5 (* 1 = 8052.5 loss)
I0314 19:50:51.904459 29479 solver.cpp:610] Iteration 6020, lr = 9.72869e-09
I0314 19:50:51.904474 29479 solver.cpp:613] Iteration 6020, avg_grad_norm = 689417
I0314 19:51:54.721956 29479 solver.cpp:214] Iteration 6040, loss = 8259.57
I0314 19:51:54.723228 29479 solver.cpp:229]     Train net output #0: loss = 6874.84 (* 1 = 6874.84 loss)
I0314 19:51:55.080529 29479 solver.cpp:610] Iteration 6040, lr = 9.72778e-09
I0314 19:51:55.080543 29479 solver.cpp:613] Iteration 6040, avg_grad_norm = 720241
I0314 19:52:58.097461 29479 solver.cpp:214] Iteration 6060, loss = 8853.59
I0314 19:52:58.097647 29479 solver.cpp:229]     Train net output #0: loss = 8697.97 (* 1 = 8697.97 loss)
I0314 19:52:58.310129 29479 solver.cpp:610] Iteration 6060, lr = 9.72688e-09
I0314 19:52:58.310142 29479 solver.cpp:613] Iteration 6060, avg_grad_norm = 817942
I0314 19:54:01.216280 29479 solver.cpp:214] Iteration 6080, loss = 8427.26
I0314 19:54:01.216410 29479 solver.cpp:229]     Train net output #0: loss = 5719.96 (* 1 = 5719.96 loss)
I0314 19:54:01.573492 29479 solver.cpp:610] Iteration 6080, lr = 9.72598e-09
I0314 19:54:01.573504 29479 solver.cpp:613] Iteration 6080, avg_grad_norm = 778906
I0314 19:55:17.285801 29479 solver.cpp:214] Iteration 6100, loss = 8900.77
I0314 19:55:17.285967 29479 solver.cpp:229]     Train net output #0: loss = 8981.53 (* 1 = 8981.53 loss)
I0314 19:55:17.391108 29479 solver.cpp:610] Iteration 6100, lr = 9.72508e-09
I0314 19:55:17.391121 29479 solver.cpp:613] Iteration 6100, avg_grad_norm = 858049
I0314 19:56:02.324405 29479 solver.cpp:214] Iteration 6120, loss = 8534.21
I0314 19:56:02.324525 29479 solver.cpp:229]     Train net output #0: loss = 6262.45 (* 1 = 6262.45 loss)
I0314 19:56:02.682271 29479 solver.cpp:610] Iteration 6120, lr = 9.72417e-09
I0314 19:56:02.682283 29479 solver.cpp:613] Iteration 6120, avg_grad_norm = 820862
I0314 19:57:05.729235 29479 solver.cpp:214] Iteration 6140, loss = 8316.95
I0314 19:57:05.729357 29479 solver.cpp:229]     Train net output #0: loss = 8348.27 (* 1 = 8348.27 loss)
I0314 19:57:06.087559 29479 solver.cpp:610] Iteration 6140, lr = 9.72327e-09
I0314 19:57:06.087574 29479 solver.cpp:613] Iteration 6140, avg_grad_norm = 758266
I0314 19:58:09.122227 29479 solver.cpp:214] Iteration 6160, loss = 8714.67
I0314 19:58:09.122359 29479 solver.cpp:229]     Train net output #0: loss = 5334.18 (* 1 = 5334.18 loss)
I0314 19:58:09.483145 29479 solver.cpp:610] Iteration 6160, lr = 9.72237e-09
I0314 19:58:09.483160 29479 solver.cpp:613] Iteration 6160, avg_grad_norm = 771778
I0314 19:59:12.661427 29479 solver.cpp:214] Iteration 6180, loss = 7964.19
I0314 19:59:12.661551 29479 solver.cpp:229]     Train net output #0: loss = 11687.6 (* 1 = 11687.6 loss)
I0314 19:59:13.019284 29479 solver.cpp:610] Iteration 6180, lr = 9.72147e-09
I0314 19:59:13.019296 29479 solver.cpp:613] Iteration 6180, avg_grad_norm = 747008
I0314 20:00:16.312716 29479 solver.cpp:214] Iteration 6200, loss = 8492.71
I0314 20:00:16.312837 29479 solver.cpp:229]     Train net output #0: loss = 8845.58 (* 1 = 8845.58 loss)
I0314 20:00:16.676244 29479 solver.cpp:610] Iteration 6200, lr = 9.72056e-09
I0314 20:00:16.676256 29479 solver.cpp:613] Iteration 6200, avg_grad_norm = 800188
I0314 20:01:20.296178 29479 solver.cpp:214] Iteration 6220, loss = 8369.77
I0314 20:01:20.296356 29479 solver.cpp:229]     Train net output #0: loss = 5720.27 (* 1 = 5720.27 loss)
I0314 20:01:20.498492 29479 solver.cpp:610] Iteration 6220, lr = 9.71966e-09
I0314 20:01:20.498505 29479 solver.cpp:613] Iteration 6220, avg_grad_norm = 769645
I0314 20:02:46.339535 29479 solver.cpp:214] Iteration 6240, loss = 8090.51
I0314 20:02:46.339751 29479 solver.cpp:229]     Train net output #0: loss = 3683.83 (* 1 = 3683.83 loss)
I0314 20:02:46.705282 29479 solver.cpp:610] Iteration 6240, lr = 9.71876e-09
I0314 20:02:46.705296 29479 solver.cpp:613] Iteration 6240, avg_grad_norm = 817640
I0314 20:03:27.670804 29479 solver.cpp:214] Iteration 6260, loss = 8144.58
I0314 20:03:27.670985 29479 solver.cpp:229]     Train net output #0: loss = 14118.8 (* 1 = 14118.8 loss)
I0314 20:03:28.034054 29479 solver.cpp:610] Iteration 6260, lr = 9.71785e-09
I0314 20:03:28.034070 29479 solver.cpp:613] Iteration 6260, avg_grad_norm = 744525
I0314 20:04:34.645881 29479 solver.cpp:214] Iteration 6280, loss = 8191.59
I0314 20:04:34.646039 29479 solver.cpp:229]     Train net output #0: loss = 5754.44 (* 1 = 5754.44 loss)
I0314 20:04:35.003073 29479 solver.cpp:610] Iteration 6280, lr = 9.71695e-09
I0314 20:04:35.003087 29479 solver.cpp:613] Iteration 6280, avg_grad_norm = 755018
I0314 20:05:38.692023 29479 solver.cpp:214] Iteration 6300, loss = 8679.28
I0314 20:05:38.692144 29479 solver.cpp:229]     Train net output #0: loss = 11206.8 (* 1 = 11206.8 loss)
I0314 20:05:39.056166 29479 solver.cpp:610] Iteration 6300, lr = 9.71605e-09
I0314 20:05:39.056180 29479 solver.cpp:613] Iteration 6300, avg_grad_norm = 775559
I0314 20:06:42.630523 29479 solver.cpp:214] Iteration 6320, loss = 8176
I0314 20:06:42.630637 29479 solver.cpp:229]     Train net output #0: loss = 5886.17 (* 1 = 5886.17 loss)
I0314 20:06:42.990272 29479 solver.cpp:610] Iteration 6320, lr = 9.71515e-09
I0314 20:06:42.990284 29479 solver.cpp:613] Iteration 6320, avg_grad_norm = 692375
I0314 20:07:46.726680 29479 solver.cpp:214] Iteration 6340, loss = 8575.9
I0314 20:07:46.726781 29479 solver.cpp:229]     Train net output #0: loss = 13264.8 (* 1 = 13264.8 loss)
I0314 20:07:46.942270 29479 solver.cpp:610] Iteration 6340, lr = 9.71424e-09
I0314 20:07:46.942284 29479 solver.cpp:613] Iteration 6340, avg_grad_norm = 707173
I0314 20:09:03.110465 29479 solver.cpp:214] Iteration 6360, loss = 8345.93
I0314 20:09:03.110672 29479 solver.cpp:229]     Train net output #0: loss = 8067.35 (* 1 = 8067.35 loss)
I0314 20:09:03.314538 29479 solver.cpp:610] Iteration 6360, lr = 9.71334e-09
I0314 20:09:03.314551 29479 solver.cpp:613] Iteration 6360, avg_grad_norm = 702533
I0314 20:10:07.737638 29479 solver.cpp:214] Iteration 6380, loss = 8505.61
I0314 20:10:07.737761 29479 solver.cpp:229]     Train net output #0: loss = 7767.97 (* 1 = 7767.97 loss)
I0314 20:10:08.097440 29479 solver.cpp:610] Iteration 6380, lr = 9.71244e-09
I0314 20:10:08.097456 29479 solver.cpp:613] Iteration 6380, avg_grad_norm = 700212
I0314 20:10:55.597283 29479 solver.cpp:214] Iteration 6400, loss = 7939.31
I0314 20:10:55.597440 29479 solver.cpp:229]     Train net output #0: loss = 5727.1 (* 1 = 5727.1 loss)
I0314 20:10:55.713367 29479 solver.cpp:610] Iteration 6400, lr = 9.71153e-09
I0314 20:10:55.713381 29479 solver.cpp:613] Iteration 6400, avg_grad_norm = 692061
I0314 20:11:58.352278 29479 solver.cpp:214] Iteration 6420, loss = 7902.23
I0314 20:11:58.352468 29479 solver.cpp:229]     Train net output #0: loss = 6038.52 (* 1 = 6038.52 loss)
I0314 20:11:58.568248 29479 solver.cpp:610] Iteration 6420, lr = 9.71063e-09
I0314 20:11:58.568260 29479 solver.cpp:613] Iteration 6420, avg_grad_norm = 665141
I0314 20:13:02.235497 29479 solver.cpp:214] Iteration 6440, loss = 8371.8
I0314 20:13:02.235618 29479 solver.cpp:229]     Train net output #0: loss = 5180.43 (* 1 = 5180.43 loss)
I0314 20:13:02.451113 29479 solver.cpp:610] Iteration 6440, lr = 9.70973e-09
I0314 20:13:02.451127 29479 solver.cpp:613] Iteration 6440, avg_grad_norm = 702101
I0314 20:14:06.134349 29479 solver.cpp:214] Iteration 6460, loss = 8425.42
I0314 20:14:06.134486 29479 solver.cpp:229]     Train net output #0: loss = 7546.98 (* 1 = 7546.98 loss)
I0314 20:14:06.500084 29479 solver.cpp:610] Iteration 6460, lr = 9.70882e-09
I0314 20:14:06.500097 29479 solver.cpp:613] Iteration 6460, avg_grad_norm = 731871
I0314 20:15:25.237779 29479 solver.cpp:214] Iteration 6480, loss = 8522.7
I0314 20:15:25.237943 29479 solver.cpp:229]     Train net output #0: loss = 6244.85 (* 1 = 6244.85 loss)
I0314 20:15:25.443492 29479 solver.cpp:610] Iteration 6480, lr = 9.70792e-09
I0314 20:15:25.443516 29479 solver.cpp:613] Iteration 6480, avg_grad_norm = 738146
I0314 20:16:29.317392 29479 solver.cpp:214] Iteration 6500, loss = 8282.71
I0314 20:16:29.317577 29479 solver.cpp:229]     Train net output #0: loss = 8772.87 (* 1 = 8772.87 loss)
I0314 20:16:29.525279 29479 solver.cpp:610] Iteration 6500, lr = 9.70702e-09
I0314 20:16:29.525292 29479 solver.cpp:613] Iteration 6500, avg_grad_norm = 772435
I0314 20:17:33.245275 29479 solver.cpp:214] Iteration 6520, loss = 8291.61
I0314 20:17:33.245465 29479 solver.cpp:229]     Train net output #0: loss = 10430.4 (* 1 = 10430.4 loss)
I0314 20:17:33.451836 29479 solver.cpp:610] Iteration 6520, lr = 9.70612e-09
I0314 20:17:33.451859 29479 solver.cpp:613] Iteration 6520, avg_grad_norm = 721617
I0314 20:18:34.015377 29479 solver.cpp:214] Iteration 6540, loss = 8965.92
I0314 20:18:34.015503 29479 solver.cpp:229]     Train net output #0: loss = 9137.04 (* 1 = 9137.04 loss)
I0314 20:18:34.122004 29479 solver.cpp:610] Iteration 6540, lr = 9.70521e-09
I0314 20:18:34.122017 29479 solver.cpp:613] Iteration 6540, avg_grad_norm = 795776
I0314 20:19:19.373942 29479 solver.cpp:214] Iteration 6560, loss = 8466.05
I0314 20:19:19.374071 29479 solver.cpp:229]     Train net output #0: loss = 9388.68 (* 1 = 9388.68 loss)
I0314 20:19:19.581861 29479 solver.cpp:610] Iteration 6560, lr = 9.70431e-09
I0314 20:19:19.581918 29479 solver.cpp:613] Iteration 6560, avg_grad_norm = 638584
I0314 20:20:23.413208 29479 solver.cpp:214] Iteration 6580, loss = 8532.86
I0314 20:20:23.413398 29479 solver.cpp:229]     Train net output #0: loss = 6818.39 (* 1 = 6818.39 loss)
I0314 20:20:23.625828 29479 solver.cpp:610] Iteration 6580, lr = 9.70341e-09
I0314 20:20:23.625843 29479 solver.cpp:613] Iteration 6580, avg_grad_norm = 737142
I0314 20:21:27.238026 29479 solver.cpp:214] Iteration 6600, loss = 7963.24
I0314 20:21:27.238225 29479 solver.cpp:229]     Train net output #0: loss = 6906.07 (* 1 = 6906.07 loss)
I0314 20:21:27.441598 29479 solver.cpp:610] Iteration 6600, lr = 9.7025e-09
I0314 20:21:27.441612 29479 solver.cpp:613] Iteration 6600, avg_grad_norm = 804017
I0314 20:22:43.870277 29479 solver.cpp:214] Iteration 6620, loss = 8271.21
I0314 20:22:43.870404 29479 solver.cpp:229]     Train net output #0: loss = 11001 (* 1 = 11001 loss)
I0314 20:22:44.082995 29479 solver.cpp:610] Iteration 6620, lr = 9.7016e-09
I0314 20:22:44.083009 29479 solver.cpp:613] Iteration 6620, avg_grad_norm = 747587
I0314 20:23:44.654119 29479 solver.cpp:214] Iteration 6640, loss = 8461.59
I0314 20:23:44.654294 29479 solver.cpp:229]     Train net output #0: loss = 7741.1 (* 1 = 7741.1 loss)
I0314 20:23:44.869230 29479 solver.cpp:610] Iteration 6640, lr = 9.7007e-09
I0314 20:23:44.869242 29479 solver.cpp:613] Iteration 6640, avg_grad_norm = 700692
I0314 20:24:48.533016 29479 solver.cpp:214] Iteration 6660, loss = 8216.03
I0314 20:24:48.533162 29479 solver.cpp:229]     Train net output #0: loss = 4236.35 (* 1 = 4236.35 loss)
I0314 20:24:48.745679 29479 solver.cpp:610] Iteration 6660, lr = 9.69979e-09
I0314 20:24:48.745693 29479 solver.cpp:613] Iteration 6660, avg_grad_norm = 673149
I0314 20:25:52.389825 29479 solver.cpp:214] Iteration 6680, loss = 8061.57
I0314 20:25:52.389952 29479 solver.cpp:229]     Train net output #0: loss = 6675.5 (* 1 = 6675.5 loss)
I0314 20:25:52.760649 29479 solver.cpp:610] Iteration 6680, lr = 9.69889e-09
I0314 20:25:52.760663 29479 solver.cpp:613] Iteration 6680, avg_grad_norm = 777338
I0314 20:26:37.496551 29479 solver.cpp:214] Iteration 6700, loss = 8016.98
I0314 20:26:37.496637 29479 solver.cpp:229]     Train net output #0: loss = 9678.13 (* 1 = 9678.13 loss)
I0314 20:26:37.612511 29479 solver.cpp:610] Iteration 6700, lr = 9.69799e-09
I0314 20:26:37.612524 29479 solver.cpp:613] Iteration 6700, avg_grad_norm = 792319
I0314 20:27:41.146540 29479 solver.cpp:214] Iteration 6720, loss = 8310.85
I0314 20:27:41.146728 29479 solver.cpp:229]     Train net output #0: loss = 7721.14 (* 1 = 7721.14 loss)
I0314 20:27:41.510828 29479 solver.cpp:610] Iteration 6720, lr = 9.69709e-09
I0314 20:27:41.510843 29479 solver.cpp:613] Iteration 6720, avg_grad_norm = 922405
I0314 20:28:57.513540 29479 solver.cpp:214] Iteration 6740, loss = 8147.1
I0314 20:28:57.513723 29479 solver.cpp:229]     Train net output #0: loss = 7728.99 (* 1 = 7728.99 loss)
I0314 20:28:57.871052 29479 solver.cpp:610] Iteration 6740, lr = 9.69618e-09
I0314 20:28:57.871067 29479 solver.cpp:613] Iteration 6740, avg_grad_norm = 808540
I0314 20:30:01.323215 29479 solver.cpp:214] Iteration 6760, loss = 7845.72
I0314 20:30:01.323334 29479 solver.cpp:229]     Train net output #0: loss = 8949.72 (* 1 = 8949.72 loss)
I0314 20:30:01.687568 29479 solver.cpp:610] Iteration 6760, lr = 9.69528e-09
I0314 20:30:01.687582 29479 solver.cpp:613] Iteration 6760, avg_grad_norm = 808258
I0314 20:31:05.345115 29479 solver.cpp:214] Iteration 6780, loss = 8148.81
I0314 20:31:05.345249 29479 solver.cpp:229]     Train net output #0: loss = 6645.77 (* 1 = 6645.77 loss)
I0314 20:31:05.709622 29479 solver.cpp:610] Iteration 6780, lr = 9.69438e-09
I0314 20:31:05.709636 29479 solver.cpp:613] Iteration 6780, avg_grad_norm = 856286
I0314 20:32:09.280890 29479 solver.cpp:214] Iteration 6800, loss = 8366.01
I0314 20:32:09.281102 29479 solver.cpp:229]     Train net output #0: loss = 5086.72 (* 1 = 5086.72 loss)
I0314 20:32:09.645485 29479 solver.cpp:610] Iteration 6800, lr = 9.69347e-09
I0314 20:32:09.645503 29479 solver.cpp:613] Iteration 6800, avg_grad_norm = 741506
I0314 20:33:13.192147 29479 solver.cpp:214] Iteration 6820, loss = 8203.37
I0314 20:33:13.192270 29479 solver.cpp:229]     Train net output #0: loss = 7228.13 (* 1 = 7228.13 loss)
I0314 20:33:13.556368 29479 solver.cpp:610] Iteration 6820, lr = 9.69257e-09
I0314 20:33:13.556381 29479 solver.cpp:613] Iteration 6820, avg_grad_norm = 654358
I0314 20:34:15.565428 29479 solver.cpp:214] Iteration 6840, loss = 8244.02
I0314 20:34:15.565611 29479 solver.cpp:229]     Train net output #0: loss = 5971.19 (* 1 = 5971.19 loss)
I0314 20:34:15.670722 29479 solver.cpp:610] Iteration 6840, lr = 9.69167e-09
I0314 20:34:15.670766 29479 solver.cpp:613] Iteration 6840, avg_grad_norm = 681750
I0314 20:35:14.145236 29479 solver.cpp:214] Iteration 6860, loss = 8333.61
I0314 20:35:14.145371 29479 solver.cpp:229]     Train net output #0: loss = 8193.71 (* 1 = 8193.71 loss)
I0314 20:35:14.343750 29479 solver.cpp:610] Iteration 6860, lr = 9.69076e-09
I0314 20:35:14.343763 29479 solver.cpp:613] Iteration 6860, avg_grad_norm = 710852
I0314 20:36:17.956580 29479 solver.cpp:214] Iteration 6880, loss = 8168.95
I0314 20:36:17.956702 29479 solver.cpp:229]     Train net output #0: loss = 5661.04 (* 1 = 5661.04 loss)
I0314 20:36:18.315950 29479 solver.cpp:610] Iteration 6880, lr = 9.68986e-09
I0314 20:36:18.315963 29479 solver.cpp:613] Iteration 6880, avg_grad_norm = 713802
I0314 20:37:21.898284 29479 solver.cpp:214] Iteration 6900, loss = 8435.53
I0314 20:37:21.898480 29479 solver.cpp:229]     Train net output #0: loss = 15133.7 (* 1 = 15133.7 loss)
I0314 20:37:22.261854 29479 solver.cpp:610] Iteration 6900, lr = 9.68896e-09
I0314 20:37:22.261868 29479 solver.cpp:613] Iteration 6900, avg_grad_norm = 804206
I0314 20:38:25.843212 29479 solver.cpp:214] Iteration 6920, loss = 7823.15
I0314 20:38:25.843358 29479 solver.cpp:229]     Train net output #0: loss = 6757.09 (* 1 = 6757.09 loss)
I0314 20:38:26.207384 29479 solver.cpp:610] Iteration 6920, lr = 9.68805e-09
I0314 20:38:26.207397 29479 solver.cpp:613] Iteration 6920, avg_grad_norm = 715832
I0314 20:39:29.971511 29479 solver.cpp:214] Iteration 6940, loss = 8069.04
I0314 20:39:29.971654 29479 solver.cpp:229]     Train net output #0: loss = 6508.43 (* 1 = 6508.43 loss)
I0314 20:39:30.174973 29479 solver.cpp:610] Iteration 6940, lr = 9.68715e-09
I0314 20:39:30.174986 29479 solver.cpp:613] Iteration 6940, avg_grad_norm = 633148
I0314 20:40:33.729277 29479 solver.cpp:214] Iteration 6960, loss = 8168.92
I0314 20:40:33.729399 29479 solver.cpp:229]     Train net output #0: loss = 9191.93 (* 1 = 9191.93 loss)
I0314 20:40:34.093682 29479 solver.cpp:610] Iteration 6960, lr = 9.68625e-09
I0314 20:40:34.093694 29479 solver.cpp:613] Iteration 6960, avg_grad_norm = 739277
I0314 20:41:37.719027 29479 solver.cpp:214] Iteration 6980, loss = 8035.95
I0314 20:41:37.719205 29479 solver.cpp:229]     Train net output #0: loss = 7882.17 (* 1 = 7882.17 loss)
I0314 20:41:38.093317 29479 solver.cpp:610] Iteration 6980, lr = 9.68534e-09
I0314 20:41:38.093329 29479 solver.cpp:613] Iteration 6980, avg_grad_norm = 771723
I0314 20:43:25.069716 29479 solver.cpp:214] Iteration 7000, loss = 8194.82
I0314 20:43:25.069900 29479 solver.cpp:229]     Train net output #0: loss = 7759.48 (* 1 = 7759.48 loss)
I0314 20:43:25.278178 29479 solver.cpp:610] Iteration 7000, lr = 9.68444e-09
I0314 20:43:25.278192 29479 solver.cpp:613] Iteration 7000, avg_grad_norm = 754054
I0314 20:44:27.493774 29479 solver.cpp:214] Iteration 7020, loss = 8253.49
I0314 20:44:27.493885 29479 solver.cpp:229]     Train net output #0: loss = 6791.16 (* 1 = 6791.16 loss)
I0314 20:44:27.845298 29479 solver.cpp:610] Iteration 7020, lr = 9.68354e-09
I0314 20:44:27.845310 29479 solver.cpp:613] Iteration 7020, avg_grad_norm = 744675
I0314 20:45:30.298750 29479 solver.cpp:214] Iteration 7040, loss = 8335.95
I0314 20:45:30.298902 29479 solver.cpp:229]     Train net output #0: loss = 8809.14 (* 1 = 8809.14 loss)
I0314 20:45:30.511477 29479 solver.cpp:610] Iteration 7040, lr = 9.68264e-09
I0314 20:45:30.511492 29479 solver.cpp:613] Iteration 7040, avg_grad_norm = 737640
I0314 20:46:33.625371 29479 solver.cpp:214] Iteration 7060, loss = 8428.04
I0314 20:46:33.625547 29479 solver.cpp:229]     Train net output #0: loss = 8117.31 (* 1 = 8117.31 loss)
I0314 20:46:33.983388 29479 solver.cpp:610] Iteration 7060, lr = 9.68173e-09
I0314 20:46:33.983423 29479 solver.cpp:613] Iteration 7060, avg_grad_norm = 838882
I0314 20:47:36.870332 29479 solver.cpp:214] Iteration 7080, loss = 8220.78
I0314 20:47:36.870582 29479 solver.cpp:229]     Train net output #0: loss = 6494.65 (* 1 = 6494.65 loss)
I0314 20:47:37.227494 29479 solver.cpp:610] Iteration 7080, lr = 9.68083e-09
I0314 20:47:37.227509 29479 solver.cpp:613] Iteration 7080, avg_grad_norm = 818194
I0314 20:48:40.175128 29479 solver.cpp:214] Iteration 7100, loss = 8208.23
I0314 20:48:40.175256 29479 solver.cpp:229]     Train net output #0: loss = 5832.98 (* 1 = 5832.98 loss)
I0314 20:48:40.533192 29479 solver.cpp:610] Iteration 7100, lr = 9.67993e-09
I0314 20:48:40.533205 29479 solver.cpp:613] Iteration 7100, avg_grad_norm = 740465
I0314 20:50:08.160089 29479 solver.cpp:214] Iteration 7120, loss = 8449.61
I0314 20:50:08.160230 29479 solver.cpp:229]     Train net output #0: loss = 4476.79 (* 1 = 4476.79 loss)
I0314 20:50:08.263921 29479 solver.cpp:610] Iteration 7120, lr = 9.67902e-09
I0314 20:50:08.263934 29479 solver.cpp:613] Iteration 7120, avg_grad_norm = 990318
I0314 20:50:33.289372 29479 solver.cpp:214] Iteration 7140, loss = 8145.41
I0314 20:50:33.289432 29479 solver.cpp:229]     Train net output #0: loss = 8455.8 (* 1 = 8455.8 loss)
I0314 20:50:33.404013 29479 solver.cpp:610] Iteration 7140, lr = 9.67812e-09
I0314 20:50:33.404026 29479 solver.cpp:613] Iteration 7140, avg_grad_norm = 847977
I0314 20:51:16.591157 29479 solver.cpp:214] Iteration 7160, loss = 8291.09
I0314 20:51:16.591361 29479 solver.cpp:229]     Train net output #0: loss = 5027.11 (* 1 = 5027.11 loss)
I0314 20:51:16.804332 29479 solver.cpp:610] Iteration 7160, lr = 9.67722e-09
I0314 20:51:16.804344 29479 solver.cpp:613] Iteration 7160, avg_grad_norm = 788784
I0314 20:52:19.872292 29479 solver.cpp:214] Iteration 7180, loss = 8256.75
I0314 20:52:19.872413 29479 solver.cpp:229]     Train net output #0: loss = 6272.46 (* 1 = 6272.46 loss)
I0314 20:52:20.236346 29479 solver.cpp:610] Iteration 7180, lr = 9.67631e-09
I0314 20:52:20.236359 29479 solver.cpp:613] Iteration 7180, avg_grad_norm = 780355
I0314 20:53:23.551916 29479 solver.cpp:214] Iteration 7200, loss = 7967.75
I0314 20:53:23.552063 29479 solver.cpp:229]     Train net output #0: loss = 7549.07 (* 1 = 7549.07 loss)
I0314 20:53:23.912029 29479 solver.cpp:610] Iteration 7200, lr = 9.67541e-09
I0314 20:53:23.912045 29479 solver.cpp:613] Iteration 7200, avg_grad_norm = 711477
I0314 20:54:27.237264 29479 solver.cpp:214] Iteration 7220, loss = 8405.29
I0314 20:54:27.237493 29479 solver.cpp:229]     Train net output #0: loss = 12536.6 (* 1 = 12536.6 loss)
I0314 20:54:27.603466 29479 solver.cpp:610] Iteration 7220, lr = 9.67451e-09
I0314 20:54:27.603510 29479 solver.cpp:613] Iteration 7220, avg_grad_norm = 804123
I0314 20:55:57.037437 29479 solver.cpp:214] Iteration 7240, loss = 8006.61
I0314 20:55:57.037583 29479 solver.cpp:229]     Train net output #0: loss = 8148.67 (* 1 = 8148.67 loss)
I0314 20:55:57.394940 29479 solver.cpp:610] Iteration 7240, lr = 9.6736e-09
I0314 20:55:57.394956 29479 solver.cpp:613] Iteration 7240, avg_grad_norm = 714958
I0314 20:57:00.907312 29479 solver.cpp:214] Iteration 7260, loss = 7910.1
I0314 20:57:00.907449 29479 solver.cpp:229]     Train net output #0: loss = 9824.48 (* 1 = 9824.48 loss)
I0314 20:57:01.111874 29479 solver.cpp:610] Iteration 7260, lr = 9.6727e-09
I0314 20:57:01.111888 29479 solver.cpp:613] Iteration 7260, avg_grad_norm = 711611
I0314 20:58:04.652482 29479 solver.cpp:214] Iteration 7280, loss = 7743.45
I0314 20:58:04.652674 29479 solver.cpp:229]     Train net output #0: loss = 5574.08 (* 1 = 5574.08 loss)
I0314 20:58:05.009670 29479 solver.cpp:610] Iteration 7280, lr = 9.6718e-09
I0314 20:58:05.009685 29479 solver.cpp:613] Iteration 7280, avg_grad_norm = 634792
I0314 20:58:49.509892 29479 solver.cpp:214] Iteration 7300, loss = 8178.63
I0314 20:58:49.510072 29479 solver.cpp:229]     Train net output #0: loss = 7980.33 (* 1 = 7980.33 loss)
I0314 20:58:49.718255 29479 solver.cpp:610] Iteration 7300, lr = 9.67089e-09
I0314 20:58:49.718266 29479 solver.cpp:613] Iteration 7300, avg_grad_norm = 732681
I0314 20:59:53.255614 29479 solver.cpp:214] Iteration 7320, loss = 7976.61
I0314 20:59:53.255796 29479 solver.cpp:229]     Train net output #0: loss = 4219.56 (* 1 = 4219.56 loss)
I0314 20:59:53.613601 29479 solver.cpp:610] Iteration 7320, lr = 9.66999e-09
I0314 20:59:53.613615 29479 solver.cpp:613] Iteration 7320, avg_grad_norm = 797206
I0314 21:00:57.289942 29479 solver.cpp:214] Iteration 7340, loss = 8655.05
I0314 21:00:57.290155 29479 solver.cpp:229]     Train net output #0: loss = 4762.09 (* 1 = 4762.09 loss)
I0314 21:00:57.655149 29479 solver.cpp:610] Iteration 7340, lr = 9.66909e-09
I0314 21:00:57.655163 29479 solver.cpp:613] Iteration 7340, avg_grad_norm = 692676
I0314 21:02:01.322686 29479 solver.cpp:214] Iteration 7360, loss = 7969.72
I0314 21:02:01.322811 29479 solver.cpp:229]     Train net output #0: loss = 6642.21 (* 1 = 6642.21 loss)
I0314 21:02:01.535501 29479 solver.cpp:610] Iteration 7360, lr = 9.66818e-09
I0314 21:02:01.535513 29479 solver.cpp:613] Iteration 7360, avg_grad_norm = 704286
I0314 21:03:20.351091 29479 solver.cpp:214] Iteration 7380, loss = 8159.24
I0314 21:03:20.351215 29479 solver.cpp:229]     Train net output #0: loss = 7737.32 (* 1 = 7737.32 loss)
I0314 21:03:20.564254 29479 solver.cpp:610] Iteration 7380, lr = 9.66728e-09
I0314 21:03:20.564267 29479 solver.cpp:613] Iteration 7380, avg_grad_norm = 648698
I0314 21:04:25.510619 29479 solver.cpp:214] Iteration 7400, loss = 8212.84
I0314 21:04:25.510761 29479 solver.cpp:229]     Train net output #0: loss = 6129.23 (* 1 = 6129.23 loss)
I0314 21:04:25.871223 29479 solver.cpp:610] Iteration 7400, lr = 9.66638e-09
I0314 21:04:25.871239 29479 solver.cpp:613] Iteration 7400, avg_grad_norm = 742523
I0314 21:05:30.292147 29479 solver.cpp:214] Iteration 7420, loss = 8052.32
I0314 21:05:30.292341 29479 solver.cpp:229]     Train net output #0: loss = 5006.06 (* 1 = 5006.06 loss)
I0314 21:05:30.658041 29479 solver.cpp:610] Iteration 7420, lr = 9.66547e-09
I0314 21:05:30.658056 29479 solver.cpp:613] Iteration 7420, avg_grad_norm = 766286
I0314 21:06:14.839870 29479 solver.cpp:214] Iteration 7440, loss = 8131.37
I0314 21:06:14.840021 29479 solver.cpp:229]     Train net output #0: loss = 11140.2 (* 1 = 11140.2 loss)
I0314 21:06:15.247462 29479 solver.cpp:610] Iteration 7440, lr = 9.66457e-09
I0314 21:06:15.247474 29479 solver.cpp:613] Iteration 7440, avg_grad_norm = 889309
I0314 21:07:19.010311 29479 solver.cpp:214] Iteration 7460, loss = 8110.6
I0314 21:07:19.010483 29479 solver.cpp:229]     Train net output #0: loss = 12326.2 (* 1 = 12326.2 loss)
I0314 21:07:19.225700 29479 solver.cpp:610] Iteration 7460, lr = 9.66367e-09
I0314 21:07:19.225713 29479 solver.cpp:613] Iteration 7460, avg_grad_norm = 682525
I0314 21:08:26.372670 29479 solver.cpp:214] Iteration 7480, loss = 8160.62
I0314 21:08:26.372928 29479 solver.cpp:229]     Train net output #0: loss = 6949.56 (* 1 = 6949.56 loss)
I0314 21:08:26.732564 29479 solver.cpp:610] Iteration 7480, lr = 9.66276e-09
I0314 21:08:26.732578 29479 solver.cpp:613] Iteration 7480, avg_grad_norm = 869203
I0314 21:09:42.596784 29479 solver.cpp:214] Iteration 7500, loss = 7850.18
I0314 21:09:42.596890 29479 solver.cpp:229]     Train net output #0: loss = 5635.82 (* 1 = 5635.82 loss)
I0314 21:09:42.965322 29479 solver.cpp:610] Iteration 7500, lr = 9.66186e-09
I0314 21:09:42.965335 29479 solver.cpp:613] Iteration 7500, avg_grad_norm = 637301
I0314 21:10:46.633808 29479 solver.cpp:214] Iteration 7520, loss = 8246.11
I0314 21:10:46.633950 29479 solver.cpp:229]     Train net output #0: loss = 4296.62 (* 1 = 4296.62 loss)
I0314 21:10:46.993383 29479 solver.cpp:610] Iteration 7520, lr = 9.66095e-09
I0314 21:10:46.993398 29479 solver.cpp:613] Iteration 7520, avg_grad_norm = 694495
I0314 21:11:50.625344 29479 solver.cpp:214] Iteration 7540, loss = 8321.29
I0314 21:11:50.625493 29479 solver.cpp:229]     Train net output #0: loss = 8083.02 (* 1 = 8083.02 loss)
I0314 21:11:50.989645 29479 solver.cpp:610] Iteration 7540, lr = 9.66005e-09
I0314 21:11:50.989658 29479 solver.cpp:613] Iteration 7540, avg_grad_norm = 703491
I0314 21:12:55.064432 29479 solver.cpp:214] Iteration 7560, loss = 8109.55
I0314 21:12:55.064623 29479 solver.cpp:229]     Train net output #0: loss = 7647.8 (* 1 = 7647.8 loss)
I0314 21:12:55.427883 29479 solver.cpp:610] Iteration 7560, lr = 9.65915e-09
I0314 21:12:55.427897 29479 solver.cpp:613] Iteration 7560, avg_grad_norm = 862869
I0314 21:13:49.983475 29479 solver.cpp:214] Iteration 7580, loss = 8340.85
I0314 21:13:49.983629 29479 solver.cpp:229]     Train net output #0: loss = 7416.2 (* 1 = 7416.2 loss)
I0314 21:13:50.096554 29479 solver.cpp:610] Iteration 7580, lr = 9.65824e-09
I0314 21:13:50.096568 29479 solver.cpp:613] Iteration 7580, avg_grad_norm = 982186
I0314 21:14:47.669327 29479 solver.cpp:214] Iteration 7600, loss = 8057.54
I0314 21:14:47.669456 29479 solver.cpp:229]     Train net output #0: loss = 5666.68 (* 1 = 5666.68 loss)
I0314 21:14:48.030558 29479 solver.cpp:610] Iteration 7600, lr = 9.65734e-09
I0314 21:14:48.030572 29479 solver.cpp:613] Iteration 7600, avg_grad_norm = 801670
I0314 21:16:16.413095 29479 solver.cpp:214] Iteration 7620, loss = 8029.13
I0314 21:16:16.413312 29479 solver.cpp:229]     Train net output #0: loss = 7547.29 (* 1 = 7547.29 loss)
I0314 21:16:16.613005 29479 solver.cpp:610] Iteration 7620, lr = 9.65644e-09
I0314 21:16:16.613024 29479 solver.cpp:613] Iteration 7620, avg_grad_norm = 747432
I0314 21:17:23.805510 29479 solver.cpp:214] Iteration 7640, loss = 8087.12
I0314 21:17:23.805656 29479 solver.cpp:229]     Train net output #0: loss = 4861.34 (* 1 = 4861.34 loss)
I0314 21:17:24.021175 29479 solver.cpp:610] Iteration 7640, lr = 9.65553e-09
I0314 21:17:24.021189 29479 solver.cpp:613] Iteration 7640, avg_grad_norm = 650318
I0314 21:18:27.656230 29479 solver.cpp:214] Iteration 7660, loss = 8265.64
I0314 21:18:27.656445 29479 solver.cpp:229]     Train net output #0: loss = 14735.8 (* 1 = 14735.8 loss)
I0314 21:18:27.861655 29479 solver.cpp:610] Iteration 7660, lr = 9.65463e-09
I0314 21:18:27.861668 29479 solver.cpp:613] Iteration 7660, avg_grad_norm = 713037
I0314 21:19:31.811841 29479 solver.cpp:214] Iteration 7680, loss = 8112.38
I0314 21:19:31.812031 29479 solver.cpp:229]     Train net output #0: loss = 8592.36 (* 1 = 8592.36 loss)
I0314 21:19:32.017376 29479 solver.cpp:610] Iteration 7680, lr = 9.65373e-09
I0314 21:19:32.017390 29479 solver.cpp:613] Iteration 7680, avg_grad_norm = 678814
I0314 21:20:35.698472 29479 solver.cpp:214] Iteration 7700, loss = 8505.33
I0314 21:20:35.698649 29479 solver.cpp:229]     Train net output #0: loss = 5921.64 (* 1 = 5921.64 loss)
I0314 21:20:35.904548 29479 solver.cpp:610] Iteration 7700, lr = 9.65282e-09
I0314 21:20:35.904561 29479 solver.cpp:613] Iteration 7700, avg_grad_norm = 710881
I0314 21:21:27.993082 29479 solver.cpp:214] Iteration 7720, loss = 8412.51
I0314 21:21:27.993232 29479 solver.cpp:229]     Train net output #0: loss = 9041.87 (* 1 = 9041.87 loss)
I0314 21:21:28.109633 29479 solver.cpp:610] Iteration 7720, lr = 9.65192e-09
I0314 21:21:28.109647 29479 solver.cpp:613] Iteration 7720, avg_grad_norm = 708888
I0314 21:22:23.807090 29479 solver.cpp:214] Iteration 7740, loss = 8199.74
I0314 21:22:23.807214 29479 solver.cpp:229]     Train net output #0: loss = 6593.86 (* 1 = 6593.86 loss)
I0314 21:22:24.022418 29479 solver.cpp:610] Iteration 7740, lr = 9.65102e-09
I0314 21:22:24.022433 29479 solver.cpp:613] Iteration 7740, avg_grad_norm = 685587
I0314 21:23:40.505632 29479 solver.cpp:214] Iteration 7760, loss = 8241.34
I0314 21:23:40.505779 29479 solver.cpp:229]     Train net output #0: loss = 9513.9 (* 1 = 9513.9 loss)
I0314 21:23:40.869807 29479 solver.cpp:610] Iteration 7760, lr = 9.65011e-09
I0314 21:23:40.869819 29479 solver.cpp:613] Iteration 7760, avg_grad_norm = 716948
I0314 21:24:44.463723 29479 solver.cpp:214] Iteration 7780, loss = 8221.87
I0314 21:24:44.463843 29479 solver.cpp:229]     Train net output #0: loss = 6160.39 (* 1 = 6160.39 loss)
I0314 21:24:44.679512 29479 solver.cpp:610] Iteration 7780, lr = 9.64921e-09
I0314 21:24:44.679525 29479 solver.cpp:613] Iteration 7780, avg_grad_norm = 673518
I0314 21:25:48.309937 29479 solver.cpp:214] Iteration 7800, loss = 7962.28
I0314 21:25:48.310051 29479 solver.cpp:229]     Train net output #0: loss = 5477 (* 1 = 5477 loss)
I0314 21:25:48.673818 29479 solver.cpp:610] Iteration 7800, lr = 9.64831e-09
I0314 21:25:48.673831 29479 solver.cpp:613] Iteration 7800, avg_grad_norm = 723714
I0314 21:26:52.320632 29479 solver.cpp:214] Iteration 7820, loss = 8163.44
I0314 21:26:52.320755 29479 solver.cpp:229]     Train net output #0: loss = 8402.27 (* 1 = 8402.27 loss)
I0314 21:26:52.678020 29479 solver.cpp:610] Iteration 7820, lr = 9.6474e-09
I0314 21:26:52.678036 29479 solver.cpp:613] Iteration 7820, avg_grad_norm = 696076
I0314 21:27:56.142148 29479 solver.cpp:214] Iteration 7840, loss = 8114.95
I0314 21:27:56.142297 29479 solver.cpp:229]     Train net output #0: loss = 8111.64 (* 1 = 8111.64 loss)
I0314 21:27:56.506299 29479 solver.cpp:610] Iteration 7840, lr = 9.6465e-09
I0314 21:27:56.506311 29479 solver.cpp:613] Iteration 7840, avg_grad_norm = 593333
I0314 21:29:00.235357 29479 solver.cpp:214] Iteration 7860, loss = 7809.31
I0314 21:29:00.235483 29479 solver.cpp:229]     Train net output #0: loss = 9573.56 (* 1 = 9573.56 loss)
I0314 21:29:00.599227 29479 solver.cpp:610] Iteration 7860, lr = 9.64559e-09
I0314 21:29:00.599239 29479 solver.cpp:613] Iteration 7860, avg_grad_norm = 637943
I0314 21:30:07.711205 29479 solver.cpp:214] Iteration 7880, loss = 8191.94
I0314 21:30:07.711359 29479 solver.cpp:229]     Train net output #0: loss = 5779.5 (* 1 = 5779.5 loss)
I0314 21:30:08.075206 29479 solver.cpp:610] Iteration 7880, lr = 9.64469e-09
I0314 21:30:08.075218 29479 solver.cpp:613] Iteration 7880, avg_grad_norm = 639058
I0314 21:31:12.010566 29479 solver.cpp:214] Iteration 7900, loss = 7950.38
I0314 21:31:12.010705 29479 solver.cpp:229]     Train net output #0: loss = 10548.1 (* 1 = 10548.1 loss)
I0314 21:31:12.225806 29479 solver.cpp:610] Iteration 7900, lr = 9.64379e-09
I0314 21:31:12.225821 29479 solver.cpp:613] Iteration 7900, avg_grad_norm = 697290
I0314 21:32:16.047376 29479 solver.cpp:214] Iteration 7920, loss = 7878.54
I0314 21:32:16.047523 29479 solver.cpp:229]     Train net output #0: loss = 5876.92 (* 1 = 5876.92 loss)
I0314 21:32:16.263439 29479 solver.cpp:610] Iteration 7920, lr = 9.64288e-09
I0314 21:32:16.263454 29479 solver.cpp:613] Iteration 7920, avg_grad_norm = 786450
I0314 21:33:19.982336 29479 solver.cpp:214] Iteration 7940, loss = 8179.86
I0314 21:33:19.982504 29479 solver.cpp:229]     Train net output #0: loss = 9219.1 (* 1 = 9219.1 loss)
I0314 21:33:20.324183 29479 solver.cpp:610] Iteration 7940, lr = 9.64198e-09
I0314 21:33:20.324196 29479 solver.cpp:613] Iteration 7940, avg_grad_norm = 721990
I0314 21:34:23.820801 29479 solver.cpp:214] Iteration 7960, loss = 8237.06
I0314 21:34:23.820953 29479 solver.cpp:229]     Train net output #0: loss = 5097.53 (* 1 = 5097.53 loss)
I0314 21:34:24.190244 29479 solver.cpp:610] Iteration 7960, lr = 9.64108e-09
I0314 21:34:24.190259 29479 solver.cpp:613] Iteration 7960, avg_grad_norm = 713932
I0314 21:35:27.842898 29479 solver.cpp:214] Iteration 7980, loss = 8249.8
I0314 21:35:27.843022 29479 solver.cpp:229]     Train net output #0: loss = 4812 (* 1 = 4812 loss)
I0314 21:35:28.200042 29479 solver.cpp:610] Iteration 7980, lr = 9.64017e-09
I0314 21:35:28.200054 29479 solver.cpp:613] Iteration 7980, avg_grad_norm = 758549
I0314 21:36:44.336088 29479 solver.cpp:214] Iteration 8000, loss = 8120.56
I0314 21:36:44.336325 29479 solver.cpp:229]     Train net output #0: loss = 12360.4 (* 1 = 12360.4 loss)
I0314 21:36:44.442358 29479 solver.cpp:610] Iteration 8000, lr = 9.63927e-09
I0314 21:36:44.442370 29479 solver.cpp:613] Iteration 8000, avg_grad_norm = 817777
I0314 21:37:28.575690 29479 solver.cpp:214] Iteration 8020, loss = 8289.69
I0314 21:37:28.575881 29479 solver.cpp:229]     Train net output #0: loss = 4090.23 (* 1 = 4090.23 loss)
I0314 21:37:28.781329 29479 solver.cpp:610] Iteration 8020, lr = 9.63837e-09
I0314 21:37:28.781343 29479 solver.cpp:613] Iteration 8020, avg_grad_norm = 867410
I0314 21:38:32.612375 29479 solver.cpp:214] Iteration 8040, loss = 8018.06
I0314 21:38:32.612517 29479 solver.cpp:229]     Train net output #0: loss = 7129.66 (* 1 = 7129.66 loss)
I0314 21:38:32.818368 29479 solver.cpp:610] Iteration 8040, lr = 9.63746e-09
I0314 21:38:32.818382 29479 solver.cpp:613] Iteration 8040, avg_grad_norm = 709181
I0314 21:39:36.504631 29479 solver.cpp:214] Iteration 8060, loss = 8183.6
I0314 21:39:36.504766 29479 solver.cpp:229]     Train net output #0: loss = 7048.01 (* 1 = 7048.01 loss)
I0314 21:39:36.705348 29479 solver.cpp:610] Iteration 8060, lr = 9.63656e-09
I0314 21:39:36.705360 29479 solver.cpp:613] Iteration 8060, avg_grad_norm = 781929
I0314 21:40:37.385718 29479 solver.cpp:214] Iteration 8080, loss = 7799.46
I0314 21:40:37.385848 29479 solver.cpp:229]     Train net output #0: loss = 6770.79 (* 1 = 6770.79 loss)
I0314 21:40:37.587327 29479 solver.cpp:610] Iteration 8080, lr = 9.63565e-09
I0314 21:40:37.587339 29479 solver.cpp:613] Iteration 8080, avg_grad_norm = 642426
I0314 21:41:40.960561 29479 solver.cpp:214] Iteration 8100, loss = 8171.19
I0314 21:41:40.960687 29479 solver.cpp:229]     Train net output #0: loss = 7114.05 (* 1 = 7114.05 loss)
I0314 21:41:41.319116 29479 solver.cpp:610] Iteration 8100, lr = 9.63475e-09
I0314 21:41:41.319129 29479 solver.cpp:613] Iteration 8100, avg_grad_norm = 758517
I0314 21:42:44.889962 29479 solver.cpp:214] Iteration 8120, loss = 8032.26
I0314 21:42:44.890100 29479 solver.cpp:229]     Train net output #0: loss = 9600.3 (* 1 = 9600.3 loss)
I0314 21:42:45.095252 29479 solver.cpp:610] Iteration 8120, lr = 9.63385e-09
I0314 21:42:45.095265 29479 solver.cpp:613] Iteration 8120, avg_grad_norm = 748112
I0314 21:44:01.248546 29479 solver.cpp:214] Iteration 8140, loss = 8410.29
I0314 21:44:01.248672 29479 solver.cpp:229]     Train net output #0: loss = 12937.6 (* 1 = 12937.6 loss)
I0314 21:44:01.614287 29479 solver.cpp:610] Iteration 8140, lr = 9.63294e-09
I0314 21:44:01.614300 29479 solver.cpp:613] Iteration 8140, avg_grad_norm = 897843
I0314 21:44:46.355214 29479 solver.cpp:214] Iteration 8160, loss = 8010.38
I0314 21:44:46.355348 29479 solver.cpp:229]     Train net output #0: loss = 9714.27 (* 1 = 9714.27 loss)
I0314 21:44:46.471402 29479 solver.cpp:610] Iteration 8160, lr = 9.63204e-09
I0314 21:44:46.471416 29479 solver.cpp:613] Iteration 8160, avg_grad_norm = 831911
I0314 21:45:49.434161 29479 solver.cpp:214] Iteration 8180, loss = 7734.15
I0314 21:45:49.434389 29479 solver.cpp:229]     Train net output #0: loss = 6070.97 (* 1 = 6070.97 loss)
I0314 21:45:49.647833 29479 solver.cpp:610] Iteration 8180, lr = 9.63114e-09
I0314 21:45:49.647846 29479 solver.cpp:613] Iteration 8180, avg_grad_norm = 679971
I0314 21:46:53.220602 29479 solver.cpp:214] Iteration 8200, loss = 8024.68
I0314 21:46:53.220758 29479 solver.cpp:229]     Train net output #0: loss = 6670.97 (* 1 = 6670.97 loss)
I0314 21:46:53.586963 29479 solver.cpp:610] Iteration 8200, lr = 9.63023e-09
I0314 21:46:53.586977 29479 solver.cpp:613] Iteration 8200, avg_grad_norm = 715144
I0314 21:47:56.934911 29479 solver.cpp:214] Iteration 8220, loss = 7882.53
I0314 21:47:56.935024 29479 solver.cpp:229]     Train net output #0: loss = 7220.13 (* 1 = 7220.13 loss)
I0314 21:47:57.295574 29479 solver.cpp:610] Iteration 8220, lr = 9.62933e-09
I0314 21:47:57.295588 29479 solver.cpp:613] Iteration 8220, avg_grad_norm = 625759
I0314 21:49:00.938778 29479 solver.cpp:214] Iteration 8240, loss = 7842.53
I0314 21:49:00.938886 29479 solver.cpp:229]     Train net output #0: loss = 5863.4 (* 1 = 5863.4 loss)
I0314 21:49:01.304947 29479 solver.cpp:610] Iteration 8240, lr = 9.62842e-09
I0314 21:49:01.304960 29479 solver.cpp:613] Iteration 8240, avg_grad_norm = 716180
I0314 21:50:28.450935 29479 solver.cpp:214] Iteration 8260, loss = 8094.79
I0314 21:50:28.451050 29479 solver.cpp:229]     Train net output #0: loss = 8448.41 (* 1 = 8448.41 loss)
I0314 21:50:28.817339 29479 solver.cpp:610] Iteration 8260, lr = 9.62752e-09
I0314 21:50:28.817351 29479 solver.cpp:613] Iteration 8260, avg_grad_norm = 729221
I0314 21:51:32.300142 29479 solver.cpp:214] Iteration 8280, loss = 8130.57
I0314 21:51:32.300323 29479 solver.cpp:229]     Train net output #0: loss = 7962.21 (* 1 = 7962.21 loss)
I0314 21:51:32.658828 29479 solver.cpp:610] Iteration 8280, lr = 9.62662e-09
I0314 21:51:32.658841 29479 solver.cpp:613] Iteration 8280, avg_grad_norm = 730487
I0314 21:52:23.487947 29479 solver.cpp:214] Iteration 8300, loss = 8140.76
I0314 21:52:23.488162 29479 solver.cpp:229]     Train net output #0: loss = 8685.62 (* 1 = 8685.62 loss)
I0314 21:52:23.602617 29479 solver.cpp:610] Iteration 8300, lr = 9.62571e-09
I0314 21:52:23.602630 29479 solver.cpp:613] Iteration 8300, avg_grad_norm = 678361
I0314 21:53:20.512544 29479 solver.cpp:214] Iteration 8320, loss = 8279.17
I0314 21:53:20.512670 29479 solver.cpp:229]     Train net output #0: loss = 14756.5 (* 1 = 14756.5 loss)
I0314 21:53:20.871136 29479 solver.cpp:610] Iteration 8320, lr = 9.62481e-09
I0314 21:53:20.871150 29479 solver.cpp:613] Iteration 8320, avg_grad_norm = 772769
I0314 21:54:24.392547 29479 solver.cpp:214] Iteration 8340, loss = 8042.87
I0314 21:54:24.392679 29479 solver.cpp:229]     Train net output #0: loss = 8377.36 (* 1 = 8377.36 loss)
I0314 21:54:24.751090 29479 solver.cpp:610] Iteration 8340, lr = 9.62391e-09
I0314 21:54:24.751103 29479 solver.cpp:613] Iteration 8340, avg_grad_norm = 809463
I0314 21:55:28.407661 29479 solver.cpp:214] Iteration 8360, loss = 8064.09
I0314 21:55:28.407764 29479 solver.cpp:229]     Train net output #0: loss = 7747.9 (* 1 = 7747.9 loss)
I0314 21:55:28.771945 29479 solver.cpp:610] Iteration 8360, lr = 9.623e-09
I0314 21:55:28.771957 29479 solver.cpp:613] Iteration 8360, avg_grad_norm = 728536
I0314 21:56:32.521085 29479 solver.cpp:214] Iteration 8380, loss = 7898.9
I0314 21:56:32.521199 29479 solver.cpp:229]     Train net output #0: loss = 6250.99 (* 1 = 6250.99 loss)
I0314 21:56:32.724565 29479 solver.cpp:610] Iteration 8380, lr = 9.6221e-09
I0314 21:56:32.724577 29479 solver.cpp:613] Iteration 8380, avg_grad_norm = 673924
I0314 21:57:49.614480 29479 solver.cpp:214] Iteration 8400, loss = 7862.31
I0314 21:57:49.614630 29479 solver.cpp:229]     Train net output #0: loss = 9757.75 (* 1 = 9757.75 loss)
I0314 21:57:49.816689 29479 solver.cpp:610] Iteration 8400, lr = 9.62119e-09
I0314 21:57:49.816715 29479 solver.cpp:613] Iteration 8400, avg_grad_norm = 706288
I0314 21:58:53.586240 29479 solver.cpp:214] Iteration 8420, loss = 7964.28
I0314 21:58:53.586388 29479 solver.cpp:229]     Train net output #0: loss = 5646.58 (* 1 = 5646.58 loss)
I0314 21:58:53.790407 29479 solver.cpp:610] Iteration 8420, lr = 9.62029e-09
I0314 21:58:53.790421 29479 solver.cpp:613] Iteration 8420, avg_grad_norm = 664236
I0314 21:59:57.231760 29479 solver.cpp:214] Iteration 8440, loss = 7709.59
I0314 21:59:57.231909 29479 solver.cpp:229]     Train net output #0: loss = 6857.27 (* 1 = 6857.27 loss)
I0314 21:59:57.600433 29479 solver.cpp:610] Iteration 8440, lr = 9.61939e-09
I0314 21:59:57.600447 29479 solver.cpp:613] Iteration 8440, avg_grad_norm = 710164
I0314 22:00:36.235045 29479 solver.cpp:214] Iteration 8460, loss = 7647.64
I0314 22:00:36.235158 29479 solver.cpp:229]     Train net output #0: loss = 5489.78 (* 1 = 5489.78 loss)
I0314 22:00:36.592838 29479 solver.cpp:610] Iteration 8460, lr = 9.61848e-09
I0314 22:00:36.592850 29479 solver.cpp:613] Iteration 8460, avg_grad_norm = 643765
I0314 22:01:40.228847 29479 solver.cpp:214] Iteration 8480, loss = 7692.53
I0314 22:01:40.228960 29479 solver.cpp:229]     Train net output #0: loss = 5336.74 (* 1 = 5336.74 loss)
I0314 22:01:40.595816 29479 solver.cpp:610] Iteration 8480, lr = 9.61758e-09
I0314 22:01:40.595829 29479 solver.cpp:613] Iteration 8480, avg_grad_norm = 595280
I0314 22:02:44.129076 29479 solver.cpp:214] Iteration 8500, loss = 8039.24
I0314 22:02:44.129194 29479 solver.cpp:229]     Train net output #0: loss = 9562.82 (* 1 = 9562.82 loss)
I0314 22:02:44.328408 29479 solver.cpp:610] Iteration 8500, lr = 9.61667e-09
I0314 22:02:44.328423 29479 solver.cpp:613] Iteration 8500, avg_grad_norm = 634009
I0314 22:04:10.290593 29479 solver.cpp:214] Iteration 8520, loss = 8078.3
I0314 22:04:10.290719 29479 solver.cpp:229]     Train net output #0: loss = 15886.4 (* 1 = 15886.4 loss)
I0314 22:04:10.648991 29479 solver.cpp:610] Iteration 8520, lr = 9.61577e-09
I0314 22:04:10.649005 29479 solver.cpp:613] Iteration 8520, avg_grad_norm = 696666
I0314 22:05:14.076716 29479 solver.cpp:214] Iteration 8540, loss = 7999.99
I0314 22:05:14.076866 29479 solver.cpp:229]     Train net output #0: loss = 4991.42 (* 1 = 4991.42 loss)
I0314 22:05:14.440696 29479 solver.cpp:610] Iteration 8540, lr = 9.61487e-09
I0314 22:05:14.440709 29479 solver.cpp:613] Iteration 8540, avg_grad_norm = 765008
I0314 22:06:18.062391 29479 solver.cpp:214] Iteration 8560, loss = 7978.37
I0314 22:06:18.062468 29479 solver.cpp:229]     Train net output #0: loss = 8118.49 (* 1 = 8118.49 loss)
I0314 22:06:18.426676 29479 solver.cpp:610] Iteration 8560, lr = 9.61396e-09
I0314 22:06:18.426689 29479 solver.cpp:613] Iteration 8560, avg_grad_norm = 749678
I0314 22:07:22.025198 29479 solver.cpp:214] Iteration 8580, loss = 7936.26
I0314 22:07:22.025336 29479 solver.cpp:229]     Train net output #0: loss = 5669.34 (* 1 = 5669.34 loss)
I0314 22:07:22.240764 29479 solver.cpp:610] Iteration 8580, lr = 9.61306e-09
I0314 22:07:22.240777 29479 solver.cpp:613] Iteration 8580, avg_grad_norm = 673094
I0314 22:08:06.462012 29479 solver.cpp:214] Iteration 8600, loss = 7980.64
I0314 22:08:06.462106 29479 solver.cpp:229]     Train net output #0: loss = 7209.83 (* 1 = 7209.83 loss)
I0314 22:08:06.816506 29479 solver.cpp:610] Iteration 8600, lr = 9.61215e-09
I0314 22:08:06.816519 29479 solver.cpp:613] Iteration 8600, avg_grad_norm = 688585
I0314 22:09:10.297986 29479 solver.cpp:214] Iteration 8620, loss = 8012.99
I0314 22:09:10.298132 29479 solver.cpp:229]     Train net output #0: loss = 8292.47 (* 1 = 8292.47 loss)
I0314 22:09:10.660586 29479 solver.cpp:610] Iteration 8620, lr = 9.61125e-09
I0314 22:09:10.660599 29479 solver.cpp:613] Iteration 8620, avg_grad_norm = 664418
I0314 22:10:26.804699 29479 solver.cpp:214] Iteration 8640, loss = 7872.14
I0314 22:10:26.804924 29479 solver.cpp:229]     Train net output #0: loss = 12356.9 (* 1 = 12356.9 loss)
I0314 22:10:27.168789 29479 solver.cpp:610] Iteration 8640, lr = 9.61035e-09
I0314 22:10:27.168807 29479 solver.cpp:613] Iteration 8640, avg_grad_norm = 587121
I0314 22:11:31.084434 29479 solver.cpp:214] Iteration 8660, loss = 7771.37
I0314 22:11:31.084602 29479 solver.cpp:229]     Train net output #0: loss = 7455.1 (* 1 = 7455.1 loss)
I0314 22:11:31.284224 29479 solver.cpp:610] Iteration 8660, lr = 9.60944e-09
I0314 22:11:31.284237 29479 solver.cpp:613] Iteration 8660, avg_grad_norm = 754142
I0314 22:12:34.733057 29479 solver.cpp:214] Iteration 8680, loss = 8015.47
I0314 22:12:34.733229 29479 solver.cpp:229]     Train net output #0: loss = 11456 (* 1 = 11456 loss)
I0314 22:12:35.091027 29479 solver.cpp:610] Iteration 8680, lr = 9.60854e-09
I0314 22:12:35.091040 29479 solver.cpp:613] Iteration 8680, avg_grad_norm = 696504
I0314 22:13:38.760422 29479 solver.cpp:214] Iteration 8700, loss = 8096.88
I0314 22:13:38.760550 29479 solver.cpp:229]     Train net output #0: loss = 5403.13 (* 1 = 5403.13 loss)
I0314 22:13:39.121220 29479 solver.cpp:610] Iteration 8700, lr = 9.60763e-09
I0314 22:13:39.121235 29479 solver.cpp:613] Iteration 8700, avg_grad_norm = 725862
I0314 22:14:42.566426 29479 solver.cpp:214] Iteration 8720, loss = 7989.98
I0314 22:14:42.566535 29479 solver.cpp:229]     Train net output #0: loss = 8929.53 (* 1 = 8929.53 loss)
I0314 22:14:42.932915 29479 solver.cpp:610] Iteration 8720, lr = 9.60673e-09
I0314 22:14:42.932930 29479 solver.cpp:613] Iteration 8720, avg_grad_norm = 708378
I0314 22:15:41.850690 29479 solver.cpp:214] Iteration 8740, loss = 7547.77
I0314 22:15:41.850843 29479 solver.cpp:229]     Train net output #0: loss = 8658.05 (* 1 = 8658.05 loss)
I0314 22:15:41.960767 29479 solver.cpp:610] Iteration 8740, lr = 9.60583e-09
I0314 22:15:41.960783 29479 solver.cpp:613] Iteration 8740, avg_grad_norm = 610266
I0314 22:16:17.726789 29479 solver.cpp:214] Iteration 8760, loss = 7562.4
I0314 22:16:17.726948 29479 solver.cpp:229]     Train net output #0: loss = 5099.8 (* 1 = 5099.8 loss)
I0314 22:16:17.940199 29479 solver.cpp:610] Iteration 8760, lr = 9.60492e-09
I0314 22:16:17.940212 29479 solver.cpp:613] Iteration 8760, avg_grad_norm = 623348
I0314 22:17:52.759057 29479 solver.cpp:214] Iteration 8780, loss = 7678.31
I0314 22:17:52.759186 29479 solver.cpp:229]     Train net output #0: loss = 5933.62 (* 1 = 5933.62 loss)
I0314 22:17:52.960290 29479 solver.cpp:610] Iteration 8780, lr = 9.60402e-09
I0314 22:17:52.960304 29479 solver.cpp:613] Iteration 8780, avg_grad_norm = 668837
I0314 22:18:56.411613 29479 solver.cpp:214] Iteration 8800, loss = 7885.34
I0314 22:18:56.411720 29479 solver.cpp:229]     Train net output #0: loss = 6148.82 (* 1 = 6148.82 loss)
I0314 22:18:56.777885 29479 solver.cpp:610] Iteration 8800, lr = 9.60311e-09
I0314 22:18:56.777899 29479 solver.cpp:613] Iteration 8800, avg_grad_norm = 789288
I0314 22:20:00.442383 29479 solver.cpp:214] Iteration 8820, loss = 7725.72
I0314 22:20:00.442589 29479 solver.cpp:229]     Train net output #0: loss = 9188.82 (* 1 = 9188.82 loss)
I0314 22:20:00.799664 29479 solver.cpp:610] Iteration 8820, lr = 9.60221e-09
I0314 22:20:00.799677 29479 solver.cpp:613] Iteration 8820, avg_grad_norm = 793198
I0314 22:21:04.339910 29479 solver.cpp:214] Iteration 8840, loss = 7630.89
I0314 22:21:04.340100 29479 solver.cpp:229]     Train net output #0: loss = 9102.32 (* 1 = 9102.32 loss)
I0314 22:21:04.706657 29479 solver.cpp:610] Iteration 8840, lr = 9.60131e-09
I0314 22:21:04.706670 29479 solver.cpp:613] Iteration 8840, avg_grad_norm = 752258
I0314 22:22:08.978499 29479 solver.cpp:214] Iteration 8860, loss = 7852.46
I0314 22:22:08.978624 29479 solver.cpp:229]     Train net output #0: loss = 7044.41 (* 1 = 7044.41 loss)
I0314 22:22:09.194370 29479 solver.cpp:610] Iteration 8860, lr = 9.6004e-09
I0314 22:22:09.194386 29479 solver.cpp:613] Iteration 8860, avg_grad_norm = 700311
I0314 22:23:12.816028 29479 solver.cpp:214] Iteration 8880, loss = 7683.02
I0314 22:23:12.816165 29479 solver.cpp:229]     Train net output #0: loss = 13526.8 (* 1 = 13526.8 loss)
I0314 22:23:13.187392 29479 solver.cpp:610] Iteration 8880, lr = 9.5995e-09
I0314 22:23:13.187407 29479 solver.cpp:613] Iteration 8880, avg_grad_norm = 704430
I0314 22:24:37.566220 29479 solver.cpp:214] Iteration 8900, loss = 7870.84
I0314 22:24:37.566402 29479 solver.cpp:229]     Train net output #0: loss = 8715.03 (* 1 = 8715.03 loss)
I0314 22:24:37.922843 29479 solver.cpp:610] Iteration 8900, lr = 9.59859e-09
I0314 22:24:37.922857 29479 solver.cpp:613] Iteration 8900, avg_grad_norm = 693334
I0314 22:25:40.986202 29479 solver.cpp:214] Iteration 8920, loss = 7848.36
I0314 22:25:40.986348 29479 solver.cpp:229]     Train net output #0: loss = 5038.9 (* 1 = 5038.9 loss)
I0314 22:25:41.191886 29479 solver.cpp:610] Iteration 8920, lr = 9.59769e-09
I0314 22:25:41.191900 29479 solver.cpp:613] Iteration 8920, avg_grad_norm = 686800
I0314 22:26:44.128358 29479 solver.cpp:214] Iteration 8940, loss = 7566.78
I0314 22:26:44.128449 29479 solver.cpp:229]     Train net output #0: loss = 9005.33 (* 1 = 9005.33 loss)
I0314 22:26:44.486433 29479 solver.cpp:610] Iteration 8940, lr = 9.59679e-09
I0314 22:26:44.486445 29479 solver.cpp:613] Iteration 8940, avg_grad_norm = 650906
I0314 22:27:47.443086 29479 solver.cpp:214] Iteration 8960, loss = 7985.11
I0314 22:27:47.443225 29479 solver.cpp:229]     Train net output #0: loss = 9567.08 (* 1 = 9567.08 loss)
I0314 22:27:47.802364 29479 solver.cpp:610] Iteration 8960, lr = 9.59588e-09
I0314 22:27:47.802378 29479 solver.cpp:613] Iteration 8960, avg_grad_norm = 639764
I0314 22:28:50.839349 29479 solver.cpp:214] Iteration 8980, loss = 7508.72
I0314 22:28:50.839467 29479 solver.cpp:229]     Train net output #0: loss = 7216.52 (* 1 = 7216.52 loss)
I0314 22:28:51.197695 29479 solver.cpp:610] Iteration 8980, lr = 9.59498e-09
I0314 22:28:51.197710 29479 solver.cpp:613] Iteration 8980, avg_grad_norm = 681937
I0314 22:29:54.355273 29479 solver.cpp:214] Iteration 9000, loss = 7910.66
I0314 22:29:54.355401 29479 solver.cpp:229]     Train net output #0: loss = 3766.62 (* 1 = 3766.62 loss)
I0314 22:29:54.570535 29479 solver.cpp:610] Iteration 9000, lr = 9.59407e-09
I0314 22:29:54.570549 29479 solver.cpp:613] Iteration 9000, avg_grad_norm = 805799
I0314 22:31:13.447095 29479 solver.cpp:214] Iteration 9020, loss = 7496.3
I0314 22:31:13.447242 29479 solver.cpp:229]     Train net output #0: loss = 5565.35 (* 1 = 5565.35 loss)
I0314 22:31:13.551532 29479 solver.cpp:610] Iteration 9020, lr = 9.59317e-09
I0314 22:31:13.551544 29479 solver.cpp:613] Iteration 9020, avg_grad_norm = 804990
I0314 22:31:58.751359 29479 solver.cpp:214] Iteration 9040, loss = 7847.32
I0314 22:31:58.751509 29479 solver.cpp:229]     Train net output #0: loss = 5760.71 (* 1 = 5760.71 loss)
I0314 22:31:59.109567 29479 solver.cpp:610] Iteration 9040, lr = 9.59226e-09
I0314 22:31:59.109580 29479 solver.cpp:613] Iteration 9040, avg_grad_norm = 741407
I0314 22:33:02.588521 29479 solver.cpp:214] Iteration 9060, loss = 8089.76
I0314 22:33:02.588714 29479 solver.cpp:229]     Train net output #0: loss = 4356.86 (* 1 = 4356.86 loss)
I0314 22:33:02.954588 29479 solver.cpp:610] Iteration 9060, lr = 9.59136e-09
I0314 22:33:02.954602 29479 solver.cpp:613] Iteration 9060, avg_grad_norm = 734035
I0314 22:34:06.506865 29479 solver.cpp:214] Iteration 9080, loss = 7614.16
I0314 22:34:06.507020 29479 solver.cpp:229]     Train net output #0: loss = 5312.25 (* 1 = 5312.25 loss)
I0314 22:34:06.870517 29479 solver.cpp:610] Iteration 9080, lr = 9.59046e-09
I0314 22:34:06.870529 29479 solver.cpp:613] Iteration 9080, avg_grad_norm = 608644
I0314 22:35:10.510890 29479 solver.cpp:214] Iteration 9100, loss = 7538.81
I0314 22:35:10.511015 29479 solver.cpp:229]     Train net output #0: loss = 4958.97 (* 1 = 4958.97 loss)
I0314 22:35:10.724033 29479 solver.cpp:610] Iteration 9100, lr = 9.58955e-09
I0314 22:35:10.724046 29479 solver.cpp:613] Iteration 9100, avg_grad_norm = 659520
I0314 22:36:14.526463 29479 solver.cpp:214] Iteration 9120, loss = 8175.69
I0314 22:36:14.526592 29479 solver.cpp:229]     Train net output #0: loss = 12150.7 (* 1 = 12150.7 loss)
I0314 22:36:14.739245 29479 solver.cpp:610] Iteration 9120, lr = 9.58865e-09
I0314 22:36:14.739259 29479 solver.cpp:613] Iteration 9120, avg_grad_norm = 773148
I0314 22:37:18.510370 29479 solver.cpp:214] Iteration 9140, loss = 7849.81
I0314 22:37:18.510475 29479 solver.cpp:229]     Train net output #0: loss = 8259.14 (* 1 = 8259.14 loss)
I0314 22:37:18.719797 29479 solver.cpp:610] Iteration 9140, lr = 9.58774e-09
I0314 22:37:18.719810 29479 solver.cpp:613] Iteration 9140, avg_grad_norm = 772774
I0314 22:38:34.772106 29479 solver.cpp:214] Iteration 9160, loss = 7955.84
I0314 22:38:34.772269 29479 solver.cpp:229]     Train net output #0: loss = 9612.15 (* 1 = 9612.15 loss)
I0314 22:38:35.136071 29479 solver.cpp:610] Iteration 9160, lr = 9.58684e-09
I0314 22:38:35.136085 29479 solver.cpp:613] Iteration 9160, avg_grad_norm = 833851
I0314 22:39:16.130707 29479 solver.cpp:214] Iteration 9180, loss = 7866.81
I0314 22:39:16.130857 29479 solver.cpp:229]     Train net output #0: loss = 6951.39 (* 1 = 6951.39 loss)
I0314 22:39:16.247025 29479 solver.cpp:610] Iteration 9180, lr = 9.58594e-09
I0314 22:39:16.247037 29479 solver.cpp:613] Iteration 9180, avg_grad_norm = 737992
I0314 22:40:12.971434 29479 solver.cpp:214] Iteration 9200, loss = 7740.1
I0314 22:40:12.971575 29479 solver.cpp:229]     Train net output #0: loss = 5231.34 (* 1 = 5231.34 loss)
I0314 22:40:13.342965 29479 solver.cpp:610] Iteration 9200, lr = 9.58503e-09
I0314 22:40:13.342978 29479 solver.cpp:613] Iteration 9200, avg_grad_norm = 680898
I0314 22:41:17.035679 29479 solver.cpp:214] Iteration 9220, loss = 7868.3
I0314 22:41:17.035822 29479 solver.cpp:229]     Train net output #0: loss = 7558.35 (* 1 = 7558.35 loss)
I0314 22:41:17.393776 29479 solver.cpp:610] Iteration 9220, lr = 9.58413e-09
I0314 22:41:17.393790 29479 solver.cpp:613] Iteration 9220, avg_grad_norm = 713695
I0314 22:42:21.142731 29479 solver.cpp:214] Iteration 9240, loss = 7725.06
I0314 22:42:21.142838 29479 solver.cpp:229]     Train net output #0: loss = 5511.6 (* 1 = 5511.6 loss)
I0314 22:42:21.358156 29479 solver.cpp:610] Iteration 9240, lr = 9.58322e-09
I0314 22:42:21.358170 29479 solver.cpp:613] Iteration 9240, avg_grad_norm = 702824
I0314 22:43:25.156522 29479 solver.cpp:214] Iteration 9260, loss = 7567.58
I0314 22:43:25.156644 29479 solver.cpp:229]     Train net output #0: loss = 5706.36 (* 1 = 5706.36 loss)
I0314 22:43:25.520870 29479 solver.cpp:610] Iteration 9260, lr = 9.58232e-09
I0314 22:43:25.520884 29479 solver.cpp:613] Iteration 9260, avg_grad_norm = 673349
I0314 22:44:41.749959 29479 solver.cpp:214] Iteration 9280, loss = 8019.51
I0314 22:44:41.750089 29479 solver.cpp:229]     Train net output #0: loss = 6111.79 (* 1 = 6111.79 loss)
I0314 22:44:42.117123 29479 solver.cpp:610] Iteration 9280, lr = 9.58141e-09
I0314 22:44:42.117137 29479 solver.cpp:613] Iteration 9280, avg_grad_norm = 780245
I0314 22:45:45.735677 29479 solver.cpp:214] Iteration 9300, loss = 7769.25
I0314 22:45:45.735786 29479 solver.cpp:229]     Train net output #0: loss = 10134.6 (* 1 = 10134.6 loss)
I0314 22:45:46.101112 29479 solver.cpp:610] Iteration 9300, lr = 9.58051e-09
I0314 22:45:46.101125 29479 solver.cpp:613] Iteration 9300, avg_grad_norm = 685271
I0314 22:46:49.823801 29479 solver.cpp:214] Iteration 9320, loss = 7934.49
I0314 22:46:49.823923 29479 solver.cpp:229]     Train net output #0: loss = 4887.4 (* 1 = 4887.4 loss)
I0314 22:46:50.193392 29479 solver.cpp:610] Iteration 9320, lr = 9.57961e-09
I0314 22:46:50.193403 29479 solver.cpp:613] Iteration 9320, avg_grad_norm = 680870
I0314 22:47:20.229416 29479 solver.cpp:214] Iteration 9340, loss = 8038.7
I0314 22:47:20.229532 29479 solver.cpp:229]     Train net output #0: loss = 5359.8 (* 1 = 5359.8 loss)
I0314 22:47:20.345731 29479 solver.cpp:610] Iteration 9340, lr = 9.5787e-09
I0314 22:47:20.345744 29479 solver.cpp:613] Iteration 9340, avg_grad_norm = 825677
I0314 22:48:23.833490 29479 solver.cpp:214] Iteration 9360, loss = 8077.36
I0314 22:48:23.833673 29479 solver.cpp:229]     Train net output #0: loss = 8840 (* 1 = 8840 loss)
I0314 22:48:24.041853 29479 solver.cpp:610] Iteration 9360, lr = 9.5778e-09
I0314 22:48:24.041867 29479 solver.cpp:613] Iteration 9360, avg_grad_norm = 867452
I0314 22:49:27.709545 29479 solver.cpp:214] Iteration 9380, loss = 7820.53
I0314 22:49:27.709658 29479 solver.cpp:229]     Train net output #0: loss = 10888.8 (* 1 = 10888.8 loss)
I0314 22:49:28.069113 29479 solver.cpp:610] Iteration 9380, lr = 9.57689e-09
I0314 22:49:28.069126 29479 solver.cpp:613] Iteration 9380, avg_grad_norm = 631051
I0314 22:50:44.705273 29479 solver.cpp:214] Iteration 9400, loss = 8015.69
I0314 22:50:44.705420 29479 solver.cpp:229]     Train net output #0: loss = 12048.4 (* 1 = 12048.4 loss)
I0314 22:50:45.065171 29479 solver.cpp:610] Iteration 9400, lr = 9.57599e-09
I0314 22:50:45.065184 29479 solver.cpp:613] Iteration 9400, avg_grad_norm = 729804
I0314 22:51:48.917382 29479 solver.cpp:214] Iteration 9420, loss = 7540.83
I0314 22:51:48.917570 29479 solver.cpp:229]     Train net output #0: loss = 8726.36 (* 1 = 8726.36 loss)
I0314 22:51:49.124100 29479 solver.cpp:610] Iteration 9420, lr = 9.57508e-09
I0314 22:51:49.124114 29479 solver.cpp:613] Iteration 9420, avg_grad_norm = 784230
I0314 22:52:53.016245 29479 solver.cpp:214] Iteration 9440, loss = 7724.32
I0314 22:52:53.016434 29479 solver.cpp:229]     Train net output #0: loss = 8444.58 (* 1 = 8444.58 loss)
I0314 22:52:53.227641 29479 solver.cpp:610] Iteration 9440, lr = 9.57418e-09
I0314 22:52:53.227654 29479 solver.cpp:613] Iteration 9440, avg_grad_norm = 666804
I0314 22:53:56.988379 29479 solver.cpp:214] Iteration 9460, loss = 7773.35
I0314 22:53:56.988490 29479 solver.cpp:229]     Train net output #0: loss = 12186 (* 1 = 12186 loss)
I0314 22:53:57.204064 29479 solver.cpp:610] Iteration 9460, lr = 9.57328e-09
I0314 22:53:57.204077 29479 solver.cpp:613] Iteration 9460, avg_grad_norm = 676062
I0314 22:54:58.858129 29479 solver.cpp:214] Iteration 9480, loss = 7996.18
I0314 22:54:58.858256 29479 solver.cpp:229]     Train net output #0: loss = 11164.2 (* 1 = 11164.2 loss)
I0314 22:54:58.963178 29479 solver.cpp:610] Iteration 9480, lr = 9.57237e-09
I0314 22:54:58.963191 29479 solver.cpp:613] Iteration 9480, avg_grad_norm = 677071
I0314 22:55:29.568953 29479 solver.cpp:214] Iteration 9500, loss = 8053.81
I0314 22:55:29.569046 29479 solver.cpp:229]     Train net output #0: loss = 5864.36 (* 1 = 5864.36 loss)
I0314 22:55:29.774544 29479 solver.cpp:610] Iteration 9500, lr = 9.57147e-09
I0314 22:55:29.774557 29479 solver.cpp:613] Iteration 9500, avg_grad_norm = 676106
I0314 22:56:33.578999 29479 solver.cpp:214] Iteration 9520, loss = 7492.6
I0314 22:56:33.579109 29479 solver.cpp:229]     Train net output #0: loss = 5079.4 (* 1 = 5079.4 loss)
I0314 22:56:33.776592 29479 solver.cpp:610] Iteration 9520, lr = 9.57056e-09
I0314 22:56:33.776605 29479 solver.cpp:613] Iteration 9520, avg_grad_norm = 619925
I0314 22:57:50.566221 29479 solver.cpp:214] Iteration 9540, loss = 7637.75
I0314 22:57:50.566356 29479 solver.cpp:229]     Train net output #0: loss = 6548.7 (* 1 = 6548.7 loss)
I0314 22:57:50.923494 29479 solver.cpp:610] Iteration 9540, lr = 9.56966e-09
I0314 22:57:50.923507 29479 solver.cpp:613] Iteration 9540, avg_grad_norm = 741447
I0314 22:58:54.439784 29479 solver.cpp:214] Iteration 9560, loss = 7516.4
I0314 22:58:54.439970 29479 solver.cpp:229]     Train net output #0: loss = 12733.9 (* 1 = 12733.9 loss)
I0314 22:58:54.805248 29479 solver.cpp:610] Iteration 9560, lr = 9.56875e-09
I0314 22:58:54.805264 29479 solver.cpp:613] Iteration 9560, avg_grad_norm = 629670
I0314 22:59:58.551506 29479 solver.cpp:214] Iteration 9580, loss = 7606.95
I0314 22:59:58.551636 29479 solver.cpp:229]     Train net output #0: loss = 5394 (* 1 = 5394 loss)
I0314 22:59:58.755861 29479 solver.cpp:610] Iteration 9580, lr = 9.56785e-09
I0314 22:59:58.755873 29479 solver.cpp:613] Iteration 9580, avg_grad_norm = 720234
I0314 23:01:02.462119 29479 solver.cpp:214] Iteration 9600, loss = 8005.9
I0314 23:01:02.462270 29479 solver.cpp:229]     Train net output #0: loss = 3391.86 (* 1 = 3391.86 loss)
I0314 23:01:02.828311 29479 solver.cpp:610] Iteration 9600, lr = 9.56694e-09
I0314 23:01:02.828325 29479 solver.cpp:613] Iteration 9600, avg_grad_norm = 683945
I0314 23:02:06.404314 29479 solver.cpp:214] Iteration 9620, loss = 7637.55
I0314 23:02:06.404420 29479 solver.cpp:229]     Train net output #0: loss = 12652.5 (* 1 = 12652.5 loss)
I0314 23:02:06.764780 29479 solver.cpp:610] Iteration 9620, lr = 9.56604e-09
I0314 23:02:06.764796 29479 solver.cpp:613] Iteration 9620, avg_grad_norm = 615701
I0314 23:03:06.158061 29479 solver.cpp:214] Iteration 9640, loss = 7874.32
I0314 23:03:06.158242 29479 solver.cpp:229]     Train net output #0: loss = 15000.9 (* 1 = 15000.9 loss)
I0314 23:03:06.267036 29479 solver.cpp:610] Iteration 9640, lr = 9.56514e-09
I0314 23:03:06.267079 29479 solver.cpp:613] Iteration 9640, avg_grad_norm = 655602
I0314 23:04:11.117250 29479 solver.cpp:214] Iteration 9660, loss = 7925.04
I0314 23:04:11.117374 29479 solver.cpp:229]     Train net output #0: loss = 6318.06 (* 1 = 6318.06 loss)
I0314 23:04:11.317495 29479 solver.cpp:610] Iteration 9660, lr = 9.56423e-09
I0314 23:04:11.317508 29479 solver.cpp:613] Iteration 9660, avg_grad_norm = 609373
I0314 23:05:14.903236 29479 solver.cpp:214] Iteration 9680, loss = 7331.38
I0314 23:05:14.903404 29479 solver.cpp:229]     Train net output #0: loss = 4976.73 (* 1 = 4976.73 loss)
I0314 23:05:15.261742 29479 solver.cpp:610] Iteration 9680, lr = 9.56333e-09
I0314 23:05:15.261756 29479 solver.cpp:613] Iteration 9680, avg_grad_norm = 615424
I0314 23:06:18.969384 29479 solver.cpp:214] Iteration 9700, loss = 7716.42
I0314 23:06:18.969499 29479 solver.cpp:229]     Train net output #0: loss = 15691.2 (* 1 = 15691.2 loss)
I0314 23:06:19.172521 29479 solver.cpp:610] Iteration 9700, lr = 9.56242e-09
I0314 23:06:19.172534 29479 solver.cpp:613] Iteration 9700, avg_grad_norm = 616291
I0314 23:07:22.744742 29479 solver.cpp:214] Iteration 9720, loss = 7928.69
I0314 23:07:22.744868 29479 solver.cpp:229]     Train net output #0: loss = 6544.49 (* 1 = 6544.49 loss)
I0314 23:07:23.113626 29479 solver.cpp:610] Iteration 9720, lr = 9.56152e-09
I0314 23:07:23.113638 29479 solver.cpp:613] Iteration 9720, avg_grad_norm = 704101
I0314 23:08:26.824165 29479 solver.cpp:214] Iteration 9740, loss = 7970.18
I0314 23:08:26.824295 29479 solver.cpp:229]     Train net output #0: loss = 5001.67 (* 1 = 5001.67 loss)
I0314 23:08:27.192384 29479 solver.cpp:610] Iteration 9740, lr = 9.56061e-09
I0314 23:08:27.192399 29479 solver.cpp:613] Iteration 9740, avg_grad_norm = 651718
I0314 23:09:30.669754 29479 solver.cpp:214] Iteration 9760, loss = 7632.32
I0314 23:09:30.669905 29479 solver.cpp:229]     Train net output #0: loss = 11678.7 (* 1 = 11678.7 loss)
I0314 23:09:31.033715 29479 solver.cpp:610] Iteration 9760, lr = 9.55971e-09
I0314 23:09:31.033728 29479 solver.cpp:613] Iteration 9760, avg_grad_norm = 669281
I0314 23:10:47.372871 29479 solver.cpp:214] Iteration 9780, loss = 7541.76
I0314 23:10:47.372983 29479 solver.cpp:229]     Train net output #0: loss = 5456.64 (* 1 = 5456.64 loss)
I0314 23:10:47.731292 29479 solver.cpp:610] Iteration 9780, lr = 9.5588e-09
I0314 23:10:47.731308 29479 solver.cpp:613] Iteration 9780, avg_grad_norm = 591544
I0314 23:11:17.899116 29479 solver.cpp:214] Iteration 9800, loss = 7783.96
I0314 23:11:17.899245 29479 solver.cpp:229]     Train net output #0: loss = 11773.9 (* 1 = 11773.9 loss)
I0314 23:11:18.236531 29479 solver.cpp:610] Iteration 9800, lr = 9.5579e-09
I0314 23:11:18.236542 29479 solver.cpp:613] Iteration 9800, avg_grad_norm = 644026
I0314 23:12:21.680438 29479 solver.cpp:214] Iteration 9820, loss = 7288.91
I0314 23:12:21.680624 29479 solver.cpp:229]     Train net output #0: loss = 4943.82 (* 1 = 4943.82 loss)
I0314 23:12:22.046337 29479 solver.cpp:610] Iteration 9820, lr = 9.557e-09
I0314 23:12:22.046350 29479 solver.cpp:613] Iteration 9820, avg_grad_norm = 635303
I0314 23:13:25.900485 29479 solver.cpp:214] Iteration 9840, loss = 7914.83
I0314 23:13:25.900699 29479 solver.cpp:229]     Train net output #0: loss = 6284.12 (* 1 = 6284.12 loss)
I0314 23:13:26.264968 29479 solver.cpp:610] Iteration 9840, lr = 9.55609e-09
I0314 23:13:26.264987 29479 solver.cpp:613] Iteration 9840, avg_grad_norm = 656223
I0314 23:14:29.854182 29479 solver.cpp:214] Iteration 9860, loss = 7741.27
I0314 23:14:29.854318 29479 solver.cpp:229]     Train net output #0: loss = 9473.47 (* 1 = 9473.47 loss)
I0314 23:14:30.213132 29479 solver.cpp:610] Iteration 9860, lr = 9.55519e-09
I0314 23:14:30.213192 29479 solver.cpp:613] Iteration 9860, avg_grad_norm = 590838
I0314 23:15:34.019913 29479 solver.cpp:214] Iteration 9880, loss = 7416.27
I0314 23:15:34.020090 29479 solver.cpp:229]     Train net output #0: loss = 7751.67 (* 1 = 7751.67 loss)
I0314 23:15:34.386364 29479 solver.cpp:610] Iteration 9880, lr = 9.55428e-09
I0314 23:15:34.386378 29479 solver.cpp:613] Iteration 9880, avg_grad_norm = 613363
I0314 23:16:38.114719 29479 solver.cpp:214] Iteration 9900, loss = 7778.56
I0314 23:16:38.114852 29479 solver.cpp:229]     Train net output #0: loss = 5323.84 (* 1 = 5323.84 loss)
I0314 23:16:38.330409 29479 solver.cpp:610] Iteration 9900, lr = 9.55338e-09
I0314 23:16:38.330421 29479 solver.cpp:613] Iteration 9900, avg_grad_norm = 653343
I0314 23:17:59.200472 29479 solver.cpp:214] Iteration 9920, loss = 8021.28
I0314 23:17:59.200598 29479 solver.cpp:229]     Train net output #0: loss = 3294.51 (* 1 = 3294.51 loss)
I0314 23:17:59.560394 29479 solver.cpp:610] Iteration 9920, lr = 9.55247e-09
I0314 23:17:59.560407 29479 solver.cpp:613] Iteration 9920, avg_grad_norm = 684658
I0314 23:18:53.107586 29479 solver.cpp:214] Iteration 9940, loss = 7780.58
I0314 23:18:53.107741 29479 solver.cpp:229]     Train net output #0: loss = 6384.38 (* 1 = 6384.38 loss)
I0314 23:18:53.222976 29479 solver.cpp:610] Iteration 9940, lr = 9.55157e-09
I0314 23:18:53.222990 29479 solver.cpp:613] Iteration 9940, avg_grad_norm = 650792
I0314 23:19:47.117815 29479 solver.cpp:214] Iteration 9960, loss = 8058.88
I0314 23:19:47.118017 29479 solver.cpp:229]     Train net output #0: loss = 11325.8 (* 1 = 11325.8 loss)
I0314 23:19:47.482530 29479 solver.cpp:610] Iteration 9960, lr = 9.55066e-09
I0314 23:19:47.482543 29479 solver.cpp:613] Iteration 9960, avg_grad_norm = 706446
I0314 23:20:51.219130 29479 solver.cpp:214] Iteration 9980, loss = 7892.05
I0314 23:20:51.219245 29479 solver.cpp:229]     Train net output #0: loss = 11780.6 (* 1 = 11780.6 loss)
I0314 23:20:51.435053 29479 solver.cpp:610] Iteration 9980, lr = 9.54976e-09
I0314 23:20:51.435066 29479 solver.cpp:613] Iteration 9980, avg_grad_norm = 635316
I0314 23:21:52.653226 29479 solver.cpp:458] Snapshotting to models/pnet/VGG_VOC2012ext_iter_10000.caffemodel
I0314 23:21:53.938305 29479 solver.cpp:466] Snapshotting solver state to models/pnet/VGG_VOC2012ext_iter_10000.solverstate
I0314 23:21:57.579850 29479 solver.cpp:214] Iteration 10000, loss = 7429.57
I0314 23:21:57.579900 29479 solver.cpp:229]     Train net output #0: loss = 8038.05 (* 1 = 8038.05 loss)
I0314 23:21:57.760805 29479 solver.cpp:610] Iteration 10000, lr = 9.54885e-09
I0314 23:21:57.760819 29479 solver.cpp:613] Iteration 10000, avg_grad_norm = 690058
I0314 23:23:01.531705 29479 solver.cpp:214] Iteration 10020, loss = 7869.77
I0314 23:23:01.531906 29479 solver.cpp:229]     Train net output #0: loss = 7155.56 (* 1 = 7155.56 loss)
I0314 23:23:01.747022 29479 solver.cpp:610] Iteration 10020, lr = 9.54795e-09
I0314 23:23:01.747036 29479 solver.cpp:613] Iteration 10020, avg_grad_norm = 683168
I0314 23:24:18.726208 29479 solver.cpp:214] Iteration 10040, loss = 7475.44
I0314 23:24:18.726364 29479 solver.cpp:229]     Train net output #0: loss = 5078.13 (* 1 = 5078.13 loss)
I0314 23:24:19.090911 29479 solver.cpp:610] Iteration 10040, lr = 9.54704e-09
I0314 23:24:19.090926 29479 solver.cpp:613] Iteration 10040, avg_grad_norm = 716525
I0314 23:25:22.694939 29479 solver.cpp:214] Iteration 10060, loss = 7722.94
I0314 23:25:22.695066 29479 solver.cpp:229]     Train net output #0: loss = 10108.6 (* 1 = 10108.6 loss)
I0314 23:25:23.059331 29479 solver.cpp:610] Iteration 10060, lr = 9.54614e-09
I0314 23:25:23.059345 29479 solver.cpp:613] Iteration 10060, avg_grad_norm = 739734
I0314 23:26:26.828055 29479 solver.cpp:214] Iteration 10080, loss = 7936.25
I0314 23:26:26.828174 29479 solver.cpp:229]     Train net output #0: loss = 5545 (* 1 = 5545 loss)
I0314 23:26:27.044309 29479 solver.cpp:610] Iteration 10080, lr = 9.54523e-09
I0314 23:26:27.044322 29479 solver.cpp:613] Iteration 10080, avg_grad_norm = 753016
I0314 23:27:11.637868 29479 solver.cpp:214] Iteration 10100, loss = 7663.96
I0314 23:27:11.638011 29479 solver.cpp:229]     Train net output #0: loss = 3840.78 (* 1 = 3840.78 loss)
I0314 23:27:11.978790 29479 solver.cpp:610] Iteration 10100, lr = 9.54433e-09
I0314 23:27:11.978803 29479 solver.cpp:613] Iteration 10100, avg_grad_norm = 755985
I0314 23:28:15.715490 29479 solver.cpp:214] Iteration 10120, loss = 7587.1
I0314 23:28:15.715606 29479 solver.cpp:229]     Train net output #0: loss = 4766.01 (* 1 = 4766.01 loss)
I0314 23:28:16.079927 29479 solver.cpp:610] Iteration 10120, lr = 9.54343e-09
I0314 23:28:16.079941 29479 solver.cpp:613] Iteration 10120, avg_grad_norm = 753085
I0314 23:29:19.799437 29479 solver.cpp:214] Iteration 10140, loss = 7493.02
I0314 23:29:19.799545 29479 solver.cpp:229]     Train net output #0: loss = 6912.74 (* 1 = 6912.74 loss)
I0314 23:29:20.157904 29479 solver.cpp:610] Iteration 10140, lr = 9.54252e-09
I0314 23:29:20.157917 29479 solver.cpp:613] Iteration 10140, avg_grad_norm = 699466
I0314 23:30:37.418589 29479 solver.cpp:214] Iteration 10160, loss = 7727.53
I0314 23:30:37.418706 29479 solver.cpp:229]     Train net output #0: loss = 7205.8 (* 1 = 7205.8 loss)
I0314 23:30:37.781875 29479 solver.cpp:610] Iteration 10160, lr = 9.54162e-09
I0314 23:30:37.781888 29479 solver.cpp:613] Iteration 10160, avg_grad_norm = 603385
I0314 23:31:42.513389 29479 solver.cpp:214] Iteration 10180, loss = 7280.15
I0314 23:31:42.513533 29479 solver.cpp:229]     Train net output #0: loss = 7243.03 (* 1 = 7243.03 loss)
I0314 23:31:42.882602 29479 solver.cpp:610] Iteration 10180, lr = 9.54071e-09
I0314 23:31:42.882616 29479 solver.cpp:613] Iteration 10180, avg_grad_norm = 712304
I0314 23:32:46.721024 29479 solver.cpp:214] Iteration 10200, loss = 7565.98
I0314 23:32:46.721209 29479 solver.cpp:229]     Train net output #0: loss = 9444.71 (* 1 = 9444.71 loss)
I0314 23:32:46.922461 29479 solver.cpp:610] Iteration 10200, lr = 9.53981e-09
I0314 23:32:46.922477 29479 solver.cpp:613] Iteration 10200, avg_grad_norm = 669872
I0314 23:33:50.876289 29479 solver.cpp:214] Iteration 10220, loss = 7573.86
I0314 23:33:50.876401 29479 solver.cpp:229]     Train net output #0: loss = 9678.88 (* 1 = 9678.88 loss)
I0314 23:33:51.091972 29479 solver.cpp:610] Iteration 10220, lr = 9.5389e-09
I0314 23:33:51.091985 29479 solver.cpp:613] Iteration 10220, avg_grad_norm = 658324
I0314 23:34:35.881362 29479 solver.cpp:214] Iteration 10240, loss = 7490.8
I0314 23:34:35.881515 29479 solver.cpp:229]     Train net output #0: loss = 5716 (* 1 = 5716 loss)
I0314 23:34:35.999711 29479 solver.cpp:610] Iteration 10240, lr = 9.538e-09
I0314 23:34:35.999723 29479 solver.cpp:613] Iteration 10240, avg_grad_norm = 631664
I0314 23:35:39.726701 29479 solver.cpp:214] Iteration 10260, loss = 7531.48
I0314 23:35:39.726847 29479 solver.cpp:229]     Train net output #0: loss = 5456.79 (* 1 = 5456.79 loss)
I0314 23:35:39.943037 29479 solver.cpp:610] Iteration 10260, lr = 9.53709e-09
I0314 23:35:39.943048 29479 solver.cpp:613] Iteration 10260, avg_grad_norm = 632306
I0314 23:36:43.804652 29479 solver.cpp:214] Iteration 10280, loss = 7546.78
I0314 23:36:43.804846 29479 solver.cpp:229]     Train net output #0: loss = 6503.94 (* 1 = 6503.94 loss)
I0314 23:36:44.018347 29479 solver.cpp:610] Iteration 10280, lr = 9.53619e-09
I0314 23:36:44.018360 29479 solver.cpp:613] Iteration 10280, avg_grad_norm = 634966
I0314 23:38:00.852327 29479 solver.cpp:214] Iteration 10300, loss = 7463.76
I0314 23:38:00.852526 29479 solver.cpp:229]     Train net output #0: loss = 6425.29 (* 1 = 6425.29 loss)
I0314 23:38:01.221345 29479 solver.cpp:610] Iteration 10300, lr = 9.53528e-09
I0314 23:38:01.221359 29479 solver.cpp:613] Iteration 10300, avg_grad_norm = 646067
I0314 23:39:05.384515 29479 solver.cpp:214] Iteration 10320, loss = 7514.57
I0314 23:39:05.384657 29479 solver.cpp:229]     Train net output #0: loss = 6027.42 (* 1 = 6027.42 loss)
I0314 23:39:05.601498 29479 solver.cpp:610] Iteration 10320, lr = 9.53438e-09
I0314 23:39:05.601512 29479 solver.cpp:613] Iteration 10320, avg_grad_norm = 622620
I0314 23:40:09.200022 29479 solver.cpp:214] Iteration 10340, loss = 7557.85
I0314 23:40:09.200193 29479 solver.cpp:229]     Train net output #0: loss = 5145.86 (* 1 = 5145.86 loss)
I0314 23:40:09.557981 29479 solver.cpp:610] Iteration 10340, lr = 9.53347e-09
I0314 23:40:09.557994 29479 solver.cpp:613] Iteration 10340, avg_grad_norm = 684702
I0314 23:41:13.332726 29479 solver.cpp:214] Iteration 10360, loss = 7553.58
I0314 23:41:13.332834 29479 solver.cpp:229]     Train net output #0: loss = 10985.2 (* 1 = 10985.2 loss)
I0314 23:41:13.702441 29479 solver.cpp:610] Iteration 10360, lr = 9.53257e-09
I0314 23:41:13.702455 29479 solver.cpp:613] Iteration 10360, avg_grad_norm = 650700
I0314 23:42:14.461432 29479 solver.cpp:214] Iteration 10380, loss = 7499.73
I0314 23:42:14.461612 29479 solver.cpp:229]     Train net output #0: loss = 5051.85 (* 1 = 5051.85 loss)
I0314 23:42:14.569205 29479 solver.cpp:610] Iteration 10380, lr = 9.53166e-09
I0314 23:42:14.569217 29479 solver.cpp:613] Iteration 10380, avg_grad_norm = 622717
I0314 23:42:40.451448 29479 solver.cpp:214] Iteration 10400, loss = 7944.8
I0314 23:42:40.451524 29479 solver.cpp:229]     Train net output #0: loss = 5804.55 (* 1 = 5804.55 loss)
I0314 23:42:40.574812 29479 solver.cpp:610] Iteration 10400, lr = 9.53076e-09
I0314 23:42:40.574826 29479 solver.cpp:613] Iteration 10400, avg_grad_norm = 684678
I0314 23:43:18.542268 29479 solver.cpp:214] Iteration 10420, loss = 7759.06
I0314 23:43:18.542421 29479 solver.cpp:229]     Train net output #0: loss = 5721.26 (* 1 = 5721.26 loss)
I0314 23:43:18.647600 29479 solver.cpp:610] Iteration 10420, lr = 9.52985e-09
I0314 23:43:18.647614 29479 solver.cpp:613] Iteration 10420, avg_grad_norm = 723594
I0314 23:43:42.571388 29479 solver.cpp:214] Iteration 10440, loss = 7226.44
I0314 23:43:42.571452 29479 solver.cpp:229]     Train net output #0: loss = 6989.38 (* 1 = 6989.38 loss)
I0314 23:43:42.686074 29479 solver.cpp:610] Iteration 10440, lr = 9.52895e-09
I0314 23:43:42.686087 29479 solver.cpp:613] Iteration 10440, avg_grad_norm = 711629
I0314 23:44:08.252779 29479 solver.cpp:214] Iteration 10460, loss = 8055.88
I0314 23:44:08.252986 29479 solver.cpp:229]     Train net output #0: loss = 5307.23 (* 1 = 5307.23 loss)
I0314 23:44:08.367521 29479 solver.cpp:610] Iteration 10460, lr = 9.52805e-09
I0314 23:44:08.367534 29479 solver.cpp:613] Iteration 10460, avg_grad_norm = 649813
I0314 23:44:33.991866 29479 solver.cpp:214] Iteration 10480, loss = 7790.31
I0314 23:44:33.991940 29479 solver.cpp:229]     Train net output #0: loss = 4830.51 (* 1 = 4830.51 loss)
I0314 23:44:34.106549 29479 solver.cpp:610] Iteration 10480, lr = 9.52714e-09
I0314 23:44:34.106564 29479 solver.cpp:613] Iteration 10480, avg_grad_norm = 625156
I0314 23:44:59.767393 29479 solver.cpp:214] Iteration 10500, loss = 7201.74
I0314 23:44:59.767612 29479 solver.cpp:229]     Train net output #0: loss = 5793.03 (* 1 = 5793.03 loss)
I0314 23:44:59.882007 29479 solver.cpp:610] Iteration 10500, lr = 9.52623e-09
I0314 23:44:59.882021 29479 solver.cpp:613] Iteration 10500, avg_grad_norm = 646838
I0314 23:45:25.771180 29479 solver.cpp:214] Iteration 10520, loss = 7759.42
I0314 23:45:25.771245 29479 solver.cpp:229]     Train net output #0: loss = 7776.95 (* 1 = 7776.95 loss)
I0314 23:45:25.887276 29479 solver.cpp:610] Iteration 10520, lr = 9.52533e-09
I0314 23:45:25.887290 29479 solver.cpp:613] Iteration 10520, avg_grad_norm = 776214
I0314 23:46:18.789505 29479 solver.cpp:214] Iteration 10540, loss = 7450.31
I0314 23:46:18.789628 29479 solver.cpp:229]     Train net output #0: loss = 6734.95 (* 1 = 6734.95 loss)
I0314 23:46:18.892560 29479 solver.cpp:610] Iteration 10540, lr = 9.52443e-09
I0314 23:46:18.892575 29479 solver.cpp:613] Iteration 10540, avg_grad_norm = 649332
I0314 23:46:42.329884 29479 solver.cpp:214] Iteration 10560, loss = 7787.88
I0314 23:46:42.329948 29479 solver.cpp:229]     Train net output #0: loss = 3370.54 (* 1 = 3370.54 loss)
I0314 23:46:42.435287 29479 solver.cpp:610] Iteration 10560, lr = 9.52352e-09
I0314 23:46:42.435302 29479 solver.cpp:613] Iteration 10560, avg_grad_norm = 629121
I0314 23:47:05.957671 29479 solver.cpp:214] Iteration 10580, loss = 7470.33
I0314 23:47:05.957854 29479 solver.cpp:229]     Train net output #0: loss = 10012.6 (* 1 = 10012.6 loss)
I0314 23:47:06.062979 29479 solver.cpp:610] Iteration 10580, lr = 9.52262e-09
I0314 23:47:06.062994 29479 solver.cpp:613] Iteration 10580, avg_grad_norm = 627493
I0314 23:47:30.893101 29479 solver.cpp:214] Iteration 10600, loss = 7298.53
I0314 23:47:30.893156 29479 solver.cpp:229]     Train net output #0: loss = 7659.7 (* 1 = 7659.7 loss)
I0314 23:47:31.006295 29479 solver.cpp:610] Iteration 10600, lr = 9.52171e-09
I0314 23:47:31.006309 29479 solver.cpp:613] Iteration 10600, avg_grad_norm = 667177
I0314 23:47:56.608342 29479 solver.cpp:214] Iteration 10620, loss = 7283.63
I0314 23:47:56.608481 29479 solver.cpp:229]     Train net output #0: loss = 7081.03 (* 1 = 7081.03 loss)
I0314 23:47:56.722991 29479 solver.cpp:610] Iteration 10620, lr = 9.52081e-09
I0314 23:47:56.723006 29479 solver.cpp:613] Iteration 10620, avg_grad_norm = 659819
I0314 23:48:22.193338 29479 solver.cpp:214] Iteration 10640, loss = 7487.41
I0314 23:48:22.193382 29479 solver.cpp:229]     Train net output #0: loss = 4535.46 (* 1 = 4535.46 loss)
I0314 23:48:22.306324 29479 solver.cpp:610] Iteration 10640, lr = 9.5199e-09
I0314 23:48:22.306339 29479 solver.cpp:613] Iteration 10640, avg_grad_norm = 671538
I0314 23:48:47.597055 29479 solver.cpp:214] Iteration 10660, loss = 7431.23
I0314 23:48:47.597265 29479 solver.cpp:229]     Train net output #0: loss = 5545.33 (* 1 = 5545.33 loss)
I0314 23:48:47.709962 29479 solver.cpp:610] Iteration 10660, lr = 9.519e-09
I0314 23:48:47.709975 29479 solver.cpp:613] Iteration 10660, avg_grad_norm = 612626
I0314 23:49:24.528508 29479 solver.cpp:214] Iteration 10680, loss = 7364.88
I0314 23:49:24.528637 29479 solver.cpp:229]     Train net output #0: loss = 4474.19 (* 1 = 4474.19 loss)
I0314 23:49:24.633718 29479 solver.cpp:610] Iteration 10680, lr = 9.51809e-09
I0314 23:49:24.633731 29479 solver.cpp:613] Iteration 10680, avg_grad_norm = 581352
I0314 23:49:48.777894 29479 solver.cpp:214] Iteration 10700, loss = 7455.87
I0314 23:49:48.777971 29479 solver.cpp:229]     Train net output #0: loss = 8662.29 (* 1 = 8662.29 loss)
I0314 23:49:48.892596 29479 solver.cpp:610] Iteration 10700, lr = 9.51719e-09
I0314 23:49:48.892609 29479 solver.cpp:613] Iteration 10700, avg_grad_norm = 632331
I0314 23:50:14.467644 29479 solver.cpp:214] Iteration 10720, loss = 7469.5
I0314 23:50:14.467752 29479 solver.cpp:229]     Train net output #0: loss = 8753.1 (* 1 = 8753.1 loss)
I0314 23:50:14.582350 29479 solver.cpp:610] Iteration 10720, lr = 9.51628e-09
I0314 23:50:14.582363 29479 solver.cpp:613] Iteration 10720, avg_grad_norm = 781394
I0314 23:50:40.034175 29479 solver.cpp:214] Iteration 10740, loss = 7639.27
I0314 23:50:40.034237 29479 solver.cpp:229]     Train net output #0: loss = 6594.02 (* 1 = 6594.02 loss)
I0314 23:50:40.147307 29479 solver.cpp:610] Iteration 10740, lr = 9.51538e-09
I0314 23:50:40.147321 29479 solver.cpp:613] Iteration 10740, avg_grad_norm = 683489
I0314 23:51:05.451107 29479 solver.cpp:214] Iteration 10760, loss = 7638.74
I0314 23:51:05.451226 29479 solver.cpp:229]     Train net output #0: loss = 6989.12 (* 1 = 6989.12 loss)
I0314 23:51:05.564203 29479 solver.cpp:610] Iteration 10760, lr = 9.51447e-09
I0314 23:51:05.564215 29479 solver.cpp:613] Iteration 10760, avg_grad_norm = 704810
I0314 23:51:30.952394 29479 solver.cpp:214] Iteration 10780, loss = 7871.89
I0314 23:51:30.952445 29479 solver.cpp:229]     Train net output #0: loss = 6994.05 (* 1 = 6994.05 loss)
I0314 23:51:31.067078 29479 solver.cpp:610] Iteration 10780, lr = 9.51357e-09
I0314 23:51:31.067091 29479 solver.cpp:613] Iteration 10780, avg_grad_norm = 756166
I0314 23:52:15.983134 29479 solver.cpp:214] Iteration 10800, loss = 7281.36
I0314 23:52:15.983286 29479 solver.cpp:229]     Train net output #0: loss = 6291.08 (* 1 = 6291.08 loss)
I0314 23:52:16.087085 29479 solver.cpp:610] Iteration 10800, lr = 9.51266e-09
I0314 23:52:16.087097 29479 solver.cpp:613] Iteration 10800, avg_grad_norm = 656124
I0314 23:52:39.532706 29479 solver.cpp:214] Iteration 10820, loss = 7776.41
I0314 23:52:39.532814 29479 solver.cpp:229]     Train net output #0: loss = 8811.65 (* 1 = 8811.65 loss)
I0314 23:52:39.637861 29479 solver.cpp:610] Iteration 10820, lr = 9.51176e-09
I0314 23:52:39.637874 29479 solver.cpp:613] Iteration 10820, avg_grad_norm = 721181
I0314 23:53:03.818210 29479 solver.cpp:214] Iteration 10840, loss = 7501.35
I0314 23:53:03.818382 29479 solver.cpp:229]     Train net output #0: loss = 7110.22 (* 1 = 7110.22 loss)
I0314 23:53:03.931231 29479 solver.cpp:610] Iteration 10840, lr = 9.51085e-09
I0314 23:53:03.931243 29479 solver.cpp:613] Iteration 10840, avg_grad_norm = 728822
I0314 23:53:29.541896 29479 solver.cpp:214] Iteration 10860, loss = 7505.27
I0314 23:53:29.541954 29479 solver.cpp:229]     Train net output #0: loss = 6737.28 (* 1 = 6737.28 loss)
I0314 23:53:29.653420 29479 solver.cpp:610] Iteration 10860, lr = 9.50995e-09
I0314 23:53:29.653434 29479 solver.cpp:613] Iteration 10860, avg_grad_norm = 687568
I0314 23:53:54.585098 29479 solver.cpp:214] Iteration 10880, loss = 7827.55
I0314 23:53:54.585366 29479 solver.cpp:229]     Train net output #0: loss = 4337.34 (* 1 = 4337.34 loss)
I0314 23:53:54.696696 29479 solver.cpp:610] Iteration 10880, lr = 9.50904e-09
I0314 23:53:54.696709 29479 solver.cpp:613] Iteration 10880, avg_grad_norm = 667901
I0314 23:54:19.784667 29479 solver.cpp:214] Iteration 10900, loss = 7723.6
I0314 23:54:19.784726 29479 solver.cpp:229]     Train net output #0: loss = 5829.04 (* 1 = 5829.04 loss)
I0314 23:54:19.901110 29479 solver.cpp:610] Iteration 10900, lr = 9.50814e-09
I0314 23:54:19.901123 29479 solver.cpp:613] Iteration 10900, avg_grad_norm = 630991
I0314 23:54:45.511693 29479 solver.cpp:214] Iteration 10920, loss = 7399.88
I0314 23:54:45.511802 29479 solver.cpp:229]     Train net output #0: loss = 5255.91 (* 1 = 5255.91 loss)
I0314 23:54:45.623149 29479 solver.cpp:610] Iteration 10920, lr = 9.50723e-09
I0314 23:54:45.623162 29479 solver.cpp:613] Iteration 10920, avg_grad_norm = 765398
I0314 23:55:21.883424 29479 solver.cpp:214] Iteration 10940, loss = 7908.02
I0314 23:55:21.883575 29479 solver.cpp:229]     Train net output #0: loss = 8055.37 (* 1 = 8055.37 loss)
I0314 23:55:21.988582 29479 solver.cpp:610] Iteration 10940, lr = 9.50633e-09
I0314 23:55:21.988596 29479 solver.cpp:613] Iteration 10940, avg_grad_norm = 602820
I0314 23:55:46.609443 29479 solver.cpp:214] Iteration 10960, loss = 7346.61
I0314 23:55:46.609513 29479 solver.cpp:229]     Train net output #0: loss = 12727.3 (* 1 = 12727.3 loss)
I0314 23:55:46.723991 29479 solver.cpp:610] Iteration 10960, lr = 9.50542e-09
I0314 23:55:46.724030 29479 solver.cpp:613] Iteration 10960, avg_grad_norm = 588570
I0314 23:56:12.335975 29479 solver.cpp:214] Iteration 10980, loss = 7493.18
I0314 23:56:12.336069 29479 solver.cpp:229]     Train net output #0: loss = 6895.61 (* 1 = 6895.61 loss)
I0314 23:56:12.450978 29479 solver.cpp:610] Iteration 10980, lr = 9.50452e-09
I0314 23:56:12.450990 29479 solver.cpp:613] Iteration 10980, avg_grad_norm = 610896
I0314 23:56:38.056354 29479 solver.cpp:214] Iteration 11000, loss = 7787.36
I0314 23:56:38.056442 29479 solver.cpp:229]     Train net output #0: loss = 8511.75 (* 1 = 8511.75 loss)
I0314 23:56:38.171022 29479 solver.cpp:610] Iteration 11000, lr = 9.50361e-09
I0314 23:56:38.171036 29479 solver.cpp:613] Iteration 11000, avg_grad_norm = 743075
I0314 23:57:03.576653 29479 solver.cpp:214] Iteration 11020, loss = 7441.45
I0314 23:57:03.576844 29479 solver.cpp:229]     Train net output #0: loss = 6000.09 (* 1 = 6000.09 loss)
I0314 23:57:03.689621 29479 solver.cpp:610] Iteration 11020, lr = 9.50271e-09
I0314 23:57:03.689635 29479 solver.cpp:613] Iteration 11020, avg_grad_norm = 632265
I0314 23:57:28.885821 29479 solver.cpp:214] Iteration 11040, loss = 7566.39
I0314 23:57:28.885891 29479 solver.cpp:229]     Train net output #0: loss = 4653.52 (* 1 = 4653.52 loss)
I0314 23:57:28.998661 29479 solver.cpp:610] Iteration 11040, lr = 9.5018e-09
I0314 23:57:28.998674 29479 solver.cpp:613] Iteration 11040, avg_grad_norm = 633202
I0314 23:58:06.098392 29479 solver.cpp:214] Iteration 11060, loss = 7451.6
I0314 23:58:06.098577 29479 solver.cpp:229]     Train net output #0: loss = 6052.4 (* 1 = 6052.4 loss)
I0314 23:58:06.203589 29479 solver.cpp:610] Iteration 11060, lr = 9.5009e-09
I0314 23:58:06.203603 29479 solver.cpp:613] Iteration 11060, avg_grad_norm = 676393
I0314 23:58:30.310945 29479 solver.cpp:214] Iteration 11080, loss = 7035.71
I0314 23:58:30.311027 29479 solver.cpp:229]     Train net output #0: loss = 5321.05 (* 1 = 5321.05 loss)
I0314 23:58:30.425590 29479 solver.cpp:610] Iteration 11080, lr = 9.49999e-09
I0314 23:58:30.425604 29479 solver.cpp:613] Iteration 11080, avg_grad_norm = 669738
I0314 23:58:55.971024 29479 solver.cpp:214] Iteration 11100, loss = 7462.58
I0314 23:58:55.971150 29479 solver.cpp:229]     Train net output #0: loss = 5815.57 (* 1 = 5815.57 loss)
I0314 23:58:56.085729 29479 solver.cpp:610] Iteration 11100, lr = 9.49908e-09
I0314 23:58:56.085742 29479 solver.cpp:613] Iteration 11100, avg_grad_norm = 635250
I0314 23:59:21.626379 29479 solver.cpp:214] Iteration 11120, loss = 7501.28
I0314 23:59:21.626444 29479 solver.cpp:229]     Train net output #0: loss = 8097.94 (* 1 = 8097.94 loss)
I0314 23:59:21.740984 29479 solver.cpp:610] Iteration 11120, lr = 9.49818e-09
I0314 23:59:21.740998 29479 solver.cpp:613] Iteration 11120, avg_grad_norm = 711464
I0314 23:59:47.257417 29479 solver.cpp:214] Iteration 11140, loss = 7645.35
I0314 23:59:47.257601 29479 solver.cpp:229]     Train net output #0: loss = 6148.71 (* 1 = 6148.71 loss)
I0314 23:59:47.370424 29479 solver.cpp:610] Iteration 11140, lr = 9.49727e-09
I0314 23:59:47.370437 29479 solver.cpp:613] Iteration 11140, avg_grad_norm = 775147
I0315 00:00:12.560148 29479 solver.cpp:214] Iteration 11160, loss = 7534.43
I0315 00:00:12.560214 29479 solver.cpp:229]     Train net output #0: loss = 6363.97 (* 1 = 6363.97 loss)
I0315 00:00:12.673107 29479 solver.cpp:610] Iteration 11160, lr = 9.49637e-09
I0315 00:00:12.673120 29479 solver.cpp:613] Iteration 11160, avg_grad_norm = 605251
I0315 00:01:20.453444 29479 solver.cpp:214] Iteration 11180, loss = 7718.26
I0315 00:01:20.453547 29479 solver.cpp:229]     Train net output #0: loss = 6137.5 (* 1 = 6137.5 loss)
I0315 00:01:20.558709 29479 solver.cpp:610] Iteration 11180, lr = 9.49546e-09
I0315 00:01:20.558723 29479 solver.cpp:613] Iteration 11180, avg_grad_norm = 699202
I0315 00:01:43.956223 29479 solver.cpp:214] Iteration 11200, loss = 7453.82
I0315 00:01:43.956291 29479 solver.cpp:229]     Train net output #0: loss = 14900.6 (* 1 = 14900.6 loss)
I0315 00:01:44.060117 29479 solver.cpp:610] Iteration 11200, lr = 9.49456e-09
I0315 00:01:44.060130 29479 solver.cpp:613] Iteration 11200, avg_grad_norm = 645238
I0315 00:02:07.558876 29479 solver.cpp:214] Iteration 11220, loss = 7652.29
I0315 00:02:07.558992 29479 solver.cpp:229]     Train net output #0: loss = 7162.32 (* 1 = 7162.32 loss)
I0315 00:02:07.663486 29479 solver.cpp:610] Iteration 11220, lr = 9.49365e-09
I0315 00:02:07.663498 29479 solver.cpp:613] Iteration 11220, avg_grad_norm = 718446
I0315 00:02:31.250344 29479 solver.cpp:214] Iteration 11240, loss = 7326.24
I0315 00:02:31.250404 29479 solver.cpp:229]     Train net output #0: loss = 4647.79 (* 1 = 4647.79 loss)
I0315 00:02:31.362021 29479 solver.cpp:610] Iteration 11240, lr = 9.49275e-09
I0315 00:02:31.362035 29479 solver.cpp:613] Iteration 11240, avg_grad_norm = 615003
I0315 00:02:56.320193 29479 solver.cpp:214] Iteration 11260, loss = 7570.57
I0315 00:02:56.320329 29479 solver.cpp:229]     Train net output #0: loss = 4678.52 (* 1 = 4678.52 loss)
I0315 00:02:56.431838 29479 solver.cpp:610] Iteration 11260, lr = 9.49184e-09
I0315 00:02:56.431851 29479 solver.cpp:613] Iteration 11260, avg_grad_norm = 608934
I0315 00:03:21.422847 29479 solver.cpp:214] Iteration 11280, loss = 7494.38
I0315 00:03:21.422919 29479 solver.cpp:229]     Train net output #0: loss = 7233.24 (* 1 = 7233.24 loss)
I0315 00:03:21.534430 29479 solver.cpp:610] Iteration 11280, lr = 9.49094e-09
I0315 00:03:21.534447 29479 solver.cpp:613] Iteration 11280, avg_grad_norm = 637141
I0315 00:03:46.896329 29479 solver.cpp:214] Iteration 11300, loss = 7638.42
I0315 00:03:46.896527 29479 solver.cpp:229]     Train net output #0: loss = 12278.7 (* 1 = 12278.7 loss)
I0315 00:03:47.011003 29479 solver.cpp:610] Iteration 11300, lr = 9.49003e-09
I0315 00:03:47.011015 29479 solver.cpp:613] Iteration 11300, avg_grad_norm = 701074
I0315 00:04:24.572980 29479 solver.cpp:214] Iteration 11320, loss = 7492.52
I0315 00:04:24.573231 29479 solver.cpp:229]     Train net output #0: loss = 10270 (* 1 = 10270 loss)
I0315 00:04:24.678215 29479 solver.cpp:610] Iteration 11320, lr = 9.48913e-09
I0315 00:04:24.678231 29479 solver.cpp:613] Iteration 11320, avg_grad_norm = 691380
I0315 00:04:49.092221 29479 solver.cpp:214] Iteration 11340, loss = 7188.71
I0315 00:04:49.092277 29479 solver.cpp:229]     Train net output #0: loss = 6001.22 (* 1 = 6001.22 loss)
I0315 00:04:49.205271 29479 solver.cpp:610] Iteration 11340, lr = 9.48822e-09
I0315 00:04:49.205283 29479 solver.cpp:613] Iteration 11340, avg_grad_norm = 662805
I0315 00:05:14.694814 29479 solver.cpp:214] Iteration 11360, loss = 7514.38
I0315 00:05:14.694952 29479 solver.cpp:229]     Train net output #0: loss = 9531.19 (* 1 = 9531.19 loss)
I0315 00:05:14.809592 29479 solver.cpp:610] Iteration 11360, lr = 9.48732e-09
I0315 00:05:14.809607 29479 solver.cpp:613] Iteration 11360, avg_grad_norm = 735813
I0315 00:05:40.412324 29479 solver.cpp:214] Iteration 11380, loss = 8028
I0315 00:05:40.412379 29479 solver.cpp:229]     Train net output #0: loss = 9165.71 (* 1 = 9165.71 loss)
I0315 00:05:40.526873 29479 solver.cpp:610] Iteration 11380, lr = 9.48641e-09
I0315 00:05:40.526888 29479 solver.cpp:613] Iteration 11380, avg_grad_norm = 604030
I0315 00:06:05.890172 29479 solver.cpp:214] Iteration 11400, loss = 7253.66
I0315 00:06:05.890404 29479 solver.cpp:229]     Train net output #0: loss = 6723.19 (* 1 = 6723.19 loss)
I0315 00:06:06.003267 29479 solver.cpp:610] Iteration 11400, lr = 9.48551e-09
I0315 00:06:06.003298 29479 solver.cpp:613] Iteration 11400, avg_grad_norm = 702744
I0315 00:06:31.392860 29479 solver.cpp:214] Iteration 11420, loss = 7415.76
I0315 00:06:31.392921 29479 solver.cpp:229]     Train net output #0: loss = 6062.92 (* 1 = 6062.92 loss)
I0315 00:06:31.507452 29479 solver.cpp:610] Iteration 11420, lr = 9.4846e-09
I0315 00:06:31.507465 29479 solver.cpp:613] Iteration 11420, avg_grad_norm = 615555
I0315 00:07:10.593343 29479 solver.cpp:214] Iteration 11440, loss = 7730.41
I0315 00:07:10.593499 29479 solver.cpp:229]     Train net output #0: loss = 5543.13 (* 1 = 5543.13 loss)
I0315 00:07:10.698590 29479 solver.cpp:610] Iteration 11440, lr = 9.4837e-09
I0315 00:07:10.698603 29479 solver.cpp:613] Iteration 11440, avg_grad_norm = 601328
I0315 00:07:34.381551 29479 solver.cpp:214] Iteration 11460, loss = 7215.73
I0315 00:07:34.381619 29479 solver.cpp:229]     Train net output #0: loss = 6245.97 (* 1 = 6245.97 loss)
I0315 00:07:34.494496 29479 solver.cpp:610] Iteration 11460, lr = 9.48279e-09
I0315 00:07:34.494510 29479 solver.cpp:613] Iteration 11460, avg_grad_norm = 693044
I0315 00:07:59.985038 29479 solver.cpp:214] Iteration 11480, loss = 7475.66
I0315 00:07:59.985162 29479 solver.cpp:229]     Train net output #0: loss = 13714.8 (* 1 = 13714.8 loss)
I0315 00:08:00.099570 29479 solver.cpp:610] Iteration 11480, lr = 9.48189e-09
I0315 00:08:00.099583 29479 solver.cpp:613] Iteration 11480, avg_grad_norm = 668548
I0315 00:08:25.679208 29479 solver.cpp:214] Iteration 11500, loss = 7548.57
I0315 00:08:25.679268 29479 solver.cpp:229]     Train net output #0: loss = 6998.65 (* 1 = 6998.65 loss)
I0315 00:08:25.793908 29479 solver.cpp:610] Iteration 11500, lr = 9.48098e-09
I0315 00:08:25.793922 29479 solver.cpp:613] Iteration 11500, avg_grad_norm = 625591
I0315 00:08:51.231881 29479 solver.cpp:214] Iteration 11520, loss = 7385.61
I0315 00:08:51.232022 29479 solver.cpp:229]     Train net output #0: loss = 9268.31 (* 1 = 9268.31 loss)
I0315 00:08:51.344859 29479 solver.cpp:610] Iteration 11520, lr = 9.48007e-09
I0315 00:08:51.344874 29479 solver.cpp:613] Iteration 11520, avg_grad_norm = 589403
I0315 00:09:16.659791 29479 solver.cpp:214] Iteration 11540, loss = 7639.31
I0315 00:09:16.659859 29479 solver.cpp:229]     Train net output #0: loss = 9705.57 (* 1 = 9705.57 loss)
I0315 00:09:16.774499 29479 solver.cpp:610] Iteration 11540, lr = 9.47917e-09
I0315 00:09:16.774514 29479 solver.cpp:613] Iteration 11540, avg_grad_norm = 595168
I0315 00:10:03.564429 29479 solver.cpp:214] Iteration 11560, loss = 7400.15
I0315 00:10:03.564637 29479 solver.cpp:229]     Train net output #0: loss = 3565.39 (* 1 = 3565.39 loss)
I0315 00:10:03.669751 29479 solver.cpp:610] Iteration 11560, lr = 9.47826e-09
I0315 00:10:03.669764 29479 solver.cpp:613] Iteration 11560, avg_grad_norm = 679096
I0315 00:10:27.093515 29479 solver.cpp:214] Iteration 11580, loss = 7469.79
I0315 00:10:27.093562 29479 solver.cpp:229]     Train net output #0: loss = 5285.39 (* 1 = 5285.39 loss)
I0315 00:10:27.198796 29479 solver.cpp:610] Iteration 11580, lr = 9.47736e-09
I0315 00:10:27.198808 29479 solver.cpp:613] Iteration 11580, avg_grad_norm = 609980
I0315 00:10:51.132083 29479 solver.cpp:214] Iteration 11600, loss = 7557.84
I0315 00:10:51.132293 29479 solver.cpp:229]     Train net output #0: loss = 6221.03 (* 1 = 6221.03 loss)
I0315 00:10:51.245226 29479 solver.cpp:610] Iteration 11600, lr = 9.47645e-09
I0315 00:10:51.245241 29479 solver.cpp:613] Iteration 11600, avg_grad_norm = 671833
I0315 00:11:16.554898 29479 solver.cpp:214] Iteration 11620, loss = 7661.2
I0315 00:11:16.554970 29479 solver.cpp:229]     Train net output #0: loss = 4512.25 (* 1 = 4512.25 loss)
I0315 00:11:16.667906 29479 solver.cpp:610] Iteration 11620, lr = 9.47555e-09
I0315 00:11:16.667920 29479 solver.cpp:613] Iteration 11620, avg_grad_norm = 869747
I0315 00:11:42.117708 29479 solver.cpp:214] Iteration 11640, loss = 7444.65
I0315 00:11:42.117897 29479 solver.cpp:229]     Train net output #0: loss = 6322.64 (* 1 = 6322.64 loss)
I0315 00:11:42.232341 29479 solver.cpp:610] Iteration 11640, lr = 9.47464e-09
I0315 00:11:42.232355 29479 solver.cpp:613] Iteration 11640, avg_grad_norm = 745328
I0315 00:12:07.841691 29479 solver.cpp:214] Iteration 11660, loss = 7475.1
I0315 00:12:07.841747 29479 solver.cpp:229]     Train net output #0: loss = 8634.71 (* 1 = 8634.71 loss)
I0315 00:12:07.956465 29479 solver.cpp:610] Iteration 11660, lr = 9.47374e-09
I0315 00:12:07.956480 29479 solver.cpp:613] Iteration 11660, avg_grad_norm = 676222
I0315 00:12:33.312383 29479 solver.cpp:214] Iteration 11680, loss = 7661.07
I0315 00:12:33.312532 29479 solver.cpp:229]     Train net output #0: loss = 7213.21 (* 1 = 7213.21 loss)
I0315 00:12:33.425464 29479 solver.cpp:610] Iteration 11680, lr = 9.47283e-09
I0315 00:12:33.425478 29479 solver.cpp:613] Iteration 11680, avg_grad_norm = 656718
I0315 00:13:09.880053 29479 solver.cpp:214] Iteration 11700, loss = 7234.83
I0315 00:13:09.880208 29479 solver.cpp:229]     Train net output #0: loss = 6736.39 (* 1 = 6736.39 loss)
I0315 00:13:09.985471 29479 solver.cpp:610] Iteration 11700, lr = 9.47193e-09
I0315 00:13:09.985484 29479 solver.cpp:613] Iteration 11700, avg_grad_norm = 644548
I0315 00:13:34.629782 29479 solver.cpp:214] Iteration 11720, loss = 7468.6
I0315 00:13:34.629842 29479 solver.cpp:229]     Train net output #0: loss = 6020.34 (* 1 = 6020.34 loss)
I0315 00:13:34.744338 29479 solver.cpp:610] Iteration 11720, lr = 9.47102e-09
I0315 00:13:34.744379 29479 solver.cpp:613] Iteration 11720, avg_grad_norm = 612961
I0315 00:14:00.398026 29479 solver.cpp:214] Iteration 11740, loss = 7449.13
I0315 00:14:00.398150 29479 solver.cpp:229]     Train net output #0: loss = 6527.57 (* 1 = 6527.57 loss)
I0315 00:14:00.512061 29479 solver.cpp:610] Iteration 11740, lr = 9.47011e-09
I0315 00:14:00.512075 29479 solver.cpp:613] Iteration 11740, avg_grad_norm = 597539
I0315 00:14:25.783359 29479 solver.cpp:214] Iteration 11760, loss = 7308.94
I0315 00:14:25.783421 29479 solver.cpp:229]     Train net output #0: loss = 8669.96 (* 1 = 8669.96 loss)
I0315 00:14:25.896364 29479 solver.cpp:610] Iteration 11760, lr = 9.46921e-09
I0315 00:14:25.896378 29479 solver.cpp:613] Iteration 11760, avg_grad_norm = 638935
I0315 00:14:51.317885 29479 solver.cpp:214] Iteration 11780, loss = 7430.09
I0315 00:14:51.318145 29479 solver.cpp:229]     Train net output #0: loss = 12622.2 (* 1 = 12622.2 loss)
I0315 00:14:51.432431 29479 solver.cpp:610] Iteration 11780, lr = 9.4683e-09
I0315 00:14:51.432445 29479 solver.cpp:613] Iteration 11780, avg_grad_norm = 625649
I0315 00:15:16.966667 29479 solver.cpp:214] Iteration 11800, loss = 7413.37
I0315 00:15:16.966737 29479 solver.cpp:229]     Train net output #0: loss = 7729.92 (* 1 = 7729.92 loss)
I0315 00:15:17.081209 29479 solver.cpp:610] Iteration 11800, lr = 9.4674e-09
I0315 00:15:17.081223 29479 solver.cpp:613] Iteration 11800, avg_grad_norm = 593930
I0315 00:15:58.450215 29479 solver.cpp:214] Iteration 11820, loss = 7374.02
I0315 00:15:58.450353 29479 solver.cpp:229]     Train net output #0: loss = 9201 (* 1 = 9201 loss)
I0315 00:15:58.554496 29479 solver.cpp:610] Iteration 11820, lr = 9.46649e-09
I0315 00:15:58.554548 29479 solver.cpp:613] Iteration 11820, avg_grad_norm = 561846
I0315 00:16:22.099079 29479 solver.cpp:214] Iteration 11840, loss = 7432.04
I0315 00:16:22.099146 29479 solver.cpp:229]     Train net output #0: loss = 9353.47 (* 1 = 9353.47 loss)
I0315 00:16:22.209210 29479 solver.cpp:610] Iteration 11840, lr = 9.46559e-09
I0315 00:16:22.209224 29479 solver.cpp:613] Iteration 11840, avg_grad_norm = 717988
I0315 00:16:47.635668 29479 solver.cpp:214] Iteration 11860, loss = 7574.03
I0315 00:16:47.635782 29479 solver.cpp:229]     Train net output #0: loss = 12346.4 (* 1 = 12346.4 loss)
I0315 00:16:47.750253 29479 solver.cpp:610] Iteration 11860, lr = 9.46468e-09
I0315 00:16:47.750267 29479 solver.cpp:613] Iteration 11860, avg_grad_norm = 724388
I0315 00:17:13.347035 29479 solver.cpp:214] Iteration 11880, loss = 7357.25
I0315 00:17:13.347100 29479 solver.cpp:229]     Train net output #0: loss = 14161.3 (* 1 = 14161.3 loss)
I0315 00:17:13.461798 29479 solver.cpp:610] Iteration 11880, lr = 9.46378e-09
I0315 00:17:13.461812 29479 solver.cpp:613] Iteration 11880, avg_grad_norm = 604653
I0315 00:17:39.059103 29479 solver.cpp:214] Iteration 11900, loss = 7845.09
I0315 00:17:39.059234 29479 solver.cpp:229]     Train net output #0: loss = 7470.92 (* 1 = 7470.92 loss)
I0315 00:17:39.173717 29479 solver.cpp:610] Iteration 11900, lr = 9.46287e-09
I0315 00:17:39.173732 29479 solver.cpp:613] Iteration 11900, avg_grad_norm = 631488
I0315 00:18:04.761214 29479 solver.cpp:214] Iteration 11920, loss = 7318.37
I0315 00:18:04.761265 29479 solver.cpp:229]     Train net output #0: loss = 6086.4 (* 1 = 6086.4 loss)
I0315 00:18:04.875700 29479 solver.cpp:610] Iteration 11920, lr = 9.46197e-09
I0315 00:18:04.875712 29479 solver.cpp:613] Iteration 11920, avg_grad_norm = 647101
I0315 00:19:00.238667 29479 solver.cpp:214] Iteration 11940, loss = 7555.32
I0315 00:19:00.238800 29479 solver.cpp:229]     Train net output #0: loss = 8302.18 (* 1 = 8302.18 loss)
I0315 00:19:00.343884 29479 solver.cpp:610] Iteration 11940, lr = 9.46106e-09
I0315 00:19:00.343899 29479 solver.cpp:613] Iteration 11940, avg_grad_norm = 587712
I0315 00:19:23.788322 29479 solver.cpp:214] Iteration 11960, loss = 7309.2
I0315 00:19:23.788389 29479 solver.cpp:229]     Train net output #0: loss = 6405.16 (* 1 = 6405.16 loss)
I0315 00:19:23.893672 29479 solver.cpp:610] Iteration 11960, lr = 9.46015e-09
I0315 00:19:23.893687 29479 solver.cpp:613] Iteration 11960, avg_grad_norm = 643718
I0315 00:19:47.409200 29479 solver.cpp:214] Iteration 11980, loss = 7946.27
I0315 00:19:47.409332 29479 solver.cpp:229]     Train net output #0: loss = 7092.36 (* 1 = 7092.36 loss)
I0315 00:19:47.514382 29479 solver.cpp:610] Iteration 11980, lr = 9.45925e-09
I0315 00:19:47.514396 29479 solver.cpp:613] Iteration 11980, avg_grad_norm = 684422
I0315 00:20:12.017768 29479 solver.cpp:214] Iteration 12000, loss = 7521.07
I0315 00:20:12.017823 29479 solver.cpp:229]     Train net output #0: loss = 7205.69 (* 1 = 7205.69 loss)
I0315 00:20:12.129348 29479 solver.cpp:610] Iteration 12000, lr = 9.45834e-09
I0315 00:20:12.129361 29479 solver.cpp:613] Iteration 12000, avg_grad_norm = 649956
I0315 00:20:37.395494 29479 solver.cpp:214] Iteration 12020, loss = 7681.02
I0315 00:20:37.395684 29479 solver.cpp:229]     Train net output #0: loss = 3616.88 (* 1 = 3616.88 loss)
I0315 00:20:37.510063 29479 solver.cpp:610] Iteration 12020, lr = 9.45744e-09
I0315 00:20:37.510076 29479 solver.cpp:613] Iteration 12020, avg_grad_norm = 682822
I0315 00:21:03.137511 29479 solver.cpp:214] Iteration 12040, loss = 7925.47
I0315 00:21:03.137573 29479 solver.cpp:229]     Train net output #0: loss = 6968.91 (* 1 = 6968.91 loss)
I0315 00:21:03.251958 29479 solver.cpp:610] Iteration 12040, lr = 9.45653e-09
I0315 00:21:03.251973 29479 solver.cpp:613] Iteration 12040, avg_grad_norm = 684736
I0315 00:21:28.713882 29479 solver.cpp:214] Iteration 12060, loss = 7422.93
I0315 00:21:28.714103 29479 solver.cpp:229]     Train net output #0: loss = 6578.83 (* 1 = 6578.83 loss)
I0315 00:21:28.826844 29479 solver.cpp:610] Iteration 12060, lr = 9.45563e-09
I0315 00:21:28.826858 29479 solver.cpp:613] Iteration 12060, avg_grad_norm = 662049
I0315 00:22:05.398084 29479 solver.cpp:214] Iteration 12080, loss = 7572.46
I0315 00:22:05.398217 29479 solver.cpp:229]     Train net output #0: loss = 6560.67 (* 1 = 6560.67 loss)
I0315 00:22:05.503556 29479 solver.cpp:610] Iteration 12080, lr = 9.45472e-09
I0315 00:22:05.503569 29479 solver.cpp:613] Iteration 12080, avg_grad_norm = 714499
I0315 00:22:29.876305 29479 solver.cpp:214] Iteration 12100, loss = 7295.99
I0315 00:22:29.876374 29479 solver.cpp:229]     Train net output #0: loss = 12709.3 (* 1 = 12709.3 loss)
I0315 00:22:29.992337 29479 solver.cpp:610] Iteration 12100, lr = 9.45381e-09
I0315 00:22:29.992350 29479 solver.cpp:613] Iteration 12100, avg_grad_norm = 650455
I0315 00:22:55.691660 29479 solver.cpp:214] Iteration 12120, loss = 7127.67
I0315 00:22:55.691787 29479 solver.cpp:229]     Train net output #0: loss = 3807.62 (* 1 = 3807.62 loss)
I0315 00:22:55.804559 29479 solver.cpp:610] Iteration 12120, lr = 9.45291e-09
I0315 00:22:55.804572 29479 solver.cpp:613] Iteration 12120, avg_grad_norm = 744350
I0315 00:23:21.005318 29479 solver.cpp:214] Iteration 12140, loss = 7375.47
I0315 00:23:21.005409 29479 solver.cpp:229]     Train net output #0: loss = 9127.64 (* 1 = 9127.64 loss)
I0315 00:23:21.118306 29479 solver.cpp:610] Iteration 12140, lr = 9.452e-09
I0315 00:23:21.118319 29479 solver.cpp:613] Iteration 12140, avg_grad_norm = 662574
I0315 00:23:46.579727 29479 solver.cpp:214] Iteration 12160, loss = 7272.56
I0315 00:23:46.579879 29479 solver.cpp:229]     Train net output #0: loss = 6065.83 (* 1 = 6065.83 loss)
I0315 00:23:46.694327 29479 solver.cpp:610] Iteration 12160, lr = 9.4511e-09
I0315 00:23:46.694340 29479 solver.cpp:613] Iteration 12160, avg_grad_norm = 602296
I0315 00:24:12.229511 29479 solver.cpp:214] Iteration 12180, loss = 7102.04
I0315 00:24:12.229568 29479 solver.cpp:229]     Train net output #0: loss = 4961.05 (* 1 = 4961.05 loss)
I0315 00:24:12.343964 29479 solver.cpp:610] Iteration 12180, lr = 9.45019e-09
I0315 00:24:12.343977 29479 solver.cpp:613] Iteration 12180, avg_grad_norm = 638115
I0315 00:24:49.822744 29479 solver.cpp:214] Iteration 12200, loss = 7579.74
I0315 00:24:49.822886 29479 solver.cpp:229]     Train net output #0: loss = 9712.06 (* 1 = 9712.06 loss)
I0315 00:24:49.928165 29479 solver.cpp:610] Iteration 12200, lr = 9.44929e-09
I0315 00:24:49.928212 29479 solver.cpp:613] Iteration 12200, avg_grad_norm = 608200
I0315 00:25:13.719000 29479 solver.cpp:214] Iteration 12220, loss = 7257.55
I0315 00:25:13.719055 29479 solver.cpp:229]     Train net output #0: loss = 6097.82 (* 1 = 6097.82 loss)
I0315 00:25:13.831959 29479 solver.cpp:610] Iteration 12220, lr = 9.44838e-09
I0315 00:25:13.831974 29479 solver.cpp:613] Iteration 12220, avg_grad_norm = 651522
I0315 00:25:39.402586 29479 solver.cpp:214] Iteration 12240, loss = 7477.09
I0315 00:25:39.402801 29479 solver.cpp:229]     Train net output #0: loss = 12527.9 (* 1 = 12527.9 loss)
I0315 00:25:39.517096 29479 solver.cpp:610] Iteration 12240, lr = 9.44747e-09
I0315 00:25:39.517120 29479 solver.cpp:613] Iteration 12240, avg_grad_norm = 648540
I0315 00:26:05.139523 29479 solver.cpp:214] Iteration 12260, loss = 7268.49
I0315 00:26:05.139597 29479 solver.cpp:229]     Train net output #0: loss = 6429.64 (* 1 = 6429.64 loss)
I0315 00:26:05.254128 29479 solver.cpp:610] Iteration 12260, lr = 9.44657e-09
I0315 00:26:05.254142 29479 solver.cpp:613] Iteration 12260, avg_grad_norm = 639631
I0315 00:26:30.785970 29479 solver.cpp:214] Iteration 12280, loss = 7625.21
I0315 00:26:30.786150 29479 solver.cpp:229]     Train net output #0: loss = 7628.85 (* 1 = 7628.85 loss)
I0315 00:26:30.899034 29479 solver.cpp:610] Iteration 12280, lr = 9.44566e-09
I0315 00:26:30.899047 29479 solver.cpp:613] Iteration 12280, avg_grad_norm = 649565
I0315 00:26:56.087489 29479 solver.cpp:214] Iteration 12300, loss = 7711.18
I0315 00:26:56.087543 29479 solver.cpp:229]     Train net output #0: loss = 9133.16 (* 1 = 9133.16 loss)
I0315 00:26:56.200749 29479 solver.cpp:610] Iteration 12300, lr = 9.44476e-09
I0315 00:26:56.200763 29479 solver.cpp:613] Iteration 12300, avg_grad_norm = 619043
I0315 00:27:40.389190 29479 solver.cpp:214] Iteration 12320, loss = 7597.64
I0315 00:27:40.389302 29479 solver.cpp:229]     Train net output #0: loss = 4669.68 (* 1 = 4669.68 loss)
I0315 00:27:40.494498 29479 solver.cpp:610] Iteration 12320, lr = 9.44385e-09
I0315 00:27:40.494511 29479 solver.cpp:613] Iteration 12320, avg_grad_norm = 673728
I0315 00:28:03.950474 29479 solver.cpp:214] Iteration 12340, loss = 7147.6
I0315 00:28:03.950551 29479 solver.cpp:229]     Train net output #0: loss = 8317.72 (* 1 = 8317.72 loss)
I0315 00:28:04.054191 29479 solver.cpp:610] Iteration 12340, lr = 9.44295e-09
I0315 00:28:04.054205 29479 solver.cpp:613] Iteration 12340, avg_grad_norm = 626065
I0315 00:28:28.334527 29479 solver.cpp:214] Iteration 12360, loss = 7402.73
I0315 00:28:28.334718 29479 solver.cpp:229]     Train net output #0: loss = 5048.77 (* 1 = 5048.77 loss)
I0315 00:28:28.449223 29479 solver.cpp:610] Iteration 12360, lr = 9.44204e-09
I0315 00:28:28.449235 29479 solver.cpp:613] Iteration 12360, avg_grad_norm = 678022
I0315 00:28:53.998051 29479 solver.cpp:214] Iteration 12380, loss = 7416.97
I0315 00:28:53.998117 29479 solver.cpp:229]     Train net output #0: loss = 10047.4 (* 1 = 10047.4 loss)
I0315 00:28:54.112612 29479 solver.cpp:610] Iteration 12380, lr = 9.44113e-09
I0315 00:28:54.112624 29479 solver.cpp:613] Iteration 12380, avg_grad_norm = 666796
I0315 00:29:19.427541 29479 solver.cpp:214] Iteration 12400, loss = 7486.63
I0315 00:29:19.427660 29479 solver.cpp:229]     Train net output #0: loss = 4544.12 (* 1 = 4544.12 loss)
I0315 00:29:19.540740 29479 solver.cpp:610] Iteration 12400, lr = 9.44023e-09
I0315 00:29:19.540753 29479 solver.cpp:613] Iteration 12400, avg_grad_norm = 676500
I0315 00:29:44.781707 29479 solver.cpp:214] Iteration 12420, loss = 7592.65
I0315 00:29:44.781764 29479 solver.cpp:229]     Train net output #0: loss = 6905.86 (* 1 = 6905.86 loss)
I0315 00:29:44.894673 29479 solver.cpp:610] Iteration 12420, lr = 9.43932e-09
I0315 00:29:44.894686 29479 solver.cpp:613] Iteration 12420, avg_grad_norm = 711358
I0315 00:30:10.460500 29479 solver.cpp:214] Iteration 12440, loss = 7525.85
I0315 00:30:10.460623 29479 solver.cpp:229]     Train net output #0: loss = 10720.2 (* 1 = 10720.2 loss)
I0315 00:30:10.574976 29479 solver.cpp:610] Iteration 12440, lr = 9.43842e-09
I0315 00:30:10.574990 29479 solver.cpp:613] Iteration 12440, avg_grad_norm = 616736
I0315 00:30:49.785678 29479 solver.cpp:214] Iteration 12460, loss = 7418.9
I0315 00:30:49.785815 29479 solver.cpp:229]     Train net output #0: loss = 5906.96 (* 1 = 5906.96 loss)
I0315 00:30:49.890827 29479 solver.cpp:610] Iteration 12460, lr = 9.43751e-09
I0315 00:30:49.890843 29479 solver.cpp:613] Iteration 12460, avg_grad_norm = 681854
I0315 00:31:14.021848 29479 solver.cpp:214] Iteration 12480, loss = 7869.72
I0315 00:31:14.021911 29479 solver.cpp:229]     Train net output #0: loss = 5141.56 (* 1 = 5141.56 loss)
I0315 00:31:14.134801 29479 solver.cpp:610] Iteration 12480, lr = 9.43661e-09
I0315 00:31:14.134814 29479 solver.cpp:613] Iteration 12480, avg_grad_norm = 656717
I0315 00:31:39.728651 29479 solver.cpp:214] Iteration 12500, loss = 7545.77
I0315 00:31:39.728868 29479 solver.cpp:229]     Train net output #0: loss = 3762.69 (* 1 = 3762.69 loss)
I0315 00:31:39.843117 29479 solver.cpp:610] Iteration 12500, lr = 9.4357e-09
I0315 00:31:39.843132 29479 solver.cpp:613] Iteration 12500, avg_grad_norm = 672221
I0315 00:32:05.424907 29479 solver.cpp:214] Iteration 12520, loss = 7838.13
I0315 00:32:05.424957 29479 solver.cpp:229]     Train net output #0: loss = 6239.06 (* 1 = 6239.06 loss)
I0315 00:32:05.539546 29479 solver.cpp:610] Iteration 12520, lr = 9.43479e-09
I0315 00:32:05.539561 29479 solver.cpp:613] Iteration 12520, avg_grad_norm = 710509
I0315 00:32:31.109748 29479 solver.cpp:214] Iteration 12540, loss = 7106.78
I0315 00:32:31.109946 29479 solver.cpp:229]     Train net output #0: loss = 7583.26 (* 1 = 7583.26 loss)
I0315 00:32:31.224511 29479 solver.cpp:610] Iteration 12540, lr = 9.43389e-09
I0315 00:32:31.224525 29479 solver.cpp:613] Iteration 12540, avg_grad_norm = 629457
I0315 00:32:56.792858 29479 solver.cpp:214] Iteration 12560, loss = 7356.88
I0315 00:32:56.792923 29479 solver.cpp:229]     Train net output #0: loss = 5855.44 (* 1 = 5855.44 loss)
I0315 00:32:56.907394 29479 solver.cpp:610] Iteration 12560, lr = 9.43298e-09
I0315 00:32:56.907408 29479 solver.cpp:613] Iteration 12560, avg_grad_norm = 574621
I0315 00:33:45.581048 29479 solver.cpp:214] Iteration 12580, loss = 7172.47
I0315 00:33:45.581166 29479 solver.cpp:229]     Train net output #0: loss = 4872.35 (* 1 = 4872.35 loss)
I0315 00:33:45.686645 29479 solver.cpp:610] Iteration 12580, lr = 9.43208e-09
I0315 00:33:45.686672 29479 solver.cpp:613] Iteration 12580, avg_grad_norm = 680827
I0315 00:34:09.128999 29479 solver.cpp:214] Iteration 12600, loss = 7347.25
I0315 00:34:09.129062 29479 solver.cpp:229]     Train net output #0: loss = 11232.9 (* 1 = 11232.9 loss)
I0315 00:34:09.234235 29479 solver.cpp:610] Iteration 12600, lr = 9.43117e-09
I0315 00:34:09.234249 29479 solver.cpp:613] Iteration 12600, avg_grad_norm = 647540
I0315 00:34:33.389531 29479 solver.cpp:214] Iteration 12620, loss = 7560.94
I0315 00:34:33.389642 29479 solver.cpp:229]     Train net output #0: loss = 6822.26 (* 1 = 6822.26 loss)
I0315 00:34:33.502523 29479 solver.cpp:610] Iteration 12620, lr = 9.43027e-09
I0315 00:34:33.502537 29479 solver.cpp:613] Iteration 12620, avg_grad_norm = 684172
I0315 00:34:58.875439 29479 solver.cpp:214] Iteration 12640, loss = 7066.63
I0315 00:34:58.875490 29479 solver.cpp:229]     Train net output #0: loss = 6727.32 (* 1 = 6727.32 loss)
I0315 00:34:58.990165 29479 solver.cpp:610] Iteration 12640, lr = 9.42936e-09
I0315 00:34:58.990178 29479 solver.cpp:613] Iteration 12640, avg_grad_norm = 611059
I0315 00:35:24.581284 29479 solver.cpp:214] Iteration 12660, loss = 7364.09
I0315 00:35:24.581444 29479 solver.cpp:229]     Train net output #0: loss = 9313.74 (* 1 = 9313.74 loss)
I0315 00:35:24.695654 29479 solver.cpp:610] Iteration 12660, lr = 9.42845e-09
I0315 00:35:24.695668 29479 solver.cpp:613] Iteration 12660, avg_grad_norm = 727748
I0315 00:35:50.148789 29479 solver.cpp:214] Iteration 12680, loss = 7691.82
I0315 00:35:50.148864 29479 solver.cpp:229]     Train net output #0: loss = 9883.82 (* 1 = 9883.82 loss)
I0315 00:35:50.261910 29479 solver.cpp:610] Iteration 12680, lr = 9.42755e-09
I0315 00:35:50.261963 29479 solver.cpp:613] Iteration 12680, avg_grad_norm = 636006
I0315 00:36:28.509510 29479 solver.cpp:214] Iteration 12700, loss = 7575.84
I0315 00:36:28.509613 29479 solver.cpp:229]     Train net output #0: loss = 11512.6 (* 1 = 11512.6 loss)
I0315 00:36:28.614717 29479 solver.cpp:610] Iteration 12700, lr = 9.42664e-09
I0315 00:36:28.614732 29479 solver.cpp:613] Iteration 12700, avg_grad_norm = 584583
I0315 00:36:52.086688 29479 solver.cpp:214] Iteration 12720, loss = 7332.83
I0315 00:36:52.086756 29479 solver.cpp:229]     Train net output #0: loss = 14448.9 (* 1 = 14448.9 loss)
I0315 00:36:52.192026 29479 solver.cpp:610] Iteration 12720, lr = 9.42574e-09
I0315 00:36:52.192039 29479 solver.cpp:613] Iteration 12720, avg_grad_norm = 708801
I0315 00:37:17.180240 29479 solver.cpp:214] Iteration 12740, loss = 7457.92
I0315 00:37:17.180433 29479 solver.cpp:229]     Train net output #0: loss = 7228.53 (* 1 = 7228.53 loss)
I0315 00:37:17.294937 29479 solver.cpp:610] Iteration 12740, lr = 9.42483e-09
I0315 00:37:17.294950 29479 solver.cpp:613] Iteration 12740, avg_grad_norm = 631186
I0315 00:37:42.893292 29479 solver.cpp:214] Iteration 12760, loss = 7111.93
I0315 00:37:42.893373 29479 solver.cpp:229]     Train net output #0: loss = 10328.9 (* 1 = 10328.9 loss)
I0315 00:37:43.007835 29479 solver.cpp:610] Iteration 12760, lr = 9.42392e-09
I0315 00:37:43.007849 29479 solver.cpp:613] Iteration 12760, avg_grad_norm = 585178
I0315 00:38:08.590616 29479 solver.cpp:214] Iteration 12780, loss = 7017.22
I0315 00:38:08.590755 29479 solver.cpp:229]     Train net output #0: loss = 3980.33 (* 1 = 3980.33 loss)
I0315 00:38:08.705551 29479 solver.cpp:610] Iteration 12780, lr = 9.42302e-09
I0315 00:38:08.705564 29479 solver.cpp:613] Iteration 12780, avg_grad_norm = 600326
I0315 00:38:34.286811 29479 solver.cpp:214] Iteration 12800, loss = 7092.45
I0315 00:38:34.286871 29479 solver.cpp:229]     Train net output #0: loss = 4407.23 (* 1 = 4407.23 loss)
I0315 00:38:34.401504 29479 solver.cpp:610] Iteration 12800, lr = 9.42211e-09
I0315 00:38:34.401517 29479 solver.cpp:613] Iteration 12800, avg_grad_norm = 662873
I0315 00:38:59.890386 29479 solver.cpp:214] Iteration 12820, loss = 7480.91
I0315 00:38:59.890522 29479 solver.cpp:229]     Train net output #0: loss = 6341.43 (* 1 = 6341.43 loss)
I0315 00:39:00.003132 29479 solver.cpp:610] Iteration 12820, lr = 9.42121e-09
I0315 00:39:00.003145 29479 solver.cpp:613] Iteration 12820, avg_grad_norm = 686219
I0315 00:39:36.654436 29479 solver.cpp:214] Iteration 12840, loss = 7217.97
I0315 00:39:36.654573 29479 solver.cpp:229]     Train net output #0: loss = 8569.15 (* 1 = 8569.15 loss)
I0315 00:39:36.759723 29479 solver.cpp:610] Iteration 12840, lr = 9.4203e-09
I0315 00:39:36.759737 29479 solver.cpp:613] Iteration 12840, avg_grad_norm = 689740
I0315 00:40:00.954758 29479 solver.cpp:214] Iteration 12860, loss = 7210.38
I0315 00:40:00.954830 29479 solver.cpp:229]     Train net output #0: loss = 6549.98 (* 1 = 6549.98 loss)
I0315 00:40:01.070871 29479 solver.cpp:610] Iteration 12860, lr = 9.41939e-09
I0315 00:40:01.070884 29479 solver.cpp:613] Iteration 12860, avg_grad_norm = 694215
I0315 00:40:26.779208 29479 solver.cpp:214] Iteration 12880, loss = 7309.42
I0315 00:40:26.779364 29479 solver.cpp:229]     Train net output #0: loss = 11074 (* 1 = 11074 loss)
I0315 00:40:26.893853 29479 solver.cpp:610] Iteration 12880, lr = 9.41849e-09
I0315 00:40:26.893867 29479 solver.cpp:613] Iteration 12880, avg_grad_norm = 688412
I0315 00:40:52.477180 29479 solver.cpp:214] Iteration 12900, loss = 7431.16
I0315 00:40:52.477236 29479 solver.cpp:229]     Train net output #0: loss = 9257.23 (* 1 = 9257.23 loss)
I0315 00:40:52.592087 29479 solver.cpp:610] Iteration 12900, lr = 9.41758e-09
I0315 00:40:52.592102 29479 solver.cpp:613] Iteration 12900, avg_grad_norm = 584768
I0315 00:41:17.901588 29479 solver.cpp:214] Iteration 12920, loss = 6938.68
I0315 00:41:17.901734 29479 solver.cpp:229]     Train net output #0: loss = 5330.87 (* 1 = 5330.87 loss)
I0315 00:41:18.014503 29479 solver.cpp:610] Iteration 12920, lr = 9.41668e-09
I0315 00:41:18.014518 29479 solver.cpp:613] Iteration 12920, avg_grad_norm = 630287
I0315 00:41:43.511405 29479 solver.cpp:214] Iteration 12940, loss = 7295.08
I0315 00:41:43.511464 29479 solver.cpp:229]     Train net output #0: loss = 3696.91 (* 1 = 3696.91 loss)
I0315 00:41:43.626158 29479 solver.cpp:610] Iteration 12940, lr = 9.41577e-09
I0315 00:41:43.626171 29479 solver.cpp:613] Iteration 12940, avg_grad_norm = 660178
I0315 00:42:22.560232 29479 solver.cpp:214] Iteration 12960, loss = 7470.19
I0315 00:42:22.560369 29479 solver.cpp:229]     Train net output #0: loss = 7824.65 (* 1 = 7824.65 loss)
I0315 00:42:22.665555 29479 solver.cpp:610] Iteration 12960, lr = 9.41486e-09
I0315 00:42:22.665567 29479 solver.cpp:613] Iteration 12960, avg_grad_norm = 728918
I0315 00:42:46.191061 29479 solver.cpp:214] Iteration 12980, loss = 7457.89
I0315 00:42:46.191120 29479 solver.cpp:229]     Train net output #0: loss = 4807.13 (* 1 = 4807.13 loss)
I0315 00:42:46.296175 29479 solver.cpp:610] Iteration 12980, lr = 9.41396e-09
I0315 00:42:46.296187 29479 solver.cpp:613] Iteration 12980, avg_grad_norm = 701135
I0315 00:43:12.004566 29479 solver.cpp:214] Iteration 13000, loss = 7136.42
I0315 00:43:12.004747 29479 solver.cpp:229]     Train net output #0: loss = 5891.1 (* 1 = 5891.1 loss)
I0315 00:43:12.116222 29479 solver.cpp:610] Iteration 13000, lr = 9.41305e-09
I0315 00:43:12.116236 29479 solver.cpp:613] Iteration 13000, avg_grad_norm = 586910
I0315 00:43:37.043061 29479 solver.cpp:214] Iteration 13020, loss = 7381.05
I0315 00:43:37.043154 29479 solver.cpp:229]     Train net output #0: loss = 6605.64 (* 1 = 6605.64 loss)
I0315 00:43:37.154986 29479 solver.cpp:610] Iteration 13020, lr = 9.41215e-09
I0315 00:43:37.155000 29479 solver.cpp:613] Iteration 13020, avg_grad_norm = 745608
I0315 00:44:02.683429 29479 solver.cpp:214] Iteration 13040, loss = 7453.56
I0315 00:44:02.683562 29479 solver.cpp:229]     Train net output #0: loss = 5118.57 (* 1 = 5118.57 loss)
I0315 00:44:02.798046 29479 solver.cpp:610] Iteration 13040, lr = 9.41124e-09
I0315 00:44:02.798059 29479 solver.cpp:613] Iteration 13040, avg_grad_norm = 567317
I0315 00:44:28.343014 29479 solver.cpp:214] Iteration 13060, loss = 7764.17
I0315 00:44:28.343077 29479 solver.cpp:229]     Train net output #0: loss = 4912.03 (* 1 = 4912.03 loss)
I0315 00:44:28.457808 29479 solver.cpp:610] Iteration 13060, lr = 9.41033e-09
I0315 00:44:28.457820 29479 solver.cpp:613] Iteration 13060, avg_grad_norm = 598396
I0315 00:45:06.731575 29479 solver.cpp:214] Iteration 13080, loss = 7450.72
I0315 00:45:06.731681 29479 solver.cpp:229]     Train net output #0: loss = 12322 (* 1 = 12322 loss)
I0315 00:45:06.835913 29479 solver.cpp:610] Iteration 13080, lr = 9.40943e-09
I0315 00:45:06.835927 29479 solver.cpp:613] Iteration 13080, avg_grad_norm = 631827
I0315 00:45:30.346870 29479 solver.cpp:214] Iteration 13100, loss = 7134.2
I0315 00:45:30.346935 29479 solver.cpp:229]     Train net output #0: loss = 8294.94 (* 1 = 8294.94 loss)
I0315 00:45:30.452047 29479 solver.cpp:610] Iteration 13100, lr = 9.40852e-09
I0315 00:45:30.452062 29479 solver.cpp:613] Iteration 13100, avg_grad_norm = 636715
I0315 00:45:55.763281 29479 solver.cpp:214] Iteration 13120, loss = 7344.6
I0315 00:45:55.763382 29479 solver.cpp:229]     Train net output #0: loss = 4907.99 (* 1 = 4907.99 loss)
I0315 00:45:55.879390 29479 solver.cpp:610] Iteration 13120, lr = 9.40762e-09
I0315 00:45:55.879403 29479 solver.cpp:613] Iteration 13120, avg_grad_norm = 743931
I0315 00:46:21.493242 29479 solver.cpp:214] Iteration 13140, loss = 7429.32
I0315 00:46:21.493295 29479 solver.cpp:229]     Train net output #0: loss = 9714.97 (* 1 = 9714.97 loss)
I0315 00:46:21.607800 29479 solver.cpp:610] Iteration 13140, lr = 9.40671e-09
I0315 00:46:21.607813 29479 solver.cpp:613] Iteration 13140, avg_grad_norm = 817361
I0315 00:46:47.193106 29479 solver.cpp:214] Iteration 13160, loss = 7220.29
I0315 00:46:47.193228 29479 solver.cpp:229]     Train net output #0: loss = 5393.6 (* 1 = 5393.6 loss)
I0315 00:46:47.306136 29479 solver.cpp:610] Iteration 13160, lr = 9.4058e-09
I0315 00:46:47.306150 29479 solver.cpp:613] Iteration 13160, avg_grad_norm = 690517
I0315 00:47:12.597522 29479 solver.cpp:214] Iteration 13180, loss = 7153.85
I0315 00:47:12.597576 29479 solver.cpp:229]     Train net output #0: loss = 12859.7 (* 1 = 12859.7 loss)
I0315 00:47:12.710561 29479 solver.cpp:610] Iteration 13180, lr = 9.4049e-09
I0315 00:47:12.710574 29479 solver.cpp:613] Iteration 13180, avg_grad_norm = 569895
I0315 00:47:38.208375 29479 solver.cpp:214] Iteration 13200, loss = 7219.38
I0315 00:47:38.208508 29479 solver.cpp:229]     Train net output #0: loss = 4700.14 (* 1 = 4700.14 loss)
I0315 00:47:38.322851 29479 solver.cpp:610] Iteration 13200, lr = 9.40399e-09
I0315 00:47:38.322866 29479 solver.cpp:613] Iteration 13200, avg_grad_norm = 645125
I0315 00:48:21.716310 29479 solver.cpp:214] Iteration 13220, loss = 7422.17
I0315 00:48:21.716495 29479 solver.cpp:229]     Train net output #0: loss = 9860.28 (* 1 = 9860.28 loss)
I0315 00:48:21.820909 29479 solver.cpp:610] Iteration 13220, lr = 9.40308e-09
I0315 00:48:21.820924 29479 solver.cpp:613] Iteration 13220, avg_grad_norm = 660409
I0315 00:48:45.354445 29479 solver.cpp:214] Iteration 13240, loss = 7309.34
I0315 00:48:45.354496 29479 solver.cpp:229]     Train net output #0: loss = 8545.35 (* 1 = 8545.35 loss)
I0315 00:48:45.464099 29479 solver.cpp:610] Iteration 13240, lr = 9.40218e-09
I0315 00:48:45.464113 29479 solver.cpp:613] Iteration 13240, avg_grad_norm = 587146
I0315 00:49:10.928436 29479 solver.cpp:214] Iteration 13260, loss = 7013.17
I0315 00:49:10.928550 29479 solver.cpp:229]     Train net output #0: loss = 3967.78 (* 1 = 3967.78 loss)
I0315 00:49:11.044519 29479 solver.cpp:610] Iteration 13260, lr = 9.40127e-09
I0315 00:49:11.044533 29479 solver.cpp:613] Iteration 13260, avg_grad_norm = 630958
I0315 00:49:36.579049 29479 solver.cpp:214] Iteration 13280, loss = 7012.22
I0315 00:49:36.579108 29479 solver.cpp:229]     Train net output #0: loss = 6371.09 (* 1 = 6371.09 loss)
I0315 00:49:36.690609 29479 solver.cpp:610] Iteration 13280, lr = 9.40037e-09
I0315 00:49:36.690623 29479 solver.cpp:613] Iteration 13280, avg_grad_norm = 578314
I0315 00:50:01.750772 29479 solver.cpp:214] Iteration 13300, loss = 7218.28
I0315 00:50:01.750891 29479 solver.cpp:229]     Train net output #0: loss = 7998.58 (* 1 = 7998.58 loss)
I0315 00:50:01.865483 29479 solver.cpp:610] Iteration 13300, lr = 9.39946e-09
I0315 00:50:01.865497 29479 solver.cpp:613] Iteration 13300, avg_grad_norm = 607628
I0315 00:50:27.461643 29479 solver.cpp:214] Iteration 13320, loss = 7425.79
I0315 00:50:27.461696 29479 solver.cpp:229]     Train net output #0: loss = 10948.1 (* 1 = 10948.1 loss)
I0315 00:50:27.576259 29479 solver.cpp:610] Iteration 13320, lr = 9.39855e-09
I0315 00:50:27.576272 29479 solver.cpp:613] Iteration 13320, avg_grad_norm = 679150
I0315 00:51:07.946486 29479 solver.cpp:214] Iteration 13340, loss = 7182.47
I0315 00:51:07.946616 29479 solver.cpp:229]     Train net output #0: loss = 6594.69 (* 1 = 6594.69 loss)
I0315 00:51:08.050343 29479 solver.cpp:610] Iteration 13340, lr = 9.39765e-09
I0315 00:51:08.050356 29479 solver.cpp:613] Iteration 13340, avg_grad_norm = 582872
I0315 00:51:31.573886 29479 solver.cpp:214] Iteration 13360, loss = 7429.2
I0315 00:51:31.573950 29479 solver.cpp:229]     Train net output #0: loss = 12234.3 (* 1 = 12234.3 loss)
I0315 00:51:31.679095 29479 solver.cpp:610] Iteration 13360, lr = 9.39674e-09
I0315 00:51:31.679111 29479 solver.cpp:613] Iteration 13360, avg_grad_norm = 597540
I0315 00:51:56.980291 29479 solver.cpp:214] Iteration 13380, loss = 7390.36
I0315 00:51:56.980401 29479 solver.cpp:229]     Train net output #0: loss = 5267.71 (* 1 = 5267.71 loss)
I0315 00:51:57.096426 29479 solver.cpp:610] Iteration 13380, lr = 9.39583e-09
I0315 00:51:57.096439 29479 solver.cpp:613] Iteration 13380, avg_grad_norm = 652045
I0315 00:52:22.806962 29479 solver.cpp:214] Iteration 13400, loss = 7009.89
I0315 00:52:22.807010 29479 solver.cpp:229]     Train net output #0: loss = 5020.98 (* 1 = 5020.98 loss)
I0315 00:52:22.919924 29479 solver.cpp:610] Iteration 13400, lr = 9.39493e-09
I0315 00:52:22.919937 29479 solver.cpp:613] Iteration 13400, avg_grad_norm = 641994
I0315 00:52:48.204440 29479 solver.cpp:214] Iteration 13420, loss = 7373
I0315 00:52:48.204565 29479 solver.cpp:229]     Train net output #0: loss = 7081.32 (* 1 = 7081.32 loss)
I0315 00:52:48.317504 29479 solver.cpp:610] Iteration 13420, lr = 9.39402e-09
I0315 00:52:48.317517 29479 solver.cpp:613] Iteration 13420, avg_grad_norm = 704929
I0315 00:53:13.878410 29479 solver.cpp:214] Iteration 13440, loss = 7270.91
I0315 00:53:13.878474 29479 solver.cpp:229]     Train net output #0: loss = 12853.8 (* 1 = 12853.8 loss)
I0315 00:53:13.993037 29479 solver.cpp:610] Iteration 13440, lr = 9.39312e-09
I0315 00:53:13.993052 29479 solver.cpp:613] Iteration 13440, avg_grad_norm = 682363
I0315 00:53:39.603924 29479 solver.cpp:214] Iteration 13460, loss = 7341.94
I0315 00:53:39.604092 29479 solver.cpp:229]     Train net output #0: loss = 7464.51 (* 1 = 7464.51 loss)
I0315 00:53:39.718312 29479 solver.cpp:610] Iteration 13460, lr = 9.39221e-09
I0315 00:53:39.718327 29479 solver.cpp:613] Iteration 13460, avg_grad_norm = 673378
I0315 00:54:16.142252 29479 solver.cpp:214] Iteration 13480, loss = 7125.18
I0315 00:54:16.142384 29479 solver.cpp:229]     Train net output #0: loss = 9304.42 (* 1 = 9304.42 loss)
I0315 00:54:16.247501 29479 solver.cpp:610] Iteration 13480, lr = 9.3913e-09
I0315 00:54:16.247514 29479 solver.cpp:613] Iteration 13480, avg_grad_norm = 669580
I0315 00:54:41.185461 29479 solver.cpp:214] Iteration 13500, loss = 7141.61
I0315 00:54:41.185513 29479 solver.cpp:229]     Train net output #0: loss = 10627.5 (* 1 = 10627.5 loss)
I0315 00:54:41.300051 29479 solver.cpp:610] Iteration 13500, lr = 9.3904e-09
I0315 00:54:41.300065 29479 solver.cpp:613] Iteration 13500, avg_grad_norm = 685645
I0315 00:55:06.895511 29479 solver.cpp:214] Iteration 13520, loss = 7661.17
I0315 00:55:06.895643 29479 solver.cpp:229]     Train net output #0: loss = 5534.81 (* 1 = 5534.81 loss)
I0315 00:55:07.010078 29479 solver.cpp:610] Iteration 13520, lr = 9.38949e-09
I0315 00:55:07.010092 29479 solver.cpp:613] Iteration 13520, avg_grad_norm = 667993
I0315 00:55:32.615061 29479 solver.cpp:214] Iteration 13540, loss = 7329.05
I0315 00:55:32.615134 29479 solver.cpp:229]     Train net output #0: loss = 9431.92 (* 1 = 9431.92 loss)
I0315 00:55:32.729581 29479 solver.cpp:610] Iteration 13540, lr = 9.38858e-09
I0315 00:55:32.729619 29479 solver.cpp:613] Iteration 13540, avg_grad_norm = 658220
I0315 00:55:58.333889 29479 solver.cpp:214] Iteration 13560, loss = 7294.11
I0315 00:55:58.334017 29479 solver.cpp:229]     Train net output #0: loss = 10527.8 (* 1 = 10527.8 loss)
I0315 00:55:58.448400 29479 solver.cpp:610] Iteration 13560, lr = 9.38768e-09
I0315 00:55:58.448426 29479 solver.cpp:613] Iteration 13560, avg_grad_norm = 675205
I0315 00:56:24.045100 29479 solver.cpp:214] Iteration 13580, loss = 7602.32
I0315 00:56:24.045166 29479 solver.cpp:229]     Train net output #0: loss = 7437.06 (* 1 = 7437.06 loss)
I0315 00:56:24.159631 29479 solver.cpp:610] Iteration 13580, lr = 9.38677e-09
I0315 00:56:24.159644 29479 solver.cpp:613] Iteration 13580, avg_grad_norm = 723228
I0315 00:57:13.240537 29479 solver.cpp:214] Iteration 13600, loss = 7506.95
I0315 00:57:13.240666 29479 solver.cpp:229]     Train net output #0: loss = 5812.88 (* 1 = 5812.88 loss)
I0315 00:57:13.345933 29479 solver.cpp:610] Iteration 13600, lr = 9.38587e-09
I0315 00:57:13.345947 29479 solver.cpp:613] Iteration 13600, avg_grad_norm = 665183
I0315 00:57:36.837373 29479 solver.cpp:214] Iteration 13620, loss = 7223.51
I0315 00:57:36.837430 29479 solver.cpp:229]     Train net output #0: loss = 5151.78 (* 1 = 5151.78 loss)
I0315 00:57:36.942821 29479 solver.cpp:610] Iteration 13620, lr = 9.38496e-09
I0315 00:57:36.942834 29479 solver.cpp:613] Iteration 13620, avg_grad_norm = 580253
I0315 00:58:01.234295 29479 solver.cpp:214] Iteration 13640, loss = 7284.75
I0315 00:58:01.234377 29479 solver.cpp:229]     Train net output #0: loss = 8561.21 (* 1 = 8561.21 loss)
I0315 00:58:01.345813 29479 solver.cpp:610] Iteration 13640, lr = 9.38405e-09
I0315 00:58:01.345825 29479 solver.cpp:613] Iteration 13640, avg_grad_norm = 570792
I0315 00:58:26.730049 29479 solver.cpp:214] Iteration 13660, loss = 7125.04
I0315 00:58:26.730110 29479 solver.cpp:229]     Train net output #0: loss = 5633.43 (* 1 = 5633.43 loss)
I0315 00:58:26.846122 29479 solver.cpp:610] Iteration 13660, lr = 9.38315e-09
I0315 00:58:26.846134 29479 solver.cpp:613] Iteration 13660, avg_grad_norm = 717347
I0315 00:58:52.376924 29479 solver.cpp:214] Iteration 13680, loss = 7663.34
I0315 00:58:52.377107 29479 solver.cpp:229]     Train net output #0: loss = 7533.39 (* 1 = 7533.39 loss)
I0315 00:58:52.489789 29479 solver.cpp:610] Iteration 13680, lr = 9.38224e-09
I0315 00:58:52.489802 29479 solver.cpp:613] Iteration 13680, avg_grad_norm = 603121
I0315 00:59:17.774736 29479 solver.cpp:214] Iteration 13700, loss = 7336.43
I0315 00:59:17.774790 29479 solver.cpp:229]     Train net output #0: loss = 7563.59 (* 1 = 7563.59 loss)
I0315 00:59:17.887639 29479 solver.cpp:610] Iteration 13700, lr = 9.38133e-09
I0315 00:59:17.887652 29479 solver.cpp:613] Iteration 13700, avg_grad_norm = 645536
I0315 01:00:09.252508 29479 solver.cpp:214] Iteration 13720, loss = 7590.7
I0315 01:00:09.252640 29479 solver.cpp:229]     Train net output #0: loss = 5160.98 (* 1 = 5160.98 loss)
I0315 01:00:09.357800 29479 solver.cpp:610] Iteration 13720, lr = 9.38043e-09
I0315 01:00:09.357812 29479 solver.cpp:613] Iteration 13720, avg_grad_norm = 740167
I0315 01:00:32.761049 29479 solver.cpp:214] Iteration 13740, loss = 7331.14
I0315 01:00:32.761101 29479 solver.cpp:229]     Train net output #0: loss = 4979.92 (* 1 = 4979.92 loss)
I0315 01:00:32.865546 29479 solver.cpp:610] Iteration 13740, lr = 9.37952e-09
I0315 01:00:32.865566 29479 solver.cpp:613] Iteration 13740, avg_grad_norm = 726950
I0315 01:00:56.539237 29479 solver.cpp:214] Iteration 13760, loss = 7184.18
I0315 01:00:56.539369 29479 solver.cpp:229]     Train net output #0: loss = 3542.82 (* 1 = 3542.82 loss)
I0315 01:00:56.652534 29479 solver.cpp:610] Iteration 13760, lr = 9.37861e-09
I0315 01:00:56.652546 29479 solver.cpp:613] Iteration 13760, avg_grad_norm = 650508
I0315 01:01:21.940619 29479 solver.cpp:214] Iteration 13780, loss = 7600.9
I0315 01:01:21.940670 29479 solver.cpp:229]     Train net output #0: loss = 5903.74 (* 1 = 5903.74 loss)
I0315 01:01:22.054405 29479 solver.cpp:610] Iteration 13780, lr = 9.37771e-09
I0315 01:01:22.054419 29479 solver.cpp:613] Iteration 13780, avg_grad_norm = 714461
I0315 01:01:47.701546 29479 solver.cpp:214] Iteration 13800, loss = 6895.2
I0315 01:01:47.701653 29479 solver.cpp:229]     Train net output #0: loss = 10387.7 (* 1 = 10387.7 loss)
I0315 01:01:47.816063 29479 solver.cpp:610] Iteration 13800, lr = 9.3768e-09
I0315 01:01:47.816076 29479 solver.cpp:613] Iteration 13800, avg_grad_norm = 606886
I0315 01:02:13.457224 29479 solver.cpp:214] Iteration 13820, loss = 7354.42
I0315 01:02:13.457270 29479 solver.cpp:229]     Train net output #0: loss = 9341.32 (* 1 = 9341.32 loss)
I0315 01:02:13.571705 29479 solver.cpp:610] Iteration 13820, lr = 9.37589e-09
I0315 01:02:13.571718 29479 solver.cpp:613] Iteration 13820, avg_grad_norm = 704457
I0315 01:02:38.895319 29479 solver.cpp:214] Iteration 13840, loss = 7306.81
I0315 01:02:38.895439 29479 solver.cpp:229]     Train net output #0: loss = 8861.63 (* 1 = 8861.63 loss)
I0315 01:02:39.008218 29479 solver.cpp:610] Iteration 13840, lr = 9.37499e-09
I0315 01:02:39.008230 29479 solver.cpp:613] Iteration 13840, avg_grad_norm = 714825
I0315 01:03:18.016634 29479 solver.cpp:214] Iteration 13860, loss = 6927.38
I0315 01:03:18.016726 29479 solver.cpp:229]     Train net output #0: loss = 8286.42 (* 1 = 8286.42 loss)
I0315 01:03:18.121805 29479 solver.cpp:610] Iteration 13860, lr = 9.37408e-09
I0315 01:03:18.121819 29479 solver.cpp:613] Iteration 13860, avg_grad_norm = 643736
I0315 01:03:42.427772 29479 solver.cpp:214] Iteration 13880, loss = 7076.67
I0315 01:03:42.427822 29479 solver.cpp:229]     Train net output #0: loss = 10525.7 (* 1 = 10525.7 loss)
I0315 01:03:42.542321 29479 solver.cpp:610] Iteration 13880, lr = 9.37318e-09
I0315 01:03:42.542335 29479 solver.cpp:613] Iteration 13880, avg_grad_norm = 574976
I0315 01:04:08.160579 29479 solver.cpp:214] Iteration 13900, loss = 7093.96
I0315 01:04:08.160706 29479 solver.cpp:229]     Train net output #0: loss = 5248.33 (* 1 = 5248.33 loss)
I0315 01:04:08.275166 29479 solver.cpp:610] Iteration 13900, lr = 9.37227e-09
I0315 01:04:08.275179 29479 solver.cpp:613] Iteration 13900, avg_grad_norm = 688996
I0315 01:04:33.904434 29479 solver.cpp:214] Iteration 13920, loss = 7580.81
I0315 01:04:33.904497 29479 solver.cpp:229]     Train net output #0: loss = 8217.52 (* 1 = 8217.52 loss)
I0315 01:04:34.019131 29479 solver.cpp:610] Iteration 13920, lr = 9.37136e-09
I0315 01:04:34.019145 29479 solver.cpp:613] Iteration 13920, avg_grad_norm = 603519
I0315 01:04:59.662225 29479 solver.cpp:214] Iteration 13940, loss = 7145.21
I0315 01:04:59.662446 29479 solver.cpp:229]     Train net output #0: loss = 10193.2 (* 1 = 10193.2 loss)
I0315 01:04:59.776902 29479 solver.cpp:610] Iteration 13940, lr = 9.37046e-09
I0315 01:04:59.776916 29479 solver.cpp:613] Iteration 13940, avg_grad_norm = 701704
I0315 01:05:25.101922 29479 solver.cpp:214] Iteration 13960, loss = 7469.44
I0315 01:05:25.101982 29479 solver.cpp:229]     Train net output #0: loss = 5750.49 (* 1 = 5750.49 loss)
I0315 01:05:25.214874 29479 solver.cpp:610] Iteration 13960, lr = 9.36955e-09
I0315 01:05:25.214915 29479 solver.cpp:613] Iteration 13960, avg_grad_norm = 732497
I0315 01:06:02.465396 29479 solver.cpp:214] Iteration 13980, loss = 7350.65
I0315 01:06:02.465529 29479 solver.cpp:229]     Train net output #0: loss = 8195.17 (* 1 = 8195.17 loss)
I0315 01:06:02.570551 29479 solver.cpp:610] Iteration 13980, lr = 9.36864e-09
I0315 01:06:02.570564 29479 solver.cpp:613] Iteration 13980, avg_grad_norm = 644509
I0315 01:06:26.763038 29479 solver.cpp:214] Iteration 14000, loss = 7398.06
I0315 01:06:26.763085 29479 solver.cpp:229]     Train net output #0: loss = 4428.59 (* 1 = 4428.59 loss)
I0315 01:06:26.877737 29479 solver.cpp:610] Iteration 14000, lr = 9.36774e-09
I0315 01:06:26.877749 29479 solver.cpp:613] Iteration 14000, avg_grad_norm = 646858
I0315 01:06:52.473654 29479 solver.cpp:214] Iteration 14020, loss = 6887.63
I0315 01:06:52.473740 29479 solver.cpp:229]     Train net output #0: loss = 8741.16 (* 1 = 8741.16 loss)
I0315 01:06:52.588254 29479 solver.cpp:610] Iteration 14020, lr = 9.36683e-09
I0315 01:06:52.588268 29479 solver.cpp:613] Iteration 14020, avg_grad_norm = 682558
I0315 01:07:18.164818 29479 solver.cpp:214] Iteration 14040, loss = 6829.44
I0315 01:07:18.164868 29479 solver.cpp:229]     Train net output #0: loss = 8419.67 (* 1 = 8419.67 loss)
I0315 01:07:18.279479 29479 solver.cpp:610] Iteration 14040, lr = 9.36592e-09
I0315 01:07:18.279494 29479 solver.cpp:613] Iteration 14040, avg_grad_norm = 627726
I0315 01:07:43.823158 29479 solver.cpp:214] Iteration 14060, loss = 7240.27
I0315 01:07:43.823308 29479 solver.cpp:229]     Train net output #0: loss = 5361.65 (* 1 = 5361.65 loss)
I0315 01:07:43.937611 29479 solver.cpp:610] Iteration 14060, lr = 9.36502e-09
I0315 01:07:43.937624 29479 solver.cpp:613] Iteration 14060, avg_grad_norm = 694617
I0315 01:08:09.480770 29479 solver.cpp:214] Iteration 14080, loss = 7312.01
I0315 01:08:09.480818 29479 solver.cpp:229]     Train net output #0: loss = 6802.53 (* 1 = 6802.53 loss)
I0315 01:08:09.595413 29479 solver.cpp:610] Iteration 14080, lr = 9.36411e-09
I0315 01:08:09.595427 29479 solver.cpp:613] Iteration 14080, avg_grad_norm = 678542
I0315 01:08:47.384852 29479 solver.cpp:214] Iteration 14100, loss = 7414.22
I0315 01:08:47.385004 29479 solver.cpp:229]     Train net output #0: loss = 5885.11 (* 1 = 5885.11 loss)
I0315 01:08:47.490077 29479 solver.cpp:610] Iteration 14100, lr = 9.3632e-09
I0315 01:08:47.490092 29479 solver.cpp:613] Iteration 14100, avg_grad_norm = 566802
I0315 01:09:10.948113 29479 solver.cpp:214] Iteration 14120, loss = 7200.52
I0315 01:09:10.948173 29479 solver.cpp:229]     Train net output #0: loss = 10440.9 (* 1 = 10440.9 loss)
I0315 01:09:11.053169 29479 solver.cpp:610] Iteration 14120, lr = 9.3623e-09
I0315 01:09:11.053181 29479 solver.cpp:613] Iteration 14120, avg_grad_norm = 602090
I0315 01:09:36.432884 29479 solver.cpp:214] Iteration 14140, loss = 7198.89
I0315 01:09:36.432998 29479 solver.cpp:229]     Train net output #0: loss = 4671.4 (* 1 = 4671.4 loss)
I0315 01:09:36.547613 29479 solver.cpp:610] Iteration 14140, lr = 9.36139e-09
I0315 01:09:36.547628 29479 solver.cpp:613] Iteration 14140, avg_grad_norm = 613155
I0315 01:10:02.092053 29479 solver.cpp:214] Iteration 14160, loss = 7882.98
I0315 01:10:02.092113 29479 solver.cpp:229]     Train net output #0: loss = 4862.99 (* 1 = 4862.99 loss)
I0315 01:10:02.206562 29479 solver.cpp:610] Iteration 14160, lr = 9.36048e-09
I0315 01:10:02.206576 29479 solver.cpp:613] Iteration 14160, avg_grad_norm = 619171
I0315 01:10:27.812382 29479 solver.cpp:214] Iteration 14180, loss = 7357.06
I0315 01:10:27.812561 29479 solver.cpp:229]     Train net output #0: loss = 5908.01 (* 1 = 5908.01 loss)
I0315 01:10:27.926976 29479 solver.cpp:610] Iteration 14180, lr = 9.35958e-09
I0315 01:10:27.926990 29479 solver.cpp:613] Iteration 14180, avg_grad_norm = 620357
I0315 01:10:53.504926 29479 solver.cpp:214] Iteration 14200, loss = 7480.06
I0315 01:10:53.504978 29479 solver.cpp:229]     Train net output #0: loss = 6761.49 (* 1 = 6761.49 loss)
I0315 01:10:53.617877 29479 solver.cpp:610] Iteration 14200, lr = 9.35867e-09
I0315 01:10:53.617889 29479 solver.cpp:613] Iteration 14200, avg_grad_norm = 692451
I0315 01:11:18.914083 29479 solver.cpp:214] Iteration 14220, loss = 6946.43
I0315 01:11:18.914224 29479 solver.cpp:229]     Train net output #0: loss = 9148.04 (* 1 = 9148.04 loss)
I0315 01:11:19.026986 29479 solver.cpp:610] Iteration 14220, lr = 9.35776e-09
I0315 01:11:19.026999 29479 solver.cpp:613] Iteration 14220, avg_grad_norm = 766899
I0315 01:11:56.032747 29479 solver.cpp:214] Iteration 14240, loss = 7177.06
I0315 01:11:56.032863 29479 solver.cpp:229]     Train net output #0: loss = 6923.73 (* 1 = 6923.73 loss)
I0315 01:11:56.138020 29479 solver.cpp:610] Iteration 14240, lr = 9.35686e-09
I0315 01:11:56.138032 29479 solver.cpp:613] Iteration 14240, avg_grad_norm = 706500
I0315 01:12:20.950992 29479 solver.cpp:214] Iteration 14260, loss = 7379.14
I0315 01:12:20.951045 29479 solver.cpp:229]     Train net output #0: loss = 7462.13 (* 1 = 7462.13 loss)
I0315 01:12:21.065783 29479 solver.cpp:610] Iteration 14260, lr = 9.35595e-09
I0315 01:12:21.065798 29479 solver.cpp:613] Iteration 14260, avg_grad_norm = 622536
I0315 01:12:46.665673 29479 solver.cpp:214] Iteration 14280, loss = 7210.17
I0315 01:12:46.665874 29479 solver.cpp:229]     Train net output #0: loss = 9733.97 (* 1 = 9733.97 loss)
I0315 01:12:46.780259 29479 solver.cpp:610] Iteration 14280, lr = 9.35504e-09
I0315 01:12:46.780277 29479 solver.cpp:613] Iteration 14280, avg_grad_norm = 588540
I0315 01:13:12.377483 29479 solver.cpp:214] Iteration 14300, loss = 7024.16
I0315 01:13:12.377549 29479 solver.cpp:229]     Train net output #0: loss = 9302.05 (* 1 = 9302.05 loss)
I0315 01:13:12.492396 29479 solver.cpp:610] Iteration 14300, lr = 9.35414e-09
I0315 01:13:12.492409 29479 solver.cpp:613] Iteration 14300, avg_grad_norm = 633496
I0315 01:13:38.096824 29479 solver.cpp:214] Iteration 14320, loss = 7008.27
I0315 01:13:38.096933 29479 solver.cpp:229]     Train net output #0: loss = 5826.25 (* 1 = 5826.25 loss)
I0315 01:13:38.211534 29479 solver.cpp:610] Iteration 14320, lr = 9.35323e-09
I0315 01:13:38.211547 29479 solver.cpp:613] Iteration 14320, avg_grad_norm = 678754
I0315 01:14:03.822640 29479 solver.cpp:214] Iteration 14340, loss = 7236.2
I0315 01:14:03.822697 29479 solver.cpp:229]     Train net output #0: loss = 10174.2 (* 1 = 10174.2 loss)
I0315 01:14:03.937237 29479 solver.cpp:610] Iteration 14340, lr = 9.35232e-09
I0315 01:14:03.937252 29479 solver.cpp:613] Iteration 14340, avg_grad_norm = 707592
I0315 01:14:41.173971 29479 solver.cpp:214] Iteration 14360, loss = 7109.15
I0315 01:14:41.174089 29479 solver.cpp:229]     Train net output #0: loss = 4596.7 (* 1 = 4596.7 loss)
I0315 01:14:41.279165 29479 solver.cpp:610] Iteration 14360, lr = 9.35142e-09
I0315 01:14:41.279178 29479 solver.cpp:613] Iteration 14360, avg_grad_norm = 622836
I0315 01:15:05.194938 29479 solver.cpp:214] Iteration 14380, loss = 6856.63
I0315 01:15:05.195008 29479 solver.cpp:229]     Train net output #0: loss = 6183.91 (* 1 = 6183.91 loss)
I0315 01:15:05.308014 29479 solver.cpp:610] Iteration 14380, lr = 9.35051e-09
I0315 01:15:05.308053 29479 solver.cpp:613] Iteration 14380, avg_grad_norm = 616272
I0315 01:15:31.058809 29479 solver.cpp:214] Iteration 14400, loss = 7149.37
I0315 01:15:31.058959 29479 solver.cpp:229]     Train net output #0: loss = 9680.41 (* 1 = 9680.41 loss)
I0315 01:15:31.173413 29479 solver.cpp:610] Iteration 14400, lr = 9.3496e-09
I0315 01:15:31.173426 29479 solver.cpp:613] Iteration 14400, avg_grad_norm = 658154
I0315 01:15:56.778071 29479 solver.cpp:214] Iteration 14420, loss = 7260.71
I0315 01:15:56.778149 29479 solver.cpp:229]     Train net output #0: loss = 5846.36 (* 1 = 5846.36 loss)
I0315 01:15:56.892690 29479 solver.cpp:610] Iteration 14420, lr = 9.3487e-09
I0315 01:15:56.892705 29479 solver.cpp:613] Iteration 14420, avg_grad_norm = 651968
I0315 01:16:22.307340 29479 solver.cpp:214] Iteration 14440, loss = 7194.51
I0315 01:16:22.307473 29479 solver.cpp:229]     Train net output #0: loss = 6999.85 (* 1 = 6999.85 loss)
I0315 01:16:22.420310 29479 solver.cpp:610] Iteration 14440, lr = 9.34779e-09
I0315 01:16:22.420323 29479 solver.cpp:613] Iteration 14440, avg_grad_norm = 552994
I0315 01:16:47.798382 29479 solver.cpp:214] Iteration 14460, loss = 7207.29
I0315 01:16:47.798434 29479 solver.cpp:229]     Train net output #0: loss = 9114.5 (* 1 = 9114.5 loss)
I0315 01:16:47.912772 29479 solver.cpp:610] Iteration 14460, lr = 9.34688e-09
I0315 01:16:47.912786 29479 solver.cpp:613] Iteration 14460, avg_grad_norm = 639412
I0315 01:17:33.710021 29479 solver.cpp:214] Iteration 14480, loss = 7234.6
I0315 01:17:33.710119 29479 solver.cpp:229]     Train net output #0: loss = 7057.12 (* 1 = 7057.12 loss)
I0315 01:17:33.814576 29479 solver.cpp:610] Iteration 14480, lr = 9.34598e-09
I0315 01:17:33.814589 29479 solver.cpp:613] Iteration 14480, avg_grad_norm = 624522
I0315 01:17:57.295667 29479 solver.cpp:214] Iteration 14500, loss = 7178.57
I0315 01:17:57.295718 29479 solver.cpp:229]     Train net output #0: loss = 6188.31 (* 1 = 6188.31 loss)
I0315 01:17:57.401038 29479 solver.cpp:610] Iteration 14500, lr = 9.34507e-09
I0315 01:17:57.401051 29479 solver.cpp:613] Iteration 14500, avg_grad_norm = 695630
I0315 01:18:21.542280 29479 solver.cpp:214] Iteration 14520, loss = 7448.8
I0315 01:18:21.542490 29479 solver.cpp:229]     Train net output #0: loss = 6914.38 (* 1 = 6914.38 loss)
I0315 01:18:21.655309 29479 solver.cpp:610] Iteration 14520, lr = 9.34416e-09
I0315 01:18:21.655344 29479 solver.cpp:613] Iteration 14520, avg_grad_norm = 737687
I0315 01:18:47.194000 29479 solver.cpp:214] Iteration 14540, loss = 6886.16
I0315 01:18:47.194077 29479 solver.cpp:229]     Train net output #0: loss = 5507.17 (* 1 = 5507.17 loss)
I0315 01:18:47.308682 29479 solver.cpp:610] Iteration 14540, lr = 9.34326e-09
I0315 01:18:47.308701 29479 solver.cpp:613] Iteration 14540, avg_grad_norm = 553455
I0315 01:19:12.862444 29479 solver.cpp:214] Iteration 14560, loss = 7023.93
I0315 01:19:12.862607 29479 solver.cpp:229]     Train net output #0: loss = 6700.81 (* 1 = 6700.81 loss)
I0315 01:19:12.975344 29479 solver.cpp:610] Iteration 14560, lr = 9.34235e-09
I0315 01:19:12.975360 29479 solver.cpp:613] Iteration 14560, avg_grad_norm = 532712
I0315 01:19:38.258385 29479 solver.cpp:214] Iteration 14580, loss = 7182.87
I0315 01:19:38.258476 29479 solver.cpp:229]     Train net output #0: loss = 7548.5 (* 1 = 7548.5 loss)
I0315 01:19:38.371299 29479 solver.cpp:610] Iteration 14580, lr = 9.34144e-09
I0315 01:19:38.371312 29479 solver.cpp:613] Iteration 14580, avg_grad_norm = 700094
I0315 01:20:03.848914 29479 solver.cpp:214] Iteration 14600, loss = 7052.93
I0315 01:20:03.849069 29479 solver.cpp:229]     Train net output #0: loss = 6162.42 (* 1 = 6162.42 loss)
I0315 01:20:03.963742 29479 solver.cpp:610] Iteration 14600, lr = 9.34054e-09
I0315 01:20:03.963778 29479 solver.cpp:613] Iteration 14600, avg_grad_norm = 655516
I0315 01:20:44.061295 29479 solver.cpp:214] Iteration 14620, loss = 7091.94
I0315 01:20:44.061425 29479 solver.cpp:229]     Train net output #0: loss = 4350.64 (* 1 = 4350.64 loss)
I0315 01:20:44.166466 29479 solver.cpp:610] Iteration 14620, lr = 9.33963e-09
I0315 01:20:44.166481 29479 solver.cpp:613] Iteration 14620, avg_grad_norm = 597322
I0315 01:21:08.238378 29479 solver.cpp:214] Iteration 14640, loss = 7279.58
I0315 01:21:08.238427 29479 solver.cpp:229]     Train net output #0: loss = 6181.58 (* 1 = 6181.58 loss)
I0315 01:21:08.352882 29479 solver.cpp:610] Iteration 14640, lr = 9.33872e-09
I0315 01:21:08.352895 29479 solver.cpp:613] Iteration 14640, avg_grad_norm = 631919
I0315 01:21:33.977380 29479 solver.cpp:214] Iteration 14660, loss = 7338.64
I0315 01:21:33.977552 29479 solver.cpp:229]     Train net output #0: loss = 9512.29 (* 1 = 9512.29 loss)
I0315 01:21:34.091958 29479 solver.cpp:610] Iteration 14660, lr = 9.33781e-09
I0315 01:21:34.091971 29479 solver.cpp:613] Iteration 14660, avg_grad_norm = 666174
I0315 01:21:59.695252 29479 solver.cpp:214] Iteration 14680, loss = 7394.9
I0315 01:21:59.695317 29479 solver.cpp:229]     Train net output #0: loss = 6376 (* 1 = 6376 loss)
I0315 01:21:59.809828 29479 solver.cpp:610] Iteration 14680, lr = 9.33691e-09
I0315 01:21:59.809841 29479 solver.cpp:613] Iteration 14680, avg_grad_norm = 714957
I0315 01:22:25.284734 29479 solver.cpp:214] Iteration 14700, loss = 7222.2
I0315 01:22:25.284853 29479 solver.cpp:229]     Train net output #0: loss = 4393.77 (* 1 = 4393.77 loss)
I0315 01:22:25.397872 29479 solver.cpp:610] Iteration 14700, lr = 9.336e-09
I0315 01:22:25.397887 29479 solver.cpp:613] Iteration 14700, avg_grad_norm = 615686
I0315 01:22:50.695981 29479 solver.cpp:214] Iteration 14720, loss = 7236.03
I0315 01:22:50.696040 29479 solver.cpp:229]     Train net output #0: loss = 12011.9 (* 1 = 12011.9 loss)
I0315 01:22:50.809008 29479 solver.cpp:610] Iteration 14720, lr = 9.33509e-09
I0315 01:22:50.809022 29479 solver.cpp:613] Iteration 14720, avg_grad_norm = 565620
I0315 01:23:28.218273 29479 solver.cpp:214] Iteration 14740, loss = 7383.21
I0315 01:23:28.218390 29479 solver.cpp:229]     Train net output #0: loss = 4452.23 (* 1 = 4452.23 loss)
I0315 01:23:28.323577 29479 solver.cpp:610] Iteration 14740, lr = 9.33419e-09
I0315 01:23:28.323592 29479 solver.cpp:613] Iteration 14740, avg_grad_norm = 663487
I0315 01:23:52.191781 29479 solver.cpp:214] Iteration 14760, loss = 7170.41
I0315 01:23:52.191845 29479 solver.cpp:229]     Train net output #0: loss = 13118 (* 1 = 13118 loss)
I0315 01:23:52.303347 29479 solver.cpp:610] Iteration 14760, lr = 9.33328e-09
I0315 01:23:52.303361 29479 solver.cpp:613] Iteration 14760, avg_grad_norm = 656887
I0315 01:24:17.781958 29479 solver.cpp:214] Iteration 14780, loss = 7248.08
I0315 01:24:17.782065 29479 solver.cpp:229]     Train net output #0: loss = 4040.92 (* 1 = 4040.92 loss)
I0315 01:24:17.896471 29479 solver.cpp:610] Iteration 14780, lr = 9.33237e-09
I0315 01:24:17.896484 29479 solver.cpp:613] Iteration 14780, avg_grad_norm = 568262
I0315 01:24:43.502285 29479 solver.cpp:214] Iteration 14800, loss = 7285.96
I0315 01:24:43.502343 29479 solver.cpp:229]     Train net output #0: loss = 9852.79 (* 1 = 9852.79 loss)
I0315 01:24:43.617060 29479 solver.cpp:610] Iteration 14800, lr = 9.33147e-09
I0315 01:24:43.617074 29479 solver.cpp:613] Iteration 14800, avg_grad_norm = 593256
I0315 01:25:09.249162 29479 solver.cpp:214] Iteration 14820, loss = 6971.02
I0315 01:25:09.249256 29479 solver.cpp:229]     Train net output #0: loss = 5755.1 (* 1 = 5755.1 loss)
I0315 01:25:09.363740 29479 solver.cpp:610] Iteration 14820, lr = 9.33056e-09
I0315 01:25:09.363754 29479 solver.cpp:613] Iteration 14820, avg_grad_norm = 568371
I0315 01:25:34.968598 29479 solver.cpp:214] Iteration 14840, loss = 7383.96
I0315 01:25:34.968655 29479 solver.cpp:229]     Train net output #0: loss = 7992.26 (* 1 = 7992.26 loss)
I0315 01:25:35.083309 29479 solver.cpp:610] Iteration 14840, lr = 9.32965e-09
I0315 01:25:35.083323 29479 solver.cpp:613] Iteration 14840, avg_grad_norm = 696363
I0315 01:26:13.117419 29479 solver.cpp:214] Iteration 14860, loss = 7001.97
I0315 01:26:13.117630 29479 solver.cpp:229]     Train net output #0: loss = 4968.11 (* 1 = 4968.11 loss)
I0315 01:26:13.222751 29479 solver.cpp:610] Iteration 14860, lr = 9.32875e-09
I0315 01:26:13.222765 29479 solver.cpp:613] Iteration 14860, avg_grad_norm = 641081
I0315 01:26:36.664703 29479 solver.cpp:214] Iteration 14880, loss = 6989.01
I0315 01:26:36.664767 29479 solver.cpp:229]     Train net output #0: loss = 4869.79 (* 1 = 4869.79 loss)
I0315 01:26:36.769876 29479 solver.cpp:610] Iteration 14880, lr = 9.32784e-09
I0315 01:26:36.769889 29479 solver.cpp:613] Iteration 14880, avg_grad_norm = 669516
I0315 01:27:01.958112 29479 solver.cpp:214] Iteration 14900, loss = 6982.8
I0315 01:27:01.958266 29479 solver.cpp:229]     Train net output #0: loss = 10435 (* 1 = 10435 loss)
I0315 01:27:02.074079 29479 solver.cpp:610] Iteration 14900, lr = 9.32693e-09
I0315 01:27:02.074092 29479 solver.cpp:613] Iteration 14900, avg_grad_norm = 592999
I0315 01:27:27.745285 29479 solver.cpp:214] Iteration 14920, loss = 7191.01
I0315 01:27:27.745329 29479 solver.cpp:229]     Train net output #0: loss = 7668.76 (* 1 = 7668.76 loss)
I0315 01:27:27.859930 29479 solver.cpp:610] Iteration 14920, lr = 9.32602e-09
I0315 01:27:27.859944 29479 solver.cpp:613] Iteration 14920, avg_grad_norm = 672403
I0315 01:27:53.157968 29479 solver.cpp:214] Iteration 14940, loss = 7098.44
I0315 01:27:53.158110 29479 solver.cpp:229]     Train net output #0: loss = 4197.63 (* 1 = 4197.63 loss)
I0315 01:27:53.270861 29479 solver.cpp:610] Iteration 14940, lr = 9.32512e-09
I0315 01:27:53.270875 29479 solver.cpp:613] Iteration 14940, avg_grad_norm = 688829
I0315 01:28:18.635345 29479 solver.cpp:214] Iteration 14960, loss = 7693.01
I0315 01:28:18.635398 29479 solver.cpp:229]     Train net output #0: loss = 6047.57 (* 1 = 6047.57 loss)
I0315 01:28:18.749970 29479 solver.cpp:610] Iteration 14960, lr = 9.32421e-09
I0315 01:28:18.749985 29479 solver.cpp:613] Iteration 14960, avg_grad_norm = 682804
I0315 01:28:44.340031 29479 solver.cpp:214] Iteration 14980, loss = 7002.55
I0315 01:28:44.340134 29479 solver.cpp:229]     Train net output #0: loss = 9836.36 (* 1 = 9836.36 loss)
I0315 01:28:44.454602 29479 solver.cpp:610] Iteration 14980, lr = 9.3233e-09
I0315 01:28:44.454617 29479 solver.cpp:613] Iteration 14980, avg_grad_norm = 601044
I0315 01:29:21.322624 29479 solver.cpp:214] Iteration 15000, loss = 7200.93
I0315 01:29:21.322738 29479 solver.cpp:229]     Train net output #0: loss = 5736.44 (* 1 = 5736.44 loss)
I0315 01:29:21.427906 29479 solver.cpp:610] Iteration 15000, lr = 9.3224e-09
I0315 01:29:21.427919 29479 solver.cpp:613] Iteration 15000, avg_grad_norm = 611742
I0315 01:29:45.978051 29479 solver.cpp:214] Iteration 15020, loss = 7268.63
I0315 01:29:45.978119 29479 solver.cpp:229]     Train net output #0: loss = 5727.33 (* 1 = 5727.33 loss)
I0315 01:29:46.094115 29479 solver.cpp:610] Iteration 15020, lr = 9.32149e-09
I0315 01:29:46.094128 29479 solver.cpp:613] Iteration 15020, avg_grad_norm = 618637
I0315 01:30:11.872388 29479 solver.cpp:214] Iteration 15040, loss = 7158.01
I0315 01:30:11.872510 29479 solver.cpp:229]     Train net output #0: loss = 5009.08 (* 1 = 5009.08 loss)
I0315 01:30:11.987006 29479 solver.cpp:610] Iteration 15040, lr = 9.32058e-09
I0315 01:30:11.987020 29479 solver.cpp:613] Iteration 15040, avg_grad_norm = 624888
I0315 01:30:37.322078 29479 solver.cpp:214] Iteration 15060, loss = 7143.48
I0315 01:30:37.322135 29479 solver.cpp:229]     Train net output #0: loss = 9888.37 (* 1 = 9888.37 loss)
I0315 01:30:37.435205 29479 solver.cpp:610] Iteration 15060, lr = 9.31967e-09
I0315 01:30:37.435220 29479 solver.cpp:613] Iteration 15060, avg_grad_norm = 664840
I0315 01:31:02.902801 29479 solver.cpp:214] Iteration 15080, loss = 7177.85
I0315 01:31:02.902946 29479 solver.cpp:229]     Train net output #0: loss = 12534 (* 1 = 12534 loss)
I0315 01:31:03.017699 29479 solver.cpp:610] Iteration 15080, lr = 9.31877e-09
I0315 01:31:03.017711 29479 solver.cpp:613] Iteration 15080, avg_grad_norm = 641286
I0315 01:31:28.622938 29479 solver.cpp:214] Iteration 15100, loss = 7188.27
I0315 01:31:28.622987 29479 solver.cpp:229]     Train net output #0: loss = 6288.33 (* 1 = 6288.33 loss)
I0315 01:31:28.737524 29479 solver.cpp:610] Iteration 15100, lr = 9.31786e-09
I0315 01:31:28.737536 29479 solver.cpp:613] Iteration 15100, avg_grad_norm = 746609
I0315 01:32:09.059155 29479 solver.cpp:214] Iteration 15120, loss = 6919.71
I0315 01:32:09.059315 29479 solver.cpp:229]     Train net output #0: loss = 6336.06 (* 1 = 6336.06 loss)
I0315 01:32:09.163202 29479 solver.cpp:610] Iteration 15120, lr = 9.31695e-09
I0315 01:32:09.163214 29479 solver.cpp:613] Iteration 15120, avg_grad_norm = 628181
I0315 01:32:32.667703 29479 solver.cpp:214] Iteration 15140, loss = 7280.51
I0315 01:32:32.667760 29479 solver.cpp:229]     Train net output #0: loss = 6148.17 (* 1 = 6148.17 loss)
I0315 01:32:32.773643 29479 solver.cpp:610] Iteration 15140, lr = 9.31605e-09
I0315 01:32:32.773656 29479 solver.cpp:613] Iteration 15140, avg_grad_norm = 573961
I0315 01:32:58.219496 29479 solver.cpp:214] Iteration 15160, loss = 7445.32
I0315 01:32:58.219642 29479 solver.cpp:229]     Train net output #0: loss = 9893.96 (* 1 = 9893.96 loss)
I0315 01:32:58.334146 29479 solver.cpp:610] Iteration 15160, lr = 9.31514e-09
I0315 01:32:58.334158 29479 solver.cpp:613] Iteration 15160, avg_grad_norm = 589712
I0315 01:33:23.923214 29479 solver.cpp:214] Iteration 15180, loss = 7171.83
I0315 01:33:23.923274 29479 solver.cpp:229]     Train net output #0: loss = 9042.49 (* 1 = 9042.49 loss)
I0315 01:33:24.037744 29479 solver.cpp:610] Iteration 15180, lr = 9.31423e-09
I0315 01:33:24.037757 29479 solver.cpp:613] Iteration 15180, avg_grad_norm = 926309
I0315 01:33:49.636968 29479 solver.cpp:214] Iteration 15200, loss = 7328.95
I0315 01:33:49.637233 29479 solver.cpp:229]     Train net output #0: loss = 2846.84 (* 1 = 2846.84 loss)
I0315 01:33:49.751914 29479 solver.cpp:610] Iteration 15200, lr = 9.31333e-09
I0315 01:33:49.751927 29479 solver.cpp:613] Iteration 15200, avg_grad_norm = 815288
I0315 01:34:15.326458 29479 solver.cpp:214] Iteration 15220, loss = 7151.47
I0315 01:34:15.326520 29479 solver.cpp:229]     Train net output #0: loss = 9919.38 (* 1 = 9919.38 loss)
I0315 01:34:15.441037 29479 solver.cpp:610] Iteration 15220, lr = 9.31242e-09
I0315 01:34:15.441052 29479 solver.cpp:613] Iteration 15220, avg_grad_norm = 645408
I0315 01:35:19.749349 29479 solver.cpp:214] Iteration 15240, loss = 7107.19
I0315 01:35:19.749517 29479 solver.cpp:229]     Train net output #0: loss = 3560.27 (* 1 = 3560.27 loss)
I0315 01:35:19.854482 29479 solver.cpp:610] Iteration 15240, lr = 9.31151e-09
I0315 01:35:19.854517 29479 solver.cpp:613] Iteration 15240, avg_grad_norm = 584144
I0315 01:35:43.236955 29479 solver.cpp:214] Iteration 15260, loss = 7127.63
I0315 01:35:43.237020 29479 solver.cpp:229]     Train net output #0: loss = 10348.3 (* 1 = 10348.3 loss)
I0315 01:35:43.342252 29479 solver.cpp:610] Iteration 15260, lr = 9.3106e-09
I0315 01:35:43.342265 29479 solver.cpp:613] Iteration 15260, avg_grad_norm = 579163
I0315 01:36:06.766235 29479 solver.cpp:214] Iteration 15280, loss = 7303.87
I0315 01:36:06.766371 29479 solver.cpp:229]     Train net output #0: loss = 7832.63 (* 1 = 7832.63 loss)
I0315 01:36:06.870782 29479 solver.cpp:610] Iteration 15280, lr = 9.3097e-09
I0315 01:36:06.870795 29479 solver.cpp:613] Iteration 15280, avg_grad_norm = 597835
I0315 01:36:30.436626 29479 solver.cpp:214] Iteration 15300, loss = 7247.56
I0315 01:36:30.436689 29479 solver.cpp:229]     Train net output #0: loss = 12295.9 (* 1 = 12295.9 loss)
I0315 01:36:30.548303 29479 solver.cpp:610] Iteration 15300, lr = 9.30879e-09
I0315 01:36:30.548316 29479 solver.cpp:613] Iteration 15300, avg_grad_norm = 608507
I0315 01:36:55.523990 29479 solver.cpp:214] Iteration 15320, loss = 7585.47
I0315 01:36:55.524114 29479 solver.cpp:229]     Train net output #0: loss = 6946.81 (* 1 = 6946.81 loss)
I0315 01:36:55.635598 29479 solver.cpp:610] Iteration 15320, lr = 9.30788e-09
I0315 01:36:55.635612 29479 solver.cpp:613] Iteration 15320, avg_grad_norm = 648571
I0315 01:37:21.042511 29479 solver.cpp:214] Iteration 15340, loss = 7474.6
I0315 01:37:21.042567 29479 solver.cpp:229]     Train net output #0: loss = 6205.23 (* 1 = 6205.23 loss)
I0315 01:37:21.157323 29479 solver.cpp:610] Iteration 15340, lr = 9.30698e-09
I0315 01:37:21.157337 29479 solver.cpp:613] Iteration 15340, avg_grad_norm = 742189
I0315 01:37:46.618046 29479 solver.cpp:214] Iteration 15360, loss = 7240.42
I0315 01:37:46.618232 29479 solver.cpp:229]     Train net output #0: loss = 5048.54 (* 1 = 5048.54 loss)
I0315 01:37:46.731153 29479 solver.cpp:610] Iteration 15360, lr = 9.30607e-09
I0315 01:37:46.731166 29479 solver.cpp:613] Iteration 15360, avg_grad_norm = 606223
I0315 01:38:23.622216 29479 solver.cpp:214] Iteration 15380, loss = 7327.82
I0315 01:38:23.622354 29479 solver.cpp:229]     Train net output #0: loss = 6581.33 (* 1 = 6581.33 loss)
I0315 01:38:23.726665 29479 solver.cpp:610] Iteration 15380, lr = 9.30516e-09
I0315 01:38:23.726678 29479 solver.cpp:613] Iteration 15380, avg_grad_norm = 629761
I0315 01:38:47.931061 29479 solver.cpp:214] Iteration 15400, loss = 7351.29
I0315 01:38:47.931123 29479 solver.cpp:229]     Train net output #0: loss = 5838.93 (* 1 = 5838.93 loss)
I0315 01:38:48.044028 29479 solver.cpp:610] Iteration 15400, lr = 9.30425e-09
I0315 01:38:48.044044 29479 solver.cpp:613] Iteration 15400, avg_grad_norm = 622526
I0315 01:39:13.501127 29479 solver.cpp:214] Iteration 15420, loss = 7040.5
I0315 01:39:13.501226 29479 solver.cpp:229]     Train net output #0: loss = 6687.08 (* 1 = 6687.08 loss)
I0315 01:39:13.615921 29479 solver.cpp:610] Iteration 15420, lr = 9.30335e-09
I0315 01:39:13.615936 29479 solver.cpp:613] Iteration 15420, avg_grad_norm = 585674
I0315 01:39:39.209235 29479 solver.cpp:214] Iteration 15440, loss = 7270.96
I0315 01:39:39.209285 29479 solver.cpp:229]     Train net output #0: loss = 4214.7 (* 1 = 4214.7 loss)
I0315 01:39:39.323720 29479 solver.cpp:610] Iteration 15440, lr = 9.30244e-09
I0315 01:39:39.323734 29479 solver.cpp:613] Iteration 15440, avg_grad_norm = 603880
I0315 01:40:04.775411 29479 solver.cpp:214] Iteration 15460, loss = 7297.68
I0315 01:40:04.775540 29479 solver.cpp:229]     Train net output #0: loss = 9657.04 (* 1 = 9657.04 loss)
I0315 01:40:04.888452 29479 solver.cpp:610] Iteration 15460, lr = 9.30153e-09
I0315 01:40:04.888473 29479 solver.cpp:613] Iteration 15460, avg_grad_norm = 576348
I0315 01:40:30.190668 29479 solver.cpp:214] Iteration 15480, loss = 6920.78
I0315 01:40:30.190717 29479 solver.cpp:229]     Train net output #0: loss = 11253 (* 1 = 11253 loss)
I0315 01:40:30.303583 29479 solver.cpp:610] Iteration 15480, lr = 9.30062e-09
I0315 01:40:30.303596 29479 solver.cpp:613] Iteration 15480, avg_grad_norm = 571467
I0315 01:41:07.885500 29479 solver.cpp:214] Iteration 15500, loss = 7301.76
I0315 01:41:07.885607 29479 solver.cpp:229]     Train net output #0: loss = 5570.6 (* 1 = 5570.6 loss)
I0315 01:41:07.989162 29479 solver.cpp:610] Iteration 15500, lr = 9.29972e-09
I0315 01:41:07.989176 29479 solver.cpp:613] Iteration 15500, avg_grad_norm = 626559
I0315 01:41:31.694370 29479 solver.cpp:214] Iteration 15520, loss = 7016.28
I0315 01:41:31.694437 29479 solver.cpp:229]     Train net output #0: loss = 5071.1 (* 1 = 5071.1 loss)
I0315 01:41:31.809142 29479 solver.cpp:610] Iteration 15520, lr = 9.29881e-09
I0315 01:41:31.809157 29479 solver.cpp:613] Iteration 15520, avg_grad_norm = 570662
I0315 01:41:57.413313 29479 solver.cpp:214] Iteration 15540, loss = 6953.71
I0315 01:41:57.413435 29479 solver.cpp:229]     Train net output #0: loss = 5034.57 (* 1 = 5034.57 loss)
I0315 01:41:57.527909 29479 solver.cpp:610] Iteration 15540, lr = 9.2979e-09
I0315 01:41:57.527922 29479 solver.cpp:613] Iteration 15540, avg_grad_norm = 649734
I0315 01:42:23.118752 29479 solver.cpp:214] Iteration 15560, loss = 7296.79
I0315 01:42:23.118813 29479 solver.cpp:229]     Train net output #0: loss = 13824.9 (* 1 = 13824.9 loss)
I0315 01:42:23.231935 29479 solver.cpp:610] Iteration 15560, lr = 9.297e-09
I0315 01:42:23.231947 29479 solver.cpp:613] Iteration 15560, avg_grad_norm = 621153
I0315 01:42:48.510107 29479 solver.cpp:214] Iteration 15580, loss = 7272.94
I0315 01:42:48.510229 29479 solver.cpp:229]     Train net output #0: loss = 3947.39 (* 1 = 3947.39 loss)
I0315 01:42:48.623041 29479 solver.cpp:610] Iteration 15580, lr = 9.29609e-09
I0315 01:42:48.623056 29479 solver.cpp:613] Iteration 15580, avg_grad_norm = 622501
I0315 01:43:14.200897 29479 solver.cpp:214] Iteration 15600, loss = 7397.72
I0315 01:43:14.200944 29479 solver.cpp:229]     Train net output #0: loss = 8760.67 (* 1 = 8760.67 loss)
I0315 01:43:14.315495 29479 solver.cpp:610] Iteration 15600, lr = 9.29518e-09
I0315 01:43:14.315508 29479 solver.cpp:613] Iteration 15600, avg_grad_norm = 626847
I0315 01:43:52.496654 29479 solver.cpp:214] Iteration 15620, loss = 7174.74
I0315 01:43:52.496847 29479 solver.cpp:229]     Train net output #0: loss = 5614.56 (* 1 = 5614.56 loss)
I0315 01:43:52.601912 29479 solver.cpp:610] Iteration 15620, lr = 9.29427e-09
I0315 01:43:52.601925 29479 solver.cpp:613] Iteration 15620, avg_grad_norm = 687889
I0315 01:44:16.122277 29479 solver.cpp:214] Iteration 15640, loss = 7415.55
I0315 01:44:16.122334 29479 solver.cpp:229]     Train net output #0: loss = 5752.63 (* 1 = 5752.63 loss)
I0315 01:44:16.227432 29479 solver.cpp:610] Iteration 15640, lr = 9.29337e-09
I0315 01:44:16.227445 29479 solver.cpp:613] Iteration 15640, avg_grad_norm = 696104
I0315 01:44:41.027952 29479 solver.cpp:214] Iteration 15660, loss = 7045.29
I0315 01:44:41.028095 29479 solver.cpp:229]     Train net output #0: loss = 6607.97 (* 1 = 6607.97 loss)
I0315 01:44:41.142498 29479 solver.cpp:610] Iteration 15660, lr = 9.29246e-09
I0315 01:44:41.142510 29479 solver.cpp:613] Iteration 15660, avg_grad_norm = 594116
I0315 01:45:06.794795 29479 solver.cpp:214] Iteration 15680, loss = 7332.61
I0315 01:45:06.794848 29479 solver.cpp:229]     Train net output #0: loss = 5139.77 (* 1 = 5139.77 loss)
I0315 01:45:06.909402 29479 solver.cpp:610] Iteration 15680, lr = 9.29155e-09
I0315 01:45:06.909438 29479 solver.cpp:613] Iteration 15680, avg_grad_norm = 631939
I0315 01:45:32.554836 29479 solver.cpp:214] Iteration 15700, loss = 6969.24
I0315 01:45:32.555052 29479 solver.cpp:229]     Train net output #0: loss = 6894.84 (* 1 = 6894.84 loss)
I0315 01:45:32.669400 29479 solver.cpp:610] Iteration 15700, lr = 9.29064e-09
I0315 01:45:32.669414 29479 solver.cpp:613] Iteration 15700, avg_grad_norm = 588852
I0315 01:45:58.228803 29479 solver.cpp:214] Iteration 15720, loss = 7261.86
I0315 01:45:58.228850 29479 solver.cpp:229]     Train net output #0: loss = 8414.87 (* 1 = 8414.87 loss)
I0315 01:45:58.343451 29479 solver.cpp:610] Iteration 15720, lr = 9.28974e-09
I0315 01:45:58.343463 29479 solver.cpp:613] Iteration 15720, avg_grad_norm = 638455
I0315 01:46:23.916136 29479 solver.cpp:214] Iteration 15740, loss = 7149.34
I0315 01:46:23.916355 29479 solver.cpp:229]     Train net output #0: loss = 4040.42 (* 1 = 4040.42 loss)
I0315 01:46:24.030784 29479 solver.cpp:610] Iteration 15740, lr = 9.28883e-09
I0315 01:46:24.030797 29479 solver.cpp:613] Iteration 15740, avg_grad_norm = 713995
I0315 01:47:05.202860 29479 solver.cpp:214] Iteration 15760, loss = 7576
I0315 01:47:05.202999 29479 solver.cpp:229]     Train net output #0: loss = 5650.03 (* 1 = 5650.03 loss)
I0315 01:47:05.307317 29479 solver.cpp:610] Iteration 15760, lr = 9.28792e-09
I0315 01:47:05.307334 29479 solver.cpp:613] Iteration 15760, avg_grad_norm = 755035
I0315 01:47:28.854192 29479 solver.cpp:214] Iteration 15780, loss = 7125.58
I0315 01:47:28.854254 29479 solver.cpp:229]     Train net output #0: loss = 6613.12 (* 1 = 6613.12 loss)
I0315 01:47:28.966459 29479 solver.cpp:610] Iteration 15780, lr = 9.28701e-09
I0315 01:47:28.966476 29479 solver.cpp:613] Iteration 15780, avg_grad_norm = 675542
I0315 01:47:54.607432 29479 solver.cpp:214] Iteration 15800, loss = 6869.38
I0315 01:47:54.607569 29479 solver.cpp:229]     Train net output #0: loss = 7360.37 (* 1 = 7360.37 loss)
I0315 01:47:54.722148 29479 solver.cpp:610] Iteration 15800, lr = 9.28611e-09
I0315 01:47:54.722163 29479 solver.cpp:613] Iteration 15800, avg_grad_norm = 734977
I0315 01:48:20.309126 29479 solver.cpp:214] Iteration 15820, loss = 7162.55
I0315 01:48:20.309180 29479 solver.cpp:229]     Train net output #0: loss = 6285.76 (* 1 = 6285.76 loss)
I0315 01:48:20.423961 29479 solver.cpp:610] Iteration 15820, lr = 9.2852e-09
I0315 01:48:20.423977 29479 solver.cpp:613] Iteration 15820, avg_grad_norm = 651166
I0315 01:48:45.933073 29479 solver.cpp:214] Iteration 15840, loss = 7109.17
I0315 01:48:45.933326 29479 solver.cpp:229]     Train net output #0: loss = 4211.49 (* 1 = 4211.49 loss)
I0315 01:48:46.046217 29479 solver.cpp:610] Iteration 15840, lr = 9.28429e-09
I0315 01:48:46.046232 29479 solver.cpp:613] Iteration 15840, avg_grad_norm = 558092
I0315 01:49:11.356851 29479 solver.cpp:214] Iteration 15860, loss = 7004.77
I0315 01:49:11.356922 29479 solver.cpp:229]     Train net output #0: loss = 5150.24 (* 1 = 5150.24 loss)
I0315 01:49:11.471499 29479 solver.cpp:610] Iteration 15860, lr = 9.28338e-09
I0315 01:49:11.471513 29479 solver.cpp:613] Iteration 15860, avg_grad_norm = 580539
I0315 01:49:49.558521 29479 solver.cpp:214] Iteration 15880, loss = 7240.22
I0315 01:49:49.558660 29479 solver.cpp:229]     Train net output #0: loss = 8160.84 (* 1 = 8160.84 loss)
I0315 01:49:49.663813 29479 solver.cpp:610] Iteration 15880, lr = 9.28248e-09
I0315 01:49:49.663826 29479 solver.cpp:613] Iteration 15880, avg_grad_norm = 686678
I0315 01:50:13.268033 29479 solver.cpp:214] Iteration 15900, loss = 7204.08
I0315 01:50:13.268092 29479 solver.cpp:229]     Train net output #0: loss = 6619.47 (* 1 = 6619.47 loss)
I0315 01:50:13.381170 29479 solver.cpp:610] Iteration 15900, lr = 9.28157e-09
I0315 01:50:13.381183 29479 solver.cpp:613] Iteration 15900, avg_grad_norm = 635996
I0315 01:50:39.111106 29479 solver.cpp:214] Iteration 15920, loss = 7284.28
I0315 01:50:39.111238 29479 solver.cpp:229]     Train net output #0: loss = 7764.36 (* 1 = 7764.36 loss)
I0315 01:50:39.227161 29479 solver.cpp:610] Iteration 15920, lr = 9.28066e-09
I0315 01:50:39.227174 29479 solver.cpp:613] Iteration 15920, avg_grad_norm = 543774
I0315 01:51:04.715410 29479 solver.cpp:214] Iteration 15940, loss = 7467.26
I0315 01:51:04.715457 29479 solver.cpp:229]     Train net output #0: loss = 10394 (* 1 = 10394 loss)
I0315 01:51:04.828284 29479 solver.cpp:610] Iteration 15940, lr = 9.27975e-09
I0315 01:51:04.828296 29479 solver.cpp:613] Iteration 15940, avg_grad_norm = 720237
I0315 01:51:30.257722 29479 solver.cpp:214] Iteration 15960, loss = 7152.62
I0315 01:51:30.257840 29479 solver.cpp:229]     Train net output #0: loss = 6524.04 (* 1 = 6524.04 loss)
I0315 01:51:30.372242 29479 solver.cpp:610] Iteration 15960, lr = 9.27885e-09
I0315 01:51:30.372256 29479 solver.cpp:613] Iteration 15960, avg_grad_norm = 703833
I0315 01:51:55.973600 29479 solver.cpp:214] Iteration 15980, loss = 7277.46
I0315 01:51:55.973661 29479 solver.cpp:229]     Train net output #0: loss = 7086.84 (* 1 = 7086.84 loss)
I0315 01:51:56.088234 29479 solver.cpp:610] Iteration 15980, lr = 9.27794e-09
I0315 01:51:56.088248 29479 solver.cpp:613] Iteration 15980, avg_grad_norm = 715264
I0315 01:52:21.694295 29479 solver.cpp:214] Iteration 16000, loss = 7113.97
I0315 01:52:21.694432 29479 solver.cpp:229]     Train net output #0: loss = 5504.48 (* 1 = 5504.48 loss)
I0315 01:52:21.808845 29479 solver.cpp:610] Iteration 16000, lr = 9.27703e-09
I0315 01:52:21.808859 29479 solver.cpp:613] Iteration 16000, avg_grad_norm = 679194
I0315 01:52:59.580971 29479 solver.cpp:214] Iteration 16020, loss = 6987.63
I0315 01:52:59.581140 29479 solver.cpp:229]     Train net output #0: loss = 6731.46 (* 1 = 6731.46 loss)
I0315 01:52:59.686064 29479 solver.cpp:610] Iteration 16020, lr = 9.27612e-09
I0315 01:52:59.686076 29479 solver.cpp:613] Iteration 16020, avg_grad_norm = 629441
I0315 01:53:24.398375 29479 solver.cpp:214] Iteration 16040, loss = 7123.46
I0315 01:53:24.398444 29479 solver.cpp:229]     Train net output #0: loss = 6651.85 (* 1 = 6651.85 loss)
I0315 01:53:24.513015 29479 solver.cpp:610] Iteration 16040, lr = 9.27522e-09
I0315 01:53:24.513028 29479 solver.cpp:613] Iteration 16040, avg_grad_norm = 634203
I0315 01:53:50.047086 29479 solver.cpp:214] Iteration 16060, loss = 6890.93
I0315 01:53:50.047257 29479 solver.cpp:229]     Train net output #0: loss = 4200.18 (* 1 = 4200.18 loss)
I0315 01:53:50.161769 29479 solver.cpp:610] Iteration 16060, lr = 9.27431e-09
I0315 01:53:50.161782 29479 solver.cpp:613] Iteration 16060, avg_grad_norm = 638712
I0315 01:54:15.718623 29479 solver.cpp:214] Iteration 16080, loss = 6822.5
I0315 01:54:15.718683 29479 solver.cpp:229]     Train net output #0: loss = 8394.1 (* 1 = 8394.1 loss)
I0315 01:54:15.833134 29479 solver.cpp:610] Iteration 16080, lr = 9.2734e-09
I0315 01:54:15.833148 29479 solver.cpp:613] Iteration 16080, avg_grad_norm = 605127
I0315 01:54:41.427824 29479 solver.cpp:214] Iteration 16100, loss = 6969.76
I0315 01:54:41.428082 29479 solver.cpp:229]     Train net output #0: loss = 10402.3 (* 1 = 10402.3 loss)
I0315 01:54:41.542560 29479 solver.cpp:610] Iteration 16100, lr = 9.27249e-09
I0315 01:54:41.542574 29479 solver.cpp:613] Iteration 16100, avg_grad_norm = 612264
I0315 01:55:07.169404 29479 solver.cpp:214] Iteration 16120, loss = 7235.04
I0315 01:55:07.169512 29479 solver.cpp:229]     Train net output #0: loss = 10585.7 (* 1 = 10585.7 loss)
I0315 01:55:07.284168 29479 solver.cpp:610] Iteration 16120, lr = 9.27159e-09
I0315 01:55:07.284241 29479 solver.cpp:613] Iteration 16120, avg_grad_norm = 643160
I0315 01:55:48.942050 29479 solver.cpp:214] Iteration 16140, loss = 7181.22
I0315 01:55:48.942206 29479 solver.cpp:229]     Train net output #0: loss = 4351.79 (* 1 = 4351.79 loss)
I0315 01:55:49.047106 29479 solver.cpp:610] Iteration 16140, lr = 9.27068e-09
I0315 01:55:49.047119 29479 solver.cpp:613] Iteration 16140, avg_grad_norm = 673908
I0315 01:56:12.498805 29479 solver.cpp:214] Iteration 16160, loss = 7203.96
I0315 01:56:12.498901 29479 solver.cpp:229]     Train net output #0: loss = 7712.58 (* 1 = 7712.58 loss)
I0315 01:56:12.606379 29479 solver.cpp:610] Iteration 16160, lr = 9.26977e-09
I0315 01:56:12.606391 29479 solver.cpp:613] Iteration 16160, avg_grad_norm = 635220
I0315 01:56:38.040305 29479 solver.cpp:214] Iteration 16180, loss = 7198.55
I0315 01:56:38.040441 29479 solver.cpp:229]     Train net output #0: loss = 8797.11 (* 1 = 8797.11 loss)
I0315 01:56:38.155212 29479 solver.cpp:610] Iteration 16180, lr = 9.26886e-09
I0315 01:56:38.155226 29479 solver.cpp:613] Iteration 16180, avg_grad_norm = 688002
I0315 01:57:03.760526 29479 solver.cpp:214] Iteration 16200, loss = 7167.01
I0315 01:57:03.760607 29479 solver.cpp:229]     Train net output #0: loss = 6745.97 (* 1 = 6745.97 loss)
I0315 01:57:03.875128 29479 solver.cpp:610] Iteration 16200, lr = 9.26796e-09
I0315 01:57:03.875140 29479 solver.cpp:613] Iteration 16200, avg_grad_norm = 623018
I0315 01:57:29.481827 29479 solver.cpp:214] Iteration 16220, loss = 7159.15
I0315 01:57:29.481927 29479 solver.cpp:229]     Train net output #0: loss = 7898.85 (* 1 = 7898.85 loss)
I0315 01:57:29.596524 29479 solver.cpp:610] Iteration 16220, lr = 9.26705e-09
I0315 01:57:29.596539 29479 solver.cpp:613] Iteration 16220, avg_grad_norm = 567747
I0315 01:57:54.978443 29479 solver.cpp:214] Iteration 16240, loss = 7201.92
I0315 01:57:54.978492 29479 solver.cpp:229]     Train net output #0: loss = 5695.35 (* 1 = 5695.35 loss)
I0315 01:57:55.091564 29479 solver.cpp:610] Iteration 16240, lr = 9.26614e-09
I0315 01:57:55.091578 29479 solver.cpp:613] Iteration 16240, avg_grad_norm = 538072
I0315 01:58:32.754456 29479 solver.cpp:214] Iteration 16260, loss = 7099.21
I0315 01:58:32.754595 29479 solver.cpp:229]     Train net output #0: loss = 5786.2 (* 1 = 5786.2 loss)
I0315 01:58:32.858654 29479 solver.cpp:610] Iteration 16260, lr = 9.26523e-09
I0315 01:58:32.858666 29479 solver.cpp:613] Iteration 16260, avg_grad_norm = 541501
I0315 01:58:56.384997 29479 solver.cpp:214] Iteration 16280, loss = 6941.73
I0315 01:58:56.385083 29479 solver.cpp:229]     Train net output #0: loss = 7964.53 (* 1 = 7964.53 loss)
I0315 01:58:56.496541 29479 solver.cpp:610] Iteration 16280, lr = 9.26433e-09
I0315 01:58:56.496554 29479 solver.cpp:613] Iteration 16280, avg_grad_norm = 661259
I0315 01:59:21.932128 29479 solver.cpp:214] Iteration 16300, loss = 7231.48
I0315 01:59:21.932271 29479 solver.cpp:229]     Train net output #0: loss = 8254.61 (* 1 = 8254.61 loss)
I0315 01:59:22.046855 29479 solver.cpp:610] Iteration 16300, lr = 9.26342e-09
I0315 01:59:22.046870 29479 solver.cpp:613] Iteration 16300, avg_grad_norm = 640051
I0315 01:59:47.648623 29479 solver.cpp:214] Iteration 16320, loss = 7320.6
I0315 01:59:47.648694 29479 solver.cpp:229]     Train net output #0: loss = 6217.76 (* 1 = 6217.76 loss)
I0315 01:59:47.763525 29479 solver.cpp:610] Iteration 16320, lr = 9.26251e-09
I0315 01:59:47.763538 29479 solver.cpp:613] Iteration 16320, avg_grad_norm = 611914
I0315 02:00:13.386847 29479 solver.cpp:214] Iteration 16340, loss = 7111.44
I0315 02:00:13.387018 29479 solver.cpp:229]     Train net output #0: loss = 5363.58 (* 1 = 5363.58 loss)
I0315 02:00:13.501507 29479 solver.cpp:610] Iteration 16340, lr = 9.2616e-09
I0315 02:00:13.501519 29479 solver.cpp:613] Iteration 16340, avg_grad_norm = 596041
I0315 02:00:39.091236 29479 solver.cpp:214] Iteration 16360, loss = 6823.63
I0315 02:00:39.091298 29479 solver.cpp:229]     Train net output #0: loss = 6036.81 (* 1 = 6036.81 loss)
I0315 02:00:39.205698 29479 solver.cpp:610] Iteration 16360, lr = 9.26069e-09
I0315 02:00:39.205713 29479 solver.cpp:613] Iteration 16360, avg_grad_norm = 547350
I0315 02:01:04.813598 29479 solver.cpp:214] Iteration 16380, loss = 6774.69
I0315 02:01:04.813825 29479 solver.cpp:229]     Train net output #0: loss = 7899.87 (* 1 = 7899.87 loss)
I0315 02:01:04.928463 29479 solver.cpp:610] Iteration 16380, lr = 9.25979e-09
I0315 02:01:04.928479 29479 solver.cpp:613] Iteration 16380, avg_grad_norm = 612059
I0315 02:01:43.886493 29479 solver.cpp:214] Iteration 16400, loss = 6895.73
I0315 02:01:43.886636 29479 solver.cpp:229]     Train net output #0: loss = 5769.3 (* 1 = 5769.3 loss)
I0315 02:01:43.991796 29479 solver.cpp:610] Iteration 16400, lr = 9.25888e-09
I0315 02:01:43.991811 29479 solver.cpp:613] Iteration 16400, avg_grad_norm = 557976
I0315 02:02:08.463340 29479 solver.cpp:214] Iteration 16420, loss = 7066.57
I0315 02:02:08.463402 29479 solver.cpp:229]     Train net output #0: loss = 6924.84 (* 1 = 6924.84 loss)
I0315 02:02:08.578251 29479 solver.cpp:610] Iteration 16420, lr = 9.25797e-09
I0315 02:02:08.578292 29479 solver.cpp:613] Iteration 16420, avg_grad_norm = 674356
I0315 02:02:34.160799 29479 solver.cpp:214] Iteration 16440, loss = 6900.22
I0315 02:02:34.160928 29479 solver.cpp:229]     Train net output #0: loss = 5495.78 (* 1 = 5495.78 loss)
I0315 02:02:34.275492 29479 solver.cpp:610] Iteration 16440, lr = 9.25706e-09
I0315 02:02:34.275506 29479 solver.cpp:613] Iteration 16440, avg_grad_norm = 674141
I0315 02:02:59.883433 29479 solver.cpp:214] Iteration 16460, loss = 6907.62
I0315 02:02:59.883498 29479 solver.cpp:229]     Train net output #0: loss = 10118.5 (* 1 = 10118.5 loss)
I0315 02:02:59.998083 29479 solver.cpp:610] Iteration 16460, lr = 9.25616e-09
I0315 02:02:59.998097 29479 solver.cpp:613] Iteration 16460, avg_grad_norm = 663958
I0315 02:03:25.605540 29479 solver.cpp:214] Iteration 16480, loss = 6984.32
I0315 02:03:25.605655 29479 solver.cpp:229]     Train net output #0: loss = 7171.61 (* 1 = 7171.61 loss)
I0315 02:03:25.720124 29479 solver.cpp:610] Iteration 16480, lr = 9.25525e-09
I0315 02:03:25.720137 29479 solver.cpp:613] Iteration 16480, avg_grad_norm = 635789
I0315 02:03:51.325381 29479 solver.cpp:214] Iteration 16500, loss = 6895.17
I0315 02:03:51.325425 29479 solver.cpp:229]     Train net output #0: loss = 8244.64 (* 1 = 8244.64 loss)
I0315 02:03:51.440006 29479 solver.cpp:610] Iteration 16500, lr = 9.25434e-09
I0315 02:03:51.440019 29479 solver.cpp:613] Iteration 16500, avg_grad_norm = 669903
I0315 02:04:28.578428 29479 solver.cpp:214] Iteration 16520, loss = 7115.9
I0315 02:04:28.578557 29479 solver.cpp:229]     Train net output #0: loss = 4963.81 (* 1 = 4963.81 loss)
I0315 02:04:28.683686 29479 solver.cpp:610] Iteration 16520, lr = 9.25343e-09
I0315 02:04:28.683699 29479 solver.cpp:613] Iteration 16520, avg_grad_norm = 680091
I0315 02:04:52.616813 29479 solver.cpp:214] Iteration 16540, loss = 7100.48
I0315 02:04:52.616888 29479 solver.cpp:229]     Train net output #0: loss = 7175.42 (* 1 = 7175.42 loss)
I0315 02:04:52.729830 29479 solver.cpp:610] Iteration 16540, lr = 9.25252e-09
I0315 02:04:52.729868 29479 solver.cpp:613] Iteration 16540, avg_grad_norm = 744321
I0315 02:05:18.403237 29479 solver.cpp:214] Iteration 16560, loss = 6798.32
I0315 02:05:18.403391 29479 solver.cpp:229]     Train net output #0: loss = 3218.93 (* 1 = 3218.93 loss)
I0315 02:05:18.519578 29479 solver.cpp:610] Iteration 16560, lr = 9.25162e-09
I0315 02:05:18.519592 29479 solver.cpp:613] Iteration 16560, avg_grad_norm = 611341
I0315 02:05:43.983285 29479 solver.cpp:214] Iteration 16580, loss = 7260.05
I0315 02:05:43.983341 29479 solver.cpp:229]     Train net output #0: loss = 9471.53 (* 1 = 9471.53 loss)
I0315 02:05:44.096283 29479 solver.cpp:610] Iteration 16580, lr = 9.25071e-09
I0315 02:05:44.096297 29479 solver.cpp:613] Iteration 16580, avg_grad_norm = 587828
I0315 02:06:09.404287 29479 solver.cpp:214] Iteration 16600, loss = 6694.48
I0315 02:06:09.404475 29479 solver.cpp:229]     Train net output #0: loss = 9174.09 (* 1 = 9174.09 loss)
I0315 02:06:09.519127 29479 solver.cpp:610] Iteration 16600, lr = 9.2498e-09
I0315 02:06:09.519140 29479 solver.cpp:613] Iteration 16600, avg_grad_norm = 599304
I0315 02:06:35.120442 29479 solver.cpp:214] Iteration 16620, loss = 7051.29
I0315 02:06:35.120506 29479 solver.cpp:229]     Train net output #0: loss = 5134.07 (* 1 = 5134.07 loss)
I0315 02:06:35.235076 29479 solver.cpp:610] Iteration 16620, lr = 9.24889e-09
I0315 02:06:35.235090 29479 solver.cpp:613] Iteration 16620, avg_grad_norm = 701622
I0315 02:07:12.999408 29479 solver.cpp:214] Iteration 16640, loss = 6869.55
I0315 02:07:12.999507 29479 solver.cpp:229]     Train net output #0: loss = 14286.7 (* 1 = 14286.7 loss)
I0315 02:07:13.104857 29479 solver.cpp:610] Iteration 16640, lr = 9.24799e-09
I0315 02:07:13.104871 29479 solver.cpp:613] Iteration 16640, avg_grad_norm = 849108
I0315 02:07:36.622298 29479 solver.cpp:214] Iteration 16660, loss = 7011.81
I0315 02:07:36.622350 29479 solver.cpp:229]     Train net output #0: loss = 3883.91 (* 1 = 3883.91 loss)
I0315 02:07:36.727351 29479 solver.cpp:610] Iteration 16660, lr = 9.24708e-09
I0315 02:07:36.727365 29479 solver.cpp:613] Iteration 16660, avg_grad_norm = 640962
I0315 02:08:02.269213 29479 solver.cpp:214] Iteration 16680, loss = 7298.55
I0315 02:08:02.269331 29479 solver.cpp:229]     Train net output #0: loss = 5198.83 (* 1 = 5198.83 loss)
I0315 02:08:02.385512 29479 solver.cpp:610] Iteration 16680, lr = 9.24617e-09
I0315 02:08:02.385525 29479 solver.cpp:613] Iteration 16680, avg_grad_norm = 598499
I0315 02:08:27.880210 29479 solver.cpp:214] Iteration 16700, loss = 6911.64
I0315 02:08:27.880277 29479 solver.cpp:229]     Train net output #0: loss = 5998.73 (* 1 = 5998.73 loss)
I0315 02:08:27.993265 29479 solver.cpp:610] Iteration 16700, lr = 9.24526e-09
I0315 02:08:27.993279 29479 solver.cpp:613] Iteration 16700, avg_grad_norm = 550662
I0315 02:08:53.359278 29479 solver.cpp:214] Iteration 16720, loss = 6788.18
I0315 02:08:53.359390 29479 solver.cpp:229]     Train net output #0: loss = 4811.51 (* 1 = 4811.51 loss)
I0315 02:08:53.473863 29479 solver.cpp:610] Iteration 16720, lr = 9.24435e-09
I0315 02:08:53.473876 29479 solver.cpp:613] Iteration 16720, avg_grad_norm = 565174
I0315 02:09:19.080369 29479 solver.cpp:214] Iteration 16740, loss = 7417.48
I0315 02:09:19.080422 29479 solver.cpp:229]     Train net output #0: loss = 9108.15 (* 1 = 9108.15 loss)
I0315 02:09:19.194933 29479 solver.cpp:610] Iteration 16740, lr = 9.24345e-09
I0315 02:09:19.194947 29479 solver.cpp:613] Iteration 16740, avg_grad_norm = 674396
I0315 02:09:44.801635 29479 solver.cpp:214] Iteration 16760, loss = 7098.63
I0315 02:09:44.801765 29479 solver.cpp:229]     Train net output #0: loss = 8948.98 (* 1 = 8948.98 loss)
I0315 02:09:44.916321 29479 solver.cpp:610] Iteration 16760, lr = 9.24254e-09
I0315 02:09:44.916373 29479 solver.cpp:613] Iteration 16760, avg_grad_norm = 733968
I0315 02:10:39.562393 29479 solver.cpp:214] Iteration 16780, loss = 7125.67
I0315 02:10:39.562510 29479 solver.cpp:229]     Train net output #0: loss = 7380.11 (* 1 = 7380.11 loss)
I0315 02:10:39.667619 29479 solver.cpp:610] Iteration 16780, lr = 9.24163e-09
I0315 02:10:39.667634 29479 solver.cpp:613] Iteration 16780, avg_grad_norm = 753586
I0315 02:11:03.104336 29479 solver.cpp:214] Iteration 16800, loss = 7069.4
I0315 02:11:03.104408 29479 solver.cpp:229]     Train net output #0: loss = 4099.39 (* 1 = 4099.39 loss)
I0315 02:11:03.209611 29479 solver.cpp:610] Iteration 16800, lr = 9.24072e-09
I0315 02:11:03.209625 29479 solver.cpp:613] Iteration 16800, avg_grad_norm = 605326
I0315 02:11:27.301512 29479 solver.cpp:214] Iteration 16820, loss = 6988.14
I0315 02:11:27.301676 29479 solver.cpp:229]     Train net output #0: loss = 5635.32 (* 1 = 5635.32 loss)
I0315 02:11:27.414460 29479 solver.cpp:610] Iteration 16820, lr = 9.23981e-09
I0315 02:11:27.414472 29479 solver.cpp:613] Iteration 16820, avg_grad_norm = 646688
I0315 02:11:52.616904 29479 solver.cpp:214] Iteration 16840, loss = 7105.45
I0315 02:11:52.616982 29479 solver.cpp:229]     Train net output #0: loss = 12243.8 (* 1 = 12243.8 loss)
I0315 02:11:52.730087 29479 solver.cpp:610] Iteration 16840, lr = 9.23891e-09
I0315 02:11:52.730100 29479 solver.cpp:613] Iteration 16840, avg_grad_norm = 601820
I0315 02:12:18.100529 29479 solver.cpp:214] Iteration 16860, loss = 6978.16
I0315 02:12:18.100656 29479 solver.cpp:229]     Train net output #0: loss = 3891.14 (* 1 = 3891.14 loss)
I0315 02:12:18.215014 29479 solver.cpp:610] Iteration 16860, lr = 9.238e-09
I0315 02:12:18.215028 29479 solver.cpp:613] Iteration 16860, avg_grad_norm = 610933
I0315 02:12:43.778233 29479 solver.cpp:214] Iteration 16880, loss = 6911.98
I0315 02:12:43.778300 29479 solver.cpp:229]     Train net output #0: loss = 4464.22 (* 1 = 4464.22 loss)
I0315 02:12:43.892865 29479 solver.cpp:610] Iteration 16880, lr = 9.23709e-09
I0315 02:12:43.892879 29479 solver.cpp:613] Iteration 16880, avg_grad_norm = 626809
I0315 02:13:21.328178 29479 solver.cpp:214] Iteration 16900, loss = 7243.99
I0315 02:13:21.328279 29479 solver.cpp:229]     Train net output #0: loss = 13273.8 (* 1 = 13273.8 loss)
I0315 02:13:21.433581 29479 solver.cpp:610] Iteration 16900, lr = 9.23618e-09
I0315 02:13:21.433594 29479 solver.cpp:613] Iteration 16900, avg_grad_norm = 634478
I0315 02:13:45.173574 29479 solver.cpp:214] Iteration 16920, loss = 7018.07
I0315 02:13:45.173640 29479 solver.cpp:229]     Train net output #0: loss = 6240.52 (* 1 = 6240.52 loss)
I0315 02:13:45.288383 29479 solver.cpp:610] Iteration 16920, lr = 9.23527e-09
I0315 02:13:45.288396 29479 solver.cpp:613] Iteration 16920, avg_grad_norm = 642822
I0315 02:14:10.878571 29479 solver.cpp:214] Iteration 16940, loss = 7210.92
I0315 02:14:10.878787 29479 solver.cpp:229]     Train net output #0: loss = 8197.89 (* 1 = 8197.89 loss)
I0315 02:14:10.993432 29479 solver.cpp:610] Iteration 16940, lr = 9.23437e-09
I0315 02:14:10.993445 29479 solver.cpp:613] Iteration 16940, avg_grad_norm = 682344
I0315 02:14:36.454162 29479 solver.cpp:214] Iteration 16960, loss = 7284.4
I0315 02:14:36.454233 29479 solver.cpp:229]     Train net output #0: loss = 9657.19 (* 1 = 9657.19 loss)
I0315 02:14:36.567152 29479 solver.cpp:610] Iteration 16960, lr = 9.23346e-09
I0315 02:14:36.567165 29479 solver.cpp:613] Iteration 16960, avg_grad_norm = 633676
I0315 02:15:01.815924 29479 solver.cpp:214] Iteration 16980, loss = 7250.56
I0315 02:15:01.816110 29479 solver.cpp:229]     Train net output #0: loss = 7694.19 (* 1 = 7694.19 loss)
I0315 02:15:01.929090 29479 solver.cpp:610] Iteration 16980, lr = 9.23255e-09
I0315 02:15:01.929105 29479 solver.cpp:613] Iteration 16980, avg_grad_norm = 681650
I0315 02:15:27.499225 29479 solver.cpp:214] Iteration 17000, loss = 7021.46
I0315 02:15:27.499292 29479 solver.cpp:229]     Train net output #0: loss = 5831.18 (* 1 = 5831.18 loss)
I0315 02:15:27.615146 29479 solver.cpp:610] Iteration 17000, lr = 9.23164e-09
I0315 02:15:27.615160 29479 solver.cpp:613] Iteration 17000, avg_grad_norm = 564426
I0315 02:16:14.782110 29479 solver.cpp:214] Iteration 17020, loss = 7363.66
I0315 02:16:14.782223 29479 solver.cpp:229]     Train net output #0: loss = 9562 (* 1 = 9562 loss)
I0315 02:16:14.885946 29479 solver.cpp:610] Iteration 17020, lr = 9.23073e-09
I0315 02:16:14.885959 29479 solver.cpp:613] Iteration 17020, avg_grad_norm = 720712
I0315 02:16:38.289284 29479 solver.cpp:214] Iteration 17040, loss = 6753.44
I0315 02:16:38.289353 29479 solver.cpp:229]     Train net output #0: loss = 6879.66 (* 1 = 6879.66 loss)
I0315 02:16:38.394649 29479 solver.cpp:610] Iteration 17040, lr = 9.22983e-09
I0315 02:16:38.394662 29479 solver.cpp:613] Iteration 17040, avg_grad_norm = 674104
I0315 02:17:02.199533 29479 solver.cpp:214] Iteration 17060, loss = 6967.47
I0315 02:17:02.199743 29479 solver.cpp:229]     Train net output #0: loss = 7022.5 (* 1 = 7022.5 loss)
I0315 02:17:02.312537 29479 solver.cpp:610] Iteration 17060, lr = 9.22892e-09
I0315 02:17:02.312551 29479 solver.cpp:613] Iteration 17060, avg_grad_norm = 706982
I0315 02:17:27.731871 29479 solver.cpp:214] Iteration 17080, loss = 7050.19
I0315 02:17:27.731940 29479 solver.cpp:229]     Train net output #0: loss = 6770.4 (* 1 = 6770.4 loss)
I0315 02:17:27.846541 29479 solver.cpp:610] Iteration 17080, lr = 9.22801e-09
I0315 02:17:27.846554 29479 solver.cpp:613] Iteration 17080, avg_grad_norm = 609216
I0315 02:17:53.389951 29479 solver.cpp:214] Iteration 17100, loss = 7270.63
I0315 02:17:53.390089 29479 solver.cpp:229]     Train net output #0: loss = 6621.64 (* 1 = 6621.64 loss)
I0315 02:17:53.504405 29479 solver.cpp:610] Iteration 17100, lr = 9.2271e-09
I0315 02:17:53.504418 29479 solver.cpp:613] Iteration 17100, avg_grad_norm = 570098
I0315 02:18:18.756237 29479 solver.cpp:214] Iteration 17120, loss = 7365.41
I0315 02:18:18.756307 29479 solver.cpp:229]     Train net output #0: loss = 15069.5 (* 1 = 15069.5 loss)
I0315 02:18:18.867859 29479 solver.cpp:610] Iteration 17120, lr = 9.22619e-09
I0315 02:18:18.867872 29479 solver.cpp:613] Iteration 17120, avg_grad_norm = 641370
I0315 02:18:43.940459 29479 solver.cpp:214] Iteration 17140, loss = 6737.27
I0315 02:18:43.940620 29479 solver.cpp:229]     Train net output #0: loss = 4455.29 (* 1 = 4455.29 loss)
I0315 02:18:44.055089 29479 solver.cpp:610] Iteration 17140, lr = 9.22529e-09
I0315 02:18:44.055104 29479 solver.cpp:613] Iteration 17140, avg_grad_norm = 627323
I0315 02:19:20.574065 29479 solver.cpp:214] Iteration 17160, loss = 6839.62
I0315 02:19:20.574218 29479 solver.cpp:229]     Train net output #0: loss = 5870.68 (* 1 = 5870.68 loss)
I0315 02:19:20.679241 29479 solver.cpp:610] Iteration 17160, lr = 9.22438e-09
I0315 02:19:20.679255 29479 solver.cpp:613] Iteration 17160, avg_grad_norm = 582682
I0315 02:19:45.103597 29479 solver.cpp:214] Iteration 17180, loss = 6839.36
I0315 02:19:45.103648 29479 solver.cpp:229]     Train net output #0: loss = 10361.3 (* 1 = 10361.3 loss)
I0315 02:19:45.218313 29479 solver.cpp:610] Iteration 17180, lr = 9.22347e-09
I0315 02:19:45.218327 29479 solver.cpp:613] Iteration 17180, avg_grad_norm = 589436
I0315 02:20:10.778348 29479 solver.cpp:214] Iteration 17200, loss = 6832.52
I0315 02:20:10.778475 29479 solver.cpp:229]     Train net output #0: loss = 6532.51 (* 1 = 6532.51 loss)
I0315 02:20:10.892900 29479 solver.cpp:610] Iteration 17200, lr = 9.22256e-09
I0315 02:20:10.892913 29479 solver.cpp:613] Iteration 17200, avg_grad_norm = 581998
I0315 02:20:36.452280 29479 solver.cpp:214] Iteration 17220, loss = 7320.37
I0315 02:20:36.452334 29479 solver.cpp:229]     Train net output #0: loss = 8842.15 (* 1 = 8842.15 loss)
I0315 02:20:36.566794 29479 solver.cpp:610] Iteration 17220, lr = 9.22165e-09
I0315 02:20:36.566807 29479 solver.cpp:613] Iteration 17220, avg_grad_norm = 622227
I0315 02:21:02.130153 29479 solver.cpp:214] Iteration 17240, loss = 6924.78
I0315 02:21:02.130298 29479 solver.cpp:229]     Train net output #0: loss = 8374.86 (* 1 = 8374.86 loss)
I0315 02:21:02.244617 29479 solver.cpp:610] Iteration 17240, lr = 9.22075e-09
I0315 02:21:02.244631 29479 solver.cpp:613] Iteration 17240, avg_grad_norm = 607846
I0315 02:21:27.803669 29479 solver.cpp:214] Iteration 17260, loss = 7158.83
I0315 02:21:27.803730 29479 solver.cpp:229]     Train net output #0: loss = 5324.53 (* 1 = 5324.53 loss)
I0315 02:21:27.918349 29479 solver.cpp:610] Iteration 17260, lr = 9.21984e-09
I0315 02:21:27.918361 29479 solver.cpp:613] Iteration 17260, avg_grad_norm = 650625
I0315 02:22:05.508769 29479 solver.cpp:214] Iteration 17280, loss = 7274.5
I0315 02:22:05.508910 29479 solver.cpp:229]     Train net output #0: loss = 11824.7 (* 1 = 11824.7 loss)
I0315 02:22:05.614001 29479 solver.cpp:610] Iteration 17280, lr = 9.21893e-09
I0315 02:22:05.614014 29479 solver.cpp:613] Iteration 17280, avg_grad_norm = 608653
I0315 02:22:29.350081 29479 solver.cpp:214] Iteration 17300, loss = 6549.69
I0315 02:22:29.350144 29479 solver.cpp:229]     Train net output #0: loss = 7036.1 (* 1 = 7036.1 loss)
I0315 02:22:29.462976 29479 solver.cpp:610] Iteration 17300, lr = 9.21802e-09
I0315 02:22:29.462990 29479 solver.cpp:613] Iteration 17300, avg_grad_norm = 566744
I0315 02:22:54.904930 29479 solver.cpp:214] Iteration 17320, loss = 7054.26
I0315 02:22:54.905149 29479 solver.cpp:229]     Train net output #0: loss = 5700.94 (* 1 = 5700.94 loss)
I0315 02:22:55.019467 29479 solver.cpp:610] Iteration 17320, lr = 9.21711e-09
I0315 02:22:55.019480 29479 solver.cpp:613] Iteration 17320, avg_grad_norm = 554624
I0315 02:23:20.653293 29479 solver.cpp:214] Iteration 17340, loss = 7231.79
I0315 02:23:20.653374 29479 solver.cpp:229]     Train net output #0: loss = 10283 (* 1 = 10283 loss)
I0315 02:23:20.767882 29479 solver.cpp:610] Iteration 17340, lr = 9.2162e-09
I0315 02:23:20.767896 29479 solver.cpp:613] Iteration 17340, avg_grad_norm = 708624
I0315 02:23:46.327666 29479 solver.cpp:214] Iteration 17360, loss = 7285.34
I0315 02:23:46.327780 29479 solver.cpp:229]     Train net output #0: loss = 8057.73 (* 1 = 8057.73 loss)
I0315 02:23:46.442047 29479 solver.cpp:610] Iteration 17360, lr = 9.2153e-09
I0315 02:23:46.442060 29479 solver.cpp:613] Iteration 17360, avg_grad_norm = 594578
I0315 02:24:11.995522 29479 solver.cpp:214] Iteration 17380, loss = 6850.87
I0315 02:24:11.995585 29479 solver.cpp:229]     Train net output #0: loss = 4460.14 (* 1 = 4460.14 loss)
I0315 02:24:12.110153 29479 solver.cpp:610] Iteration 17380, lr = 9.21439e-09
I0315 02:24:12.110167 29479 solver.cpp:613] Iteration 17380, avg_grad_norm = 594483
I0315 02:25:01.131690 29479 solver.cpp:214] Iteration 17400, loss = 6941.44
I0315 02:25:01.131815 29479 solver.cpp:229]     Train net output #0: loss = 10557.1 (* 1 = 10557.1 loss)
I0315 02:25:01.235605 29479 solver.cpp:610] Iteration 17400, lr = 9.21348e-09
I0315 02:25:01.235620 29479 solver.cpp:613] Iteration 17400, avg_grad_norm = 597268
I0315 02:25:24.667114 29479 solver.cpp:214] Iteration 17420, loss = 7032.27
I0315 02:25:24.667181 29479 solver.cpp:229]     Train net output #0: loss = 6937.88 (* 1 = 6937.88 loss)
I0315 02:25:24.772280 29479 solver.cpp:610] Iteration 17420, lr = 9.21257e-09
I0315 02:25:24.772295 29479 solver.cpp:613] Iteration 17420, avg_grad_norm = 605096
I0315 02:25:48.378254 29479 solver.cpp:214] Iteration 17440, loss = 6640.64
I0315 02:25:48.378362 29479 solver.cpp:229]     Train net output #0: loss = 3034.96 (* 1 = 3034.96 loss)
I0315 02:25:48.489962 29479 solver.cpp:610] Iteration 17440, lr = 9.21166e-09
I0315 02:25:48.489975 29479 solver.cpp:613] Iteration 17440, avg_grad_norm = 556498
I0315 02:26:13.772236 29479 solver.cpp:214] Iteration 17460, loss = 7176.73
I0315 02:26:13.772302 29479 solver.cpp:229]     Train net output #0: loss = 7384.59 (* 1 = 7384.59 loss)
I0315 02:26:13.886855 29479 solver.cpp:610] Iteration 17460, lr = 9.21075e-09
I0315 02:26:13.886868 29479 solver.cpp:613] Iteration 17460, avg_grad_norm = 644292
I0315 02:26:39.428526 29479 solver.cpp:214] Iteration 17480, loss = 7098.93
I0315 02:26:39.428665 29479 solver.cpp:229]     Train net output #0: loss = 8393.38 (* 1 = 8393.38 loss)
I0315 02:26:39.543094 29479 solver.cpp:610] Iteration 17480, lr = 9.20985e-09
I0315 02:26:39.543107 29479 solver.cpp:613] Iteration 17480, avg_grad_norm = 575732
I0315 02:27:05.085176 29479 solver.cpp:214] Iteration 17500, loss = 6703.36
I0315 02:27:05.085242 29479 solver.cpp:229]     Train net output #0: loss = 4129.42 (* 1 = 4129.42 loss)
I0315 02:27:05.199623 29479 solver.cpp:610] Iteration 17500, lr = 9.20894e-09
I0315 02:27:05.199636 29479 solver.cpp:613] Iteration 17500, avg_grad_norm = 634237
I0315 02:27:30.742226 29479 solver.cpp:214] Iteration 17520, loss = 7095.56
I0315 02:27:30.742408 29479 solver.cpp:229]     Train net output #0: loss = 5429.24 (* 1 = 5429.24 loss)
I0315 02:27:30.856847 29479 solver.cpp:610] Iteration 17520, lr = 9.20803e-09
I0315 02:27:30.856859 29479 solver.cpp:613] Iteration 17520, avg_grad_norm = 611720
I0315 02:28:08.844862 29479 solver.cpp:214] Iteration 17540, loss = 7249.25
I0315 02:28:08.844995 29479 solver.cpp:229]     Train net output #0: loss = 5456.6 (* 1 = 5456.6 loss)
I0315 02:28:08.950040 29479 solver.cpp:610] Iteration 17540, lr = 9.20712e-09
I0315 02:28:08.950053 29479 solver.cpp:613] Iteration 17540, avg_grad_norm = 552204
I0315 02:28:33.093065 29479 solver.cpp:214] Iteration 17560, loss = 7217.98
I0315 02:28:33.093119 29479 solver.cpp:229]     Train net output #0: loss = 11458.5 (* 1 = 11458.5 loss)
I0315 02:28:33.207664 29479 solver.cpp:610] Iteration 17560, lr = 9.20621e-09
I0315 02:28:33.207679 29479 solver.cpp:613] Iteration 17560, avg_grad_norm = 662006
I0315 02:28:58.799320 29479 solver.cpp:214] Iteration 17580, loss = 7295.14
I0315 02:28:58.799530 29479 solver.cpp:229]     Train net output #0: loss = 6420.71 (* 1 = 6420.71 loss)
I0315 02:28:58.913951 29479 solver.cpp:610] Iteration 17580, lr = 9.20531e-09
I0315 02:28:58.913966 29479 solver.cpp:613] Iteration 17580, avg_grad_norm = 764880
I0315 02:29:24.524063 29479 solver.cpp:214] Iteration 17600, loss = 7244.11
I0315 02:29:24.524132 29479 solver.cpp:229]     Train net output #0: loss = 6431.38 (* 1 = 6431.38 loss)
I0315 02:29:24.638605 29479 solver.cpp:610] Iteration 17600, lr = 9.2044e-09
I0315 02:29:24.638619 29479 solver.cpp:613] Iteration 17600, avg_grad_norm = 634926
I0315 02:29:50.179486 29479 solver.cpp:214] Iteration 17620, loss = 6749.73
I0315 02:29:50.179636 29479 solver.cpp:229]     Train net output #0: loss = 5781.9 (* 1 = 5781.9 loss)
I0315 02:29:50.294155 29479 solver.cpp:610] Iteration 17620, lr = 9.20349e-09
I0315 02:29:50.294168 29479 solver.cpp:613] Iteration 17620, avg_grad_norm = 594692
I0315 02:30:15.840031 29479 solver.cpp:214] Iteration 17640, loss = 7207.95
I0315 02:30:15.840092 29479 solver.cpp:229]     Train net output #0: loss = 13101.6 (* 1 = 13101.6 loss)
I0315 02:30:15.954782 29479 solver.cpp:610] Iteration 17640, lr = 9.20258e-09
I0315 02:30:15.954797 29479 solver.cpp:613] Iteration 17640, avg_grad_norm = 547115
I0315 02:30:58.724575 29479 solver.cpp:214] Iteration 17660, loss = 6794.13
I0315 02:30:58.724719 29479 solver.cpp:229]     Train net output #0: loss = 8161.16 (* 1 = 8161.16 loss)
I0315 02:30:58.829841 29479 solver.cpp:610] Iteration 17660, lr = 9.20167e-09
I0315 02:30:58.829854 29479 solver.cpp:613] Iteration 17660, avg_grad_norm = 662038
I0315 02:31:22.349540 29479 solver.cpp:214] Iteration 17680, loss = 7016.86
I0315 02:31:22.349603 29479 solver.cpp:229]     Train net output #0: loss = 7814.22 (* 1 = 7814.22 loss)
I0315 02:31:22.454673 29479 solver.cpp:610] Iteration 17680, lr = 9.20076e-09
I0315 02:31:22.454686 29479 solver.cpp:613] Iteration 17680, avg_grad_norm = 739361
I0315 02:31:47.473924 29479 solver.cpp:214] Iteration 17700, loss = 7259.79
I0315 02:31:47.474045 29479 solver.cpp:229]     Train net output #0: loss = 6655 (* 1 = 6655 loss)
I0315 02:31:47.588367 29479 solver.cpp:610] Iteration 17700, lr = 9.19986e-09
I0315 02:31:47.588381 29479 solver.cpp:613] Iteration 17700, avg_grad_norm = 618583
I0315 02:32:13.157385 29479 solver.cpp:214] Iteration 17720, loss = 6963.46
I0315 02:32:13.157455 29479 solver.cpp:229]     Train net output #0: loss = 11185.2 (* 1 = 11185.2 loss)
I0315 02:32:13.271909 29479 solver.cpp:610] Iteration 17720, lr = 9.19895e-09
I0315 02:32:13.271922 29479 solver.cpp:613] Iteration 17720, avg_grad_norm = 626274
I0315 02:32:38.603821 29479 solver.cpp:214] Iteration 17740, loss = 6908.24
I0315 02:32:38.603955 29479 solver.cpp:229]     Train net output #0: loss = 5823.97 (* 1 = 5823.97 loss)
I0315 02:32:38.716843 29479 solver.cpp:610] Iteration 17740, lr = 9.19804e-09
I0315 02:32:38.716857 29479 solver.cpp:613] Iteration 17740, avg_grad_norm = 664018
I0315 02:33:04.126569 29479 solver.cpp:214] Iteration 17760, loss = 6763.54
I0315 02:33:04.126624 29479 solver.cpp:229]     Train net output #0: loss = 5827.53 (* 1 = 5827.53 loss)
I0315 02:33:04.241123 29479 solver.cpp:610] Iteration 17760, lr = 9.19713e-09
I0315 02:33:04.241137 29479 solver.cpp:613] Iteration 17760, avg_grad_norm = 562328
I0315 02:33:53.355849 29479 solver.cpp:214] Iteration 17780, loss = 7069.04
I0315 02:33:53.355978 29479 solver.cpp:229]     Train net output #0: loss = 5789.55 (* 1 = 5789.55 loss)
I0315 02:33:53.461035 29479 solver.cpp:610] Iteration 17780, lr = 9.19622e-09
I0315 02:33:53.461047 29479 solver.cpp:613] Iteration 17780, avg_grad_norm = 601437
I0315 02:34:16.873714 29479 solver.cpp:214] Iteration 17800, loss = 6624.71
I0315 02:34:16.873775 29479 solver.cpp:229]     Train net output #0: loss = 6613.12 (* 1 = 6613.12 loss)
I0315 02:34:16.979020 29479 solver.cpp:610] Iteration 17800, lr = 9.19531e-09
I0315 02:34:16.979034 29479 solver.cpp:613] Iteration 17800, avg_grad_norm = 532573
I0315 02:34:40.600160 29479 solver.cpp:214] Iteration 17820, loss = 6898.17
I0315 02:34:40.600311 29479 solver.cpp:229]     Train net output #0: loss = 5934.53 (* 1 = 5934.53 loss)
I0315 02:34:40.711757 29479 solver.cpp:610] Iteration 17820, lr = 9.19441e-09
I0315 02:34:40.711797 29479 solver.cpp:613] Iteration 17820, avg_grad_norm = 599956
I0315 02:35:06.271039 29479 solver.cpp:214] Iteration 17840, loss = 6900.34
I0315 02:35:06.271121 29479 solver.cpp:229]     Train net output #0: loss = 11259.6 (* 1 = 11259.6 loss)
I0315 02:35:06.385638 29479 solver.cpp:610] Iteration 17840, lr = 9.1935e-09
I0315 02:35:06.385651 29479 solver.cpp:613] Iteration 17840, avg_grad_norm = 581383
I0315 02:35:31.848248 29479 solver.cpp:214] Iteration 17860, loss = 6865.95
I0315 02:35:31.848363 29479 solver.cpp:229]     Train net output #0: loss = 5608.74 (* 1 = 5608.74 loss)
I0315 02:35:31.961366 29479 solver.cpp:610] Iteration 17860, lr = 9.19259e-09
I0315 02:35:31.961380 29479 solver.cpp:613] Iteration 17860, avg_grad_norm = 574677
I0315 02:35:57.246309 29479 solver.cpp:214] Iteration 17880, loss = 6823.51
I0315 02:35:57.246366 29479 solver.cpp:229]     Train net output #0: loss = 4897.43 (* 1 = 4897.43 loss)
I0315 02:35:57.359400 29479 solver.cpp:610] Iteration 17880, lr = 9.19168e-09
I0315 02:35:57.359413 29479 solver.cpp:613] Iteration 17880, avg_grad_norm = 572083
I0315 02:36:22.772817 29479 solver.cpp:214] Iteration 17900, loss = 6847.68
I0315 02:36:22.773011 29479 solver.cpp:229]     Train net output #0: loss = 6572.72 (* 1 = 6572.72 loss)
I0315 02:36:22.887431 29479 solver.cpp:610] Iteration 17900, lr = 9.19077e-09
I0315 02:36:22.887445 29479 solver.cpp:613] Iteration 17900, avg_grad_norm = 581071
I0315 02:36:59.812129 29479 solver.cpp:214] Iteration 17920, loss = 6798.64
I0315 02:36:59.812244 29479 solver.cpp:229]     Train net output #0: loss = 6533.82 (* 1 = 6533.82 loss)
I0315 02:36:59.916442 29479 solver.cpp:610] Iteration 17920, lr = 9.18986e-09
I0315 02:36:59.916455 29479 solver.cpp:613] Iteration 17920, avg_grad_norm = 608589
I0315 02:37:24.335707 29479 solver.cpp:214] Iteration 17940, loss = 6834.58
I0315 02:37:24.335753 29479 solver.cpp:229]     Train net output #0: loss = 5762.49 (* 1 = 5762.49 loss)
I0315 02:37:24.450215 29479 solver.cpp:610] Iteration 17940, lr = 9.18895e-09
I0315 02:37:24.450229 29479 solver.cpp:613] Iteration 17940, avg_grad_norm = 582918
I0315 02:37:50.044112 29479 solver.cpp:214] Iteration 17960, loss = 6901.01
I0315 02:37:50.044294 29479 solver.cpp:229]     Train net output #0: loss = 4296.63 (* 1 = 4296.63 loss)
I0315 02:37:50.158826 29479 solver.cpp:610] Iteration 17960, lr = 9.18805e-09
I0315 02:37:50.158839 29479 solver.cpp:613] Iteration 17960, avg_grad_norm = 620073
I0315 02:38:15.726027 29479 solver.cpp:214] Iteration 17980, loss = 6858
I0315 02:38:15.726083 29479 solver.cpp:229]     Train net output #0: loss = 5746.46 (* 1 = 5746.46 loss)
I0315 02:38:15.840629 29479 solver.cpp:610] Iteration 17980, lr = 9.18714e-09
I0315 02:38:15.840643 29479 solver.cpp:613] Iteration 17980, avg_grad_norm = 573441
I0315 02:38:41.292812 29479 solver.cpp:214] Iteration 18000, loss = 6940.67
I0315 02:38:41.293068 29479 solver.cpp:229]     Train net output #0: loss = 8733.19 (* 1 = 8733.19 loss)
I0315 02:38:41.405832 29479 solver.cpp:610] Iteration 18000, lr = 9.18623e-09
I0315 02:38:41.405845 29479 solver.cpp:613] Iteration 18000, avg_grad_norm = 533050
I0315 02:39:06.696661 29479 solver.cpp:214] Iteration 18020, loss = 7219.91
I0315 02:39:06.696705 29479 solver.cpp:229]     Train net output #0: loss = 8587.34 (* 1 = 8587.34 loss)
I0315 02:39:06.809746 29479 solver.cpp:610] Iteration 18020, lr = 9.18532e-09
I0315 02:39:06.809761 29479 solver.cpp:613] Iteration 18020, avg_grad_norm = 599511
I0315 02:39:46.955493 29479 solver.cpp:214] Iteration 18040, loss = 7003.17
I0315 02:39:46.955634 29479 solver.cpp:229]     Train net output #0: loss = 5337.07 (* 1 = 5337.07 loss)
I0315 02:39:47.059478 29479 solver.cpp:610] Iteration 18040, lr = 9.18441e-09
I0315 02:39:47.059515 29479 solver.cpp:613] Iteration 18040, avg_grad_norm = 599578
I0315 02:40:10.589869 29479 solver.cpp:214] Iteration 18060, loss = 6622.75
I0315 02:40:10.589915 29479 solver.cpp:229]     Train net output #0: loss = 6681.17 (* 1 = 6681.17 loss)
I0315 02:40:10.695022 29479 solver.cpp:610] Iteration 18060, lr = 9.1835e-09
I0315 02:40:10.695035 29479 solver.cpp:613] Iteration 18060, avg_grad_norm = 702214
I0315 02:40:36.091223 29479 solver.cpp:214] Iteration 18080, loss = 7457.71
I0315 02:40:36.091408 29479 solver.cpp:229]     Train net output #0: loss = 7214.92 (* 1 = 7214.92 loss)
I0315 02:40:36.205806 29479 solver.cpp:610] Iteration 18080, lr = 9.18259e-09
I0315 02:40:36.205818 29479 solver.cpp:613] Iteration 18080, avg_grad_norm = 684271
I0315 02:41:01.803779 29479 solver.cpp:214] Iteration 18100, loss = 7082.44
I0315 02:41:01.803838 29479 solver.cpp:229]     Train net output #0: loss = 6123.73 (* 1 = 6123.73 loss)
I0315 02:41:01.918303 29479 solver.cpp:610] Iteration 18100, lr = 9.18169e-09
I0315 02:41:01.918316 29479 solver.cpp:613] Iteration 18100, avg_grad_norm = 577168
I0315 02:41:27.514256 29479 solver.cpp:214] Iteration 18120, loss = 6648.83
I0315 02:41:27.514431 29479 solver.cpp:229]     Train net output #0: loss = 11460.4 (* 1 = 11460.4 loss)
I0315 02:41:27.629027 29479 solver.cpp:610] Iteration 18120, lr = 9.18078e-09
I0315 02:41:27.629040 29479 solver.cpp:613] Iteration 18120, avg_grad_norm = 645080
I0315 02:41:53.228689 29479 solver.cpp:214] Iteration 18140, loss = 7054.12
I0315 02:41:53.228763 29479 solver.cpp:229]     Train net output #0: loss = 5503.1 (* 1 = 5503.1 loss)
I0315 02:41:53.343194 29479 solver.cpp:610] Iteration 18140, lr = 9.17987e-09
I0315 02:41:53.343209 29479 solver.cpp:613] Iteration 18140, avg_grad_norm = 710631
I0315 02:42:31.428645 29479 solver.cpp:214] Iteration 18160, loss = 6809.48
I0315 02:42:31.428781 29479 solver.cpp:229]     Train net output #0: loss = 13045.8 (* 1 = 13045.8 loss)
I0315 02:42:31.533913 29479 solver.cpp:610] Iteration 18160, lr = 9.17896e-09
I0315 02:42:31.533926 29479 solver.cpp:613] Iteration 18160, avg_grad_norm = 571407
I0315 02:42:54.983310 29479 solver.cpp:214] Iteration 18180, loss = 7146.41
I0315 02:42:54.983400 29479 solver.cpp:229]     Train net output #0: loss = 10551.5 (* 1 = 10551.5 loss)
I0315 02:42:55.088486 29479 solver.cpp:610] Iteration 18180, lr = 9.17805e-09
I0315 02:42:55.088500 29479 solver.cpp:613] Iteration 18180, avg_grad_norm = 574864
I0315 02:43:19.883554 29479 solver.cpp:214] Iteration 18200, loss = 6818.99
I0315 02:43:19.883697 29479 solver.cpp:229]     Train net output #0: loss = 9725.33 (* 1 = 9725.33 loss)
I0315 02:43:19.998086 29479 solver.cpp:610] Iteration 18200, lr = 9.17714e-09
I0315 02:43:19.998100 29479 solver.cpp:613] Iteration 18200, avg_grad_norm = 609260
I0315 02:43:45.529788 29479 solver.cpp:214] Iteration 18220, loss = 6647.95
I0315 02:43:45.529876 29479 solver.cpp:229]     Train net output #0: loss = 6426.69 (* 1 = 6426.69 loss)
I0315 02:43:45.644222 29479 solver.cpp:610] Iteration 18220, lr = 9.17623e-09
I0315 02:43:45.644235 29479 solver.cpp:613] Iteration 18220, avg_grad_norm = 626336
I0315 02:44:11.209614 29479 solver.cpp:214] Iteration 18240, loss = 6684.79
I0315 02:44:11.209866 29479 solver.cpp:229]     Train net output #0: loss = 11567.9 (* 1 = 11567.9 loss)
I0315 02:44:11.324131 29479 solver.cpp:610] Iteration 18240, lr = 9.17533e-09
I0315 02:44:11.324144 29479 solver.cpp:613] Iteration 18240, avg_grad_norm = 635410
I0315 02:44:36.931782 29479 solver.cpp:214] Iteration 18260, loss = 6766.67
I0315 02:44:36.931869 29479 solver.cpp:229]     Train net output #0: loss = 4354.89 (* 1 = 4354.89 loss)
I0315 02:44:37.046535 29479 solver.cpp:610] Iteration 18260, lr = 9.17442e-09
I0315 02:44:37.046586 29479 solver.cpp:613] Iteration 18260, avg_grad_norm = 599014
I0315 02:45:02.554931 29479 solver.cpp:214] Iteration 18280, loss = 6810.46
I0315 02:45:02.555131 29479 solver.cpp:229]     Train net output #0: loss = 3945.18 (* 1 = 3945.18 loss)
I0315 02:45:02.668078 29479 solver.cpp:610] Iteration 18280, lr = 9.17351e-09
I0315 02:45:02.668092 29479 solver.cpp:613] Iteration 18280, avg_grad_norm = 629535
I0315 02:46:02.662776 29479 solver.cpp:214] Iteration 18300, loss = 6795.79
I0315 02:46:02.662943 29479 solver.cpp:229]     Train net output #0: loss = 7865.67 (* 1 = 7865.67 loss)
I0315 02:46:02.768043 29479 solver.cpp:610] Iteration 18300, lr = 9.1726e-09
I0315 02:46:02.768057 29479 solver.cpp:613] Iteration 18300, avg_grad_norm = 569742
I0315 02:46:26.165330 29479 solver.cpp:214] Iteration 18320, loss = 6890.51
I0315 02:46:26.165398 29479 solver.cpp:229]     Train net output #0: loss = 12675.9 (* 1 = 12675.9 loss)
I0315 02:46:26.270459 29479 solver.cpp:610] Iteration 18320, lr = 9.17169e-09
I0315 02:46:26.270473 29479 solver.cpp:613] Iteration 18320, avg_grad_norm = 708872
I0315 02:46:49.722636 29479 solver.cpp:214] Iteration 18340, loss = 6731.26
I0315 02:46:49.722751 29479 solver.cpp:229]     Train net output #0: loss = 4969.24 (* 1 = 4969.24 loss)
I0315 02:46:49.827853 29479 solver.cpp:610] Iteration 18340, lr = 9.17078e-09
I0315 02:46:49.827865 29479 solver.cpp:613] Iteration 18340, avg_grad_norm = 679695
I0315 02:47:14.595417 29479 solver.cpp:214] Iteration 18360, loss = 7095.83
I0315 02:47:14.595484 29479 solver.cpp:229]     Train net output #0: loss = 10725.1 (* 1 = 10725.1 loss)
I0315 02:47:14.708463 29479 solver.cpp:610] Iteration 18360, lr = 9.16987e-09
I0315 02:47:14.708475 29479 solver.cpp:613] Iteration 18360, avg_grad_norm = 762113
I0315 02:47:40.226557 29479 solver.cpp:214] Iteration 18380, loss = 6974.45
I0315 02:47:40.226706 29479 solver.cpp:229]     Train net output #0: loss = 7691.17 (* 1 = 7691.17 loss)
I0315 02:47:40.341166 29479 solver.cpp:610] Iteration 18380, lr = 9.16897e-09
I0315 02:47:40.341179 29479 solver.cpp:613] Iteration 18380, avg_grad_norm = 713354
I0315 02:48:05.903151 29479 solver.cpp:214] Iteration 18400, loss = 7218.14
I0315 02:48:05.903220 29479 solver.cpp:229]     Train net output #0: loss = 7040.48 (* 1 = 7040.48 loss)
I0315 02:48:06.017936 29479 solver.cpp:610] Iteration 18400, lr = 9.16806e-09
I0315 02:48:06.017949 29479 solver.cpp:613] Iteration 18400, avg_grad_norm = 615986
I0315 02:48:46.702373 29479 solver.cpp:214] Iteration 18420, loss = 6656.42
I0315 02:48:46.702513 29479 solver.cpp:229]     Train net output #0: loss = 3466.78 (* 1 = 3466.78 loss)
I0315 02:48:46.806272 29479 solver.cpp:610] Iteration 18420, lr = 9.16715e-09
I0315 02:48:46.806287 29479 solver.cpp:613] Iteration 18420, avg_grad_norm = 589675
I0315 02:49:10.323235 29479 solver.cpp:214] Iteration 18440, loss = 7144.52
I0315 02:49:10.323289 29479 solver.cpp:229]     Train net output #0: loss = 8308.48 (* 1 = 8308.48 loss)
I0315 02:49:10.427089 29479 solver.cpp:610] Iteration 18440, lr = 9.16624e-09
I0315 02:49:10.427103 29479 solver.cpp:613] Iteration 18440, avg_grad_norm = 695547
I0315 02:49:35.200615 29479 solver.cpp:214] Iteration 18460, loss = 6925.87
I0315 02:49:35.200752 29479 solver.cpp:229]     Train net output #0: loss = 5188.67 (* 1 = 5188.67 loss)
I0315 02:49:35.315170 29479 solver.cpp:610] Iteration 18460, lr = 9.16533e-09
I0315 02:49:35.315183 29479 solver.cpp:613] Iteration 18460, avg_grad_norm = 740980
I0315 02:50:00.919754 29479 solver.cpp:214] Iteration 18480, loss = 6835.62
I0315 02:50:00.919806 29479 solver.cpp:229]     Train net output #0: loss = 11821.4 (* 1 = 11821.4 loss)
I0315 02:50:01.034428 29479 solver.cpp:610] Iteration 18480, lr = 9.16442e-09
I0315 02:50:01.034441 29479 solver.cpp:613] Iteration 18480, avg_grad_norm = 594487
I0315 02:50:26.621990 29479 solver.cpp:214] Iteration 18500, loss = 7146.27
I0315 02:50:26.622146 29479 solver.cpp:229]     Train net output #0: loss = 4978.55 (* 1 = 4978.55 loss)
I0315 02:50:26.736549 29479 solver.cpp:610] Iteration 18500, lr = 9.16351e-09
I0315 02:50:26.736562 29479 solver.cpp:613] Iteration 18500, avg_grad_norm = 613989
I0315 02:50:51.937773 29479 solver.cpp:214] Iteration 18520, loss = 7138.43
I0315 02:50:51.937837 29479 solver.cpp:229]     Train net output #0: loss = 11230.9 (* 1 = 11230.9 loss)
I0315 02:50:52.050789 29479 solver.cpp:610] Iteration 18520, lr = 9.1626e-09
I0315 02:50:52.050802 29479 solver.cpp:613] Iteration 18520, avg_grad_norm = 529336
I0315 02:51:17.446656 29479 solver.cpp:214] Iteration 18540, loss = 6712.49
I0315 02:51:17.446786 29479 solver.cpp:229]     Train net output #0: loss = 6558.75 (* 1 = 6558.75 loss)
I0315 02:51:17.561295 29479 solver.cpp:610] Iteration 18540, lr = 9.16169e-09
I0315 02:51:17.561307 29479 solver.cpp:613] Iteration 18540, avg_grad_norm = 617483
I0315 02:51:53.674814 29479 solver.cpp:214] Iteration 18560, loss = 7294.97
I0315 02:51:53.674973 29479 solver.cpp:229]     Train net output #0: loss = 6917.29 (* 1 = 6917.29 loss)
I0315 02:51:53.779407 29479 solver.cpp:610] Iteration 18560, lr = 9.16079e-09
I0315 02:51:53.779419 29479 solver.cpp:613] Iteration 18560, avg_grad_norm = 632360
I0315 02:52:18.786336 29479 solver.cpp:214] Iteration 18580, loss = 6697.16
I0315 02:52:18.786406 29479 solver.cpp:229]     Train net output #0: loss = 3882.59 (* 1 = 3882.59 loss)
I0315 02:52:18.900974 29479 solver.cpp:610] Iteration 18580, lr = 9.15988e-09
I0315 02:52:18.900990 29479 solver.cpp:613] Iteration 18580, avg_grad_norm = 553423
I0315 02:52:44.443972 29479 solver.cpp:214] Iteration 18600, loss = 6951.56
I0315 02:52:44.444126 29479 solver.cpp:229]     Train net output #0: loss = 5739.41 (* 1 = 5739.41 loss)
I0315 02:52:44.558647 29479 solver.cpp:610] Iteration 18600, lr = 9.15897e-09
I0315 02:52:44.558661 29479 solver.cpp:613] Iteration 18600, avg_grad_norm = 577973
I0315 02:53:10.099309 29479 solver.cpp:214] Iteration 18620, loss = 7085.06
I0315 02:53:10.099375 29479 solver.cpp:229]     Train net output #0: loss = 6039.41 (* 1 = 6039.41 loss)
I0315 02:53:10.214022 29479 solver.cpp:610] Iteration 18620, lr = 9.15806e-09
I0315 02:53:10.214037 29479 solver.cpp:613] Iteration 18620, avg_grad_norm = 565359
I0315 02:53:35.753182 29479 solver.cpp:214] Iteration 18640, loss = 6891.04
I0315 02:53:35.760805 29479 solver.cpp:229]     Train net output #0: loss = 4454.94 (* 1 = 4454.94 loss)
I0315 02:53:35.867594 29479 solver.cpp:610] Iteration 18640, lr = 9.15715e-09
I0315 02:53:35.867609 29479 solver.cpp:613] Iteration 18640, avg_grad_norm = 541278
I0315 02:54:01.189463 29479 solver.cpp:214] Iteration 18660, loss = 6908.71
I0315 02:54:01.189532 29479 solver.cpp:229]     Train net output #0: loss = 8389.07 (* 1 = 8389.07 loss)
I0315 02:54:01.302319 29479 solver.cpp:610] Iteration 18660, lr = 9.15624e-09
I0315 02:54:01.302331 29479 solver.cpp:613] Iteration 18660, avg_grad_norm = 557372
I0315 02:54:46.356361 29479 solver.cpp:214] Iteration 18680, loss = 6832.96
I0315 02:54:46.356500 29479 solver.cpp:229]     Train net output #0: loss = 9156.47 (* 1 = 9156.47 loss)
I0315 02:54:46.461480 29479 solver.cpp:610] Iteration 18680, lr = 9.15533e-09
I0315 02:54:46.461493 29479 solver.cpp:613] Iteration 18680, avg_grad_norm = 576509
I0315 02:55:09.982620 29479 solver.cpp:214] Iteration 18700, loss = 6382.83
I0315 02:55:09.982691 29479 solver.cpp:229]     Train net output #0: loss = 3845.41 (* 1 = 3845.41 loss)
I0315 02:55:10.087908 29479 solver.cpp:610] Iteration 18700, lr = 9.15442e-09
I0315 02:55:10.087923 29479 solver.cpp:613] Iteration 18700, avg_grad_norm = 566935
I0315 02:55:35.083472 29479 solver.cpp:214] Iteration 18720, loss = 6850.66
I0315 02:55:35.083708 29479 solver.cpp:229]     Train net output #0: loss = 4252.67 (* 1 = 4252.67 loss)
I0315 02:55:35.198241 29479 solver.cpp:610] Iteration 18720, lr = 9.15352e-09
I0315 02:55:35.198254 29479 solver.cpp:613] Iteration 18720, avg_grad_norm = 580859
I0315 02:56:00.771978 29479 solver.cpp:214] Iteration 18740, loss = 6952.27
I0315 02:56:00.772044 29479 solver.cpp:229]     Train net output #0: loss = 4761.23 (* 1 = 4761.23 loss)
I0315 02:56:00.886641 29479 solver.cpp:610] Iteration 18740, lr = 9.15261e-09
I0315 02:56:00.886656 29479 solver.cpp:613] Iteration 18740, avg_grad_norm = 607341
I0315 02:56:26.230393 29479 solver.cpp:214] Iteration 18760, loss = 6970.79
I0315 02:56:26.230523 29479 solver.cpp:229]     Train net output #0: loss = 4099.23 (* 1 = 4099.23 loss)
I0315 02:56:26.343387 29479 solver.cpp:610] Iteration 18760, lr = 9.1517e-09
I0315 02:56:26.343401 29479 solver.cpp:613] Iteration 18760, avg_grad_norm = 657784
I0315 02:56:51.591692 29479 solver.cpp:214] Iteration 18780, loss = 6971.48
I0315 02:56:51.591758 29479 solver.cpp:229]     Train net output #0: loss = 9576.25 (* 1 = 9576.25 loss)
I0315 02:56:51.707762 29479 solver.cpp:610] Iteration 18780, lr = 9.15079e-09
I0315 02:56:51.707777 29479 solver.cpp:613] Iteration 18780, avg_grad_norm = 589001
I0315 02:57:30.878015 29479 solver.cpp:214] Iteration 18800, loss = 7108.02
I0315 02:57:30.878206 29479 solver.cpp:229]     Train net output #0: loss = 9958.21 (* 1 = 9958.21 loss)
I0315 02:57:30.983225 29479 solver.cpp:610] Iteration 18800, lr = 9.14988e-09
I0315 02:57:30.983239 29479 solver.cpp:613] Iteration 18800, avg_grad_norm = 595437
I0315 02:57:54.431404 29479 solver.cpp:214] Iteration 18820, loss = 6852.4
I0315 02:57:54.431470 29479 solver.cpp:229]     Train net output #0: loss = 6053.67 (* 1 = 6053.67 loss)
I0315 02:57:54.536767 29479 solver.cpp:610] Iteration 18820, lr = 9.14897e-09
I0315 02:57:54.536780 29479 solver.cpp:613] Iteration 18820, avg_grad_norm = 578782
I0315 02:58:19.777501 29479 solver.cpp:214] Iteration 18840, loss = 6973.82
I0315 02:58:19.777665 29479 solver.cpp:229]     Train net output #0: loss = 4995.92 (* 1 = 4995.92 loss)
I0315 02:58:19.892056 29479 solver.cpp:610] Iteration 18840, lr = 9.14806e-09
I0315 02:58:19.892071 29479 solver.cpp:613] Iteration 18840, avg_grad_norm = 557218
I0315 02:58:45.438577 29479 solver.cpp:214] Iteration 18860, loss = 6779.44
I0315 02:58:45.438642 29479 solver.cpp:229]     Train net output #0: loss = 3323.31 (* 1 = 3323.31 loss)
I0315 02:58:45.553221 29479 solver.cpp:610] Iteration 18860, lr = 9.14715e-09
I0315 02:58:45.553236 29479 solver.cpp:613] Iteration 18860, avg_grad_norm = 603202
I0315 02:59:11.049612 29479 solver.cpp:214] Iteration 18880, loss = 6966.64
I0315 02:59:11.049747 29479 solver.cpp:229]     Train net output #0: loss = 9707.76 (* 1 = 9707.76 loss)
I0315 02:59:11.162310 29479 solver.cpp:610] Iteration 18880, lr = 9.14624e-09
I0315 02:59:11.162325 29479 solver.cpp:613] Iteration 18880, avg_grad_norm = 623195
I0315 02:59:36.463297 29479 solver.cpp:214] Iteration 18900, loss = 6909.59
I0315 02:59:36.463364 29479 solver.cpp:229]     Train net output #0: loss = 11935 (* 1 = 11935 loss)
I0315 02:59:36.576194 29479 solver.cpp:610] Iteration 18900, lr = 9.14534e-09
I0315 02:59:36.576207 29479 solver.cpp:613] Iteration 18900, avg_grad_norm = 686126
I0315 03:00:01.987571 29479 solver.cpp:214] Iteration 18920, loss = 7040.97
I0315 03:00:01.987706 29479 solver.cpp:229]     Train net output #0: loss = 6419.56 (* 1 = 6419.56 loss)
I0315 03:00:02.102164 29479 solver.cpp:610] Iteration 18920, lr = 9.14443e-09
I0315 03:00:02.102179 29479 solver.cpp:613] Iteration 18920, avg_grad_norm = 679251
I0315 03:00:42.923403 29479 solver.cpp:214] Iteration 18940, loss = 6810.47
I0315 03:00:42.923504 29479 solver.cpp:229]     Train net output #0: loss = 5067.58 (* 1 = 5067.58 loss)
I0315 03:00:43.028545 29479 solver.cpp:610] Iteration 18940, lr = 9.14352e-09
I0315 03:00:43.028558 29479 solver.cpp:613] Iteration 18940, avg_grad_norm = 618117
I0315 03:01:07.071152 29479 solver.cpp:214] Iteration 18960, loss = 6679.42
I0315 03:01:07.071223 29479 solver.cpp:229]     Train net output #0: loss = 7017.37 (* 1 = 7017.37 loss)
I0315 03:01:07.185717 29479 solver.cpp:610] Iteration 18960, lr = 9.14261e-09
I0315 03:01:07.185731 29479 solver.cpp:613] Iteration 18960, avg_grad_norm = 618384
I0315 03:01:32.729982 29479 solver.cpp:214] Iteration 18980, loss = 6921.77
I0315 03:01:32.730144 29479 solver.cpp:229]     Train net output #0: loss = 5812.89 (* 1 = 5812.89 loss)
I0315 03:01:32.844789 29479 solver.cpp:610] Iteration 18980, lr = 9.1417e-09
I0315 03:01:32.844804 29479 solver.cpp:613] Iteration 18980, avg_grad_norm = 643528
I0315 03:01:58.408696 29479 solver.cpp:214] Iteration 19000, loss = 7322.48
I0315 03:01:58.408771 29479 solver.cpp:229]     Train net output #0: loss = 5430.59 (* 1 = 5430.59 loss)
I0315 03:01:58.523305 29479 solver.cpp:610] Iteration 19000, lr = 9.14079e-09
I0315 03:01:58.523320 29479 solver.cpp:613] Iteration 19000, avg_grad_norm = 537513
I0315 03:02:24.066884 29479 solver.cpp:214] Iteration 19020, loss = 6647.38
I0315 03:02:24.067034 29479 solver.cpp:229]     Train net output #0: loss = 4780.37 (* 1 = 4780.37 loss)
I0315 03:02:24.181501 29479 solver.cpp:610] Iteration 19020, lr = 9.13988e-09
I0315 03:02:24.181515 29479 solver.cpp:613] Iteration 19020, avg_grad_norm = 594449
I0315 03:02:49.518200 29479 solver.cpp:214] Iteration 19040, loss = 6918.19
I0315 03:02:49.518275 29479 solver.cpp:229]     Train net output #0: loss = 12821.3 (* 1 = 12821.3 loss)
I0315 03:02:49.631232 29479 solver.cpp:610] Iteration 19040, lr = 9.13897e-09
I0315 03:02:49.631247 29479 solver.cpp:613] Iteration 19040, avg_grad_norm = 582520
I0315 03:03:45.245724 29479 solver.cpp:214] Iteration 19060, loss = 7057.24
I0315 03:03:45.245944 29479 solver.cpp:229]     Train net output #0: loss = 6972.03 (* 1 = 6972.03 loss)
I0315 03:03:45.350867 29479 solver.cpp:610] Iteration 19060, lr = 9.13806e-09
I0315 03:03:45.350880 29479 solver.cpp:613] Iteration 19060, avg_grad_norm = 544553
I0315 03:04:08.773154 29479 solver.cpp:214] Iteration 19080, loss = 6689.55
I0315 03:04:08.773213 29479 solver.cpp:229]     Train net output #0: loss = 10509.5 (* 1 = 10509.5 loss)
I0315 03:04:08.878345 29479 solver.cpp:610] Iteration 19080, lr = 9.13715e-09
I0315 03:04:08.878357 29479 solver.cpp:613] Iteration 19080, avg_grad_norm = 612800
I0315 03:04:32.503187 29479 solver.cpp:214] Iteration 19100, loss = 6855.29
I0315 03:04:32.503331 29479 solver.cpp:229]     Train net output #0: loss = 6607.65 (* 1 = 6607.65 loss)
I0315 03:04:32.614789 29479 solver.cpp:610] Iteration 19100, lr = 9.13624e-09
I0315 03:04:32.614820 29479 solver.cpp:613] Iteration 19100, avg_grad_norm = 609295
I0315 03:04:57.821542 29479 solver.cpp:214] Iteration 19120, loss = 6912.93
I0315 03:04:57.821615 29479 solver.cpp:229]     Train net output #0: loss = 5349.93 (* 1 = 5349.93 loss)
I0315 03:04:57.936028 29479 solver.cpp:610] Iteration 19120, lr = 9.13534e-09
I0315 03:04:57.936041 29479 solver.cpp:613] Iteration 19120, avg_grad_norm = 554841
I0315 03:05:23.507766 29479 solver.cpp:214] Iteration 19140, loss = 6793.76
I0315 03:05:23.507967 29479 solver.cpp:229]     Train net output #0: loss = 5696.71 (* 1 = 5696.71 loss)
I0315 03:05:23.622352 29479 solver.cpp:610] Iteration 19140, lr = 9.13443e-09
I0315 03:05:23.622366 29479 solver.cpp:613] Iteration 19140, avg_grad_norm = 623171
I0315 03:05:48.931381 29479 solver.cpp:214] Iteration 19160, loss = 7101.44
I0315 03:05:48.931450 29479 solver.cpp:229]     Train net output #0: loss = 5700.76 (* 1 = 5700.76 loss)
I0315 03:05:49.044438 29479 solver.cpp:610] Iteration 19160, lr = 9.13352e-09
I0315 03:05:49.044452 29479 solver.cpp:613] Iteration 19160, avg_grad_norm = 612583
I0315 03:06:27.107996 29479 solver.cpp:214] Iteration 19180, loss = 6753.87
I0315 03:06:27.108105 29479 solver.cpp:229]     Train net output #0: loss = 8360 (* 1 = 8360 loss)
I0315 03:06:27.213215 29479 solver.cpp:610] Iteration 19180, lr = 9.13261e-09
I0315 03:06:27.213229 29479 solver.cpp:613] Iteration 19180, avg_grad_norm = 576262
I0315 03:06:50.724997 29479 solver.cpp:214] Iteration 19200, loss = 6879.47
I0315 03:06:50.725057 29479 solver.cpp:229]     Train net output #0: loss = 5462.12 (* 1 = 5462.12 loss)
I0315 03:06:50.829465 29479 solver.cpp:610] Iteration 19200, lr = 9.1317e-09
I0315 03:06:50.829478 29479 solver.cpp:613] Iteration 19200, avg_grad_norm = 572939
I0315 03:07:16.220584 29479 solver.cpp:214] Iteration 19220, loss = 6967.81
I0315 03:07:16.220783 29479 solver.cpp:229]     Train net output #0: loss = 2742.79 (* 1 = 2742.79 loss)
I0315 03:07:16.335289 29479 solver.cpp:610] Iteration 19220, lr = 9.13079e-09
I0315 03:07:16.335302 29479 solver.cpp:613] Iteration 19220, avg_grad_norm = 603438
I0315 03:07:41.937973 29479 solver.cpp:214] Iteration 19240, loss = 7123.27
I0315 03:07:41.938038 29479 solver.cpp:229]     Train net output #0: loss = 9813.02 (* 1 = 9813.02 loss)
I0315 03:07:42.052690 29479 solver.cpp:610] Iteration 19240, lr = 9.12988e-09
I0315 03:07:42.052703 29479 solver.cpp:613] Iteration 19240, avg_grad_norm = 727760
I0315 03:08:07.575861 29479 solver.cpp:214] Iteration 19260, loss = 6778.87
I0315 03:08:07.575975 29479 solver.cpp:229]     Train net output #0: loss = 2964.34 (* 1 = 2964.34 loss)
I0315 03:08:07.688786 29479 solver.cpp:610] Iteration 19260, lr = 9.12897e-09
I0315 03:08:07.688798 29479 solver.cpp:613] Iteration 19260, avg_grad_norm = 667367
I0315 03:08:32.969434 29479 solver.cpp:214] Iteration 19280, loss = 6897.54
I0315 03:08:32.969490 29479 solver.cpp:229]     Train net output #0: loss = 3091.46 (* 1 = 3091.46 loss)
I0315 03:08:33.082291 29479 solver.cpp:610] Iteration 19280, lr = 9.12806e-09
I0315 03:08:33.082304 29479 solver.cpp:613] Iteration 19280, avg_grad_norm = 599903
I0315 03:08:58.483544 29479 solver.cpp:214] Iteration 19300, loss = 7071.66
I0315 03:08:58.483671 29479 solver.cpp:229]     Train net output #0: loss = 5623.68 (* 1 = 5623.68 loss)
I0315 03:08:58.599479 29479 solver.cpp:610] Iteration 19300, lr = 9.12715e-09
I0315 03:08:58.599493 29479 solver.cpp:613] Iteration 19300, avg_grad_norm = 571300
I0315 03:09:35.049567 29479 solver.cpp:214] Iteration 19320, loss = 6687.02
I0315 03:09:35.049693 29479 solver.cpp:229]     Train net output #0: loss = 5219.5 (* 1 = 5219.5 loss)
I0315 03:09:35.154512 29479 solver.cpp:610] Iteration 19320, lr = 9.12624e-09
I0315 03:09:35.154526 29479 solver.cpp:613] Iteration 19320, avg_grad_norm = 565668
I0315 03:09:59.938284 29479 solver.cpp:214] Iteration 19340, loss = 6906.57
I0315 03:09:59.938349 29479 solver.cpp:229]     Train net output #0: loss = 5136.32 (* 1 = 5136.32 loss)
I0315 03:10:00.052870 29479 solver.cpp:610] Iteration 19340, lr = 9.12533e-09
I0315 03:10:00.052884 29479 solver.cpp:613] Iteration 19340, avg_grad_norm = 662791
I0315 03:10:25.661887 29479 solver.cpp:214] Iteration 19360, loss = 6879.77
I0315 03:10:25.662050 29479 solver.cpp:229]     Train net output #0: loss = 4637.11 (* 1 = 4637.11 loss)
I0315 03:10:25.776346 29479 solver.cpp:610] Iteration 19360, lr = 9.12443e-09
I0315 03:10:25.776360 29479 solver.cpp:613] Iteration 19360, avg_grad_norm = 595217
I0315 03:10:51.421157 29479 solver.cpp:214] Iteration 19380, loss = 6787.9
I0315 03:10:51.421223 29479 solver.cpp:229]     Train net output #0: loss = 5472.76 (* 1 = 5472.76 loss)
I0315 03:10:51.535858 29479 solver.cpp:610] Iteration 19380, lr = 9.12352e-09
I0315 03:10:51.535871 29479 solver.cpp:613] Iteration 19380, avg_grad_norm = 721205
I0315 03:11:16.990962 29479 solver.cpp:214] Iteration 19400, loss = 6932.59
I0315 03:11:16.991082 29479 solver.cpp:229]     Train net output #0: loss = 6587.62 (* 1 = 6587.62 loss)
I0315 03:11:17.103893 29479 solver.cpp:610] Iteration 19400, lr = 9.12261e-09
I0315 03:11:17.103906 29479 solver.cpp:613] Iteration 19400, avg_grad_norm = 574287
I0315 03:11:42.487195 29479 solver.cpp:214] Iteration 19420, loss = 6822.96
I0315 03:11:42.487253 29479 solver.cpp:229]     Train net output #0: loss = 5380.78 (* 1 = 5380.78 loss)
I0315 03:11:42.601747 29479 solver.cpp:610] Iteration 19420, lr = 9.1217e-09
I0315 03:11:42.601763 29479 solver.cpp:613] Iteration 19420, avg_grad_norm = 594181
I0315 03:12:20.299216 29479 solver.cpp:214] Iteration 19440, loss = 6821.5
I0315 03:12:20.299384 29479 solver.cpp:229]     Train net output #0: loss = 3104.98 (* 1 = 3104.98 loss)
I0315 03:12:20.403167 29479 solver.cpp:610] Iteration 19440, lr = 9.12079e-09
I0315 03:12:20.403182 29479 solver.cpp:613] Iteration 19440, avg_grad_norm = 583748
I0315 03:12:44.328691 29479 solver.cpp:214] Iteration 19460, loss = 6821.03
I0315 03:12:44.328763 29479 solver.cpp:229]     Train net output #0: loss = 3560.6 (* 1 = 3560.6 loss)
I0315 03:12:44.443331 29479 solver.cpp:610] Iteration 19460, lr = 9.11988e-09
I0315 03:12:44.443344 29479 solver.cpp:613] Iteration 19460, avg_grad_norm = 567732
I0315 03:13:10.009130 29479 solver.cpp:214] Iteration 19480, loss = 7062.09
I0315 03:13:10.009249 29479 solver.cpp:229]     Train net output #0: loss = 5296.55 (* 1 = 5296.55 loss)
I0315 03:13:10.123728 29479 solver.cpp:610] Iteration 19480, lr = 9.11897e-09
I0315 03:13:10.123742 29479 solver.cpp:613] Iteration 19480, avg_grad_norm = 589601
I0315 03:13:35.683699 29479 solver.cpp:214] Iteration 19500, loss = 6776.58
I0315 03:13:35.683759 29479 solver.cpp:229]     Train net output #0: loss = 4919.12 (* 1 = 4919.12 loss)
I0315 03:13:35.798332 29479 solver.cpp:610] Iteration 19500, lr = 9.11806e-09
I0315 03:13:35.798344 29479 solver.cpp:613] Iteration 19500, avg_grad_norm = 556913
I0315 03:14:01.409767 29479 solver.cpp:214] Iteration 19520, loss = 7251.91
I0315 03:14:01.409909 29479 solver.cpp:229]     Train net output #0: loss = 11557.3 (* 1 = 11557.3 loss)
I0315 03:14:01.524526 29479 solver.cpp:610] Iteration 19520, lr = 9.11715e-09
I0315 03:14:01.524540 29479 solver.cpp:613] Iteration 19520, avg_grad_norm = 591369
I0315 03:14:27.056890 29479 solver.cpp:214] Iteration 19540, loss = 6705.49
I0315 03:14:27.056949 29479 solver.cpp:229]     Train net output #0: loss = 6195.03 (* 1 = 6195.03 loss)
I0315 03:14:27.170214 29479 solver.cpp:610] Iteration 19540, lr = 9.11624e-09
I0315 03:14:27.170228 29479 solver.cpp:613] Iteration 19540, avg_grad_norm = 542552
I0315 03:15:05.608098 29479 solver.cpp:214] Iteration 19560, loss = 6974.12
I0315 03:15:05.608227 29479 solver.cpp:229]     Train net output #0: loss = 3431.95 (* 1 = 3431.95 loss)
I0315 03:15:05.711956 29479 solver.cpp:610] Iteration 19560, lr = 9.11533e-09
I0315 03:15:05.711969 29479 solver.cpp:613] Iteration 19560, avg_grad_norm = 575366
I0315 03:15:29.222362 29479 solver.cpp:214] Iteration 19580, loss = 6734.2
I0315 03:15:29.222414 29479 solver.cpp:229]     Train net output #0: loss = 5682.28 (* 1 = 5682.28 loss)
I0315 03:15:29.327589 29479 solver.cpp:610] Iteration 19580, lr = 9.11442e-09
I0315 03:15:29.327603 29479 solver.cpp:613] Iteration 19580, avg_grad_norm = 564773
I0315 03:15:54.788542 29479 solver.cpp:214] Iteration 19600, loss = 7417.67
I0315 03:15:54.788666 29479 solver.cpp:229]     Train net output #0: loss = 5532.73 (* 1 = 5532.73 loss)
I0315 03:15:54.903059 29479 solver.cpp:610] Iteration 19600, lr = 9.11351e-09
I0315 03:15:54.903071 29479 solver.cpp:613] Iteration 19600, avg_grad_norm = 625846
I0315 03:16:20.498440 29479 solver.cpp:214] Iteration 19620, loss = 6972.85
I0315 03:16:20.498502 29479 solver.cpp:229]     Train net output #0: loss = 6248.95 (* 1 = 6248.95 loss)
I0315 03:16:20.613184 29479 solver.cpp:610] Iteration 19620, lr = 9.1126e-09
I0315 03:16:20.613209 29479 solver.cpp:613] Iteration 19620, avg_grad_norm = 682067
I0315 03:16:45.958910 29479 solver.cpp:214] Iteration 19640, loss = 7083.89
I0315 03:16:45.959029 29479 solver.cpp:229]     Train net output #0: loss = 8416.07 (* 1 = 8416.07 loss)
I0315 03:16:46.072038 29479 solver.cpp:610] Iteration 19640, lr = 9.1117e-09
I0315 03:16:46.072052 29479 solver.cpp:613] Iteration 19640, avg_grad_norm = 586198
I0315 03:17:11.611397 29479 solver.cpp:214] Iteration 19660, loss = 7307.13
I0315 03:17:11.611449 29479 solver.cpp:229]     Train net output #0: loss = 10401.7 (* 1 = 10401.7 loss)
I0315 03:17:11.727444 29479 solver.cpp:610] Iteration 19660, lr = 9.11079e-09
I0315 03:17:11.727458 29479 solver.cpp:613] Iteration 19660, avg_grad_norm = 593894
I0315 03:17:37.356834 29479 solver.cpp:214] Iteration 19680, loss = 6834.16
I0315 03:17:37.357007 29479 solver.cpp:229]     Train net output #0: loss = 4914.27 (* 1 = 4914.27 loss)
I0315 03:17:37.469836 29479 solver.cpp:610] Iteration 19680, lr = 9.10988e-09
I0315 03:17:37.469851 29479 solver.cpp:613] Iteration 19680, avg_grad_norm = 579237
I0315 03:18:21.848754 29479 solver.cpp:214] Iteration 19700, loss = 7043.68
I0315 03:18:21.848973 29479 solver.cpp:229]     Train net output #0: loss = 13419.3 (* 1 = 13419.3 loss)
I0315 03:18:21.954092 29479 solver.cpp:610] Iteration 19700, lr = 9.10897e-09
I0315 03:18:21.954105 29479 solver.cpp:613] Iteration 19700, avg_grad_norm = 663088
I0315 03:18:45.461634 29479 solver.cpp:214] Iteration 19720, loss = 6684.06
I0315 03:18:45.461685 29479 solver.cpp:229]     Train net output #0: loss = 5446.77 (* 1 = 5446.77 loss)
I0315 03:18:45.574859 29479 solver.cpp:610] Iteration 19720, lr = 9.10806e-09
I0315 03:18:45.574872 29479 solver.cpp:613] Iteration 19720, avg_grad_norm = 570053
I0315 03:19:10.831198 29479 solver.cpp:214] Iteration 19740, loss = 6605.33
I0315 03:19:10.831338 29479 solver.cpp:229]     Train net output #0: loss = 10394.9 (* 1 = 10394.9 loss)
I0315 03:19:10.944103 29479 solver.cpp:610] Iteration 19740, lr = 9.10715e-09
I0315 03:19:10.944123 29479 solver.cpp:613] Iteration 19740, avg_grad_norm = 701966
I0315 03:19:36.378777 29479 solver.cpp:214] Iteration 19760, loss = 6799.58
I0315 03:19:36.378867 29479 solver.cpp:229]     Train net output #0: loss = 9543.95 (* 1 = 9543.95 loss)
I0315 03:19:36.493329 29479 solver.cpp:610] Iteration 19760, lr = 9.10624e-09
I0315 03:19:36.493342 29479 solver.cpp:613] Iteration 19760, avg_grad_norm = 579856
I0315 03:20:02.066009 29479 solver.cpp:214] Iteration 19780, loss = 6678.72
I0315 03:20:02.066174 29479 solver.cpp:229]     Train net output #0: loss = 5051.02 (* 1 = 5051.02 loss)
I0315 03:20:02.180585 29479 solver.cpp:610] Iteration 19780, lr = 9.10533e-09
I0315 03:20:02.180600 29479 solver.cpp:613] Iteration 19780, avg_grad_norm = 529881
I0315 03:20:27.734305 29479 solver.cpp:214] Iteration 19800, loss = 6657.47
I0315 03:20:27.734380 29479 solver.cpp:229]     Train net output #0: loss = 7945.49 (* 1 = 7945.49 loss)
I0315 03:20:27.848866 29479 solver.cpp:610] Iteration 19800, lr = 9.10442e-09
I0315 03:20:27.848880 29479 solver.cpp:613] Iteration 19800, avg_grad_norm = 619766
I0315 03:21:16.085584 29479 solver.cpp:214] Iteration 19820, loss = 6977.06
I0315 03:21:16.085733 29479 solver.cpp:229]     Train net output #0: loss = 3895.85 (* 1 = 3895.85 loss)
I0315 03:21:16.189558 29479 solver.cpp:610] Iteration 19820, lr = 9.10351e-09
I0315 03:21:16.189571 29479 solver.cpp:613] Iteration 19820, avg_grad_norm = 656627
I0315 03:21:39.656925 29479 solver.cpp:214] Iteration 19840, loss = 6662.53
I0315 03:21:39.656986 29479 solver.cpp:229]     Train net output #0: loss = 5262.97 (* 1 = 5262.97 loss)
I0315 03:21:39.762147 29479 solver.cpp:610] Iteration 19840, lr = 9.1026e-09
I0315 03:21:39.762161 29479 solver.cpp:613] Iteration 19840, avg_grad_norm = 621656
I0315 03:22:04.082859 29479 solver.cpp:214] Iteration 19860, loss = 6926.35
I0315 03:22:04.083065 29479 solver.cpp:229]     Train net output #0: loss = 4841.42 (* 1 = 4841.42 loss)
I0315 03:22:04.197502 29479 solver.cpp:610] Iteration 19860, lr = 9.10169e-09
I0315 03:22:04.197517 29479 solver.cpp:613] Iteration 19860, avg_grad_norm = 589618
I0315 03:22:29.802691 29479 solver.cpp:214] Iteration 19880, loss = 6741.56
I0315 03:22:29.802755 29479 solver.cpp:229]     Train net output #0: loss = 6002.94 (* 1 = 6002.94 loss)
I0315 03:22:29.917335 29479 solver.cpp:610] Iteration 19880, lr = 9.10078e-09
I0315 03:22:29.917348 29479 solver.cpp:613] Iteration 19880, avg_grad_norm = 604199
I0315 03:22:55.036566 29479 solver.cpp:214] Iteration 19900, loss = 7028.38
I0315 03:22:55.036778 29479 solver.cpp:229]     Train net output #0: loss = 6489.6 (* 1 = 6489.6 loss)
I0315 03:22:55.148134 29479 solver.cpp:610] Iteration 19900, lr = 9.09987e-09
I0315 03:22:55.148149 29479 solver.cpp:613] Iteration 19900, avg_grad_norm = 643041
I0315 03:23:20.337533 29479 solver.cpp:214] Iteration 19920, loss = 7135.96
I0315 03:23:20.337594 29479 solver.cpp:229]     Train net output #0: loss = 5141.9 (* 1 = 5141.9 loss)
I0315 03:23:20.452205 29479 solver.cpp:610] Iteration 19920, lr = 9.09896e-09
I0315 03:23:20.452219 29479 solver.cpp:613] Iteration 19920, avg_grad_norm = 634229
I0315 03:23:58.700999 29479 solver.cpp:214] Iteration 19940, loss = 7091.07
I0315 03:23:58.712795 29479 solver.cpp:229]     Train net output #0: loss = 9260.52 (* 1 = 9260.52 loss)
I0315 03:23:58.805346 29479 solver.cpp:610] Iteration 19940, lr = 9.09805e-09
I0315 03:23:58.805359 29479 solver.cpp:613] Iteration 19940, avg_grad_norm = 694072
I0315 03:24:22.258028 29479 solver.cpp:214] Iteration 19960, loss = 6593.5
I0315 03:24:22.258106 29479 solver.cpp:229]     Train net output #0: loss = 6197.39 (* 1 = 6197.39 loss)
I0315 03:24:22.363351 29479 solver.cpp:610] Iteration 19960, lr = 9.09715e-09
I0315 03:24:22.363365 29479 solver.cpp:613] Iteration 19960, avg_grad_norm = 630573
I0315 03:24:47.444587 29479 solver.cpp:214] Iteration 19980, loss = 6879.31
I0315 03:24:47.444785 29479 solver.cpp:229]     Train net output #0: loss = 10647.4 (* 1 = 10647.4 loss)
I0315 03:24:47.559190 29479 solver.cpp:610] Iteration 19980, lr = 9.09623e-09
I0315 03:24:47.559202 29479 solver.cpp:613] Iteration 19980, avg_grad_norm = 608779
I0315 03:25:12.071789 29479 solver.cpp:458] Snapshotting to models/pnet/VGG_VOC2012ext_iter_20000.caffemodel
I0315 03:25:13.323807 29479 solver.cpp:466] Snapshotting solver state to models/pnet/VGG_VOC2012ext_iter_20000.solverstate
I0315 03:25:15.223706 29479 solver.cpp:214] Iteration 20000, loss = 6818.16
I0315 03:25:15.223755 29479 solver.cpp:229]     Train net output #0: loss = 4948 (* 1 = 4948 loss)
I0315 03:25:15.328892 29479 solver.cpp:610] Iteration 20000, lr = 9.09533e-09
I0315 03:25:15.328905 29479 solver.cpp:613] Iteration 20000, avg_grad_norm = 635614
I0315 03:25:40.205457 29479 solver.cpp:214] Iteration 20020, loss = 6982.69
I0315 03:25:40.205678 29479 solver.cpp:229]     Train net output #0: loss = 6689.87 (* 1 = 6689.87 loss)
I0315 03:25:40.321521 29479 solver.cpp:610] Iteration 20020, lr = 9.09442e-09
I0315 03:25:40.321534 29479 solver.cpp:613] Iteration 20020, avg_grad_norm = 665612
I0315 03:26:05.947856 29479 solver.cpp:214] Iteration 20040, loss = 6985.67
I0315 03:26:05.947913 29479 solver.cpp:229]     Train net output #0: loss = 4527.79 (* 1 = 4527.79 loss)
I0315 03:26:06.060792 29479 solver.cpp:610] Iteration 20040, lr = 9.09351e-09
I0315 03:26:06.060807 29479 solver.cpp:613] Iteration 20040, avg_grad_norm = 678497
I0315 03:26:31.304013 29479 solver.cpp:214] Iteration 20060, loss = 7040.1
I0315 03:26:31.304167 29479 solver.cpp:229]     Train net output #0: loss = 6476.35 (* 1 = 6476.35 loss)
I0315 03:26:31.417049 29479 solver.cpp:610] Iteration 20060, lr = 9.0926e-09
I0315 03:26:31.417065 29479 solver.cpp:613] Iteration 20060, avg_grad_norm = 638816
I0315 03:27:08.087265 29479 solver.cpp:214] Iteration 20080, loss = 6878.03
I0315 03:27:08.087461 29479 solver.cpp:229]     Train net output #0: loss = 8825.41 (* 1 = 8825.41 loss)
I0315 03:27:08.192518 29479 solver.cpp:610] Iteration 20080, lr = 9.09169e-09
I0315 03:27:08.192531 29479 solver.cpp:613] Iteration 20080, avg_grad_norm = 568661
I0315 03:27:32.754277 29479 solver.cpp:214] Iteration 20100, loss = 7254.61
I0315 03:27:32.754345 29479 solver.cpp:229]     Train net output #0: loss = 7718.79 (* 1 = 7718.79 loss)
I0315 03:27:32.868927 29479 solver.cpp:610] Iteration 20100, lr = 9.09078e-09
I0315 03:27:32.868939 29479 solver.cpp:613] Iteration 20100, avg_grad_norm = 586724
I0315 03:27:58.459471 29479 solver.cpp:214] Iteration 20120, loss = 6998.11
I0315 03:27:58.459581 29479 solver.cpp:229]     Train net output #0: loss = 7681.69 (* 1 = 7681.69 loss)
I0315 03:27:58.574156 29479 solver.cpp:610] Iteration 20120, lr = 9.08987e-09
I0315 03:27:58.574169 29479 solver.cpp:613] Iteration 20120, avg_grad_norm = 606939
I0315 03:28:24.114310 29479 solver.cpp:214] Iteration 20140, loss = 7235.13
I0315 03:28:24.114373 29479 solver.cpp:229]     Train net output #0: loss = 4950.35 (* 1 = 4950.35 loss)
I0315 03:28:24.228962 29479 solver.cpp:610] Iteration 20140, lr = 9.08896e-09
I0315 03:28:24.228976 29479 solver.cpp:613] Iteration 20140, avg_grad_norm = 543125
I0315 03:28:49.828119 29479 solver.cpp:214] Iteration 20160, loss = 6561.35
I0315 03:28:49.828383 29479 solver.cpp:229]     Train net output #0: loss = 6156.55 (* 1 = 6156.55 loss)
I0315 03:28:49.942751 29479 solver.cpp:610] Iteration 20160, lr = 9.08805e-09
I0315 03:28:49.942766 29479 solver.cpp:613] Iteration 20160, avg_grad_norm = 570158
I0315 03:29:15.418297 29479 solver.cpp:214] Iteration 20180, loss = 6965.39
I0315 03:29:15.418388 29479 solver.cpp:229]     Train net output #0: loss = 11180.1 (* 1 = 11180.1 loss)
I0315 03:29:15.531273 29479 solver.cpp:610] Iteration 20180, lr = 9.08714e-09
I0315 03:29:15.531329 29479 solver.cpp:613] Iteration 20180, avg_grad_norm = 580816
I0315 03:29:53.257619 29479 solver.cpp:214] Iteration 20200, loss = 6552.03
I0315 03:29:53.257725 29479 solver.cpp:229]     Train net output #0: loss = 4786.5 (* 1 = 4786.5 loss)
I0315 03:29:53.361907 29479 solver.cpp:610] Iteration 20200, lr = 9.08623e-09
I0315 03:29:53.361920 29479 solver.cpp:613] Iteration 20200, avg_grad_norm = 616556
I0315 03:30:17.171080 29479 solver.cpp:214] Iteration 20220, loss = 6761.87
I0315 03:30:17.171164 29479 solver.cpp:229]     Train net output #0: loss = 5487.05 (* 1 = 5487.05 loss)
I0315 03:30:17.285717 29479 solver.cpp:610] Iteration 20220, lr = 9.08532e-09
I0315 03:30:17.285732 29479 solver.cpp:613] Iteration 20220, avg_grad_norm = 642662
I0315 03:30:42.886762 29479 solver.cpp:214] Iteration 20240, loss = 7121.17
I0315 03:30:42.886903 29479 solver.cpp:229]     Train net output #0: loss = 4607.89 (* 1 = 4607.89 loss)
I0315 03:30:43.001245 29479 solver.cpp:610] Iteration 20240, lr = 9.08441e-09
I0315 03:30:43.001258 29479 solver.cpp:613] Iteration 20240, avg_grad_norm = 717574
I0315 03:31:08.603690 29479 solver.cpp:214] Iteration 20260, loss = 6506.24
I0315 03:31:08.603744 29479 solver.cpp:229]     Train net output #0: loss = 6159.68 (* 1 = 6159.68 loss)
I0315 03:31:08.718389 29479 solver.cpp:610] Iteration 20260, lr = 9.0835e-09
I0315 03:31:08.718402 29479 solver.cpp:613] Iteration 20260, avg_grad_norm = 583546
I0315 03:31:34.314303 29479 solver.cpp:214] Iteration 20280, loss = 6879.54
I0315 03:31:34.314430 29479 solver.cpp:229]     Train net output #0: loss = 9641.53 (* 1 = 9641.53 loss)
I0315 03:31:34.428908 29479 solver.cpp:610] Iteration 20280, lr = 9.08259e-09
I0315 03:31:34.428921 29479 solver.cpp:613] Iteration 20280, avg_grad_norm = 651069
I0315 03:31:59.934119 29479 solver.cpp:214] Iteration 20300, loss = 7139.24
I0315 03:31:59.934185 29479 solver.cpp:229]     Train net output #0: loss = 6727.03 (* 1 = 6727.03 loss)
I0315 03:32:00.047181 29479 solver.cpp:610] Iteration 20300, lr = 9.08168e-09
I0315 03:32:00.047194 29479 solver.cpp:613] Iteration 20300, avg_grad_norm = 582001
I0315 03:32:50.011072 29479 solver.cpp:214] Iteration 20320, loss = 7053.76
I0315 03:32:50.011183 29479 solver.cpp:229]     Train net output #0: loss = 8331.65 (* 1 = 8331.65 loss)
I0315 03:32:50.115119 29479 solver.cpp:610] Iteration 20320, lr = 9.08077e-09
I0315 03:32:50.115134 29479 solver.cpp:613] Iteration 20320, avg_grad_norm = 608749
I0315 03:33:13.535857 29479 solver.cpp:214] Iteration 20340, loss = 6790.69
I0315 03:33:13.535929 29479 solver.cpp:229]     Train net output #0: loss = 5433.86 (* 1 = 5433.86 loss)
I0315 03:33:13.641021 29479 solver.cpp:610] Iteration 20340, lr = 9.07986e-09
I0315 03:33:13.641047 29479 solver.cpp:613] Iteration 20340, avg_grad_norm = 668184
I0315 03:33:37.174700 29479 solver.cpp:214] Iteration 20360, loss = 6917.25
I0315 03:33:37.174840 29479 solver.cpp:229]     Train net output #0: loss = 4858.22 (* 1 = 4858.22 loss)
I0315 03:33:37.286346 29479 solver.cpp:610] Iteration 20360, lr = 9.07895e-09
I0315 03:33:37.286360 29479 solver.cpp:613] Iteration 20360, avg_grad_norm = 553307
I0315 03:34:02.882047 29479 solver.cpp:214] Iteration 20380, loss = 6591.86
I0315 03:34:02.882114 29479 solver.cpp:229]     Train net output #0: loss = 7387.45 (* 1 = 7387.45 loss)
I0315 03:34:02.996706 29479 solver.cpp:610] Iteration 20380, lr = 9.07804e-09
I0315 03:34:02.996718 29479 solver.cpp:613] Iteration 20380, avg_grad_norm = 628727
I0315 03:34:28.409611 29479 solver.cpp:214] Iteration 20400, loss = 6590.65
I0315 03:34:28.409770 29479 solver.cpp:229]     Train net output #0: loss = 8974.15 (* 1 = 8974.15 loss)
I0315 03:34:28.522562 29479 solver.cpp:610] Iteration 20400, lr = 9.07713e-09
I0315 03:34:28.522575 29479 solver.cpp:613] Iteration 20400, avg_grad_norm = 603835
I0315 03:34:53.803777 29479 solver.cpp:214] Iteration 20420, loss = 6472
I0315 03:34:53.803841 29479 solver.cpp:229]     Train net output #0: loss = 6619.18 (* 1 = 6619.18 loss)
I0315 03:34:53.916745 29479 solver.cpp:610] Iteration 20420, lr = 9.07622e-09
I0315 03:34:53.916759 29479 solver.cpp:613] Iteration 20420, avg_grad_norm = 648439
I0315 03:35:19.473080 29479 solver.cpp:214] Iteration 20440, loss = 6967.61
I0315 03:35:19.473237 29479 solver.cpp:229]     Train net output #0: loss = 5002.79 (* 1 = 5002.79 loss)
I0315 03:35:19.587663 29479 solver.cpp:610] Iteration 20440, lr = 9.07531e-09
I0315 03:35:19.587677 29479 solver.cpp:613] Iteration 20440, avg_grad_norm = 620525
I0315 03:36:06.422283 29479 solver.cpp:214] Iteration 20460, loss = 6695.07
I0315 03:36:06.422427 29479 solver.cpp:229]     Train net output #0: loss = 3672.61 (* 1 = 3672.61 loss)
I0315 03:36:06.527600 29479 solver.cpp:610] Iteration 20460, lr = 9.0744e-09
I0315 03:36:06.527613 29479 solver.cpp:613] Iteration 20460, avg_grad_norm = 677097
I0315 03:36:30.039968 29479 solver.cpp:214] Iteration 20480, loss = 6744.78
I0315 03:36:30.040026 29479 solver.cpp:229]     Train net output #0: loss = 5803.47 (* 1 = 5803.47 loss)
I0315 03:36:30.145212 29479 solver.cpp:610] Iteration 20480, lr = 9.07349e-09
I0315 03:36:30.145226 29479 solver.cpp:613] Iteration 20480, avg_grad_norm = 767679
I0315 03:36:54.955793 29479 solver.cpp:214] Iteration 20500, loss = 6767.47
I0315 03:36:54.955919 29479 solver.cpp:229]     Train net output #0: loss = 13828.3 (* 1 = 13828.3 loss)
I0315 03:36:55.068780 29479 solver.cpp:610] Iteration 20500, lr = 9.07258e-09
I0315 03:36:55.068794 29479 solver.cpp:613] Iteration 20500, avg_grad_norm = 616881
I0315 03:37:20.465864 29479 solver.cpp:214] Iteration 20520, loss = 6887.9
I0315 03:37:20.465927 29479 solver.cpp:229]     Train net output #0: loss = 3608.63 (* 1 = 3608.63 loss)
I0315 03:37:20.580592 29479 solver.cpp:610] Iteration 20520, lr = 9.07167e-09
I0315 03:37:20.580616 29479 solver.cpp:613] Iteration 20520, avg_grad_norm = 548187
I0315 03:37:46.177314 29479 solver.cpp:214] Iteration 20540, loss = 6392.22
I0315 03:37:46.177501 29479 solver.cpp:229]     Train net output #0: loss = 5602.9 (* 1 = 5602.9 loss)
I0315 03:37:46.291998 29479 solver.cpp:610] Iteration 20540, lr = 9.07076e-09
I0315 03:37:46.292012 29479 solver.cpp:613] Iteration 20540, avg_grad_norm = 610192
I0315 03:38:11.869035 29479 solver.cpp:214] Iteration 20560, loss = 6819.16
I0315 03:38:11.869073 29479 solver.cpp:229]     Train net output #0: loss = 7142.94 (* 1 = 7142.94 loss)
I0315 03:38:11.982025 29479 solver.cpp:610] Iteration 20560, lr = 9.06986e-09
I0315 03:38:11.982038 29479 solver.cpp:613] Iteration 20560, avg_grad_norm = 548443
I0315 03:38:49.997772 29479 solver.cpp:214] Iteration 20580, loss = 6869.29
I0315 03:38:49.997905 29479 solver.cpp:229]     Train net output #0: loss = 3047.33 (* 1 = 3047.33 loss)
I0315 03:38:50.103111 29479 solver.cpp:610] Iteration 20580, lr = 9.06894e-09
I0315 03:38:50.103126 29479 solver.cpp:613] Iteration 20580, avg_grad_norm = 592751
I0315 03:39:13.624641 29479 solver.cpp:214] Iteration 20600, loss = 7007.5
I0315 03:39:13.624692 29479 solver.cpp:229]     Train net output #0: loss = 5900.39 (* 1 = 5900.39 loss)
I0315 03:39:13.733484 29479 solver.cpp:610] Iteration 20600, lr = 9.06804e-09
I0315 03:39:13.733496 29479 solver.cpp:613] Iteration 20600, avg_grad_norm = 806451
I0315 03:39:39.230587 29479 solver.cpp:214] Iteration 20620, loss = 6677.76
I0315 03:39:39.230756 29479 solver.cpp:229]     Train net output #0: loss = 8096.38 (* 1 = 8096.38 loss)
I0315 03:39:39.345093 29479 solver.cpp:610] Iteration 20620, lr = 9.06713e-09
I0315 03:39:39.345106 29479 solver.cpp:613] Iteration 20620, avg_grad_norm = 636793
I0315 03:40:04.936700 29479 solver.cpp:214] Iteration 20640, loss = 6917.61
I0315 03:40:04.936774 29479 solver.cpp:229]     Train net output #0: loss = 15000.8 (* 1 = 15000.8 loss)
I0315 03:40:05.051180 29479 solver.cpp:610] Iteration 20640, lr = 9.06622e-09
I0315 03:40:05.051195 29479 solver.cpp:613] Iteration 20640, avg_grad_norm = 726235
I0315 03:40:30.645115 29479 solver.cpp:214] Iteration 20660, loss = 6903.92
I0315 03:40:30.645328 29479 solver.cpp:229]     Train net output #0: loss = 6117.31 (* 1 = 6117.31 loss)
I0315 03:40:30.759745 29479 solver.cpp:610] Iteration 20660, lr = 9.06531e-09
I0315 03:40:30.759759 29479 solver.cpp:613] Iteration 20660, avg_grad_norm = 597407
I0315 03:40:56.294353 29479 solver.cpp:214] Iteration 20680, loss = 7271.88
I0315 03:40:56.294409 29479 solver.cpp:229]     Train net output #0: loss = 10977.7 (* 1 = 10977.7 loss)
I0315 03:40:56.408859 29479 solver.cpp:610] Iteration 20680, lr = 9.0644e-09
I0315 03:40:56.408871 29479 solver.cpp:613] Iteration 20680, avg_grad_norm = 566743
I0315 03:41:35.141926 29479 solver.cpp:214] Iteration 20700, loss = 6895.87
I0315 03:41:35.142033 29479 solver.cpp:229]     Train net output #0: loss = 6083.09 (* 1 = 6083.09 loss)
I0315 03:41:35.245826 29479 solver.cpp:610] Iteration 20700, lr = 9.06349e-09
I0315 03:41:35.245838 29479 solver.cpp:613] Iteration 20700, avg_grad_norm = 572160
I0315 03:41:58.746105 29479 solver.cpp:214] Iteration 20720, loss = 6663.03
I0315 03:41:58.746140 29479 solver.cpp:229]     Train net output #0: loss = 11028.6 (* 1 = 11028.6 loss)
I0315 03:41:58.851352 29479 solver.cpp:610] Iteration 20720, lr = 9.06258e-09
I0315 03:41:58.851366 29479 solver.cpp:613] Iteration 20720, avg_grad_norm = 722855
I0315 03:42:23.671804 29479 solver.cpp:214] Iteration 20740, loss = 6884.45
I0315 03:42:23.671924 29479 solver.cpp:229]     Train net output #0: loss = 11102.1 (* 1 = 11102.1 loss)
I0315 03:42:23.786489 29479 solver.cpp:610] Iteration 20740, lr = 9.06167e-09
I0315 03:42:23.786501 29479 solver.cpp:613] Iteration 20740, avg_grad_norm = 764107
I0315 03:42:49.380055 29479 solver.cpp:214] Iteration 20760, loss = 6896.29
I0315 03:42:49.380106 29479 solver.cpp:229]     Train net output #0: loss = 5181.84 (* 1 = 5181.84 loss)
I0315 03:42:49.494593 29479 solver.cpp:610] Iteration 20760, lr = 9.06076e-09
I0315 03:42:49.494607 29479 solver.cpp:613] Iteration 20760, avg_grad_norm = 780281
I0315 03:43:15.087463 29479 solver.cpp:214] Iteration 20780, loss = 6724.95
I0315 03:43:15.087594 29479 solver.cpp:229]     Train net output #0: loss = 4902.22 (* 1 = 4902.22 loss)
I0315 03:43:15.202091 29479 solver.cpp:610] Iteration 20780, lr = 9.05985e-09
I0315 03:43:15.202105 29479 solver.cpp:613] Iteration 20780, avg_grad_norm = 622541
I0315 03:43:40.801090 29479 solver.cpp:214] Iteration 20800, loss = 6641.6
I0315 03:43:40.801151 29479 solver.cpp:229]     Train net output #0: loss = 5036.28 (* 1 = 5036.28 loss)
I0315 03:43:40.915734 29479 solver.cpp:610] Iteration 20800, lr = 9.05894e-09
I0315 03:43:40.915745 29479 solver.cpp:613] Iteration 20800, avg_grad_norm = 513003
I0315 03:44:06.425772 29479 solver.cpp:214] Iteration 20820, loss = 6650.26
I0315 03:44:06.425909 29479 solver.cpp:229]     Train net output #0: loss = 2479.97 (* 1 = 2479.97 loss)
I0315 03:44:06.539089 29479 solver.cpp:610] Iteration 20820, lr = 9.05803e-09
I0315 03:44:06.539103 29479 solver.cpp:613] Iteration 20820, avg_grad_norm = 512238
I0315 03:44:54.090330 29479 solver.cpp:214] Iteration 20840, loss = 6938.39
I0315 03:44:54.090486 29479 solver.cpp:229]     Train net output #0: loss = 3948.59 (* 1 = 3948.59 loss)
I0315 03:44:54.195868 29479 solver.cpp:610] Iteration 20840, lr = 9.05712e-09
I0315 03:44:54.195880 29479 solver.cpp:613] Iteration 20840, avg_grad_norm = 555076
I0315 03:45:17.629438 29479 solver.cpp:214] Iteration 20860, loss = 6789.39
I0315 03:45:17.629533 29479 solver.cpp:229]     Train net output #0: loss = 4338.9 (* 1 = 4338.9 loss)
I0315 03:45:17.734738 29479 solver.cpp:610] Iteration 20860, lr = 9.05621e-09
I0315 03:45:17.734752 29479 solver.cpp:613] Iteration 20860, avg_grad_norm = 571792
I0315 03:45:42.396844 29479 solver.cpp:214] Iteration 20880, loss = 6477.5
I0315 03:45:42.397153 29479 solver.cpp:229]     Train net output #0: loss = 3786.81 (* 1 = 3786.81 loss)
I0315 03:45:42.509753 29479 solver.cpp:610] Iteration 20880, lr = 9.0553e-09
I0315 03:45:42.509768 29479 solver.cpp:613] Iteration 20880, avg_grad_norm = 598762
I0315 03:46:08.077123 29479 solver.cpp:214] Iteration 20900, loss = 6542.51
I0315 03:46:08.077195 29479 solver.cpp:229]     Train net output #0: loss = 8217.18 (* 1 = 8217.18 loss)
I0315 03:46:08.191651 29479 solver.cpp:610] Iteration 20900, lr = 9.05439e-09
I0315 03:46:08.191665 29479 solver.cpp:613] Iteration 20900, avg_grad_norm = 591281
I0315 03:46:33.764057 29479 solver.cpp:214] Iteration 20920, loss = 6706.14
I0315 03:46:33.764154 29479 solver.cpp:229]     Train net output #0: loss = 6967.11 (* 1 = 6967.11 loss)
I0315 03:46:33.878489 29479 solver.cpp:610] Iteration 20920, lr = 9.05348e-09
I0315 03:46:33.878504 29479 solver.cpp:613] Iteration 20920, avg_grad_norm = 539178
I0315 03:46:59.224387 29479 solver.cpp:214] Iteration 20940, loss = 6905.78
I0315 03:46:59.224458 29479 solver.cpp:229]     Train net output #0: loss = 5788.56 (* 1 = 5788.56 loss)
I0315 03:46:59.337376 29479 solver.cpp:610] Iteration 20940, lr = 9.05257e-09
I0315 03:46:59.337390 29479 solver.cpp:613] Iteration 20940, avg_grad_norm = 583351
I0315 03:47:50.570767 29479 solver.cpp:214] Iteration 20960, loss = 6717.28
I0315 03:47:50.570873 29479 solver.cpp:229]     Train net output #0: loss = 8776.09 (* 1 = 8776.09 loss)
I0315 03:47:50.674780 29479 solver.cpp:610] Iteration 20960, lr = 9.05166e-09
I0315 03:47:50.674793 29479 solver.cpp:613] Iteration 20960, avg_grad_norm = 563341
I0315 03:48:14.138067 29479 solver.cpp:214] Iteration 20980, loss = 6947.72
I0315 03:48:14.138152 29479 solver.cpp:229]     Train net output #0: loss = 7101.12 (* 1 = 7101.12 loss)
I0315 03:48:14.242699 29479 solver.cpp:610] Iteration 20980, lr = 9.05075e-09
I0315 03:48:14.242713 29479 solver.cpp:613] Iteration 20980, avg_grad_norm = 520392
I0315 03:48:37.949182 29479 solver.cpp:214] Iteration 21000, loss = 6858.67
I0315 03:48:37.949393 29479 solver.cpp:229]     Train net output #0: loss = 4746.68 (* 1 = 4746.68 loss)
I0315 03:48:38.062355 29479 solver.cpp:610] Iteration 21000, lr = 9.04984e-09
I0315 03:48:38.062368 29479 solver.cpp:613] Iteration 21000, avg_grad_norm = 648080
I0315 03:49:03.360568 29479 solver.cpp:214] Iteration 21020, loss = 6556.23
I0315 03:49:03.360630 29479 solver.cpp:229]     Train net output #0: loss = 9542.52 (* 1 = 9542.52 loss)
I0315 03:49:03.473678 29479 solver.cpp:610] Iteration 21020, lr = 9.04893e-09
I0315 03:49:03.473691 29479 solver.cpp:613] Iteration 21020, avg_grad_norm = 647525
I0315 03:49:28.968047 29479 solver.cpp:214] Iteration 21040, loss = 6891.45
I0315 03:49:28.968186 29479 solver.cpp:229]     Train net output #0: loss = 11249.5 (* 1 = 11249.5 loss)
I0315 03:49:29.082598 29479 solver.cpp:610] Iteration 21040, lr = 9.04802e-09
I0315 03:49:29.082612 29479 solver.cpp:613] Iteration 21040, avg_grad_norm = 741406
I0315 03:49:54.555763 29479 solver.cpp:214] Iteration 21060, loss = 6753.39
I0315 03:49:54.555811 29479 solver.cpp:229]     Train net output #0: loss = 8023.85 (* 1 = 8023.85 loss)
I0315 03:49:54.668625 29479 solver.cpp:610] Iteration 21060, lr = 9.04711e-09
I0315 03:49:54.668639 29479 solver.cpp:613] Iteration 21060, avg_grad_norm = 639890
I0315 03:50:19.994245 29479 solver.cpp:214] Iteration 21080, loss = 6850.72
I0315 03:50:19.994374 29479 solver.cpp:229]     Train net output #0: loss = 9708.68 (* 1 = 9708.68 loss)
I0315 03:50:20.110416 29479 solver.cpp:610] Iteration 21080, lr = 9.0462e-09
I0315 03:50:20.110431 29479 solver.cpp:613] Iteration 21080, avg_grad_norm = 603972
I0315 03:50:56.891839 29479 solver.cpp:214] Iteration 21100, loss = 6583.4
I0315 03:50:56.892076 29479 solver.cpp:229]     Train net output #0: loss = 4603.31 (* 1 = 4603.31 loss)
I0315 03:50:56.997047 29479 solver.cpp:610] Iteration 21100, lr = 9.04529e-09
I0315 03:50:56.997062 29479 solver.cpp:613] Iteration 21100, avg_grad_norm = 591284
I0315 03:51:21.729692 29479 solver.cpp:214] Iteration 21120, loss = 6655.88
I0315 03:51:21.729764 29479 solver.cpp:229]     Train net output #0: loss = 8538.27 (* 1 = 8538.27 loss)
I0315 03:51:21.844084 29479 solver.cpp:610] Iteration 21120, lr = 9.04438e-09
I0315 03:51:21.844099 29479 solver.cpp:613] Iteration 21120, avg_grad_norm = 602515
I0315 03:51:47.412709 29479 solver.cpp:214] Iteration 21140, loss = 7105.22
I0315 03:51:47.412950 29479 solver.cpp:229]     Train net output #0: loss = 4999.07 (* 1 = 4999.07 loss)
I0315 03:51:47.527462 29479 solver.cpp:610] Iteration 21140, lr = 9.04347e-09
I0315 03:51:47.527475 29479 solver.cpp:613] Iteration 21140, avg_grad_norm = 630434
I0315 03:52:13.116410 29479 solver.cpp:214] Iteration 21160, loss = 6797.26
I0315 03:52:13.116466 29479 solver.cpp:229]     Train net output #0: loss = 2611.78 (* 1 = 2611.78 loss)
I0315 03:52:13.231180 29479 solver.cpp:610] Iteration 21160, lr = 9.04256e-09
I0315 03:52:13.231194 29479 solver.cpp:613] Iteration 21160, avg_grad_norm = 620892
I0315 03:52:38.816392 29479 solver.cpp:214] Iteration 21180, loss = 6825.48
I0315 03:52:38.816514 29479 solver.cpp:229]     Train net output #0: loss = 5245.73 (* 1 = 5245.73 loss)
I0315 03:52:38.930917 29479 solver.cpp:610] Iteration 21180, lr = 9.04165e-09
I0315 03:52:38.930930 29479 solver.cpp:613] Iteration 21180, avg_grad_norm = 532334
I0315 03:53:04.528419 29479 solver.cpp:214] Iteration 21200, loss = 7049.99
I0315 03:53:04.528470 29479 solver.cpp:229]     Train net output #0: loss = 6636.37 (* 1 = 6636.37 loss)
I0315 03:53:04.642973 29479 solver.cpp:610] Iteration 21200, lr = 9.04074e-09
I0315 03:53:04.642988 29479 solver.cpp:613] Iteration 21200, avg_grad_norm = 564182
I0315 03:53:47.075181 29479 solver.cpp:214] Iteration 21220, loss = 6937.06
I0315 03:53:47.075295 29479 solver.cpp:229]     Train net output #0: loss = 3771.66 (* 1 = 3771.66 loss)
I0315 03:53:47.180428 29479 solver.cpp:610] Iteration 21220, lr = 9.03982e-09
I0315 03:53:47.180443 29479 solver.cpp:613] Iteration 21220, avg_grad_norm = 564439
I0315 03:54:10.723187 29479 solver.cpp:214] Iteration 21240, loss = 6837.96
I0315 03:54:10.723240 29479 solver.cpp:229]     Train net output #0: loss = 4008.02 (* 1 = 4008.02 loss)
I0315 03:54:10.828445 29479 solver.cpp:610] Iteration 21240, lr = 9.03892e-09
I0315 03:54:10.828459 29479 solver.cpp:613] Iteration 21240, avg_grad_norm = 581737
I0315 03:54:36.339864 29479 solver.cpp:214] Iteration 21260, loss = 6732.87
I0315 03:54:36.339994 29479 solver.cpp:229]     Train net output #0: loss = 6052.49 (* 1 = 6052.49 loss)
I0315 03:54:36.454627 29479 solver.cpp:610] Iteration 21260, lr = 9.03801e-09
I0315 03:54:36.454639 29479 solver.cpp:613] Iteration 21260, avg_grad_norm = 540846
I0315 03:55:01.956645 29479 solver.cpp:214] Iteration 21280, loss = 6664.17
I0315 03:55:01.956706 29479 solver.cpp:229]     Train net output #0: loss = 8483.59 (* 1 = 8483.59 loss)
I0315 03:55:02.069608 29479 solver.cpp:610] Iteration 21280, lr = 9.03709e-09
I0315 03:55:02.069622 29479 solver.cpp:613] Iteration 21280, avg_grad_norm = 558694
I0315 03:55:27.353662 29479 solver.cpp:214] Iteration 21300, loss = 7147.25
I0315 03:55:27.353775 29479 solver.cpp:229]     Train net output #0: loss = 5040.46 (* 1 = 5040.46 loss)
I0315 03:55:27.466608 29479 solver.cpp:610] Iteration 21300, lr = 9.03618e-09
I0315 03:55:27.466621 29479 solver.cpp:613] Iteration 21300, avg_grad_norm = 632260
I0315 03:55:52.930440 29479 solver.cpp:214] Iteration 21320, loss = 6892.66
I0315 03:55:52.930521 29479 solver.cpp:229]     Train net output #0: loss = 4438.38 (* 1 = 4438.38 loss)
I0315 03:55:53.045001 29479 solver.cpp:610] Iteration 21320, lr = 9.03527e-09
I0315 03:55:53.045063 29479 solver.cpp:613] Iteration 21320, avg_grad_norm = 744011
I0315 03:56:31.035187 29479 solver.cpp:214] Iteration 21340, loss = 7072.9
I0315 03:56:31.035347 29479 solver.cpp:229]     Train net output #0: loss = 3416.54 (* 1 = 3416.54 loss)
I0315 03:56:31.140290 29479 solver.cpp:610] Iteration 21340, lr = 9.03436e-09
I0315 03:56:31.140303 29479 solver.cpp:613] Iteration 21340, avg_grad_norm = 683041
I0315 03:56:54.580798 29479 solver.cpp:214] Iteration 21360, loss = 6820.28
I0315 03:56:54.580862 29479 solver.cpp:229]     Train net output #0: loss = 5486.57 (* 1 = 5486.57 loss)
I0315 03:56:54.688974 29479 solver.cpp:610] Iteration 21360, lr = 9.03345e-09
I0315 03:56:54.688987 29479 solver.cpp:613] Iteration 21360, avg_grad_norm = 606497
I0315 03:57:20.223542 29479 solver.cpp:214] Iteration 21380, loss = 6700.78
I0315 03:57:20.223681 29479 solver.cpp:229]     Train net output #0: loss = 7003.3 (* 1 = 7003.3 loss)
I0315 03:57:20.338177 29479 solver.cpp:610] Iteration 21380, lr = 9.03254e-09
I0315 03:57:20.338191 29479 solver.cpp:613] Iteration 21380, avg_grad_norm = 553714
I0315 03:57:45.882043 29479 solver.cpp:214] Iteration 21400, loss = 7094.56
I0315 03:57:45.882107 29479 solver.cpp:229]     Train net output #0: loss = 6546.86 (* 1 = 6546.86 loss)
I0315 03:57:45.996598 29479 solver.cpp:610] Iteration 21400, lr = 9.03163e-09
I0315 03:57:45.996610 29479 solver.cpp:613] Iteration 21400, avg_grad_norm = 675555
I0315 03:58:11.541664 29479 solver.cpp:214] Iteration 21420, loss = 6449.1
I0315 03:58:11.541774 29479 solver.cpp:229]     Train net output #0: loss = 5997.18 (* 1 = 5997.18 loss)
I0315 03:58:11.656144 29479 solver.cpp:610] Iteration 21420, lr = 9.03072e-09
I0315 03:58:11.656157 29479 solver.cpp:613] Iteration 21420, avg_grad_norm = 634559
I0315 03:58:37.213840 29479 solver.cpp:214] Iteration 21440, loss = 6839.8
I0315 03:58:37.213906 29479 solver.cpp:229]     Train net output #0: loss = 4692.88 (* 1 = 4692.88 loss)
I0315 03:58:37.328383 29479 solver.cpp:610] Iteration 21440, lr = 9.02981e-09
I0315 03:58:37.328397 29479 solver.cpp:613] Iteration 21440, avg_grad_norm = 648314
I0315 03:59:02.844588 29479 solver.cpp:214] Iteration 21460, loss = 6797.41
I0315 03:59:02.844750 29479 solver.cpp:229]     Train net output #0: loss = 3753.84 (* 1 = 3753.84 loss)
I0315 03:59:02.957736 29479 solver.cpp:610] Iteration 21460, lr = 9.0289e-09
I0315 03:59:02.957800 29479 solver.cpp:613] Iteration 21460, avg_grad_norm = 607515
I0315 03:59:41.475646 29479 solver.cpp:214] Iteration 21480, loss = 6459.08
I0315 03:59:41.475793 29479 solver.cpp:229]     Train net output #0: loss = 6105.33 (* 1 = 6105.33 loss)
I0315 03:59:41.580431 29479 solver.cpp:610] Iteration 21480, lr = 9.02799e-09
I0315 03:59:41.580446 29479 solver.cpp:613] Iteration 21480, avg_grad_norm = 613424
I0315 04:00:05.863129 29479 solver.cpp:214] Iteration 21500, loss = 6633.16
I0315 04:00:05.863199 29479 solver.cpp:229]     Train net output #0: loss = 8399.59 (* 1 = 8399.59 loss)
I0315 04:00:05.977821 29479 solver.cpp:610] Iteration 21500, lr = 9.02708e-09
I0315 04:00:05.977834 29479 solver.cpp:613] Iteration 21500, avg_grad_norm = 560495
I0315 04:00:31.523120 29479 solver.cpp:214] Iteration 21520, loss = 6605.63
I0315 04:00:31.523231 29479 solver.cpp:229]     Train net output #0: loss = 4430.79 (* 1 = 4430.79 loss)
I0315 04:00:31.637749 29479 solver.cpp:610] Iteration 21520, lr = 9.02617e-09
I0315 04:00:31.637763 29479 solver.cpp:613] Iteration 21520, avg_grad_norm = 557086
I0315 04:00:57.199440 29479 solver.cpp:214] Iteration 21540, loss = 7122.09
I0315 04:00:57.199507 29479 solver.cpp:229]     Train net output #0: loss = 7174.42 (* 1 = 7174.42 loss)
I0315 04:00:57.314179 29479 solver.cpp:610] Iteration 21540, lr = 9.02526e-09
I0315 04:00:57.314193 29479 solver.cpp:613] Iteration 21540, avg_grad_norm = 609851
I0315 04:01:22.861356 29479 solver.cpp:214] Iteration 21560, loss = 6657
I0315 04:01:22.861516 29479 solver.cpp:229]     Train net output #0: loss = 6413.21 (* 1 = 6413.21 loss)
I0315 04:01:22.975960 29479 solver.cpp:610] Iteration 21560, lr = 9.02435e-09
I0315 04:01:22.975972 29479 solver.cpp:613] Iteration 21560, avg_grad_norm = 582136
I0315 04:01:48.527678 29479 solver.cpp:214] Iteration 21580, loss = 6941.4
I0315 04:01:48.527745 29479 solver.cpp:229]     Train net output #0: loss = 4703.86 (* 1 = 4703.86 loss)
I0315 04:01:48.642304 29479 solver.cpp:610] Iteration 21580, lr = 9.02344e-09
I0315 04:01:48.642318 29479 solver.cpp:613] Iteration 21580, avg_grad_norm = 575887
I0315 04:02:28.777086 29479 solver.cpp:214] Iteration 21600, loss = 6902.63
I0315 04:02:28.777312 29479 solver.cpp:229]     Train net output #0: loss = 12008.9 (* 1 = 12008.9 loss)
I0315 04:02:28.881553 29479 solver.cpp:610] Iteration 21600, lr = 9.02253e-09
I0315 04:02:28.881567 29479 solver.cpp:613] Iteration 21600, avg_grad_norm = 583050
I0315 04:02:52.511550 29479 solver.cpp:214] Iteration 21620, loss = 6885.04
I0315 04:02:52.511620 29479 solver.cpp:229]     Train net output #0: loss = 4520.83 (* 1 = 4520.83 loss)
I0315 04:02:52.624296 29479 solver.cpp:610] Iteration 21620, lr = 9.02162e-09
I0315 04:02:52.624313 29479 solver.cpp:613] Iteration 21620, avg_grad_norm = 703409
I0315 04:03:18.160527 29479 solver.cpp:214] Iteration 21640, loss = 6445.22
I0315 04:03:18.160679 29479 solver.cpp:229]     Train net output #0: loss = 8038.25 (* 1 = 8038.25 loss)
I0315 04:03:18.275424 29479 solver.cpp:610] Iteration 21640, lr = 9.02071e-09
I0315 04:03:18.275437 29479 solver.cpp:613] Iteration 21640, avg_grad_norm = 657815
I0315 04:03:43.868911 29479 solver.cpp:214] Iteration 21660, loss = 6287.37
I0315 04:03:43.869002 29479 solver.cpp:229]     Train net output #0: loss = 4868.14 (* 1 = 4868.14 loss)
I0315 04:03:43.983544 29479 solver.cpp:610] Iteration 21660, lr = 9.0198e-09
I0315 04:03:43.983559 29479 solver.cpp:613] Iteration 21660, avg_grad_norm = 601782
I0315 04:04:09.506863 29479 solver.cpp:214] Iteration 21680, loss = 6808.81
I0315 04:04:09.506999 29479 solver.cpp:229]     Train net output #0: loss = 5398.85 (* 1 = 5398.85 loss)
I0315 04:04:09.619963 29479 solver.cpp:610] Iteration 21680, lr = 9.01889e-09
I0315 04:04:09.620012 29479 solver.cpp:613] Iteration 21680, avg_grad_norm = 694776
I0315 04:04:34.912858 29479 solver.cpp:214] Iteration 21700, loss = 6773.68
I0315 04:04:34.912921 29479 solver.cpp:229]     Train net output #0: loss = 5982.06 (* 1 = 5982.06 loss)
I0315 04:04:35.025876 29479 solver.cpp:610] Iteration 21700, lr = 9.01798e-09
I0315 04:04:35.025889 29479 solver.cpp:613] Iteration 21700, avg_grad_norm = 591077
I0315 04:05:13.016309 29479 solver.cpp:214] Iteration 21720, loss = 6974.22
I0315 04:05:13.016436 29479 solver.cpp:229]     Train net output #0: loss = 10168.4 (* 1 = 10168.4 loss)
I0315 04:05:13.120666 29479 solver.cpp:610] Iteration 21720, lr = 9.01707e-09
I0315 04:05:13.120681 29479 solver.cpp:613] Iteration 21720, avg_grad_norm = 615866
I0315 04:05:36.655858 29479 solver.cpp:214] Iteration 21740, loss = 6759.46
I0315 04:05:36.655902 29479 solver.cpp:229]     Train net output #0: loss = 7213.8 (* 1 = 7213.8 loss)
I0315 04:05:36.761003 29479 solver.cpp:610] Iteration 21740, lr = 9.01616e-09
I0315 04:05:36.761015 29479 solver.cpp:613] Iteration 21740, avg_grad_norm = 583997
I0315 04:06:02.062294 29479 solver.cpp:214] Iteration 21760, loss = 6706.53
I0315 04:06:02.062430 29479 solver.cpp:229]     Train net output #0: loss = 2810.82 (* 1 = 2810.82 loss)
I0315 04:06:02.176928 29479 solver.cpp:610] Iteration 21760, lr = 9.01525e-09
I0315 04:06:02.176941 29479 solver.cpp:613] Iteration 21760, avg_grad_norm = 632047
I0315 04:06:27.779369 29479 solver.cpp:214] Iteration 21780, loss = 7414.38
I0315 04:06:27.779422 29479 solver.cpp:229]     Train net output #0: loss = 5655.93 (* 1 = 5655.93 loss)
I0315 04:06:27.893923 29479 solver.cpp:610] Iteration 21780, lr = 9.01434e-09
I0315 04:06:27.893935 29479 solver.cpp:613] Iteration 21780, avg_grad_norm = 667283
I0315 04:06:53.440258 29479 solver.cpp:214] Iteration 21800, loss = 6890.38
I0315 04:06:53.440446 29479 solver.cpp:229]     Train net output #0: loss = 8487.92 (* 1 = 8487.92 loss)
I0315 04:06:53.554869 29479 solver.cpp:610] Iteration 21800, lr = 9.01343e-09
I0315 04:06:53.554883 29479 solver.cpp:613] Iteration 21800, avg_grad_norm = 637039
I0315 04:07:19.143626 29479 solver.cpp:214] Iteration 21820, loss = 6976.51
I0315 04:07:19.143683 29479 solver.cpp:229]     Train net output #0: loss = 4956.35 (* 1 = 4956.35 loss)
I0315 04:07:19.258312 29479 solver.cpp:610] Iteration 21820, lr = 9.01252e-09
I0315 04:07:19.258327 29479 solver.cpp:613] Iteration 21820, avg_grad_norm = 587543
I0315 04:07:44.826594 29479 solver.cpp:214] Iteration 21840, loss = 6449.18
I0315 04:07:44.826756 29479 solver.cpp:229]     Train net output #0: loss = 9861.78 (* 1 = 9861.78 loss)
I0315 04:07:44.941177 29479 solver.cpp:610] Iteration 21840, lr = 9.01161e-09
I0315 04:07:44.941191 29479 solver.cpp:613] Iteration 21840, avg_grad_norm = 669163
I0315 04:08:21.939195 29479 solver.cpp:214] Iteration 21860, loss = 6700.94
I0315 04:08:21.939307 29479 solver.cpp:229]     Train net output #0: loss = 4798.07 (* 1 = 4798.07 loss)
I0315 04:08:22.044401 29479 solver.cpp:610] Iteration 21860, lr = 9.0107e-09
I0315 04:08:22.044415 29479 solver.cpp:613] Iteration 21860, avg_grad_norm = 635745
I0315 04:08:46.452054 29479 solver.cpp:214] Iteration 21880, loss = 6858.22
I0315 04:08:46.452106 29479 solver.cpp:229]     Train net output #0: loss = 5301.75 (* 1 = 5301.75 loss)
I0315 04:08:46.565156 29479 solver.cpp:610] Iteration 21880, lr = 9.00978e-09
I0315 04:08:46.565170 29479 solver.cpp:613] Iteration 21880, avg_grad_norm = 565380
I0315 04:09:12.142505 29479 solver.cpp:214] Iteration 21900, loss = 6760.7
I0315 04:09:12.142618 29479 solver.cpp:229]     Train net output #0: loss = 7070.67 (* 1 = 7070.67 loss)
I0315 04:09:12.257052 29479 solver.cpp:610] Iteration 21900, lr = 9.00887e-09
I0315 04:09:12.257066 29479 solver.cpp:613] Iteration 21900, avg_grad_norm = 526067
I0315 04:09:37.853406 29479 solver.cpp:214] Iteration 21920, loss = 6512.95
I0315 04:09:37.853469 29479 solver.cpp:229]     Train net output #0: loss = 5014.17 (* 1 = 5014.17 loss)
I0315 04:09:37.968045 29479 solver.cpp:610] Iteration 21920, lr = 9.00796e-09
I0315 04:09:37.968060 29479 solver.cpp:613] Iteration 21920, avg_grad_norm = 658670
I0315 04:10:03.556689 29479 solver.cpp:214] Iteration 21940, loss = 6585.37
I0315 04:10:03.556890 29479 solver.cpp:229]     Train net output #0: loss = 7029.82 (* 1 = 7029.82 loss)
I0315 04:10:03.671453 29479 solver.cpp:610] Iteration 21940, lr = 9.00705e-09
I0315 04:10:03.671468 29479 solver.cpp:613] Iteration 21940, avg_grad_norm = 682191
I0315 04:10:29.235896 29479 solver.cpp:214] Iteration 21960, loss = 6792.32
I0315 04:10:29.235966 29479 solver.cpp:229]     Train net output #0: loss = 5845.88 (* 1 = 5845.88 loss)
I0315 04:10:29.350507 29479 solver.cpp:610] Iteration 21960, lr = 9.00614e-09
I0315 04:10:29.350520 29479 solver.cpp:613] Iteration 21960, avg_grad_norm = 670483
I0315 04:11:12.377089 29479 solver.cpp:214] Iteration 21980, loss = 6611.72
I0315 04:11:12.377235 29479 solver.cpp:229]     Train net output #0: loss = 6992.61 (* 1 = 6992.61 loss)
I0315 04:11:12.482228 29479 solver.cpp:610] Iteration 21980, lr = 9.00523e-09
I0315 04:11:12.482241 29479 solver.cpp:613] Iteration 21980, avg_grad_norm = 576177
I0315 04:11:35.926882 29479 solver.cpp:214] Iteration 22000, loss = 6442.71
I0315 04:11:35.926949 29479 solver.cpp:229]     Train net output #0: loss = 11322.8 (* 1 = 11322.8 loss)
I0315 04:11:36.031985 29479 solver.cpp:610] Iteration 22000, lr = 9.00432e-09
I0315 04:11:36.031997 29479 solver.cpp:613] Iteration 22000, avg_grad_norm = 580109
I0315 04:12:00.884445 29479 solver.cpp:214] Iteration 22020, loss = 6670.59
I0315 04:12:00.884577 29479 solver.cpp:229]     Train net output #0: loss = 9906.52 (* 1 = 9906.52 loss)
I0315 04:12:00.999259 29479 solver.cpp:610] Iteration 22020, lr = 9.00341e-09
I0315 04:12:00.999274 29479 solver.cpp:613] Iteration 22020, avg_grad_norm = 562613
I0315 04:12:26.550653 29479 solver.cpp:214] Iteration 22040, loss = 6789.83
I0315 04:12:26.550719 29479 solver.cpp:229]     Train net output #0: loss = 5131.56 (* 1 = 5131.56 loss)
I0315 04:12:26.665508 29479 solver.cpp:610] Iteration 22040, lr = 9.0025e-09
I0315 04:12:26.665521 29479 solver.cpp:613] Iteration 22040, avg_grad_norm = 563905
I0315 04:12:52.203281 29479 solver.cpp:214] Iteration 22060, loss = 6709.99
I0315 04:12:52.203486 29479 solver.cpp:229]     Train net output #0: loss = 4749.2 (* 1 = 4749.2 loss)
I0315 04:12:52.317970 29479 solver.cpp:610] Iteration 22060, lr = 9.00159e-09
I0315 04:12:52.317982 29479 solver.cpp:613] Iteration 22060, avg_grad_norm = 556983
I0315 04:13:17.750255 29479 solver.cpp:214] Iteration 22080, loss = 6781.18
I0315 04:13:17.750319 29479 solver.cpp:229]     Train net output #0: loss = 4420.59 (* 1 = 4420.59 loss)
I0315 04:13:17.863198 29479 solver.cpp:610] Iteration 22080, lr = 9.00068e-09
I0315 04:13:17.863210 29479 solver.cpp:613] Iteration 22080, avg_grad_norm = 638198
I0315 04:13:55.779129 29479 solver.cpp:214] Iteration 22100, loss = 6770.26
I0315 04:13:55.779279 29479 solver.cpp:229]     Train net output #0: loss = 4014.13 (* 1 = 4014.13 loss)
I0315 04:13:55.884316 29479 solver.cpp:610] Iteration 22100, lr = 8.99977e-09
I0315 04:13:55.884367 29479 solver.cpp:613] Iteration 22100, avg_grad_norm = 643863
I0315 04:14:19.403576 29479 solver.cpp:214] Iteration 22120, loss = 6704.7
I0315 04:14:19.403668 29479 solver.cpp:229]     Train net output #0: loss = 3705.17 (* 1 = 3705.17 loss)
I0315 04:14:19.508206 29479 solver.cpp:610] Iteration 22120, lr = 8.99886e-09
I0315 04:14:19.508220 29479 solver.cpp:613] Iteration 22120, avg_grad_norm = 552202
I0315 04:14:44.875026 29479 solver.cpp:214] Iteration 22140, loss = 6957.62
I0315 04:14:44.875157 29479 solver.cpp:229]     Train net output #0: loss = 4167.88 (* 1 = 4167.88 loss)
I0315 04:14:44.989604 29479 solver.cpp:610] Iteration 22140, lr = 8.99795e-09
I0315 04:14:44.989617 29479 solver.cpp:613] Iteration 22140, avg_grad_norm = 640570
I0315 04:15:10.579766 29479 solver.cpp:214] Iteration 22160, loss = 6488.06
I0315 04:15:10.579828 29479 solver.cpp:229]     Train net output #0: loss = 7457.69 (* 1 = 7457.69 loss)
I0315 04:15:10.694351 29479 solver.cpp:610] Iteration 22160, lr = 8.99704e-09
I0315 04:15:10.694365 29479 solver.cpp:613] Iteration 22160, avg_grad_norm = 587668
I0315 04:15:35.766993 29479 solver.cpp:214] Iteration 22180, loss = 6586.52
I0315 04:15:35.767138 29479 solver.cpp:229]     Train net output #0: loss = 5299.44 (* 1 = 5299.44 loss)
I0315 04:15:35.879976 29479 solver.cpp:610] Iteration 22180, lr = 8.99613e-09
I0315 04:15:35.879989 29479 solver.cpp:613] Iteration 22180, avg_grad_norm = 572734
I0315 04:16:01.434376 29479 solver.cpp:214] Iteration 22200, loss = 6730.06
I0315 04:16:01.434440 29479 solver.cpp:229]     Train net output #0: loss = 5825.67 (* 1 = 5825.67 loss)
I0315 04:16:01.548887 29479 solver.cpp:610] Iteration 22200, lr = 8.99522e-09
I0315 04:16:01.548900 29479 solver.cpp:613] Iteration 22200, avg_grad_norm = 640903
I0315 04:16:27.159868 29479 solver.cpp:214] Iteration 22220, loss = 6629.37
I0315 04:16:27.160064 29479 solver.cpp:229]     Train net output #0: loss = 7569.12 (* 1 = 7569.12 loss)
I0315 04:16:27.274474 29479 solver.cpp:610] Iteration 22220, lr = 8.9943e-09
I0315 04:16:27.274487 29479 solver.cpp:613] Iteration 22220, avg_grad_norm = 599629
I0315 04:17:08.338181 29479 solver.cpp:214] Iteration 22240, loss = 6685.88
I0315 04:17:08.338377 29479 solver.cpp:229]     Train net output #0: loss = 5774.89 (* 1 = 5774.89 loss)
I0315 04:17:08.443362 29479 solver.cpp:610] Iteration 22240, lr = 8.99339e-09
I0315 04:17:08.443377 29479 solver.cpp:613] Iteration 22240, avg_grad_norm = 581759
I0315 04:17:32.308570 29479 solver.cpp:214] Iteration 22260, loss = 6775.94
I0315 04:17:32.308637 29479 solver.cpp:229]     Train net output #0: loss = 6244.24 (* 1 = 6244.24 loss)
I0315 04:17:32.423125 29479 solver.cpp:610] Iteration 22260, lr = 8.99248e-09
I0315 04:17:32.423137 29479 solver.cpp:613] Iteration 22260, avg_grad_norm = 610421
I0315 04:17:57.967432 29479 solver.cpp:214] Iteration 22280, loss = 6859.26
I0315 04:17:57.967605 29479 solver.cpp:229]     Train net output #0: loss = 5150.73 (* 1 = 5150.73 loss)
I0315 04:17:58.082028 29479 solver.cpp:610] Iteration 22280, lr = 8.99157e-09
I0315 04:17:58.082041 29479 solver.cpp:613] Iteration 22280, avg_grad_norm = 544706
I0315 04:18:23.619367 29479 solver.cpp:214] Iteration 22300, loss = 6863.95
I0315 04:18:23.619448 29479 solver.cpp:229]     Train net output #0: loss = 5923.92 (* 1 = 5923.92 loss)
I0315 04:18:23.733980 29479 solver.cpp:610] Iteration 22300, lr = 8.99066e-09
I0315 04:18:23.733994 29479 solver.cpp:613] Iteration 22300, avg_grad_norm = 570549
I0315 04:18:49.077060 29479 solver.cpp:214] Iteration 22320, loss = 6744.63
I0315 04:18:49.077190 29479 solver.cpp:229]     Train net output #0: loss = 8537.71 (* 1 = 8537.71 loss)
I0315 04:18:49.189942 29479 solver.cpp:610] Iteration 22320, lr = 8.98975e-09
I0315 04:18:49.189955 29479 solver.cpp:613] Iteration 22320, avg_grad_norm = 534578
I0315 04:19:14.499238 29479 solver.cpp:214] Iteration 22340, loss = 6849.21
I0315 04:19:14.499307 29479 solver.cpp:229]     Train net output #0: loss = 6144.39 (* 1 = 6144.39 loss)
I0315 04:19:14.613873 29479 solver.cpp:610] Iteration 22340, lr = 8.98884e-09
I0315 04:19:14.613885 29479 solver.cpp:613] Iteration 22340, avg_grad_norm = 557509
I0315 04:19:52.102079 29479 solver.cpp:214] Iteration 22360, loss = 6859.56
I0315 04:19:52.102216 29479 solver.cpp:229]     Train net output #0: loss = 4276.32 (* 1 = 4276.32 loss)
I0315 04:19:52.207237 29479 solver.cpp:610] Iteration 22360, lr = 8.98793e-09
I0315 04:19:52.207249 29479 solver.cpp:613] Iteration 22360, avg_grad_norm = 578491
I0315 04:20:16.188230 29479 solver.cpp:214] Iteration 22380, loss = 6814.45
I0315 04:20:16.188303 29479 solver.cpp:229]     Train net output #0: loss = 11388.7 (* 1 = 11388.7 loss)
I0315 04:20:16.304343 29479 solver.cpp:610] Iteration 22380, lr = 8.98702e-09
I0315 04:20:16.304358 29479 solver.cpp:613] Iteration 22380, avg_grad_norm = 629133
I0315 04:20:42.122568 29479 solver.cpp:214] Iteration 22400, loss = 6748.29
I0315 04:20:42.122719 29479 solver.cpp:229]     Train net output #0: loss = 8084.32 (* 1 = 8084.32 loss)
I0315 04:20:42.237270 29479 solver.cpp:610] Iteration 22400, lr = 8.98611e-09
I0315 04:20:42.237284 29479 solver.cpp:613] Iteration 22400, avg_grad_norm = 572014
I0315 04:21:07.714104 29479 solver.cpp:214] Iteration 22420, loss = 6834.56
I0315 04:21:07.714169 29479 solver.cpp:229]     Train net output #0: loss = 6210.75 (* 1 = 6210.75 loss)
I0315 04:21:07.827083 29479 solver.cpp:610] Iteration 22420, lr = 8.9852e-09
I0315 04:21:07.827096 29479 solver.cpp:613] Iteration 22420, avg_grad_norm = 577473
I0315 04:21:33.202345 29479 solver.cpp:214] Iteration 22440, loss = 6598.29
I0315 04:21:33.202452 29479 solver.cpp:229]     Train net output #0: loss = 9408.74 (* 1 = 9408.74 loss)
I0315 04:21:33.318480 29479 solver.cpp:610] Iteration 22440, lr = 8.98429e-09
I0315 04:21:33.318493 29479 solver.cpp:613] Iteration 22440, avg_grad_norm = 569151
I0315 04:21:59.167300 29479 solver.cpp:214] Iteration 22460, loss = 6865.15
I0315 04:21:59.167363 29479 solver.cpp:229]     Train net output #0: loss = 6653.25 (* 1 = 6653.25 loss)
I0315 04:21:59.282043 29479 solver.cpp:610] Iteration 22460, lr = 8.98338e-09
I0315 04:21:59.282058 29479 solver.cpp:613] Iteration 22460, avg_grad_norm = 567763
I0315 04:22:37.282668 29479 solver.cpp:214] Iteration 22480, loss = 6547.77
I0315 04:22:37.282795 29479 solver.cpp:229]     Train net output #0: loss = 4407.1 (* 1 = 4407.1 loss)
I0315 04:22:37.388039 29479 solver.cpp:610] Iteration 22480, lr = 8.98247e-09
I0315 04:22:37.388053 29479 solver.cpp:613] Iteration 22480, avg_grad_norm = 554183
I0315 04:23:00.909386 29479 solver.cpp:214] Iteration 22500, loss = 6578.72
I0315 04:23:00.909452 29479 solver.cpp:229]     Train net output #0: loss = 7475.66 (* 1 = 7475.66 loss)
I0315 04:23:01.014506 29479 solver.cpp:610] Iteration 22500, lr = 8.98156e-09
I0315 04:23:01.014521 29479 solver.cpp:613] Iteration 22500, avg_grad_norm = 608600
I0315 04:23:26.134454 29479 solver.cpp:214] Iteration 22520, loss = 6586.14
I0315 04:23:26.134627 29479 solver.cpp:229]     Train net output #0: loss = 12819.5 (* 1 = 12819.5 loss)
I0315 04:23:26.248929 29479 solver.cpp:610] Iteration 22520, lr = 8.98064e-09
I0315 04:23:26.248942 29479 solver.cpp:613] Iteration 22520, avg_grad_norm = 631628
I0315 04:23:51.807114 29479 solver.cpp:214] Iteration 22540, loss = 6710.43
I0315 04:23:51.807178 29479 solver.cpp:229]     Train net output #0: loss = 6012.77 (* 1 = 6012.77 loss)
I0315 04:23:51.921725 29479 solver.cpp:610] Iteration 22540, lr = 8.97973e-09
I0315 04:23:51.921738 29479 solver.cpp:613] Iteration 22540, avg_grad_norm = 622216
I0315 04:24:17.540814 29479 solver.cpp:214] Iteration 22560, loss = 6710.16
I0315 04:24:17.540961 29479 solver.cpp:229]     Train net output #0: loss = 4444.84 (* 1 = 4444.84 loss)
I0315 04:24:17.655318 29479 solver.cpp:610] Iteration 22560, lr = 8.97882e-09
I0315 04:24:17.655331 29479 solver.cpp:613] Iteration 22560, avg_grad_norm = 604932
I0315 04:24:43.248922 29479 solver.cpp:214] Iteration 22580, loss = 7199.92
I0315 04:24:43.248975 29479 solver.cpp:229]     Train net output #0: loss = 13348.3 (* 1 = 13348.3 loss)
I0315 04:24:43.363512 29479 solver.cpp:610] Iteration 22580, lr = 8.97791e-09
I0315 04:24:43.363528 29479 solver.cpp:613] Iteration 22580, avg_grad_norm = 540722
I0315 04:25:08.959069 29479 solver.cpp:214] Iteration 22600, loss = 6550.15
I0315 04:25:08.959206 29479 solver.cpp:229]     Train net output #0: loss = 8502.75 (* 1 = 8502.75 loss)
I0315 04:25:09.073664 29479 solver.cpp:610] Iteration 22600, lr = 8.977e-09
I0315 04:25:09.073678 29479 solver.cpp:613] Iteration 22600, avg_grad_norm = 545469
I0315 04:25:45.905272 29479 solver.cpp:214] Iteration 22620, loss = 6762.35
I0315 04:25:45.905479 29479 solver.cpp:229]     Train net output #0: loss = 5826.62 (* 1 = 5826.62 loss)
I0315 04:25:46.009932 29479 solver.cpp:610] Iteration 22620, lr = 8.97609e-09
I0315 04:25:46.009945 29479 solver.cpp:613] Iteration 22620, avg_grad_norm = 557053
I0315 04:26:10.525583 29479 solver.cpp:214] Iteration 22640, loss = 6817.82
I0315 04:26:10.525652 29479 solver.cpp:229]     Train net output #0: loss = 5680.29 (* 1 = 5680.29 loss)
I0315 04:26:10.640244 29479 solver.cpp:610] Iteration 22640, lr = 8.97518e-09
I0315 04:26:10.640257 29479 solver.cpp:613] Iteration 22640, avg_grad_norm = 549554
I0315 04:26:36.180979 29479 solver.cpp:214] Iteration 22660, loss = 6668.16
I0315 04:26:36.181139 29479 solver.cpp:229]     Train net output #0: loss = 4931.1 (* 1 = 4931.1 loss)
I0315 04:26:36.295490 29479 solver.cpp:610] Iteration 22660, lr = 8.97427e-09
I0315 04:26:36.295503 29479 solver.cpp:613] Iteration 22660, avg_grad_norm = 594624
I0315 04:27:01.838011 29479 solver.cpp:214] Iteration 22680, loss = 6722.11
I0315 04:27:01.838083 29479 solver.cpp:229]     Train net output #0: loss = 5614.06 (* 1 = 5614.06 loss)
I0315 04:27:01.952566 29479 solver.cpp:610] Iteration 22680, lr = 8.97336e-09
I0315 04:27:01.952579 29479 solver.cpp:613] Iteration 22680, avg_grad_norm = 608839
I0315 04:27:27.494439 29479 solver.cpp:214] Iteration 22700, loss = 6784
I0315 04:27:27.494566 29479 solver.cpp:229]     Train net output #0: loss = 7058.79 (* 1 = 7058.79 loss)
I0315 04:27:27.609071 29479 solver.cpp:610] Iteration 22700, lr = 8.97245e-09
I0315 04:27:27.609083 29479 solver.cpp:613] Iteration 22700, avg_grad_norm = 541804
I0315 04:27:53.179590 29479 solver.cpp:214] Iteration 22720, loss = 6702.2
I0315 04:27:53.179656 29479 solver.cpp:229]     Train net output #0: loss = 9284.39 (* 1 = 9284.39 loss)
I0315 04:27:53.294364 29479 solver.cpp:610] Iteration 22720, lr = 8.97154e-09
I0315 04:27:53.294378 29479 solver.cpp:613] Iteration 22720, avg_grad_norm = 589765
I0315 04:28:31.111974 29479 solver.cpp:214] Iteration 22740, loss = 6476.32
I0315 04:28:31.112098 29479 solver.cpp:229]     Train net output #0: loss = 5750.48 (* 1 = 5750.48 loss)
I0315 04:28:31.217378 29479 solver.cpp:610] Iteration 22740, lr = 8.97062e-09
I0315 04:28:31.217392 29479 solver.cpp:613] Iteration 22740, avg_grad_norm = 534747
I0315 04:28:55.030936 29479 solver.cpp:214] Iteration 22760, loss = 6818
I0315 04:28:55.031014 29479 solver.cpp:229]     Train net output #0: loss = 4335.46 (* 1 = 4335.46 loss)
I0315 04:28:55.143956 29479 solver.cpp:610] Iteration 22760, lr = 8.96971e-09
I0315 04:28:55.143995 29479 solver.cpp:613] Iteration 22760, avg_grad_norm = 607884
I0315 04:29:20.727232 29479 solver.cpp:214] Iteration 22780, loss = 7024.67
I0315 04:29:20.727394 29479 solver.cpp:229]     Train net output #0: loss = 2490.51 (* 1 = 2490.51 loss)
I0315 04:29:20.841871 29479 solver.cpp:610] Iteration 22780, lr = 8.9688e-09
I0315 04:29:20.841883 29479 solver.cpp:613] Iteration 22780, avg_grad_norm = 562792
I0315 04:29:46.437736 29479 solver.cpp:214] Iteration 22800, loss = 6673.37
I0315 04:29:46.437819 29479 solver.cpp:229]     Train net output #0: loss = 5246.46 (* 1 = 5246.46 loss)
I0315 04:29:46.552346 29479 solver.cpp:610] Iteration 22800, lr = 8.96789e-09
I0315 04:29:46.552359 29479 solver.cpp:613] Iteration 22800, avg_grad_norm = 759410
I0315 04:30:12.146673 29479 solver.cpp:214] Iteration 22820, loss = 6851.4
I0315 04:30:12.146813 29479 solver.cpp:229]     Train net output #0: loss = 6864.01 (* 1 = 6864.01 loss)
I0315 04:30:12.261260 29479 solver.cpp:610] Iteration 22820, lr = 8.96698e-09
I0315 04:30:12.261273 29479 solver.cpp:613] Iteration 22820, avg_grad_norm = 642300
I0315 04:30:37.852787 29479 solver.cpp:214] Iteration 22840, loss = 6686.19
I0315 04:30:37.852855 29479 solver.cpp:229]     Train net output #0: loss = 3956.31 (* 1 = 3956.31 loss)
I0315 04:30:37.967461 29479 solver.cpp:610] Iteration 22840, lr = 8.96607e-09
I0315 04:30:37.967520 29479 solver.cpp:613] Iteration 22840, avg_grad_norm = 609924
I0315 04:31:31.991032 29479 solver.cpp:214] Iteration 22860, loss = 6712.01
I0315 04:31:31.991147 29479 solver.cpp:229]     Train net output #0: loss = 4908.06 (* 1 = 4908.06 loss)
I0315 04:31:32.094945 29479 solver.cpp:610] Iteration 22860, lr = 8.96516e-09
I0315 04:31:32.094959 29479 solver.cpp:613] Iteration 22860, avg_grad_norm = 626208
I0315 04:31:55.518002 29479 solver.cpp:214] Iteration 22880, loss = 6637.76
I0315 04:31:55.518062 29479 solver.cpp:229]     Train net output #0: loss = 3625.38 (* 1 = 3625.38 loss)
I0315 04:31:55.623261 29479 solver.cpp:610] Iteration 22880, lr = 8.96425e-09
I0315 04:31:55.623275 29479 solver.cpp:613] Iteration 22880, avg_grad_norm = 623034
I0315 04:32:19.147073 29479 solver.cpp:214] Iteration 22900, loss = 6937.4
I0315 04:32:19.147198 29479 solver.cpp:229]     Train net output #0: loss = 6043.7 (* 1 = 6043.7 loss)
I0315 04:32:19.252166 29479 solver.cpp:610] Iteration 22900, lr = 8.96334e-09
I0315 04:32:19.252179 29479 solver.cpp:613] Iteration 22900, avg_grad_norm = 641465
I0315 04:32:44.348556 29479 solver.cpp:214] Iteration 22920, loss = 6837.89
I0315 04:32:44.348618 29479 solver.cpp:229]     Train net output #0: loss = 5875.28 (* 1 = 5875.28 loss)
I0315 04:32:44.463165 29479 solver.cpp:610] Iteration 22920, lr = 8.96243e-09
I0315 04:32:44.463176 29479 solver.cpp:613] Iteration 22920, avg_grad_norm = 656861
I0315 04:33:09.839891 29479 solver.cpp:214] Iteration 22940, loss = 7146.02
I0315 04:33:09.840015 29479 solver.cpp:229]     Train net output #0: loss = 6883.95 (* 1 = 6883.95 loss)
I0315 04:33:09.952816 29479 solver.cpp:610] Iteration 22940, lr = 8.96151e-09
I0315 04:33:09.952829 29479 solver.cpp:613] Iteration 22940, avg_grad_norm = 634038
I0315 04:33:35.171187 29479 solver.cpp:214] Iteration 22960, loss = 6996.93
I0315 04:33:35.171255 29479 solver.cpp:229]     Train net output #0: loss = 4923.01 (* 1 = 4923.01 loss)
I0315 04:33:35.284248 29479 solver.cpp:610] Iteration 22960, lr = 8.9606e-09
I0315 04:33:35.284262 29479 solver.cpp:613] Iteration 22960, avg_grad_norm = 671005
I0315 04:34:00.854604 29479 solver.cpp:214] Iteration 22980, loss = 6869.17
I0315 04:34:00.854737 29479 solver.cpp:229]     Train net output #0: loss = 7762.36 (* 1 = 7762.36 loss)
I0315 04:34:00.969307 29479 solver.cpp:610] Iteration 22980, lr = 8.95969e-09
I0315 04:34:00.969321 29479 solver.cpp:613] Iteration 22980, avg_grad_norm = 679927
I0315 04:34:47.197674 29479 solver.cpp:214] Iteration 23000, loss = 6916.81
I0315 04:34:47.197887 29479 solver.cpp:229]     Train net output #0: loss = 9533.71 (* 1 = 9533.71 loss)
I0315 04:34:47.302871 29479 solver.cpp:610] Iteration 23000, lr = 8.95878e-09
I0315 04:34:47.302884 29479 solver.cpp:613] Iteration 23000, avg_grad_norm = 592733
I0315 04:35:10.805642 29479 solver.cpp:214] Iteration 23020, loss = 6890.59
I0315 04:35:10.805699 29479 solver.cpp:229]     Train net output #0: loss = 3369.37 (* 1 = 3369.37 loss)
I0315 04:35:10.910800 29479 solver.cpp:610] Iteration 23020, lr = 8.95787e-09
I0315 04:35:10.910815 29479 solver.cpp:613] Iteration 23020, avg_grad_norm = 575927
I0315 04:35:35.790729 29479 solver.cpp:214] Iteration 23040, loss = 6654.36
I0315 04:35:35.790945 29479 solver.cpp:229]     Train net output #0: loss = 5517.93 (* 1 = 5517.93 loss)
I0315 04:35:35.903748 29479 solver.cpp:610] Iteration 23040, lr = 8.95696e-09
I0315 04:35:35.903761 29479 solver.cpp:613] Iteration 23040, avg_grad_norm = 588155
I0315 04:36:01.345861 29479 solver.cpp:214] Iteration 23060, loss = 6797.68
I0315 04:36:01.345917 29479 solver.cpp:229]     Train net output #0: loss = 5992.21 (* 1 = 5992.21 loss)
I0315 04:36:01.460357 29479 solver.cpp:610] Iteration 23060, lr = 8.95605e-09
I0315 04:36:01.460369 29479 solver.cpp:613] Iteration 23060, avg_grad_norm = 600049
I0315 04:36:27.054836 29479 solver.cpp:214] Iteration 23080, loss = 6896.72
I0315 04:36:27.054955 29479 solver.cpp:229]     Train net output #0: loss = 6708.85 (* 1 = 6708.85 loss)
I0315 04:36:27.169314 29479 solver.cpp:610] Iteration 23080, lr = 8.95514e-09
I0315 04:36:27.169327 29479 solver.cpp:613] Iteration 23080, avg_grad_norm = 597058
I0315 04:36:52.554831 29479 solver.cpp:214] Iteration 23100, loss = 6492.19
I0315 04:36:52.554898 29479 solver.cpp:229]     Train net output #0: loss = 3866.24 (* 1 = 3866.24 loss)
I0315 04:36:52.666472 29479 solver.cpp:610] Iteration 23100, lr = 8.95423e-09
I0315 04:36:52.666486 29479 solver.cpp:613] Iteration 23100, avg_grad_norm = 548642
I0315 04:37:30.355512 29479 solver.cpp:214] Iteration 23120, loss = 6851.02
I0315 04:37:30.355635 29479 solver.cpp:229]     Train net output #0: loss = 5504.45 (* 1 = 5504.45 loss)
I0315 04:37:30.460973 29479 solver.cpp:610] Iteration 23120, lr = 8.95332e-09
I0315 04:37:30.460986 29479 solver.cpp:613] Iteration 23120, avg_grad_norm = 568613
I0315 04:37:54.130102 29479 solver.cpp:214] Iteration 23140, loss = 6640.91
I0315 04:37:54.130159 29479 solver.cpp:229]     Train net output #0: loss = 8668.1 (* 1 = 8668.1 loss)
I0315 04:37:54.243038 29479 solver.cpp:610] Iteration 23140, lr = 8.9524e-09
I0315 04:37:54.243052 29479 solver.cpp:613] Iteration 23140, avg_grad_norm = 578535
I0315 04:38:19.808691 29479 solver.cpp:214] Iteration 23160, loss = 6536.01
I0315 04:38:19.808918 29479 solver.cpp:229]     Train net output #0: loss = 5537.01 (* 1 = 5537.01 loss)
I0315 04:38:19.923302 29479 solver.cpp:610] Iteration 23160, lr = 8.95149e-09
I0315 04:38:19.923316 29479 solver.cpp:613] Iteration 23160, avg_grad_norm = 611450
I0315 04:38:45.494513 29479 solver.cpp:214] Iteration 23180, loss = 6814.61
I0315 04:38:45.494572 29479 solver.cpp:229]     Train net output #0: loss = 3649.53 (* 1 = 3649.53 loss)
I0315 04:38:45.609184 29479 solver.cpp:610] Iteration 23180, lr = 8.95058e-09
I0315 04:38:45.609197 29479 solver.cpp:613] Iteration 23180, avg_grad_norm = 606191
I0315 04:39:11.236827 29479 solver.cpp:214] Iteration 23200, loss = 6885.57
I0315 04:39:11.236964 29479 solver.cpp:229]     Train net output #0: loss = 5808.17 (* 1 = 5808.17 loss)
I0315 04:39:11.350006 29479 solver.cpp:610] Iteration 23200, lr = 8.94967e-09
I0315 04:39:11.350020 29479 solver.cpp:613] Iteration 23200, avg_grad_norm = 544600
I0315 04:39:36.607861 29479 solver.cpp:214] Iteration 23220, loss = 6942.8
I0315 04:39:36.607931 29479 solver.cpp:229]     Train net output #0: loss = 4374.46 (* 1 = 4374.46 loss)
I0315 04:39:36.720875 29479 solver.cpp:610] Iteration 23220, lr = 8.94876e-09
I0315 04:39:36.720890 29479 solver.cpp:613] Iteration 23220, avg_grad_norm = 565344
I0315 04:40:15.039618 29479 solver.cpp:214] Iteration 23240, loss = 6819.13
I0315 04:40:15.039826 29479 solver.cpp:229]     Train net output #0: loss = 6012.67 (* 1 = 6012.67 loss)
I0315 04:40:15.144811 29479 solver.cpp:610] Iteration 23240, lr = 8.94785e-09
I0315 04:40:15.144824 29479 solver.cpp:613] Iteration 23240, avg_grad_norm = 630465
I0315 04:40:38.584206 29479 solver.cpp:214] Iteration 23260, loss = 6892.36
I0315 04:40:38.584277 29479 solver.cpp:229]     Train net output #0: loss = 6020.46 (* 1 = 6020.46 loss)
I0315 04:40:38.689429 29479 solver.cpp:610] Iteration 23260, lr = 8.94694e-09
I0315 04:40:38.689442 29479 solver.cpp:613] Iteration 23260, avg_grad_norm = 655561
I0315 04:41:03.612951 29479 solver.cpp:214] Iteration 23280, loss = 6646.88
I0315 04:41:03.613124 29479 solver.cpp:229]     Train net output #0: loss = 6059.68 (* 1 = 6059.68 loss)
I0315 04:41:03.727433 29479 solver.cpp:610] Iteration 23280, lr = 8.94603e-09
I0315 04:41:03.727447 29479 solver.cpp:613] Iteration 23280, avg_grad_norm = 562681
I0315 04:41:29.267251 29479 solver.cpp:214] Iteration 23300, loss = 6957.72
I0315 04:41:29.267319 29479 solver.cpp:229]     Train net output #0: loss = 6097.75 (* 1 = 6097.75 loss)
I0315 04:41:29.381970 29479 solver.cpp:610] Iteration 23300, lr = 8.94511e-09
I0315 04:41:29.381983 29479 solver.cpp:613] Iteration 23300, avg_grad_norm = 595023
I0315 04:41:54.923753 29479 solver.cpp:214] Iteration 23320, loss = 6608.61
I0315 04:41:54.923933 29479 solver.cpp:229]     Train net output #0: loss = 9301.45 (* 1 = 9301.45 loss)
I0315 04:41:55.038430 29479 solver.cpp:610] Iteration 23320, lr = 8.9442e-09
I0315 04:41:55.038442 29479 solver.cpp:613] Iteration 23320, avg_grad_norm = 546288
I0315 04:42:20.581703 29479 solver.cpp:214] Iteration 23340, loss = 6748.04
I0315 04:42:20.581773 29479 solver.cpp:229]     Train net output #0: loss = 6361.81 (* 1 = 6361.81 loss)
I0315 04:42:20.696261 29479 solver.cpp:610] Iteration 23340, lr = 8.94329e-09
I0315 04:42:20.696274 29479 solver.cpp:613] Iteration 23340, avg_grad_norm = 591288
I0315 04:42:45.980645 29479 solver.cpp:214] Iteration 23360, loss = 6724.26
I0315 04:42:45.980774 29479 solver.cpp:229]     Train net output #0: loss = 5990.21 (* 1 = 5990.21 loss)
I0315 04:42:46.093792 29479 solver.cpp:610] Iteration 23360, lr = 8.94238e-09
I0315 04:42:46.093804 29479 solver.cpp:613] Iteration 23360, avg_grad_norm = 585459
I0315 04:43:23.038507 29479 solver.cpp:214] Iteration 23380, loss = 7102.56
I0315 04:43:23.038617 29479 solver.cpp:229]     Train net output #0: loss = 7897.62 (* 1 = 7897.62 loss)
I0315 04:43:23.143019 29479 solver.cpp:610] Iteration 23380, lr = 8.94147e-09
I0315 04:43:23.143033 29479 solver.cpp:613] Iteration 23380, avg_grad_norm = 699794
I0315 04:43:47.345449 29479 solver.cpp:214] Iteration 23400, loss = 6807.82
I0315 04:43:47.345499 29479 solver.cpp:229]     Train net output #0: loss = 10103.8 (* 1 = 10103.8 loss)
I0315 04:43:47.458585 29479 solver.cpp:610] Iteration 23400, lr = 8.94056e-09
I0315 04:43:47.458600 29479 solver.cpp:613] Iteration 23400, avg_grad_norm = 671564
I0315 04:44:12.911577 29479 solver.cpp:214] Iteration 23420, loss = 6397.01
I0315 04:44:12.911721 29479 solver.cpp:229]     Train net output #0: loss = 5772.05 (* 1 = 5772.05 loss)
I0315 04:44:13.026388 29479 solver.cpp:610] Iteration 23420, lr = 8.93965e-09
I0315 04:44:13.026430 29479 solver.cpp:613] Iteration 23420, avg_grad_norm = 703274
I0315 04:44:38.639622 29479 solver.cpp:214] Iteration 23440, loss = 6749.36
I0315 04:44:38.639690 29479 solver.cpp:229]     Train net output #0: loss = 6577.29 (* 1 = 6577.29 loss)
I0315 04:44:38.754348 29479 solver.cpp:610] Iteration 23440, lr = 8.93874e-09
I0315 04:44:38.754364 29479 solver.cpp:613] Iteration 23440, avg_grad_norm = 696841
I0315 04:45:04.351655 29479 solver.cpp:214] Iteration 23460, loss = 6651.23
I0315 04:45:04.351790 29479 solver.cpp:229]     Train net output #0: loss = 4605.57 (* 1 = 4605.57 loss)
I0315 04:45:04.466243 29479 solver.cpp:610] Iteration 23460, lr = 8.93782e-09
I0315 04:45:04.466256 29479 solver.cpp:613] Iteration 23460, avg_grad_norm = 560316
I0315 04:45:30.068104 29479 solver.cpp:214] Iteration 23480, loss = 6606.83
I0315 04:45:30.068173 29479 solver.cpp:229]     Train net output #0: loss = 5451.18 (* 1 = 5451.18 loss)
I0315 04:45:30.182663 29479 solver.cpp:610] Iteration 23480, lr = 8.93691e-09
I0315 04:45:30.182677 29479 solver.cpp:613] Iteration 23480, avg_grad_norm = 565578
I0315 04:46:20.924934 29479 solver.cpp:214] Iteration 23500, loss = 6856.69
I0315 04:46:20.925119 29479 solver.cpp:229]     Train net output #0: loss = 8464.65 (* 1 = 8464.65 loss)
I0315 04:46:21.030237 29479 solver.cpp:610] Iteration 23500, lr = 8.936e-09
I0315 04:46:21.030253 29479 solver.cpp:613] Iteration 23500, avg_grad_norm = 610342
I0315 04:46:44.515545 29479 solver.cpp:214] Iteration 23520, loss = 6770.86
I0315 04:46:44.515610 29479 solver.cpp:229]     Train net output #0: loss = 3914.69 (* 1 = 3914.69 loss)
I0315 04:46:44.621019 29479 solver.cpp:610] Iteration 23520, lr = 8.93509e-09
I0315 04:46:44.621042 29479 solver.cpp:613] Iteration 23520, avg_grad_norm = 599378
I0315 04:47:08.319368 29479 solver.cpp:214] Iteration 23540, loss = 6883.64
I0315 04:47:08.319499 29479 solver.cpp:229]     Train net output #0: loss = 4270.51 (* 1 = 4270.51 loss)
I0315 04:47:08.431087 29479 solver.cpp:610] Iteration 23540, lr = 8.93418e-09
I0315 04:47:08.431100 29479 solver.cpp:613] Iteration 23540, avg_grad_norm = 638701
I0315 04:47:33.655252 29479 solver.cpp:214] Iteration 23560, loss = 7016.27
I0315 04:47:33.655315 29479 solver.cpp:229]     Train net output #0: loss = 5960.04 (* 1 = 5960.04 loss)
I0315 04:47:33.768237 29479 solver.cpp:610] Iteration 23560, lr = 8.93327e-09
I0315 04:47:33.768252 29479 solver.cpp:613] Iteration 23560, avg_grad_norm = 635528
I0315 04:47:59.087904 29479 solver.cpp:214] Iteration 23580, loss = 6787.68
I0315 04:47:59.088037 29479 solver.cpp:229]     Train net output #0: loss = 4927.51 (* 1 = 4927.51 loss)
I0315 04:47:59.203977 29479 solver.cpp:610] Iteration 23580, lr = 8.93236e-09
I0315 04:47:59.203991 29479 solver.cpp:613] Iteration 23580, avg_grad_norm = 706205
I0315 04:48:25.003113 29479 solver.cpp:214] Iteration 23600, loss = 6809.91
I0315 04:48:25.003165 29479 solver.cpp:229]     Train net output #0: loss = 7364.8 (* 1 = 7364.8 loss)
I0315 04:48:25.117926 29479 solver.cpp:610] Iteration 23600, lr = 8.93144e-09
I0315 04:48:25.117944 29479 solver.cpp:613] Iteration 23600, avg_grad_norm = 602559
I0315 04:49:26.558359 29479 solver.cpp:214] Iteration 23620, loss = 6708.09
I0315 04:49:26.558498 29479 solver.cpp:229]     Train net output #0: loss = 5308.69 (* 1 = 5308.69 loss)
I0315 04:49:26.679401 29479 solver.cpp:610] Iteration 23620, lr = 8.93053e-09
I0315 04:49:26.679415 29479 solver.cpp:613] Iteration 23620, avg_grad_norm = 612961
I0315 04:49:50.075194 29479 solver.cpp:214] Iteration 23640, loss = 6632.41
I0315 04:49:50.075284 29479 solver.cpp:229]     Train net output #0: loss = 12608.1 (* 1 = 12608.1 loss)
I0315 04:49:50.180521 29479 solver.cpp:610] Iteration 23640, lr = 8.92962e-09
I0315 04:49:50.180534 29479 solver.cpp:613] Iteration 23640, avg_grad_norm = 578541
I0315 04:50:13.635627 29479 solver.cpp:214] Iteration 23660, loss = 6610.9
I0315 04:50:13.635726 29479 solver.cpp:229]     Train net output #0: loss = 4527.47 (* 1 = 4527.47 loss)
I0315 04:50:13.740823 29479 solver.cpp:610] Iteration 23660, lr = 8.92871e-09
I0315 04:50:13.740839 29479 solver.cpp:613] Iteration 23660, avg_grad_norm = 579450
I0315 04:50:37.429548 29479 solver.cpp:214] Iteration 23680, loss = 6506.6
I0315 04:50:37.429616 29479 solver.cpp:229]     Train net output #0: loss = 5856.45 (* 1 = 5856.45 loss)
I0315 04:50:37.541086 29479 solver.cpp:610] Iteration 23680, lr = 8.9278e-09
I0315 04:50:37.541101 29479 solver.cpp:613] Iteration 23680, avg_grad_norm = 631233
I0315 04:51:02.475993 29479 solver.cpp:214] Iteration 23700, loss = 6433.47
I0315 04:51:02.476142 29479 solver.cpp:229]     Train net output #0: loss = 3086.36 (* 1 = 3086.36 loss)
I0315 04:51:02.587748 29479 solver.cpp:610] Iteration 23700, lr = 8.92689e-09
I0315 04:51:02.587761 29479 solver.cpp:613] Iteration 23700, avg_grad_norm = 613809
I0315 04:51:27.955376 29479 solver.cpp:214] Iteration 23720, loss = 6564.96
I0315 04:51:27.955440 29479 solver.cpp:229]     Train net output #0: loss = 8733.98 (* 1 = 8733.98 loss)
I0315 04:51:28.069939 29479 solver.cpp:610] Iteration 23720, lr = 8.92598e-09
I0315 04:51:28.069952 29479 solver.cpp:613] Iteration 23720, avg_grad_norm = 534801
I0315 04:51:53.648705 29479 solver.cpp:214] Iteration 23740, loss = 6797.84
I0315 04:51:53.648895 29479 solver.cpp:229]     Train net output #0: loss = 7895.99 (* 1 = 7895.99 loss)
I0315 04:51:53.763191 29479 solver.cpp:610] Iteration 23740, lr = 8.92507e-09
I0315 04:51:53.763206 29479 solver.cpp:613] Iteration 23740, avg_grad_norm = 583308
I0315 04:52:30.812909 29479 solver.cpp:214] Iteration 23760, loss = 6729.51
I0315 04:52:30.813045 29479 solver.cpp:229]     Train net output #0: loss = 3552.67 (* 1 = 3552.67 loss)
I0315 04:52:30.918092 29479 solver.cpp:610] Iteration 23760, lr = 8.92415e-09
I0315 04:52:30.918104 29479 solver.cpp:613] Iteration 23760, avg_grad_norm = 629997
I0315 04:52:54.924598 29479 solver.cpp:214] Iteration 23780, loss = 6849.21
I0315 04:52:54.924669 29479 solver.cpp:229]     Train net output #0: loss = 5691.72 (* 1 = 5691.72 loss)
I0315 04:52:55.039310 29479 solver.cpp:610] Iteration 23780, lr = 8.92324e-09
I0315 04:52:55.039324 29479 solver.cpp:613] Iteration 23780, avg_grad_norm = 565941
I0315 04:53:20.623685 29479 solver.cpp:214] Iteration 23800, loss = 6779.82
I0315 04:53:20.623857 29479 solver.cpp:229]     Train net output #0: loss = 11135.8 (* 1 = 11135.8 loss)
I0315 04:53:20.738703 29479 solver.cpp:610] Iteration 23800, lr = 8.92233e-09
I0315 04:53:20.738730 29479 solver.cpp:613] Iteration 23800, avg_grad_norm = 635952
I0315 04:53:46.313640 29479 solver.cpp:214] Iteration 23820, loss = 6772.01
I0315 04:53:46.313697 29479 solver.cpp:229]     Train net output #0: loss = 11967.9 (* 1 = 11967.9 loss)
I0315 04:53:46.428326 29479 solver.cpp:610] Iteration 23820, lr = 8.92142e-09
I0315 04:53:46.428339 29479 solver.cpp:613] Iteration 23820, avg_grad_norm = 587819
I0315 04:54:11.678954 29479 solver.cpp:214] Iteration 23840, loss = 6727.13
I0315 04:54:11.679110 29479 solver.cpp:229]     Train net output #0: loss = 5464.76 (* 1 = 5464.76 loss)
I0315 04:54:11.791928 29479 solver.cpp:610] Iteration 23840, lr = 8.92051e-09
I0315 04:54:11.791940 29479 solver.cpp:613] Iteration 23840, avg_grad_norm = 616848
I0315 04:54:37.082260 29479 solver.cpp:214] Iteration 23860, loss = 6775.21
I0315 04:54:37.082319 29479 solver.cpp:229]     Train net output #0: loss = 4259.26 (* 1 = 4259.26 loss)
I0315 04:54:37.196789 29479 solver.cpp:610] Iteration 23860, lr = 8.9196e-09
I0315 04:54:37.196801 29479 solver.cpp:613] Iteration 23860, avg_grad_norm = 594004
I0315 04:55:15.662053 29479 solver.cpp:214] Iteration 23880, loss = 6724.35
I0315 04:55:15.662161 29479 solver.cpp:229]     Train net output #0: loss = 5649.9 (* 1 = 5649.9 loss)
I0315 04:55:15.767330 29479 solver.cpp:610] Iteration 23880, lr = 8.91868e-09
I0315 04:55:15.767345 29479 solver.cpp:613] Iteration 23880, avg_grad_norm = 543798
I0315 04:55:39.228927 29479 solver.cpp:214] Iteration 23900, loss = 6546.46
I0315 04:55:39.228963 29479 solver.cpp:229]     Train net output #0: loss = 4553.44 (* 1 = 4553.44 loss)
I0315 04:55:39.334017 29479 solver.cpp:610] Iteration 23900, lr = 8.91777e-09
I0315 04:55:39.334031 29479 solver.cpp:613] Iteration 23900, avg_grad_norm = 677276
I0315 04:56:04.729513 29479 solver.cpp:214] Iteration 23920, loss = 6833.3
I0315 04:56:04.729671 29479 solver.cpp:229]     Train net output #0: loss = 4507.4 (* 1 = 4507.4 loss)
I0315 04:56:04.843993 29479 solver.cpp:610] Iteration 23920, lr = 8.91686e-09
I0315 04:56:04.844007 29479 solver.cpp:613] Iteration 23920, avg_grad_norm = 672547
I0315 04:56:30.429908 29479 solver.cpp:214] Iteration 23940, loss = 6932.65
I0315 04:56:30.429980 29479 solver.cpp:229]     Train net output #0: loss = 5128.71 (* 1 = 5128.71 loss)
I0315 04:56:30.544409 29479 solver.cpp:610] Iteration 23940, lr = 8.91595e-09
I0315 04:56:30.544422 29479 solver.cpp:613] Iteration 23940, avg_grad_norm = 713477
I0315 04:56:55.855023 29479 solver.cpp:214] Iteration 23960, loss = 6785.33
I0315 04:56:55.855276 29479 solver.cpp:229]     Train net output #0: loss = 5422.88 (* 1 = 5422.88 loss)
I0315 04:56:55.967888 29479 solver.cpp:610] Iteration 23960, lr = 8.91504e-09
I0315 04:56:55.967902 29479 solver.cpp:613] Iteration 23960, avg_grad_norm = 648627
I0315 04:57:21.295428 29479 solver.cpp:214] Iteration 23980, loss = 6429.16
I0315 04:57:21.295502 29479 solver.cpp:229]     Train net output #0: loss = 7900.03 (* 1 = 7900.03 loss)
I0315 04:57:21.409941 29479 solver.cpp:610] Iteration 23980, lr = 8.91413e-09
I0315 04:57:21.409955 29479 solver.cpp:613] Iteration 23980, avg_grad_norm = 613680
I0315 04:57:46.962771 29479 solver.cpp:214] Iteration 24000, loss = 6349.02
I0315 04:57:46.962991 29479 solver.cpp:229]     Train net output #0: loss = 11432.4 (* 1 = 11432.4 loss)
I0315 04:57:47.077400 29479 solver.cpp:610] Iteration 24000, lr = 8.91322e-09
I0315 04:57:47.077414 29479 solver.cpp:613] Iteration 24000, avg_grad_norm = 556513
I0315 04:58:32.447381 29479 solver.cpp:214] Iteration 24020, loss = 6467.21
I0315 04:58:32.447466 29479 solver.cpp:229]     Train net output #0: loss = 3348.26 (* 1 = 3348.26 loss)
I0315 04:58:32.551672 29479 solver.cpp:610] Iteration 24020, lr = 8.9123e-09
I0315 04:58:32.551686 29479 solver.cpp:613] Iteration 24020, avg_grad_norm = 541897
I0315 04:58:56.090335 29479 solver.cpp:214] Iteration 24040, loss = 6633.7
I0315 04:58:56.090395 29479 solver.cpp:229]     Train net output #0: loss = 6590.27 (* 1 = 6590.27 loss)
I0315 04:58:56.201891 29479 solver.cpp:610] Iteration 24040, lr = 8.91139e-09
I0315 04:58:56.201905 29479 solver.cpp:613] Iteration 24040, avg_grad_norm = 588251
I0315 04:59:21.482899 29479 solver.cpp:214] Iteration 24060, loss = 6493.68
I0315 04:59:21.483045 29479 solver.cpp:229]     Train net output #0: loss = 3972.79 (* 1 = 3972.79 loss)
I0315 04:59:21.597512 29479 solver.cpp:610] Iteration 24060, lr = 8.91048e-09
I0315 04:59:21.597527 29479 solver.cpp:613] Iteration 24060, avg_grad_norm = 585181
I0315 04:59:47.153884 29479 solver.cpp:214] Iteration 24080, loss = 6548.14
I0315 04:59:47.153955 29479 solver.cpp:229]     Train net output #0: loss = 8215.62 (* 1 = 8215.62 loss)
I0315 04:59:47.268635 29479 solver.cpp:610] Iteration 24080, lr = 8.90957e-09
I0315 04:59:47.268648 29479 solver.cpp:613] Iteration 24080, avg_grad_norm = 581369
I0315 05:00:12.807220 29479 solver.cpp:214] Iteration 24100, loss = 6520.99
I0315 05:00:12.807370 29479 solver.cpp:229]     Train net output #0: loss = 6265.29 (* 1 = 6265.29 loss)
I0315 05:00:12.920138 29479 solver.cpp:610] Iteration 24100, lr = 8.90866e-09
I0315 05:00:12.920152 29479 solver.cpp:613] Iteration 24100, avg_grad_norm = 633594
I0315 05:00:38.112844 29479 solver.cpp:214] Iteration 24120, loss = 6568.76
I0315 05:00:38.112915 29479 solver.cpp:229]     Train net output #0: loss = 8457.46 (* 1 = 8457.46 loss)
I0315 05:00:38.225935 29479 solver.cpp:610] Iteration 24120, lr = 8.90775e-09
I0315 05:00:38.225950 29479 solver.cpp:613] Iteration 24120, avg_grad_norm = 589043
I0315 05:01:33.846352 29479 solver.cpp:214] Iteration 24140, loss = 6617.13
I0315 05:01:33.846506 29479 solver.cpp:229]     Train net output #0: loss = 6308.56 (* 1 = 6308.56 loss)
I0315 05:01:33.951799 29479 solver.cpp:610] Iteration 24140, lr = 8.90683e-09
I0315 05:01:33.951812 29479 solver.cpp:613] Iteration 24140, avg_grad_norm = 504182
I0315 05:01:57.388175 29479 solver.cpp:214] Iteration 24160, loss = 6683.19
I0315 05:01:57.388224 29479 solver.cpp:229]     Train net output #0: loss = 5365.08 (* 1 = 5365.08 loss)
I0315 05:01:57.493347 29479 solver.cpp:610] Iteration 24160, lr = 8.90592e-09
I0315 05:01:57.493361 29479 solver.cpp:613] Iteration 24160, avg_grad_norm = 679558
I0315 05:02:21.149994 29479 solver.cpp:214] Iteration 24180, loss = 6419.35
I0315 05:02:21.150106 29479 solver.cpp:229]     Train net output #0: loss = 8117.93 (* 1 = 8117.93 loss)
I0315 05:02:21.261711 29479 solver.cpp:610] Iteration 24180, lr = 8.90501e-09
I0315 05:02:21.261725 29479 solver.cpp:613] Iteration 24180, avg_grad_norm = 575625
I0315 05:02:46.351824 29479 solver.cpp:214] Iteration 24200, loss = 6805.19
I0315 05:02:46.351891 29479 solver.cpp:229]     Train net output #0: loss = 3093.81 (* 1 = 3093.81 loss)
I0315 05:02:46.464951 29479 solver.cpp:610] Iteration 24200, lr = 8.9041e-09
I0315 05:02:46.464963 29479 solver.cpp:613] Iteration 24200, avg_grad_norm = 631391
I0315 05:03:11.806148 29479 solver.cpp:214] Iteration 24220, loss = 6435.97
I0315 05:03:11.806313 29479 solver.cpp:229]     Train net output #0: loss = 9188.47 (* 1 = 9188.47 loss)
I0315 05:03:11.920809 29479 solver.cpp:610] Iteration 24220, lr = 8.90319e-09
I0315 05:03:11.920825 29479 solver.cpp:613] Iteration 24220, avg_grad_norm = 732649
I0315 05:03:37.470948 29479 solver.cpp:214] Iteration 24240, loss = 6609.53
I0315 05:03:37.471019 29479 solver.cpp:229]     Train net output #0: loss = 5865.01 (* 1 = 5865.01 loss)
I0315 05:03:37.585443 29479 solver.cpp:610] Iteration 24240, lr = 8.90228e-09
I0315 05:03:37.585458 29479 solver.cpp:613] Iteration 24240, avg_grad_norm = 684940
I0315 05:04:32.138793 29479 solver.cpp:214] Iteration 24260, loss = 6457.95
I0315 05:04:32.138937 29479 solver.cpp:229]     Train net output #0: loss = 13521.2 (* 1 = 13521.2 loss)
I0315 05:04:32.244024 29479 solver.cpp:610] Iteration 24260, lr = 8.90136e-09
I0315 05:04:32.244036 29479 solver.cpp:613] Iteration 24260, avg_grad_norm = 647252
I0315 05:04:55.652536 29479 solver.cpp:214] Iteration 24280, loss = 6602.77
I0315 05:04:55.652606 29479 solver.cpp:229]     Train net output #0: loss = 10116.8 (* 1 = 10116.8 loss)
I0315 05:04:55.756960 29479 solver.cpp:610] Iteration 24280, lr = 8.90045e-09
I0315 05:04:55.756973 29479 solver.cpp:613] Iteration 24280, avg_grad_norm = 601302
I0315 05:05:19.212231 29479 solver.cpp:214] Iteration 24300, loss = 6876.34
I0315 05:05:19.212332 29479 solver.cpp:229]     Train net output #0: loss = 5323.8 (* 1 = 5323.8 loss)
I0315 05:05:19.317551 29479 solver.cpp:610] Iteration 24300, lr = 8.89954e-09
I0315 05:05:19.317564 29479 solver.cpp:613] Iteration 24300, avg_grad_norm = 582518
I0315 05:05:43.921941 29479 solver.cpp:214] Iteration 24320, loss = 6555.78
I0315 05:05:43.922008 29479 solver.cpp:229]     Train net output #0: loss = 4896.29 (* 1 = 4896.29 loss)
I0315 05:05:44.035048 29479 solver.cpp:610] Iteration 24320, lr = 8.89863e-09
I0315 05:05:44.035061 29479 solver.cpp:613] Iteration 24320, avg_grad_norm = 551338
I0315 05:06:09.595664 29479 solver.cpp:214] Iteration 24340, loss = 6411.4
I0315 05:06:09.595793 29479 solver.cpp:229]     Train net output #0: loss = 6871.49 (* 1 = 6871.49 loss)
I0315 05:06:09.710245 29479 solver.cpp:610] Iteration 24340, lr = 8.89772e-09
I0315 05:06:09.710295 29479 solver.cpp:613] Iteration 24340, avg_grad_norm = 556331
I0315 05:06:35.150451 29479 solver.cpp:214] Iteration 24360, loss = 7062.37
I0315 05:06:35.150504 29479 solver.cpp:229]     Train net output #0: loss = 4382.77 (* 1 = 4382.77 loss)
I0315 05:06:35.263442 29479 solver.cpp:610] Iteration 24360, lr = 8.89681e-09
I0315 05:06:35.263475 29479 solver.cpp:613] Iteration 24360, avg_grad_norm = 609470
I0315 05:07:00.567770 29479 solver.cpp:214] Iteration 24380, loss = 6689.64
I0315 05:07:00.567963 29479 solver.cpp:229]     Train net output #0: loss = 12619.4 (* 1 = 12619.4 loss)
I0315 05:07:00.680992 29479 solver.cpp:610] Iteration 24380, lr = 8.89589e-09
I0315 05:07:00.681010 29479 solver.cpp:613] Iteration 24380, avg_grad_norm = 691829
I0315 05:07:37.537363 29479 solver.cpp:214] Iteration 24400, loss = 6731.43
I0315 05:07:37.537529 29479 solver.cpp:229]     Train net output #0: loss = 6029.01 (* 1 = 6029.01 loss)
I0315 05:07:37.642494 29479 solver.cpp:610] Iteration 24400, lr = 8.89498e-09
I0315 05:07:37.642511 29479 solver.cpp:613] Iteration 24400, avg_grad_norm = 922968
I0315 05:08:02.076336 29479 solver.cpp:214] Iteration 24420, loss = 6677.84
I0315 05:08:02.076403 29479 solver.cpp:229]     Train net output #0: loss = 3860.73 (* 1 = 3860.73 loss)
I0315 05:08:02.190943 29479 solver.cpp:610] Iteration 24420, lr = 8.89407e-09
I0315 05:08:02.190956 29479 solver.cpp:613] Iteration 24420, avg_grad_norm = 594879
I0315 05:08:27.740036 29479 solver.cpp:214] Iteration 24440, loss = 6599.09
I0315 05:08:27.740236 29479 solver.cpp:229]     Train net output #0: loss = 5997.07 (* 1 = 5997.07 loss)
I0315 05:08:27.854748 29479 solver.cpp:610] Iteration 24440, lr = 8.89316e-09
I0315 05:08:27.854760 29479 solver.cpp:613] Iteration 24440, avg_grad_norm = 650454
I0315 05:08:53.408220 29479 solver.cpp:214] Iteration 24460, loss = 6724.63
I0315 05:08:53.408291 29479 solver.cpp:229]     Train net output #0: loss = 6373.02 (* 1 = 6373.02 loss)
I0315 05:08:53.522835 29479 solver.cpp:610] Iteration 24460, lr = 8.89225e-09
I0315 05:08:53.522850 29479 solver.cpp:613] Iteration 24460, avg_grad_norm = 572852
I0315 05:09:19.115751 29479 solver.cpp:214] Iteration 24480, loss = 6598.21
I0315 05:09:19.115854 29479 solver.cpp:229]     Train net output #0: loss = 7929.99 (* 1 = 7929.99 loss)
I0315 05:09:19.230643 29479 solver.cpp:610] Iteration 24480, lr = 8.89133e-09
I0315 05:09:19.230656 29479 solver.cpp:613] Iteration 24480, avg_grad_norm = 561143
I0315 05:09:44.787853 29479 solver.cpp:214] Iteration 24500, loss = 6506.14
I0315 05:09:44.787920 29479 solver.cpp:229]     Train net output #0: loss = 4163.91 (* 1 = 4163.91 loss)
I0315 05:09:44.902604 29479 solver.cpp:610] Iteration 24500, lr = 8.89042e-09
I0315 05:09:44.902618 29479 solver.cpp:613] Iteration 24500, avg_grad_norm = 569502
I0315 05:10:22.511605 29479 solver.cpp:214] Iteration 24520, loss = 6827.03
I0315 05:10:22.511741 29479 solver.cpp:229]     Train net output #0: loss = 7382.75 (* 1 = 7382.75 loss)
I0315 05:10:22.616673 29479 solver.cpp:610] Iteration 24520, lr = 8.88951e-09
I0315 05:10:22.616686 29479 solver.cpp:613] Iteration 24520, avg_grad_norm = 563222
I0315 05:10:46.451952 29479 solver.cpp:214] Iteration 24540, loss = 6607.32
I0315 05:10:46.452021 29479 solver.cpp:229]     Train net output #0: loss = 7114.13 (* 1 = 7114.13 loss)
I0315 05:10:46.567901 29479 solver.cpp:610] Iteration 24540, lr = 8.8886e-09
I0315 05:10:46.567914 29479 solver.cpp:613] Iteration 24540, avg_grad_norm = 593036
I0315 05:11:12.294193 29479 solver.cpp:214] Iteration 24560, loss = 6803.17
I0315 05:11:12.294378 29479 solver.cpp:229]     Train net output #0: loss = 4325.11 (* 1 = 4325.11 loss)
I0315 05:11:12.408805 29479 solver.cpp:610] Iteration 24560, lr = 8.88769e-09
I0315 05:11:12.408820 29479 solver.cpp:613] Iteration 24560, avg_grad_norm = 594507
I0315 05:11:37.664050 29479 solver.cpp:214] Iteration 24580, loss = 6950.43
I0315 05:11:37.664106 29479 solver.cpp:229]     Train net output #0: loss = 8721.95 (* 1 = 8721.95 loss)
I0315 05:11:37.776914 29479 solver.cpp:610] Iteration 24580, lr = 8.88677e-09
I0315 05:11:37.776947 29479 solver.cpp:613] Iteration 24580, avg_grad_norm = 605591
I0315 05:12:03.196781 29479 solver.cpp:214] Iteration 24600, loss = 6759.41
I0315 05:12:03.196915 29479 solver.cpp:229]     Train net output #0: loss = 4153.11 (* 1 = 4153.11 loss)
I0315 05:12:03.311367 29479 solver.cpp:610] Iteration 24600, lr = 8.88586e-09
I0315 05:12:03.311379 29479 solver.cpp:613] Iteration 24600, avg_grad_norm = 607539
I0315 05:12:28.860175 29479 solver.cpp:214] Iteration 24620, loss = 6655.2
I0315 05:12:28.860256 29479 solver.cpp:229]     Train net output #0: loss = 5158.76 (* 1 = 5158.76 loss)
I0315 05:12:28.974877 29479 solver.cpp:610] Iteration 24620, lr = 8.88495e-09
I0315 05:12:28.974890 29479 solver.cpp:613] Iteration 24620, avg_grad_norm = 565056
I0315 05:13:07.232470 29479 solver.cpp:214] Iteration 24640, loss = 7005.61
I0315 05:13:07.232621 29479 solver.cpp:229]     Train net output #0: loss = 6974.18 (* 1 = 6974.18 loss)
I0315 05:13:07.337761 29479 solver.cpp:610] Iteration 24640, lr = 8.88404e-09
I0315 05:13:07.337774 29479 solver.cpp:613] Iteration 24640, avg_grad_norm = 630499
I0315 05:13:30.776454 29479 solver.cpp:214] Iteration 24660, loss = 6379.75
I0315 05:13:30.776520 29479 solver.cpp:229]     Train net output #0: loss = 8547.33 (* 1 = 8547.33 loss)
I0315 05:13:30.881685 29479 solver.cpp:610] Iteration 24660, lr = 8.88313e-09
I0315 05:13:30.881698 29479 solver.cpp:613] Iteration 24660, avg_grad_norm = 609529
I0315 05:13:56.092252 29479 solver.cpp:214] Iteration 24680, loss = 6532.1
I0315 05:13:56.092407 29479 solver.cpp:229]     Train net output #0: loss = 6047.63 (* 1 = 6047.63 loss)
I0315 05:13:56.206830 29479 solver.cpp:610] Iteration 24680, lr = 8.88222e-09
I0315 05:13:56.206842 29479 solver.cpp:613] Iteration 24680, avg_grad_norm = 627980
I0315 05:14:21.811713 29479 solver.cpp:214] Iteration 24700, loss = 6702.8
I0315 05:14:21.811777 29479 solver.cpp:229]     Train net output #0: loss = 3202.37 (* 1 = 3202.37 loss)
I0315 05:14:21.926463 29479 solver.cpp:610] Iteration 24700, lr = 8.8813e-09
I0315 05:14:21.926478 29479 solver.cpp:613] Iteration 24700, avg_grad_norm = 580280
I0315 05:14:47.511050 29479 solver.cpp:214] Iteration 24720, loss = 6889.64
I0315 05:14:47.511214 29479 solver.cpp:229]     Train net output #0: loss = 5993.78 (* 1 = 5993.78 loss)
I0315 05:14:47.625556 29479 solver.cpp:610] Iteration 24720, lr = 8.88039e-09
I0315 05:14:47.625571 29479 solver.cpp:613] Iteration 24720, avg_grad_norm = 566705
I0315 05:15:13.173331 29479 solver.cpp:214] Iteration 24740, loss = 6936.2
I0315 05:15:13.173401 29479 solver.cpp:229]     Train net output #0: loss = 4416.09 (* 1 = 4416.09 loss)
I0315 05:15:13.287701 29479 solver.cpp:610] Iteration 24740, lr = 8.87948e-09
I0315 05:15:13.287714 29479 solver.cpp:613] Iteration 24740, avg_grad_norm = 570064
I0315 05:15:38.837527 29479 solver.cpp:214] Iteration 24760, loss = 6398.04
I0315 05:15:38.837733 29479 solver.cpp:229]     Train net output #0: loss = 3953.92 (* 1 = 3953.92 loss)
I0315 05:15:38.951974 29479 solver.cpp:610] Iteration 24760, lr = 8.87857e-09
I0315 05:15:38.951988 29479 solver.cpp:613] Iteration 24760, avg_grad_norm = 568893
I0315 05:16:29.680313 29479 solver.cpp:214] Iteration 24780, loss = 6450.99
I0315 05:16:29.680471 29479 solver.cpp:229]     Train net output #0: loss = 5309.76 (* 1 = 5309.76 loss)
I0315 05:16:29.785558 29479 solver.cpp:610] Iteration 24780, lr = 8.87766e-09
I0315 05:16:29.785573 29479 solver.cpp:613] Iteration 24780, avg_grad_norm = 547950
I0315 05:16:53.297739 29479 solver.cpp:214] Iteration 24800, loss = 6488.46
I0315 05:16:53.297790 29479 solver.cpp:229]     Train net output #0: loss = 5309.84 (* 1 = 5309.84 loss)
I0315 05:16:53.402961 29479 solver.cpp:610] Iteration 24800, lr = 8.87674e-09
I0315 05:16:53.402973 29479 solver.cpp:613] Iteration 24800, avg_grad_norm = 595564
I0315 05:17:18.031715 29479 solver.cpp:214] Iteration 24820, loss = 6472.9
I0315 05:17:18.031905 29479 solver.cpp:229]     Train net output #0: loss = 9630.41 (* 1 = 9630.41 loss)
I0315 05:17:18.146360 29479 solver.cpp:610] Iteration 24820, lr = 8.87583e-09
I0315 05:17:18.146374 29479 solver.cpp:613] Iteration 24820, avg_grad_norm = 567394
I0315 05:17:43.616950 29479 solver.cpp:214] Iteration 24840, loss = 6946.37
I0315 05:17:43.617014 29479 solver.cpp:229]     Train net output #0: loss = 9146.92 (* 1 = 9146.92 loss)
I0315 05:17:43.730060 29479 solver.cpp:610] Iteration 24840, lr = 8.87492e-09
I0315 05:17:43.730073 29479 solver.cpp:613] Iteration 24840, avg_grad_norm = 677440
I0315 05:18:09.000538 29479 solver.cpp:214] Iteration 24860, loss = 6555.32
I0315 05:18:09.000680 29479 solver.cpp:229]     Train net output #0: loss = 6183.08 (* 1 = 6183.08 loss)
I0315 05:18:09.113593 29479 solver.cpp:610] Iteration 24860, lr = 8.87401e-09
I0315 05:18:09.113643 29479 solver.cpp:613] Iteration 24860, avg_grad_norm = 550416
I0315 05:18:34.747822 29479 solver.cpp:214] Iteration 24880, loss = 6763.3
I0315 05:18:34.747889 29479 solver.cpp:229]     Train net output #0: loss = 5065.25 (* 1 = 5065.25 loss)
I0315 05:18:34.862581 29479 solver.cpp:610] Iteration 24880, lr = 8.8731e-09
I0315 05:18:34.862593 29479 solver.cpp:613] Iteration 24880, avg_grad_norm = 522423
I0315 05:19:37.746016 29479 solver.cpp:214] Iteration 24900, loss = 6886.14
I0315 05:19:37.746143 29479 solver.cpp:229]     Train net output #0: loss = 6099.71 (* 1 = 6099.71 loss)
I0315 05:19:37.850168 29479 solver.cpp:610] Iteration 24900, lr = 8.87218e-09
I0315 05:19:37.850183 29479 solver.cpp:613] Iteration 24900, avg_grad_norm = 559785
I0315 05:20:01.277772 29479 solver.cpp:214] Iteration 24920, loss = 6193.68
I0315 05:20:01.277824 29479 solver.cpp:229]     Train net output #0: loss = 5748.02 (* 1 = 5748.02 loss)
I0315 05:20:01.383199 29479 solver.cpp:610] Iteration 24920, lr = 8.87127e-09
I0315 05:20:01.383213 29479 solver.cpp:613] Iteration 24920, avg_grad_norm = 583982
I0315 05:20:24.834712 29479 solver.cpp:214] Iteration 24940, loss = 6733.1
I0315 05:20:24.834911 29479 solver.cpp:229]     Train net output #0: loss = 5628.65 (* 1 = 5628.65 loss)
I0315 05:20:24.939996 29479 solver.cpp:610] Iteration 24940, lr = 8.87036e-09
I0315 05:20:24.940009 29479 solver.cpp:613] Iteration 24940, avg_grad_norm = 558473
I0315 05:20:49.148385 29479 solver.cpp:214] Iteration 24960, loss = 6800.01
I0315 05:20:49.148443 29479 solver.cpp:229]     Train net output #0: loss = 4317.47 (* 1 = 4317.47 loss)
I0315 05:20:49.261236 29479 solver.cpp:610] Iteration 24960, lr = 8.86945e-09
I0315 05:20:49.261250 29479 solver.cpp:613] Iteration 24960, avg_grad_norm = 568029
I0315 05:21:14.511817 29479 solver.cpp:214] Iteration 24980, loss = 6845.84
I0315 05:21:14.512022 29479 solver.cpp:229]     Train net output #0: loss = 5674.32 (* 1 = 5674.32 loss)
I0315 05:21:14.624799 29479 solver.cpp:610] Iteration 24980, lr = 8.86854e-09
I0315 05:21:14.624811 29479 solver.cpp:613] Iteration 24980, avg_grad_norm = 587243
I0315 05:21:39.820418 29479 solver.cpp:214] Iteration 25000, loss = 6562.05
I0315 05:21:39.820492 29479 solver.cpp:229]     Train net output #0: loss = 6150.19 (* 1 = 6150.19 loss)
I0315 05:21:39.933274 29479 solver.cpp:610] Iteration 25000, lr = 8.86762e-09
I0315 05:21:39.933290 29479 solver.cpp:613] Iteration 25000, avg_grad_norm = 612647
I0315 05:22:18.142794 29479 solver.cpp:214] Iteration 25020, loss = 6485.24
I0315 05:22:18.142925 29479 solver.cpp:229]     Train net output #0: loss = 3908.6 (* 1 = 3908.6 loss)
I0315 05:22:18.248008 29479 solver.cpp:610] Iteration 25020, lr = 8.86671e-09
I0315 05:22:18.248021 29479 solver.cpp:613] Iteration 25020, avg_grad_norm = 607308
I0315 05:22:41.690850 29479 solver.cpp:214] Iteration 25040, loss = 6734.69
I0315 05:22:41.690932 29479 solver.cpp:229]     Train net output #0: loss = 5228.8 (* 1 = 5228.8 loss)
I0315 05:22:41.796027 29479 solver.cpp:610] Iteration 25040, lr = 8.8658e-09
I0315 05:22:41.796041 29479 solver.cpp:613] Iteration 25040, avg_grad_norm = 723350
I0315 05:23:06.902711 29479 solver.cpp:214] Iteration 25060, loss = 6310.74
I0315 05:23:06.902861 29479 solver.cpp:229]     Train net output #0: loss = 9435.68 (* 1 = 9435.68 loss)
I0315 05:23:07.017408 29479 solver.cpp:610] Iteration 25060, lr = 8.86489e-09
I0315 05:23:07.017421 29479 solver.cpp:613] Iteration 25060, avg_grad_norm = 628965
I0315 05:23:32.576596 29479 solver.cpp:214] Iteration 25080, loss = 6809.08
I0315 05:23:32.576668 29479 solver.cpp:229]     Train net output #0: loss = 4052.72 (* 1 = 4052.72 loss)
I0315 05:23:32.691187 29479 solver.cpp:610] Iteration 25080, lr = 8.86398e-09
I0315 05:23:32.691200 29479 solver.cpp:613] Iteration 25080, avg_grad_norm = 595910
I0315 05:23:58.042129 29479 solver.cpp:214] Iteration 25100, loss = 6768.35
I0315 05:23:58.042270 29479 solver.cpp:229]     Train net output #0: loss = 6186.42 (* 1 = 6186.42 loss)
I0315 05:23:58.155248 29479 solver.cpp:610] Iteration 25100, lr = 8.86306e-09
I0315 05:23:58.155262 29479 solver.cpp:613] Iteration 25100, avg_grad_norm = 528144
I0315 05:24:23.411413 29479 solver.cpp:214] Iteration 25120, loss = 6293.56
I0315 05:24:23.411468 29479 solver.cpp:229]     Train net output #0: loss = 6857.12 (* 1 = 6857.12 loss)
I0315 05:24:23.524400 29479 solver.cpp:610] Iteration 25120, lr = 8.86215e-09
I0315 05:24:23.524413 29479 solver.cpp:613] Iteration 25120, avg_grad_norm = 589990
I0315 05:24:49.060786 29479 solver.cpp:214] Iteration 25140, loss = 6750.78
I0315 05:24:49.060963 29479 solver.cpp:229]     Train net output #0: loss = 7604.03 (* 1 = 7604.03 loss)
I0315 05:24:49.175549 29479 solver.cpp:610] Iteration 25140, lr = 8.86124e-09
I0315 05:24:49.175562 29479 solver.cpp:613] Iteration 25140, avg_grad_norm = 567478
I0315 05:25:26.232357 29479 solver.cpp:214] Iteration 25160, loss = 6886.6
I0315 05:25:26.232595 29479 solver.cpp:229]     Train net output #0: loss = 7834.94 (* 1 = 7834.94 loss)
I0315 05:25:26.336810 29479 solver.cpp:610] Iteration 25160, lr = 8.86033e-09
I0315 05:25:26.336824 29479 solver.cpp:613] Iteration 25160, avg_grad_norm = 528767
I0315 05:25:50.769852 29479 solver.cpp:214] Iteration 25180, loss = 6780.49
I0315 05:25:50.769918 29479 solver.cpp:229]     Train net output #0: loss = 6351.68 (* 1 = 6351.68 loss)
I0315 05:25:50.884310 29479 solver.cpp:610] Iteration 25180, lr = 8.85941e-09
I0315 05:25:50.884325 29479 solver.cpp:613] Iteration 25180, avg_grad_norm = 569794
I0315 05:26:16.448961 29479 solver.cpp:214] Iteration 25200, loss = 6904.54
I0315 05:26:16.449081 29479 solver.cpp:229]     Train net output #0: loss = 4962.36 (* 1 = 4962.36 loss)
I0315 05:26:16.563524 29479 solver.cpp:610] Iteration 25200, lr = 8.8585e-09
I0315 05:26:16.563537 29479 solver.cpp:613] Iteration 25200, avg_grad_norm = 619345
I0315 05:26:42.113863 29479 solver.cpp:214] Iteration 25220, loss = 6850.84
I0315 05:26:42.113926 29479 solver.cpp:229]     Train net output #0: loss = 8194.86 (* 1 = 8194.86 loss)
I0315 05:26:42.228662 29479 solver.cpp:610] Iteration 25220, lr = 8.85759e-09
I0315 05:26:42.228675 29479 solver.cpp:613] Iteration 25220, avg_grad_norm = 588355
I0315 05:27:07.796602 29479 solver.cpp:214] Iteration 25240, loss = 6395.16
I0315 05:27:07.796804 29479 solver.cpp:229]     Train net output #0: loss = 5252.34 (* 1 = 5252.34 loss)
I0315 05:27:07.911133 29479 solver.cpp:610] Iteration 25240, lr = 8.85668e-09
I0315 05:27:07.911146 29479 solver.cpp:613] Iteration 25240, avg_grad_norm = 601778
I0315 05:27:33.445267 29479 solver.cpp:214] Iteration 25260, loss = 6838.81
I0315 05:27:33.445319 29479 solver.cpp:229]     Train net output #0: loss = 6527.66 (* 1 = 6527.66 loss)
I0315 05:27:33.558305 29479 solver.cpp:610] Iteration 25260, lr = 8.85577e-09
I0315 05:27:33.558317 29479 solver.cpp:613] Iteration 25260, avg_grad_norm = 534322
I0315 05:28:11.052932 29479 solver.cpp:214] Iteration 25280, loss = 6422.3
I0315 05:28:11.053077 29479 solver.cpp:229]     Train net output #0: loss = 3551.71 (* 1 = 3551.71 loss)
I0315 05:28:11.158191 29479 solver.cpp:610] Iteration 25280, lr = 8.85485e-09
I0315 05:28:11.158205 29479 solver.cpp:613] Iteration 25280, avg_grad_norm = 603935
I0315 05:28:34.855545 29479 solver.cpp:214] Iteration 25300, loss = 6665.02
I0315 05:28:34.855600 29479 solver.cpp:229]     Train net output #0: loss = 7228.58 (* 1 = 7228.58 loss)
I0315 05:28:34.970152 29479 solver.cpp:610] Iteration 25300, lr = 8.85394e-09
I0315 05:28:34.970166 29479 solver.cpp:613] Iteration 25300, avg_grad_norm = 779246
I0315 05:29:00.528231 29479 solver.cpp:214] Iteration 25320, loss = 6883.07
I0315 05:29:00.528447 29479 solver.cpp:229]     Train net output #0: loss = 8122.45 (* 1 = 8122.45 loss)
I0315 05:29:00.642922 29479 solver.cpp:610] Iteration 25320, lr = 8.85303e-09
I0315 05:29:00.642936 29479 solver.cpp:613] Iteration 25320, avg_grad_norm = 591638
I0315 05:29:26.243691 29479 solver.cpp:214] Iteration 25340, loss = 6603.66
I0315 05:29:26.243757 29479 solver.cpp:229]     Train net output #0: loss = 4233.06 (* 1 = 4233.06 loss)
I0315 05:29:26.358364 29479 solver.cpp:610] Iteration 25340, lr = 8.85212e-09
I0315 05:29:26.358377 29479 solver.cpp:613] Iteration 25340, avg_grad_norm = 536108
I0315 05:29:51.913066 29479 solver.cpp:214] Iteration 25360, loss = 6520.98
I0315 05:29:51.913271 29479 solver.cpp:229]     Train net output #0: loss = 12498.4 (* 1 = 12498.4 loss)
I0315 05:29:52.027648 29479 solver.cpp:610] Iteration 25360, lr = 8.8512e-09
I0315 05:29:52.027681 29479 solver.cpp:613] Iteration 25360, avg_grad_norm = 535874
I0315 05:30:17.587494 29479 solver.cpp:214] Iteration 25380, loss = 6393.06
I0315 05:30:17.587558 29479 solver.cpp:229]     Train net output #0: loss = 5681.34 (* 1 = 5681.34 loss)
I0315 05:30:17.700579 29479 solver.cpp:610] Iteration 25380, lr = 8.85029e-09
I0315 05:30:17.700593 29479 solver.cpp:613] Iteration 25380, avg_grad_norm = 613902
I0315 05:31:06.146174 29479 solver.cpp:214] Iteration 25400, loss = 6668.99
I0315 05:31:06.146348 29479 solver.cpp:229]     Train net output #0: loss = 4215.2 (* 1 = 4215.2 loss)
I0315 05:31:06.250162 29479 solver.cpp:610] Iteration 25400, lr = 8.84938e-09
I0315 05:31:06.250176 29479 solver.cpp:613] Iteration 25400, avg_grad_norm = 566476
I0315 05:31:29.650352 29479 solver.cpp:214] Iteration 25420, loss = 6351.68
I0315 05:31:29.650420 29479 solver.cpp:229]     Train net output #0: loss = 4444.54 (* 1 = 4444.54 loss)
I0315 05:31:29.755409 29479 solver.cpp:610] Iteration 25420, lr = 8.84847e-09
I0315 05:31:29.755424 29479 solver.cpp:613] Iteration 25420, avg_grad_norm = 620433
I0315 05:31:53.455298 29479 solver.cpp:214] Iteration 25440, loss = 6459.67
I0315 05:31:53.455435 29479 solver.cpp:229]     Train net output #0: loss = 4206.4 (* 1 = 4206.4 loss)
I0315 05:31:53.567041 29479 solver.cpp:610] Iteration 25440, lr = 8.84755e-09
I0315 05:31:53.567055 29479 solver.cpp:613] Iteration 25440, avg_grad_norm = 539620
I0315 05:32:19.018066 29479 solver.cpp:214] Iteration 25460, loss = 6604.67
I0315 05:32:19.018129 29479 solver.cpp:229]     Train net output #0: loss = 8630.59 (* 1 = 8630.59 loss)
I0315 05:32:19.132769 29479 solver.cpp:610] Iteration 25460, lr = 8.84664e-09
I0315 05:32:19.132784 29479 solver.cpp:613] Iteration 25460, avg_grad_norm = 629873
I0315 05:32:44.730716 29479 solver.cpp:214] Iteration 25480, loss = 6495.88
I0315 05:32:44.730844 29479 solver.cpp:229]     Train net output #0: loss = 4240.54 (* 1 = 4240.54 loss)
I0315 05:32:44.845474 29479 solver.cpp:610] Iteration 25480, lr = 8.84573e-09
I0315 05:32:44.845487 29479 solver.cpp:613] Iteration 25480, avg_grad_norm = 542774
I0315 05:33:10.079530 29479 solver.cpp:214] Iteration 25500, loss = 6494.78
I0315 05:33:10.079596 29479 solver.cpp:229]     Train net output #0: loss = 5775.46 (* 1 = 5775.46 loss)
I0315 05:33:10.192522 29479 solver.cpp:610] Iteration 25500, lr = 8.84482e-09
I0315 05:33:10.192534 29479 solver.cpp:613] Iteration 25500, avg_grad_norm = 570058
I0315 05:33:35.546754 29479 solver.cpp:214] Iteration 25520, loss = 6473.66
I0315 05:33:35.546881 29479 solver.cpp:229]     Train net output #0: loss = 5693.63 (* 1 = 5693.63 loss)
I0315 05:33:35.661321 29479 solver.cpp:610] Iteration 25520, lr = 8.84391e-09
I0315 05:33:35.661334 29479 solver.cpp:613] Iteration 25520, avg_grad_norm = 642602
I0315 05:34:42.958220 29479 solver.cpp:214] Iteration 25540, loss = 6495.81
I0315 05:34:42.958323 29479 solver.cpp:229]     Train net output #0: loss = 8875.09 (* 1 = 8875.09 loss)
I0315 05:34:43.063567 29479 solver.cpp:610] Iteration 25540, lr = 8.84299e-09
I0315 05:34:43.063580 29479 solver.cpp:613] Iteration 25540, avg_grad_norm = 615253
I0315 05:35:06.461004 29479 solver.cpp:214] Iteration 25560, loss = 6462.98
I0315 05:35:06.461062 29479 solver.cpp:229]     Train net output #0: loss = 4190.55 (* 1 = 4190.55 loss)
I0315 05:35:06.566190 29479 solver.cpp:610] Iteration 25560, lr = 8.84208e-09
I0315 05:35:06.566201 29479 solver.cpp:613] Iteration 25560, avg_grad_norm = 562036
I0315 05:35:30.026787 29479 solver.cpp:214] Iteration 25580, loss = 6560.15
I0315 05:35:30.026895 29479 solver.cpp:229]     Train net output #0: loss = 7625.32 (* 1 = 7625.32 loss)
I0315 05:35:30.131459 29479 solver.cpp:610] Iteration 25580, lr = 8.84117e-09
I0315 05:35:30.131471 29479 solver.cpp:613] Iteration 25580, avg_grad_norm = 647987
I0315 05:35:54.491770 29479 solver.cpp:214] Iteration 25600, loss = 6469.36
I0315 05:35:54.491838 29479 solver.cpp:229]     Train net output #0: loss = 4563.91 (* 1 = 4563.91 loss)
I0315 05:35:54.606397 29479 solver.cpp:610] Iteration 25600, lr = 8.84026e-09
I0315 05:35:54.606410 29479 solver.cpp:613] Iteration 25600, avg_grad_norm = 574073
I0315 05:36:20.126019 29479 solver.cpp:214] Iteration 25620, loss = 6675.43
I0315 05:36:20.126112 29479 solver.cpp:229]     Train net output #0: loss = 5705.89 (* 1 = 5705.89 loss)
I0315 05:36:20.239048 29479 solver.cpp:610] Iteration 25620, lr = 8.83934e-09
I0315 05:36:20.239060 29479 solver.cpp:613] Iteration 25620, avg_grad_norm = 590742
I0315 05:36:45.160226 29479 solver.cpp:214] Iteration 25640, loss = 6824.79
I0315 05:36:45.160295 29479 solver.cpp:229]     Train net output #0: loss = 6871.51 (* 1 = 6871.51 loss)
I0315 05:36:45.271821 29479 solver.cpp:610] Iteration 25640, lr = 8.83843e-09
I0315 05:36:45.271834 29479 solver.cpp:613] Iteration 25640, avg_grad_norm = 566762
I0315 05:37:33.715104 29479 solver.cpp:214] Iteration 25660, loss = 6601.58
I0315 05:37:33.715291 29479 solver.cpp:229]     Train net output #0: loss = 7841.07 (* 1 = 7841.07 loss)
I0315 05:37:33.820355 29479 solver.cpp:610] Iteration 25660, lr = 8.83752e-09
I0315 05:37:33.820369 29479 solver.cpp:613] Iteration 25660, avg_grad_norm = 572678
I0315 05:37:57.241755 29479 solver.cpp:214] Iteration 25680, loss = 6292.74
I0315 05:37:57.241822 29479 solver.cpp:229]     Train net output #0: loss = 8421.77 (* 1 = 8421.77 loss)
I0315 05:37:57.347051 29479 solver.cpp:610] Iteration 25680, lr = 8.83661e-09
I0315 05:37:57.347064 29479 solver.cpp:613] Iteration 25680, avg_grad_norm = 729250
I0315 05:38:21.318230 29479 solver.cpp:214] Iteration 25700, loss = 7126.71
I0315 05:38:21.318383 29479 solver.cpp:229]     Train net output #0: loss = 8144.51 (* 1 = 8144.51 loss)
I0315 05:38:21.431335 29479 solver.cpp:610] Iteration 25700, lr = 8.83569e-09
I0315 05:38:21.431349 29479 solver.cpp:613] Iteration 25700, avg_grad_norm = 723298
I0315 05:38:46.909400 29479 solver.cpp:214] Iteration 25720, loss = 6652.61
I0315 05:38:46.909471 29479 solver.cpp:229]     Train net output #0: loss = 3935.62 (* 1 = 3935.62 loss)
I0315 05:38:47.024096 29479 solver.cpp:610] Iteration 25720, lr = 8.83478e-09
I0315 05:38:47.024113 29479 solver.cpp:613] Iteration 25720, avg_grad_norm = 550745
I0315 05:39:12.632357 29479 solver.cpp:214] Iteration 25740, loss = 6295.37
I0315 05:39:12.632483 29479 solver.cpp:229]     Train net output #0: loss = 4372.77 (* 1 = 4372.77 loss)
I0315 05:39:12.746983 29479 solver.cpp:610] Iteration 25740, lr = 8.83387e-09
I0315 05:39:12.747010 29479 solver.cpp:613] Iteration 25740, avg_grad_norm = 562329
I0315 05:39:38.041648 29479 solver.cpp:214] Iteration 25760, loss = 6757.32
I0315 05:39:38.041714 29479 solver.cpp:229]     Train net output #0: loss = 5948.67 (* 1 = 5948.67 loss)
I0315 05:39:38.154629 29479 solver.cpp:610] Iteration 25760, lr = 8.83296e-09
I0315 05:39:38.154642 29479 solver.cpp:613] Iteration 25760, avg_grad_norm = 676380
I0315 05:40:19.684079 29479 solver.cpp:214] Iteration 25780, loss = 6384.83
I0315 05:40:19.684211 29479 solver.cpp:229]     Train net output #0: loss = 10274.3 (* 1 = 10274.3 loss)
I0315 05:40:19.787819 29479 solver.cpp:610] Iteration 25780, lr = 8.83204e-09
I0315 05:40:19.787833 29479 solver.cpp:613] Iteration 25780, avg_grad_norm = 601603
I0315 05:40:43.228096 29479 solver.cpp:214] Iteration 25800, loss = 6807.44
I0315 05:40:43.228174 29479 solver.cpp:229]     Train net output #0: loss = 4233.11 (* 1 = 4233.11 loss)
I0315 05:40:43.332828 29479 solver.cpp:610] Iteration 25800, lr = 8.83113e-09
I0315 05:40:43.332864 29479 solver.cpp:613] Iteration 25800, avg_grad_norm = 621871
I0315 05:41:07.751459 29479 solver.cpp:214] Iteration 25820, loss = 6467.73
I0315 05:41:07.751601 29479 solver.cpp:229]     Train net output #0: loss = 4989.48 (* 1 = 4989.48 loss)
I0315 05:41:07.866080 29479 solver.cpp:610] Iteration 25820, lr = 8.83022e-09
I0315 05:41:07.866093 29479 solver.cpp:613] Iteration 25820, avg_grad_norm = 581253
I0315 05:41:33.426352 29479 solver.cpp:214] Iteration 25840, loss = 6356.27
I0315 05:41:33.426411 29479 solver.cpp:229]     Train net output #0: loss = 4777.64 (* 1 = 4777.64 loss)
I0315 05:41:33.540966 29479 solver.cpp:610] Iteration 25840, lr = 8.82931e-09
I0315 05:41:33.540982 29479 solver.cpp:613] Iteration 25840, avg_grad_norm = 572035
I0315 05:41:59.111390 29479 solver.cpp:214] Iteration 25860, loss = 6316.51
I0315 05:41:59.111551 29479 solver.cpp:229]     Train net output #0: loss = 12488 (* 1 = 12488 loss)
I0315 05:41:59.225891 29479 solver.cpp:610] Iteration 25860, lr = 8.82839e-09
I0315 05:41:59.225906 29479 solver.cpp:613] Iteration 25860, avg_grad_norm = 531678
I0315 05:42:24.780740 29479 solver.cpp:214] Iteration 25880, loss = 6450.18
I0315 05:42:24.780802 29479 solver.cpp:229]     Train net output #0: loss = 9743.71 (* 1 = 9743.71 loss)
I0315 05:42:24.895360 29479 solver.cpp:610] Iteration 25880, lr = 8.82748e-09
I0315 05:42:24.895375 29479 solver.cpp:613] Iteration 25880, avg_grad_norm = 600034
I0315 05:42:50.356873 29479 solver.cpp:214] Iteration 25900, loss = 6426.62
I0315 05:42:50.357051 29479 solver.cpp:229]     Train net output #0: loss = 4860.32 (* 1 = 4860.32 loss)
I0315 05:42:50.469998 29479 solver.cpp:610] Iteration 25900, lr = 8.82657e-09
I0315 05:42:50.470012 29479 solver.cpp:613] Iteration 25900, avg_grad_norm = 602757
I0315 05:43:36.570801 29479 solver.cpp:214] Iteration 25920, loss = 6467.04
I0315 05:43:36.570945 29479 solver.cpp:229]     Train net output #0: loss = 3749.23 (* 1 = 3749.23 loss)
I0315 05:43:36.675009 29479 solver.cpp:610] Iteration 25920, lr = 8.82566e-09
I0315 05:43:36.675024 29479 solver.cpp:613] Iteration 25920, avg_grad_norm = 603753
I0315 05:44:00.109712 29479 solver.cpp:214] Iteration 25940, loss = 6567.55
I0315 05:44:00.109786 29479 solver.cpp:229]     Train net output #0: loss = 11302 (* 1 = 11302 loss)
I0315 05:44:00.215348 29479 solver.cpp:610] Iteration 25940, lr = 8.82474e-09
I0315 05:44:00.215361 29479 solver.cpp:613] Iteration 25940, avg_grad_norm = 618834
I0315 05:44:25.022975 29479 solver.cpp:214] Iteration 25960, loss = 6311.9
I0315 05:44:25.023094 29479 solver.cpp:229]     Train net output #0: loss = 5577.62 (* 1 = 5577.62 loss)
I0315 05:44:25.137529 29479 solver.cpp:610] Iteration 25960, lr = 8.82383e-09
I0315 05:44:25.137543 29479 solver.cpp:613] Iteration 25960, avg_grad_norm = 675719
I0315 05:44:50.741142 29479 solver.cpp:214] Iteration 25980, loss = 6756.73
I0315 05:44:50.741233 29479 solver.cpp:229]     Train net output #0: loss = 7873.59 (* 1 = 7873.59 loss)
I0315 05:44:50.855664 29479 solver.cpp:610] Iteration 25980, lr = 8.82292e-09
I0315 05:44:50.855677 29479 solver.cpp:613] Iteration 25980, avg_grad_norm = 575838
I0315 05:45:16.153764 29479 solver.cpp:214] Iteration 26000, loss = 6562.63
I0315 05:45:16.153877 29479 solver.cpp:229]     Train net output #0: loss = 6706.79 (* 1 = 6706.79 loss)
I0315 05:45:16.266721 29479 solver.cpp:610] Iteration 26000, lr = 8.82201e-09
I0315 05:45:16.266733 29479 solver.cpp:613] Iteration 26000, avg_grad_norm = 617722
I0315 05:45:41.716564 29479 solver.cpp:214] Iteration 26020, loss = 6848.93
I0315 05:45:41.716634 29479 solver.cpp:229]     Train net output #0: loss = 8702.59 (* 1 = 8702.59 loss)
I0315 05:45:41.831341 29479 solver.cpp:610] Iteration 26020, lr = 8.82109e-09
I0315 05:45:41.831353 29479 solver.cpp:613] Iteration 26020, avg_grad_norm = 597274
I0315 05:46:21.862785 29479 solver.cpp:214] Iteration 26040, loss = 6272.48
I0315 05:46:21.862908 29479 solver.cpp:229]     Train net output #0: loss = 6199.43 (* 1 = 6199.43 loss)
I0315 05:46:21.968178 29479 solver.cpp:610] Iteration 26040, lr = 8.82018e-09
I0315 05:46:21.968191 29479 solver.cpp:613] Iteration 26040, avg_grad_norm = 540412
I0315 05:46:45.418298 29479 solver.cpp:214] Iteration 26060, loss = 6783.01
I0315 05:46:45.418368 29479 solver.cpp:229]     Train net output #0: loss = 8860.48 (* 1 = 8860.48 loss)
I0315 05:46:45.523473 29479 solver.cpp:610] Iteration 26060, lr = 8.81927e-09
I0315 05:46:45.523485 29479 solver.cpp:613] Iteration 26060, avg_grad_norm = 599114
I0315 05:47:10.800220 29479 solver.cpp:214] Iteration 26080, loss = 6561.37
I0315 05:47:10.800370 29479 solver.cpp:229]     Train net output #0: loss = 8801.16 (* 1 = 8801.16 loss)
I0315 05:47:10.915168 29479 solver.cpp:610] Iteration 26080, lr = 8.81835e-09
I0315 05:47:10.915180 29479 solver.cpp:613] Iteration 26080, avg_grad_norm = 575285
I0315 05:47:36.384822 29479 solver.cpp:214] Iteration 26100, loss = 6407.26
I0315 05:47:36.384891 29479 solver.cpp:229]     Train net output #0: loss = 2926.3 (* 1 = 2926.3 loss)
I0315 05:47:36.497871 29479 solver.cpp:610] Iteration 26100, lr = 8.81744e-09
I0315 05:47:36.497884 29479 solver.cpp:613] Iteration 26100, avg_grad_norm = 533596
I0315 05:48:01.695060 29479 solver.cpp:214] Iteration 26120, loss = 6851.9
I0315 05:48:01.695221 29479 solver.cpp:229]     Train net output #0: loss = 6399.79 (* 1 = 6399.79 loss)
I0315 05:48:01.808148 29479 solver.cpp:610] Iteration 26120, lr = 8.81653e-09
I0315 05:48:01.808161 29479 solver.cpp:613] Iteration 26120, avg_grad_norm = 605803
I0315 05:48:27.478847 29479 solver.cpp:214] Iteration 26140, loss = 6759.52
I0315 05:48:27.478905 29479 solver.cpp:229]     Train net output #0: loss = 6504.11 (* 1 = 6504.11 loss)
I0315 05:48:27.593519 29479 solver.cpp:610] Iteration 26140, lr = 8.81562e-09
I0315 05:48:27.593531 29479 solver.cpp:613] Iteration 26140, avg_grad_norm = 552160
I0315 05:49:11.897805 29479 solver.cpp:214] Iteration 26160, loss = 6412.99
I0315 05:49:11.897949 29479 solver.cpp:229]     Train net output #0: loss = 7210.17 (* 1 = 7210.17 loss)
I0315 05:49:12.008375 29479 solver.cpp:610] Iteration 26160, lr = 8.8147e-09
I0315 05:49:12.008416 29479 solver.cpp:613] Iteration 26160, avg_grad_norm = 570628
I0315 05:49:35.490330 29479 solver.cpp:214] Iteration 26180, loss = 6973.68
I0315 05:49:35.490396 29479 solver.cpp:229]     Train net output #0: loss = 9173.64 (* 1 = 9173.64 loss)
I0315 05:49:35.595403 29479 solver.cpp:610] Iteration 26180, lr = 8.81379e-09
I0315 05:49:35.595417 29479 solver.cpp:613] Iteration 26180, avg_grad_norm = 581060
I0315 05:49:59.663389 29479 solver.cpp:214] Iteration 26200, loss = 6346.04
I0315 05:49:59.663516 29479 solver.cpp:229]     Train net output #0: loss = 8429.37 (* 1 = 8429.37 loss)
I0315 05:49:59.778048 29479 solver.cpp:610] Iteration 26200, lr = 8.81288e-09
I0315 05:49:59.778060 29479 solver.cpp:613] Iteration 26200, avg_grad_norm = 573688
I0315 05:50:25.347352 29479 solver.cpp:214] Iteration 26220, loss = 6582.87
I0315 05:50:25.347421 29479 solver.cpp:229]     Train net output #0: loss = 7043.47 (* 1 = 7043.47 loss)
I0315 05:50:25.461922 29479 solver.cpp:610] Iteration 26220, lr = 8.81197e-09
I0315 05:50:25.461936 29479 solver.cpp:613] Iteration 26220, avg_grad_norm = 500897
I0315 05:50:51.001446 29479 solver.cpp:214] Iteration 26240, loss = 6740.19
I0315 05:50:51.001668 29479 solver.cpp:229]     Train net output #0: loss = 6280.16 (* 1 = 6280.16 loss)
I0315 05:50:51.115811 29479 solver.cpp:610] Iteration 26240, lr = 8.81105e-09
I0315 05:50:51.115826 29479 solver.cpp:613] Iteration 26240, avg_grad_norm = 516405
I0315 05:51:16.351647 29479 solver.cpp:214] Iteration 26260, loss = 6541.11
I0315 05:51:16.351719 29479 solver.cpp:229]     Train net output #0: loss = 4665.01 (* 1 = 4665.01 loss)
I0315 05:51:16.464601 29479 solver.cpp:610] Iteration 26260, lr = 8.81014e-09
I0315 05:51:16.464615 29479 solver.cpp:613] Iteration 26260, avg_grad_norm = 561315
I0315 05:51:41.782028 29479 solver.cpp:214] Iteration 26280, loss = 6621.99
I0315 05:51:41.782148 29479 solver.cpp:229]     Train net output #0: loss = 9179.15 (* 1 = 9179.15 loss)
I0315 05:51:41.896574 29479 solver.cpp:610] Iteration 26280, lr = 8.80923e-09
I0315 05:51:41.896589 29479 solver.cpp:613] Iteration 26280, avg_grad_norm = 579033
I0315 05:52:29.352004 29479 solver.cpp:214] Iteration 26300, loss = 6442.36
I0315 05:52:29.352138 29479 solver.cpp:229]     Train net output #0: loss = 5350.75 (* 1 = 5350.75 loss)
I0315 05:52:29.456009 29479 solver.cpp:610] Iteration 26300, lr = 8.80831e-09
I0315 05:52:29.456022 29479 solver.cpp:613] Iteration 26300, avg_grad_norm = 561992
I0315 05:52:52.892678 29479 solver.cpp:214] Iteration 26320, loss = 6057.94
I0315 05:52:52.892745 29479 solver.cpp:229]     Train net output #0: loss = 7414.44 (* 1 = 7414.44 loss)
I0315 05:52:52.997928 29479 solver.cpp:610] Iteration 26320, lr = 8.8074e-09
I0315 05:52:52.997941 29479 solver.cpp:613] Iteration 26320, avg_grad_norm = 577967
I0315 05:53:17.683328 29479 solver.cpp:214] Iteration 26340, loss = 6488.29
I0315 05:53:17.683454 29479 solver.cpp:229]     Train net output #0: loss = 6759.45 (* 1 = 6759.45 loss)
I0315 05:53:17.797852 29479 solver.cpp:610] Iteration 26340, lr = 8.80649e-09
I0315 05:53:17.797865 29479 solver.cpp:613] Iteration 26340, avg_grad_norm = 511334
I0315 05:53:43.347476 29479 solver.cpp:214] Iteration 26360, loss = 6585.15
I0315 05:53:43.347537 29479 solver.cpp:229]     Train net output #0: loss = 5316.67 (* 1 = 5316.67 loss)
I0315 05:53:43.462242 29479 solver.cpp:610] Iteration 26360, lr = 8.80558e-09
I0315 05:53:43.462256 29479 solver.cpp:613] Iteration 26360, avg_grad_norm = 585182
I0315 05:54:08.781203 29479 solver.cpp:214] Iteration 26380, loss = 6641.15
I0315 05:54:08.781396 29479 solver.cpp:229]     Train net output #0: loss = 6181.53 (* 1 = 6181.53 loss)
I0315 05:54:08.894202 29479 solver.cpp:610] Iteration 26380, lr = 8.80466e-09
I0315 05:54:08.894244 29479 solver.cpp:613] Iteration 26380, avg_grad_norm = 572525
I0315 05:54:34.253789 29479 solver.cpp:214] Iteration 26400, loss = 6602.71
I0315 05:54:34.253854 29479 solver.cpp:229]     Train net output #0: loss = 4317.9 (* 1 = 4317.9 loss)
I0315 05:54:34.368477 29479 solver.cpp:610] Iteration 26400, lr = 8.80375e-09
I0315 05:54:34.368490 29479 solver.cpp:613] Iteration 26400, avg_grad_norm = 548726
I0315 05:55:12.544121 29479 solver.cpp:214] Iteration 26420, loss = 6758.58
I0315 05:55:12.544256 29479 solver.cpp:229]     Train net output #0: loss = 4784.66 (* 1 = 4784.66 loss)
I0315 05:55:12.648449 29479 solver.cpp:610] Iteration 26420, lr = 8.80284e-09
I0315 05:55:12.648463 29479 solver.cpp:613] Iteration 26420, avg_grad_norm = 570539
I0315 05:55:36.176511 29479 solver.cpp:214] Iteration 26440, loss = 6581.28
I0315 05:55:36.176556 29479 solver.cpp:229]     Train net output #0: loss = 6308.46 (* 1 = 6308.46 loss)
I0315 05:55:36.281781 29479 solver.cpp:610] Iteration 26440, lr = 8.80193e-09
I0315 05:55:36.281795 29479 solver.cpp:613] Iteration 26440, avg_grad_norm = 613248
I0315 05:56:01.868010 29479 solver.cpp:214] Iteration 26460, loss = 6636.24
I0315 05:56:01.868131 29479 solver.cpp:229]     Train net output #0: loss = 8543.92 (* 1 = 8543.92 loss)
I0315 05:56:01.981155 29479 solver.cpp:610] Iteration 26460, lr = 8.80101e-09
I0315 05:56:01.981170 29479 solver.cpp:613] Iteration 26460, avg_grad_norm = 637456
I0315 05:56:27.265738 29479 solver.cpp:214] Iteration 26480, loss = 6461.51
I0315 05:56:27.265794 29479 solver.cpp:229]     Train net output #0: loss = 5995.6 (* 1 = 5995.6 loss)
I0315 05:56:27.378628 29479 solver.cpp:610] Iteration 26480, lr = 8.8001e-09
I0315 05:56:27.378640 29479 solver.cpp:613] Iteration 26480, avg_grad_norm = 540367
I0315 05:56:52.891091 29479 solver.cpp:214] Iteration 26500, loss = 6625.59
I0315 05:56:52.891193 29479 solver.cpp:229]     Train net output #0: loss = 7404.37 (* 1 = 7404.37 loss)
I0315 05:56:53.005661 29479 solver.cpp:610] Iteration 26500, lr = 8.79919e-09
I0315 05:56:53.005673 29479 solver.cpp:613] Iteration 26500, avg_grad_norm = 642928
I0315 05:57:18.614064 29479 solver.cpp:214] Iteration 26520, loss = 6568.01
I0315 05:57:18.614116 29479 solver.cpp:229]     Train net output #0: loss = 7274.12 (* 1 = 7274.12 loss)
I0315 05:57:18.728737 29479 solver.cpp:610] Iteration 26520, lr = 8.79827e-09
I0315 05:57:18.728750 29479 solver.cpp:613] Iteration 26520, avg_grad_norm = 632538
I0315 05:57:44.341202 29479 solver.cpp:214] Iteration 26540, loss = 6722.06
I0315 05:57:44.341435 29479 solver.cpp:229]     Train net output #0: loss = 11947.3 (* 1 = 11947.3 loss)
I0315 05:57:44.455919 29479 solver.cpp:610] Iteration 26540, lr = 8.79736e-09
I0315 05:57:44.455932 29479 solver.cpp:613] Iteration 26540, avg_grad_norm = 571436
I0315 05:58:20.988018 29479 solver.cpp:214] Iteration 26560, loss = 6404.47
I0315 05:58:20.988149 29479 solver.cpp:229]     Train net output #0: loss = 8127.73 (* 1 = 8127.73 loss)
I0315 05:58:21.093165 29479 solver.cpp:610] Iteration 26560, lr = 8.79645e-09
I0315 05:58:21.093180 29479 solver.cpp:613] Iteration 26560, avg_grad_norm = 514146
I0315 05:58:45.821926 29479 solver.cpp:214] Iteration 26580, loss = 6353.09
I0315 05:58:45.822018 29479 solver.cpp:229]     Train net output #0: loss = 3995.41 (* 1 = 3995.41 loss)
I0315 05:58:45.936470 29479 solver.cpp:610] Iteration 26580, lr = 8.79553e-09
I0315 05:58:45.936485 29479 solver.cpp:613] Iteration 26580, avg_grad_norm = 514471
I0315 05:59:11.556921 29479 solver.cpp:214] Iteration 26600, loss = 6553.19
I0315 05:59:11.557118 29479 solver.cpp:229]     Train net output #0: loss = 5850.42 (* 1 = 5850.42 loss)
I0315 05:59:11.671684 29479 solver.cpp:610] Iteration 26600, lr = 8.79462e-09
I0315 05:59:11.671722 29479 solver.cpp:613] Iteration 26600, avg_grad_norm = 647205
I0315 05:59:37.173714 29479 solver.cpp:214] Iteration 26620, loss = 6974.34
I0315 05:59:37.173773 29479 solver.cpp:229]     Train net output #0: loss = 8890.57 (* 1 = 8890.57 loss)
I0315 05:59:37.286618 29479 solver.cpp:610] Iteration 26620, lr = 8.79371e-09
I0315 05:59:37.286633 29479 solver.cpp:613] Iteration 26620, avg_grad_norm = 550705
I0315 06:00:02.579751 29479 solver.cpp:214] Iteration 26640, loss = 6306.89
I0315 06:00:02.579902 29479 solver.cpp:229]     Train net output #0: loss = 5183.89 (* 1 = 5183.89 loss)
I0315 06:00:02.692854 29479 solver.cpp:610] Iteration 26640, lr = 8.7928e-09
I0315 06:00:02.692867 29479 solver.cpp:613] Iteration 26640, avg_grad_norm = 606541
I0315 06:00:28.187296 29479 solver.cpp:214] Iteration 26660, loss = 6644.05
I0315 06:00:28.187345 29479 solver.cpp:229]     Train net output #0: loss = 10439.4 (* 1 = 10439.4 loss)
I0315 06:00:28.302052 29479 solver.cpp:610] Iteration 26660, lr = 8.79188e-09
I0315 06:00:28.302065 29479 solver.cpp:613] Iteration 26660, avg_grad_norm = 631209
I0315 06:01:26.462946 29479 solver.cpp:214] Iteration 26680, loss = 6650.55
I0315 06:01:26.463093 29479 solver.cpp:229]     Train net output #0: loss = 5086.01 (* 1 = 5086.01 loss)
I0315 06:01:26.567296 29479 solver.cpp:610] Iteration 26680, lr = 8.79097e-09
I0315 06:01:26.567311 29479 solver.cpp:613] Iteration 26680, avg_grad_norm = 582149
I0315 06:01:50.050155 29479 solver.cpp:214] Iteration 26700, loss = 6391.4
I0315 06:01:50.050228 29479 solver.cpp:229]     Train net output #0: loss = 4100.23 (* 1 = 4100.23 loss)
I0315 06:01:50.154099 29479 solver.cpp:610] Iteration 26700, lr = 8.79006e-09
I0315 06:01:50.154112 29479 solver.cpp:613] Iteration 26700, avg_grad_norm = 662634
I0315 06:02:13.684023 29479 solver.cpp:214] Iteration 26720, loss = 6547.15
I0315 06:02:13.684180 29479 solver.cpp:229]     Train net output #0: loss = 4462.59 (* 1 = 4462.59 loss)
I0315 06:02:13.789186 29479 solver.cpp:610] Iteration 26720, lr = 8.78914e-09
I0315 06:02:13.789199 29479 solver.cpp:613] Iteration 26720, avg_grad_norm = 592355
I0315 06:02:38.757927 29479 solver.cpp:214] Iteration 26740, loss = 6655.51
I0315 06:02:38.757989 29479 solver.cpp:229]     Train net output #0: loss = 11503.2 (* 1 = 11503.2 loss)
I0315 06:02:38.870831 29479 solver.cpp:610] Iteration 26740, lr = 8.78823e-09
I0315 06:02:38.870843 29479 solver.cpp:613] Iteration 26740, avg_grad_norm = 533283
I0315 06:03:04.248634 29479 solver.cpp:214] Iteration 26760, loss = 6385.24
I0315 06:03:04.248791 29479 solver.cpp:229]     Train net output #0: loss = 3411.07 (* 1 = 3411.07 loss)
I0315 06:03:04.363189 29479 solver.cpp:610] Iteration 26760, lr = 8.78732e-09
I0315 06:03:04.363203 29479 solver.cpp:613] Iteration 26760, avg_grad_norm = 583815
I0315 06:03:29.956980 29479 solver.cpp:214] Iteration 26780, loss = 6751.16
I0315 06:03:29.957036 29479 solver.cpp:229]     Train net output #0: loss = 4590.24 (* 1 = 4590.24 loss)
I0315 06:03:30.071578 29479 solver.cpp:610] Iteration 26780, lr = 8.78641e-09
I0315 06:03:30.071591 29479 solver.cpp:613] Iteration 26780, avg_grad_norm = 565913
I0315 06:04:32.202906 29479 solver.cpp:214] Iteration 26800, loss = 6497.06
I0315 06:04:32.203018 29479 solver.cpp:229]     Train net output #0: loss = 11082.3 (* 1 = 11082.3 loss)
I0315 06:04:32.306783 29479 solver.cpp:610] Iteration 26800, lr = 8.78549e-09
I0315 06:04:32.306797 29479 solver.cpp:613] Iteration 26800, avg_grad_norm = 602116
I0315 06:04:55.703878 29479 solver.cpp:214] Iteration 26820, loss = 6550.09
I0315 06:04:55.703966 29479 solver.cpp:229]     Train net output #0: loss = 7567.7 (* 1 = 7567.7 loss)
I0315 06:04:55.809182 29479 solver.cpp:610] Iteration 26820, lr = 8.78458e-09
I0315 06:04:55.809196 29479 solver.cpp:613] Iteration 26820, avg_grad_norm = 560807
I0315 06:05:19.244766 29479 solver.cpp:214] Iteration 26840, loss = 6586.96
I0315 06:05:19.244938 29479 solver.cpp:229]     Train net output #0: loss = 3820.89 (* 1 = 3820.89 loss)
I0315 06:05:19.349984 29479 solver.cpp:610] Iteration 26840, lr = 8.78367e-09
I0315 06:05:19.349998 29479 solver.cpp:613] Iteration 26840, avg_grad_norm = 525634
I0315 06:05:43.161459 29479 solver.cpp:214] Iteration 26860, loss = 6805.69
I0315 06:05:43.161512 29479 solver.cpp:229]     Train net output #0: loss = 7609.83 (* 1 = 7609.83 loss)
I0315 06:05:43.273056 29479 solver.cpp:610] Iteration 26860, lr = 8.78275e-09
I0315 06:05:43.273071 29479 solver.cpp:613] Iteration 26860, avg_grad_norm = 665064
I0315 06:06:08.456837 29479 solver.cpp:214] Iteration 26880, loss = 6453.37
I0315 06:06:08.457072 29479 solver.cpp:229]     Train net output #0: loss = 5942.98 (* 1 = 5942.98 loss)
I0315 06:06:08.569687 29479 solver.cpp:610] Iteration 26880, lr = 8.78184e-09
I0315 06:06:08.569702 29479 solver.cpp:613] Iteration 26880, avg_grad_norm = 602879
I0315 06:06:34.129781 29479 solver.cpp:214] Iteration 26900, loss = 6584.01
I0315 06:06:34.129827 29479 solver.cpp:229]     Train net output #0: loss = 10960.5 (* 1 = 10960.5 loss)
I0315 06:06:34.244526 29479 solver.cpp:610] Iteration 26900, lr = 8.78093e-09
I0315 06:06:34.244539 29479 solver.cpp:613] Iteration 26900, avg_grad_norm = 597530
I0315 06:06:59.763756 29479 solver.cpp:214] Iteration 26920, loss = 6718.31
I0315 06:06:59.763934 29479 solver.cpp:229]     Train net output #0: loss = 4703.68 (* 1 = 4703.68 loss)
I0315 06:06:59.876714 29479 solver.cpp:610] Iteration 26920, lr = 8.78001e-09
I0315 06:06:59.876744 29479 solver.cpp:613] Iteration 26920, avg_grad_norm = 599022
I0315 06:07:45.486382 29479 solver.cpp:214] Iteration 26940, loss = 6365.5
I0315 06:07:45.486497 29479 solver.cpp:229]     Train net output #0: loss = 5015.59 (* 1 = 5015.59 loss)
I0315 06:07:45.591608 29479 solver.cpp:610] Iteration 26940, lr = 8.7791e-09
I0315 06:07:45.591621 29479 solver.cpp:613] Iteration 26940, avg_grad_norm = 578912
I0315 06:08:09.093463 29479 solver.cpp:214] Iteration 26960, loss = 6623.74
I0315 06:08:09.093554 29479 solver.cpp:229]     Train net output #0: loss = 7609.48 (* 1 = 7609.48 loss)
I0315 06:08:09.198511 29479 solver.cpp:610] Iteration 26960, lr = 8.77819e-09
I0315 06:08:09.198524 29479 solver.cpp:613] Iteration 26960, avg_grad_norm = 625634
I0315 06:08:34.563611 29479 solver.cpp:214] Iteration 26980, loss = 6496.08
I0315 06:08:34.563740 29479 solver.cpp:229]     Train net output #0: loss = 3769.67 (* 1 = 3769.67 loss)
I0315 06:08:34.678272 29479 solver.cpp:610] Iteration 26980, lr = 8.77727e-09
I0315 06:08:34.678287 29479 solver.cpp:613] Iteration 26980, avg_grad_norm = 540785
I0315 06:09:00.133384 29479 solver.cpp:214] Iteration 27000, loss = 6437.2
I0315 06:09:00.133435 29479 solver.cpp:229]     Train net output #0: loss = 3618.07 (* 1 = 3618.07 loss)
I0315 06:09:00.246351 29479 solver.cpp:610] Iteration 27000, lr = 8.77636e-09
I0315 06:09:00.246366 29479 solver.cpp:613] Iteration 27000, avg_grad_norm = 585134
I0315 06:09:25.555188 29479 solver.cpp:214] Iteration 27020, loss = 6584.29
I0315 06:09:25.555332 29479 solver.cpp:229]     Train net output #0: loss = 11618.8 (* 1 = 11618.8 loss)
I0315 06:09:25.668251 29479 solver.cpp:610] Iteration 27020, lr = 8.77545e-09
I0315 06:09:25.668265 29479 solver.cpp:613] Iteration 27020, avg_grad_norm = 567016
I0315 06:09:51.093067 29479 solver.cpp:214] Iteration 27040, loss = 6504.67
I0315 06:09:51.093116 29479 solver.cpp:229]     Train net output #0: loss = 4360.07 (* 1 = 4360.07 loss)
I0315 06:09:51.207873 29479 solver.cpp:610] Iteration 27040, lr = 8.77453e-09
I0315 06:09:51.207887 29479 solver.cpp:613] Iteration 27040, avg_grad_norm = 560839
I0315 06:10:28.349241 29479 solver.cpp:214] Iteration 27060, loss = 6436.56
I0315 06:10:28.349432 29479 solver.cpp:229]     Train net output #0: loss = 5074.02 (* 1 = 5074.02 loss)
I0315 06:10:28.453449 29479 solver.cpp:610] Iteration 27060, lr = 8.77362e-09
I0315 06:10:28.453464 29479 solver.cpp:613] Iteration 27060, avg_grad_norm = 540984
I0315 06:10:52.443014 29479 solver.cpp:214] Iteration 27080, loss = 6480.99
I0315 06:10:52.443068 29479 solver.cpp:229]     Train net output #0: loss = 5644.04 (* 1 = 5644.04 loss)
I0315 06:10:52.557852 29479 solver.cpp:610] Iteration 27080, lr = 8.77271e-09
I0315 06:10:52.557867 29479 solver.cpp:613] Iteration 27080, avg_grad_norm = 561249
I0315 06:11:18.162165 29479 solver.cpp:214] Iteration 27100, loss = 6784.13
I0315 06:11:18.162305 29479 solver.cpp:229]     Train net output #0: loss = 5054.16 (* 1 = 5054.16 loss)
I0315 06:11:18.276954 29479 solver.cpp:610] Iteration 27100, lr = 8.7718e-09
I0315 06:11:18.276969 29479 solver.cpp:613] Iteration 27100, avg_grad_norm = 585401
I0315 06:11:43.806918 29479 solver.cpp:214] Iteration 27120, loss = 6401.88
I0315 06:11:43.806982 29479 solver.cpp:229]     Train net output #0: loss = 4235.49 (* 1 = 4235.49 loss)
I0315 06:11:43.919867 29479 solver.cpp:610] Iteration 27120, lr = 8.77088e-09
I0315 06:11:43.919880 29479 solver.cpp:613] Iteration 27120, avg_grad_norm = 547863
I0315 06:12:09.210484 29479 solver.cpp:214] Iteration 27140, loss = 6981.09
I0315 06:12:09.210602 29479 solver.cpp:229]     Train net output #0: loss = 5984.25 (* 1 = 5984.25 loss)
I0315 06:12:09.323539 29479 solver.cpp:610] Iteration 27140, lr = 8.76997e-09
I0315 06:12:09.323552 29479 solver.cpp:613] Iteration 27140, avg_grad_norm = 607661
I0315 06:12:34.908324 29479 solver.cpp:214] Iteration 27160, loss = 6351.3
I0315 06:12:34.908385 29479 solver.cpp:229]     Train net output #0: loss = 8294.79 (* 1 = 8294.79 loss)
I0315 06:12:35.023185 29479 solver.cpp:610] Iteration 27160, lr = 8.76906e-09
I0315 06:12:35.023198 29479 solver.cpp:613] Iteration 27160, avg_grad_norm = 598895
I0315 06:13:12.891932 29479 solver.cpp:214] Iteration 27180, loss = 6689.75
I0315 06:13:12.892052 29479 solver.cpp:229]     Train net output #0: loss = 12111.9 (* 1 = 12111.9 loss)
I0315 06:13:12.996999 29479 solver.cpp:610] Iteration 27180, lr = 8.76814e-09
I0315 06:13:12.997011 29479 solver.cpp:613] Iteration 27180, avg_grad_norm = 564684
I0315 06:13:36.447816 29479 solver.cpp:214] Iteration 27200, loss = 6359.81
I0315 06:13:36.447908 29479 solver.cpp:229]     Train net output #0: loss = 3778.66 (* 1 = 3778.66 loss)
I0315 06:13:36.552893 29479 solver.cpp:610] Iteration 27200, lr = 8.76723e-09
I0315 06:13:36.552907 29479 solver.cpp:613] Iteration 27200, avg_grad_norm = 537606
I0315 06:14:01.871578 29479 solver.cpp:214] Iteration 27220, loss = 7081.92
I0315 06:14:01.871726 29479 solver.cpp:229]     Train net output #0: loss = 5846.71 (* 1 = 5846.71 loss)
I0315 06:14:01.986080 29479 solver.cpp:610] Iteration 27220, lr = 8.76632e-09
I0315 06:14:01.986122 29479 solver.cpp:613] Iteration 27220, avg_grad_norm = 608486
I0315 06:14:27.603876 29479 solver.cpp:214] Iteration 27240, loss = 6589.56
I0315 06:14:27.603930 29479 solver.cpp:229]     Train net output #0: loss = 6891.43 (* 1 = 6891.43 loss)
I0315 06:14:27.718549 29479 solver.cpp:610] Iteration 27240, lr = 8.7654e-09
I0315 06:14:27.718562 29479 solver.cpp:613] Iteration 27240, avg_grad_norm = 578214
I0315 06:14:53.088683 29479 solver.cpp:214] Iteration 27260, loss = 6855.62
I0315 06:14:53.088920 29479 solver.cpp:229]     Train net output #0: loss = 10360.1 (* 1 = 10360.1 loss)
I0315 06:14:53.201853 29479 solver.cpp:610] Iteration 27260, lr = 8.76449e-09
I0315 06:14:53.201866 29479 solver.cpp:613] Iteration 27260, avg_grad_norm = 587812
I0315 06:15:18.555824 29479 solver.cpp:214] Iteration 27280, loss = 6910.58
I0315 06:15:18.555889 29479 solver.cpp:229]     Train net output #0: loss = 3523.62 (* 1 = 3523.62 loss)
I0315 06:15:18.670603 29479 solver.cpp:610] Iteration 27280, lr = 8.76358e-09
I0315 06:15:18.670615 29479 solver.cpp:613] Iteration 27280, avg_grad_norm = 565833
I0315 06:15:44.232090 29479 solver.cpp:214] Iteration 27300, loss = 6511.81
I0315 06:15:44.232260 29479 solver.cpp:229]     Train net output #0: loss = 5584.64 (* 1 = 5584.64 loss)
I0315 06:15:44.346596 29479 solver.cpp:610] Iteration 27300, lr = 8.76266e-09
I0315 06:15:44.346634 29479 solver.cpp:613] Iteration 27300, avg_grad_norm = 507287
I0315 06:16:58.103422 29479 solver.cpp:214] Iteration 27320, loss = 6679.04
I0315 06:16:58.103533 29479 solver.cpp:229]     Train net output #0: loss = 4903.56 (* 1 = 4903.56 loss)
I0315 06:16:58.208909 29479 solver.cpp:610] Iteration 27320, lr = 8.76175e-09
I0315 06:16:58.208921 29479 solver.cpp:613] Iteration 27320, avg_grad_norm = 594149
I0315 06:17:21.630877 29479 solver.cpp:214] Iteration 27340, loss = 6360.29
I0315 06:17:21.630934 29479 solver.cpp:229]     Train net output #0: loss = 4815.38 (* 1 = 4815.38 loss)
I0315 06:17:21.736214 29479 solver.cpp:610] Iteration 27340, lr = 8.76084e-09
I0315 06:17:21.736227 29479 solver.cpp:613] Iteration 27340, avg_grad_norm = 519979
I0315 06:17:45.199769 29479 solver.cpp:214] Iteration 27360, loss = 6291.65
I0315 06:17:45.199924 29479 solver.cpp:229]     Train net output #0: loss = 4600.2 (* 1 = 4600.2 loss)
I0315 06:17:45.305054 29479 solver.cpp:610] Iteration 27360, lr = 8.75992e-09
I0315 06:17:45.305068 29479 solver.cpp:613] Iteration 27360, avg_grad_norm = 615903
I0315 06:18:09.247480 29479 solver.cpp:214] Iteration 27380, loss = 6451.73
I0315 06:18:09.247565 29479 solver.cpp:229]     Train net output #0: loss = 3919.65 (* 1 = 3919.65 loss)
I0315 06:18:09.359118 29479 solver.cpp:610] Iteration 27380, lr = 8.75901e-09
I0315 06:18:09.359133 29479 solver.cpp:613] Iteration 27380, avg_grad_norm = 557951
I0315 06:18:34.441747 29479 solver.cpp:214] Iteration 27400, loss = 6376.68
I0315 06:18:34.441936 29479 solver.cpp:229]     Train net output #0: loss = 6733.34 (* 1 = 6733.34 loss)
I0315 06:18:34.554641 29479 solver.cpp:610] Iteration 27400, lr = 8.7581e-09
I0315 06:18:34.554654 29479 solver.cpp:613] Iteration 27400, avg_grad_norm = 563320
I0315 06:19:00.078434 29479 solver.cpp:214] Iteration 27420, loss = 6353.48
I0315 06:19:00.078501 29479 solver.cpp:229]     Train net output #0: loss = 4903.55 (* 1 = 4903.55 loss)
I0315 06:19:00.192934 29479 solver.cpp:610] Iteration 27420, lr = 8.75718e-09
I0315 06:19:00.192947 29479 solver.cpp:613] Iteration 27420, avg_grad_norm = 562257
I0315 06:19:49.321023 29479 solver.cpp:214] Iteration 27440, loss = 6653.67
I0315 06:19:49.321140 29479 solver.cpp:229]     Train net output #0: loss = 7180.72 (* 1 = 7180.72 loss)
I0315 06:19:49.426381 29479 solver.cpp:610] Iteration 27440, lr = 8.75627e-09
I0315 06:19:49.426395 29479 solver.cpp:613] Iteration 27440, avg_grad_norm = 524088
I0315 06:20:12.917830 29479 solver.cpp:214] Iteration 27460, loss = 6306.83
I0315 06:20:12.917894 29479 solver.cpp:229]     Train net output #0: loss = 4193.71 (* 1 = 4193.71 loss)
I0315 06:20:13.023042 29479 solver.cpp:610] Iteration 27460, lr = 8.75536e-09
I0315 06:20:13.023056 29479 solver.cpp:613] Iteration 27460, avg_grad_norm = 517398
I0315 06:20:37.085372 29479 solver.cpp:214] Iteration 27480, loss = 6641.46
I0315 06:20:37.085484 29479 solver.cpp:229]     Train net output #0: loss = 11644.5 (* 1 = 11644.5 loss)
I0315 06:20:37.198562 29479 solver.cpp:610] Iteration 27480, lr = 8.75444e-09
I0315 06:20:37.198575 29479 solver.cpp:613] Iteration 27480, avg_grad_norm = 578713
I0315 06:21:02.631507 29479 solver.cpp:214] Iteration 27500, loss = 6429.82
I0315 06:21:02.631572 29479 solver.cpp:229]     Train net output #0: loss = 4807.19 (* 1 = 4807.19 loss)
I0315 06:21:02.745995 29479 solver.cpp:610] Iteration 27500, lr = 8.75353e-09
I0315 06:21:02.746007 29479 solver.cpp:613] Iteration 27500, avg_grad_norm = 566392
I0315 06:21:28.349274 29479 solver.cpp:214] Iteration 27520, loss = 6694.14
I0315 06:21:28.349393 29479 solver.cpp:229]     Train net output #0: loss = 6725.17 (* 1 = 6725.17 loss)
I0315 06:21:28.463901 29479 solver.cpp:610] Iteration 27520, lr = 8.75262e-09
I0315 06:21:28.463913 29479 solver.cpp:613] Iteration 27520, avg_grad_norm = 592771
I0315 06:21:53.709112 29479 solver.cpp:214] Iteration 27540, loss = 6815.34
I0315 06:21:53.709162 29479 solver.cpp:229]     Train net output #0: loss = 7566.76 (* 1 = 7566.76 loss)
I0315 06:21:53.820546 29479 solver.cpp:610] Iteration 27540, lr = 8.7517e-09
I0315 06:21:53.820560 29479 solver.cpp:613] Iteration 27540, avg_grad_norm = 579296
I0315 06:22:31.747782 29479 solver.cpp:214] Iteration 27560, loss = 6743.52
I0315 06:22:31.747970 29479 solver.cpp:229]     Train net output #0: loss = 3577.69 (* 1 = 3577.69 loss)
I0315 06:22:31.851675 29479 solver.cpp:610] Iteration 27560, lr = 8.75079e-09
I0315 06:22:31.851688 29479 solver.cpp:613] Iteration 27560, avg_grad_norm = 605418
I0315 06:22:55.301669 29479 solver.cpp:214] Iteration 27580, loss = 6287.21
I0315 06:22:55.301733 29479 solver.cpp:229]     Train net output #0: loss = 9312.78 (* 1 = 9312.78 loss)
I0315 06:22:55.406504 29479 solver.cpp:610] Iteration 27580, lr = 8.74988e-09
I0315 06:22:55.406517 29479 solver.cpp:613] Iteration 27580, avg_grad_norm = 570264
I0315 06:23:20.631649 29479 solver.cpp:214] Iteration 27600, loss = 6513.59
I0315 06:23:20.631794 29479 solver.cpp:229]     Train net output #0: loss = 3997.85 (* 1 = 3997.85 loss)
I0315 06:23:20.747696 29479 solver.cpp:610] Iteration 27600, lr = 8.74896e-09
I0315 06:23:20.747710 29479 solver.cpp:613] Iteration 27600, avg_grad_norm = 597012
I0315 06:23:46.339912 29479 solver.cpp:214] Iteration 27620, loss = 6506.8
I0315 06:23:46.339964 29479 solver.cpp:229]     Train net output #0: loss = 5612.66 (* 1 = 5612.66 loss)
I0315 06:23:46.451881 29479 solver.cpp:610] Iteration 27620, lr = 8.74805e-09
I0315 06:23:46.451894 29479 solver.cpp:613] Iteration 27620, avg_grad_norm = 621399
I0315 06:24:11.440274 29479 solver.cpp:214] Iteration 27640, loss = 6691.46
I0315 06:24:11.440470 29479 solver.cpp:229]     Train net output #0: loss = 5529.44 (* 1 = 5529.44 loss)
I0315 06:24:11.551806 29479 solver.cpp:610] Iteration 27640, lr = 8.74714e-09
I0315 06:24:11.551843 29479 solver.cpp:613] Iteration 27640, avg_grad_norm = 615497
I0315 06:24:37.075109 29479 solver.cpp:214] Iteration 27660, loss = 6612.71
I0315 06:24:37.075172 29479 solver.cpp:229]     Train net output #0: loss = 6614 (* 1 = 6614 loss)
I0315 06:24:37.189878 29479 solver.cpp:610] Iteration 27660, lr = 8.74622e-09
I0315 06:24:37.189896 29479 solver.cpp:613] Iteration 27660, avg_grad_norm = 565141
I0315 06:25:02.804424 29479 solver.cpp:214] Iteration 27680, loss = 6721.81
I0315 06:25:02.804636 29479 solver.cpp:229]     Train net output #0: loss = 8123.91 (* 1 = 8123.91 loss)
I0315 06:25:02.919241 29479 solver.cpp:610] Iteration 27680, lr = 8.74531e-09
I0315 06:25:02.919256 29479 solver.cpp:613] Iteration 27680, avg_grad_norm = 535131
I0315 06:25:39.509068 29479 solver.cpp:214] Iteration 27700, loss = 6584.73
I0315 06:25:39.509182 29479 solver.cpp:229]     Train net output #0: loss = 5110.52 (* 1 = 5110.52 loss)
I0315 06:25:39.614348 29479 solver.cpp:610] Iteration 27700, lr = 8.74439e-09
I0315 06:25:39.614362 29479 solver.cpp:613] Iteration 27700, avg_grad_norm = 574651
I0315 06:26:04.109155 29479 solver.cpp:214] Iteration 27720, loss = 6971.12
I0315 06:26:04.109239 29479 solver.cpp:229]     Train net output #0: loss = 10001.9 (* 1 = 10001.9 loss)
I0315 06:26:04.223522 29479 solver.cpp:610] Iteration 27720, lr = 8.74348e-09
I0315 06:26:04.223536 29479 solver.cpp:613] Iteration 27720, avg_grad_norm = 575365
I0315 06:26:29.775643 29479 solver.cpp:214] Iteration 27740, loss = 6627.34
I0315 06:26:29.775861 29479 solver.cpp:229]     Train net output #0: loss = 6881.88 (* 1 = 6881.88 loss)
I0315 06:26:29.890308 29479 solver.cpp:610] Iteration 27740, lr = 8.74257e-09
I0315 06:26:29.890322 29479 solver.cpp:613] Iteration 27740, avg_grad_norm = 563192
I0315 06:26:55.454783 29479 solver.cpp:214] Iteration 27760, loss = 6936.2
I0315 06:26:55.454857 29479 solver.cpp:229]     Train net output #0: loss = 6638.61 (* 1 = 6638.61 loss)
I0315 06:26:55.569417 29479 solver.cpp:610] Iteration 27760, lr = 8.74165e-09
I0315 06:26:55.569432 29479 solver.cpp:613] Iteration 27760, avg_grad_norm = 598755
I0315 06:27:21.107776 29479 solver.cpp:214] Iteration 27780, loss = 6282.46
I0315 06:27:21.107904 29479 solver.cpp:229]     Train net output #0: loss = 7203.43 (* 1 = 7203.43 loss)
I0315 06:27:21.222304 29479 solver.cpp:610] Iteration 27780, lr = 8.74074e-09
I0315 06:27:21.222319 29479 solver.cpp:613] Iteration 27780, avg_grad_norm = 594073
I0315 06:27:46.771123 29479 solver.cpp:214] Iteration 27800, loss = 6647.43
I0315 06:27:46.771181 29479 solver.cpp:229]     Train net output #0: loss = 4415.08 (* 1 = 4415.08 loss)
I0315 06:27:46.885782 29479 solver.cpp:610] Iteration 27800, lr = 8.73983e-09
I0315 06:27:46.885795 29479 solver.cpp:613] Iteration 27800, avg_grad_norm = 546591
I0315 06:28:24.484215 29479 solver.cpp:214] Iteration 27820, loss = 6252.71
I0315 06:28:24.484341 29479 solver.cpp:229]     Train net output #0: loss = 6424.56 (* 1 = 6424.56 loss)
I0315 06:28:24.589309 29479 solver.cpp:610] Iteration 27820, lr = 8.73891e-09
I0315 06:28:24.589321 29479 solver.cpp:613] Iteration 27820, avg_grad_norm = 532675
I0315 06:28:48.237913 29479 solver.cpp:214] Iteration 27840, loss = 6431.87
I0315 06:28:48.237973 29479 solver.cpp:229]     Train net output #0: loss = 8428.27 (* 1 = 8428.27 loss)
I0315 06:28:48.350893 29479 solver.cpp:610] Iteration 27840, lr = 8.738e-09
I0315 06:28:48.350906 29479 solver.cpp:613] Iteration 27840, avg_grad_norm = 585480
I0315 06:29:13.891929 29479 solver.cpp:214] Iteration 27860, loss = 6685.08
I0315 06:29:13.892073 29479 solver.cpp:229]     Train net output #0: loss = 4281.21 (* 1 = 4281.21 loss)
I0315 06:29:14.006609 29479 solver.cpp:610] Iteration 27860, lr = 8.73709e-09
I0315 06:29:14.006652 29479 solver.cpp:613] Iteration 27860, avg_grad_norm = 606277
I0315 06:29:39.576493 29479 solver.cpp:214] Iteration 27880, loss = 6271.28
I0315 06:29:39.576557 29479 solver.cpp:229]     Train net output #0: loss = 4159.92 (* 1 = 4159.92 loss)
I0315 06:29:39.691073 29479 solver.cpp:610] Iteration 27880, lr = 8.73617e-09
I0315 06:29:39.691087 29479 solver.cpp:613] Iteration 27880, avg_grad_norm = 621201
I0315 06:30:05.224786 29479 solver.cpp:214] Iteration 27900, loss = 6553.42
I0315 06:30:05.224992 29479 solver.cpp:229]     Train net output #0: loss = 9895.34 (* 1 = 9895.34 loss)
I0315 06:30:05.339419 29479 solver.cpp:610] Iteration 27900, lr = 8.73526e-09
I0315 06:30:05.339433 29479 solver.cpp:613] Iteration 27900, avg_grad_norm = 690646
I0315 06:30:30.926779 29479 solver.cpp:214] Iteration 27920, loss = 6857.66
I0315 06:30:30.926847 29479 solver.cpp:229]     Train net output #0: loss = 5352.47 (* 1 = 5352.47 loss)
I0315 06:30:31.041352 29479 solver.cpp:610] Iteration 27920, lr = 8.73435e-09
I0315 06:30:31.041368 29479 solver.cpp:613] Iteration 27920, avg_grad_norm = 612137
I0315 06:31:30.688691 29479 solver.cpp:214] Iteration 27940, loss = 6752.99
I0315 06:31:30.688834 29479 solver.cpp:229]     Train net output #0: loss = 9106.46 (* 1 = 9106.46 loss)
I0315 06:31:30.794029 29479 solver.cpp:610] Iteration 27940, lr = 8.73343e-09
I0315 06:31:30.794042 29479 solver.cpp:613] Iteration 27940, avg_grad_norm = 636685
I0315 06:31:54.200245 29479 solver.cpp:214] Iteration 27960, loss = 6422.9
I0315 06:31:54.200314 29479 solver.cpp:229]     Train net output #0: loss = 5059.28 (* 1 = 5059.28 loss)
I0315 06:31:54.304231 29479 solver.cpp:610] Iteration 27960, lr = 8.73252e-09
I0315 06:31:54.304244 29479 solver.cpp:613] Iteration 27960, avg_grad_norm = 674761
I0315 06:32:17.730509 29479 solver.cpp:214] Iteration 27980, loss = 6656.71
I0315 06:32:17.730630 29479 solver.cpp:229]     Train net output #0: loss = 9305.33 (* 1 = 9305.33 loss)
I0315 06:32:17.835845 29479 solver.cpp:610] Iteration 27980, lr = 8.7316e-09
I0315 06:32:17.835858 29479 solver.cpp:613] Iteration 27980, avg_grad_norm = 586256
I0315 06:32:41.733475 29479 solver.cpp:214] Iteration 28000, loss = 6229.3
I0315 06:32:41.733538 29479 solver.cpp:229]     Train net output #0: loss = 4353.09 (* 1 = 4353.09 loss)
I0315 06:32:41.845041 29479 solver.cpp:610] Iteration 28000, lr = 8.73069e-09
I0315 06:32:41.845053 29479 solver.cpp:613] Iteration 28000, avg_grad_norm = 565766
I0315 06:33:07.183430 29479 solver.cpp:214] Iteration 28020, loss = 6325.86
I0315 06:33:07.183600 29479 solver.cpp:229]     Train net output #0: loss = 8835.68 (* 1 = 8835.68 loss)
I0315 06:33:07.298344 29479 solver.cpp:610] Iteration 28020, lr = 8.72978e-09
I0315 06:33:07.298360 29479 solver.cpp:613] Iteration 28020, avg_grad_norm = 562456
I0315 06:33:32.904621 29479 solver.cpp:214] Iteration 28040, loss = 6168.32
I0315 06:33:32.904707 29479 solver.cpp:229]     Train net output #0: loss = 5297.9 (* 1 = 5297.9 loss)
I0315 06:33:33.019171 29479 solver.cpp:610] Iteration 28040, lr = 8.72886e-09
I0315 06:33:33.019184 29479 solver.cpp:613] Iteration 28040, avg_grad_norm = 607634
I0315 06:33:58.519872 29479 solver.cpp:214] Iteration 28060, loss = 6647.37
I0315 06:33:58.520082 29479 solver.cpp:229]     Train net output #0: loss = 6064.99 (* 1 = 6064.99 loss)
I0315 06:33:58.632967 29479 solver.cpp:610] Iteration 28060, lr = 8.72795e-09
I0315 06:33:58.632982 29479 solver.cpp:613] Iteration 28060, avg_grad_norm = 596553
I0315 06:34:44.463901 29479 solver.cpp:214] Iteration 28080, loss = 6353.18
I0315 06:34:44.464026 29479 solver.cpp:229]     Train net output #0: loss = 4516.45 (* 1 = 4516.45 loss)
I0315 06:34:44.569355 29479 solver.cpp:610] Iteration 28080, lr = 8.72704e-09
I0315 06:34:44.569370 29479 solver.cpp:613] Iteration 28080, avg_grad_norm = 681095
I0315 06:35:08.046349 29479 solver.cpp:214] Iteration 28100, loss = 6428.39
I0315 06:35:08.046422 29479 solver.cpp:229]     Train net output #0: loss = 7392.46 (* 1 = 7392.46 loss)
I0315 06:35:08.151497 29479 solver.cpp:610] Iteration 28100, lr = 8.72612e-09
I0315 06:35:08.151511 29479 solver.cpp:613] Iteration 28100, avg_grad_norm = 608507
I0315 06:35:33.202968 29479 solver.cpp:214] Iteration 28120, loss = 6465.75
I0315 06:35:33.203184 29479 solver.cpp:229]     Train net output #0: loss = 4769.13 (* 1 = 4769.13 loss)
I0315 06:35:33.317524 29479 solver.cpp:610] Iteration 28120, lr = 8.72521e-09
I0315 06:35:33.317538 29479 solver.cpp:613] Iteration 28120, avg_grad_norm = 602172
I0315 06:35:58.886171 29479 solver.cpp:214] Iteration 28140, loss = 6589.97
I0315 06:35:58.886248 29479 solver.cpp:229]     Train net output #0: loss = 4647.83 (* 1 = 4647.83 loss)
I0315 06:35:59.000706 29479 solver.cpp:610] Iteration 28140, lr = 8.7243e-09
I0315 06:35:59.000740 29479 solver.cpp:613] Iteration 28140, avg_grad_norm = 618884
I0315 06:36:24.498484 29479 solver.cpp:214] Iteration 28160, loss = 6120.81
I0315 06:36:24.498605 29479 solver.cpp:229]     Train net output #0: loss = 4891.21 (* 1 = 4891.21 loss)
I0315 06:36:24.611424 29479 solver.cpp:610] Iteration 28160, lr = 8.72338e-09
I0315 06:36:24.611439 29479 solver.cpp:613] Iteration 28160, avg_grad_norm = 562785
I0315 06:36:49.896515 29479 solver.cpp:214] Iteration 28180, loss = 6528.25
I0315 06:36:49.896570 29479 solver.cpp:229]     Train net output #0: loss = 8096.63 (* 1 = 8096.63 loss)
I0315 06:36:50.009356 29479 solver.cpp:610] Iteration 28180, lr = 8.72247e-09
I0315 06:36:50.009369 29479 solver.cpp:613] Iteration 28180, avg_grad_norm = 531103
I0315 06:37:27.508991 29479 solver.cpp:214] Iteration 28200, loss = 6540.34
I0315 06:37:27.509165 29479 solver.cpp:229]     Train net output #0: loss = 3580.74 (* 1 = 3580.74 loss)
I0315 06:37:27.614051 29479 solver.cpp:610] Iteration 28200, lr = 8.72155e-09
I0315 06:37:27.614064 29479 solver.cpp:613] Iteration 28200, avg_grad_norm = 579056
I0315 06:37:51.253710 29479 solver.cpp:214] Iteration 28220, loss = 6641.11
I0315 06:37:51.253778 29479 solver.cpp:229]     Train net output #0: loss = 6352.82 (* 1 = 6352.82 loss)
I0315 06:37:51.365274 29479 solver.cpp:610] Iteration 28220, lr = 8.72064e-09
I0315 06:37:51.365288 29479 solver.cpp:613] Iteration 28220, avg_grad_norm = 545201
I0315 06:38:16.889361 29479 solver.cpp:214] Iteration 28240, loss = 6414.34
I0315 06:38:16.889515 29479 solver.cpp:229]     Train net output #0: loss = 3461.38 (* 1 = 3461.38 loss)
I0315 06:38:17.004076 29479 solver.cpp:610] Iteration 28240, lr = 8.71973e-09
I0315 06:38:17.004091 29479 solver.cpp:613] Iteration 28240, avg_grad_norm = 535108
I0315 06:38:42.607025 29479 solver.cpp:214] Iteration 28260, loss = 6538.08
I0315 06:38:42.607096 29479 solver.cpp:229]     Train net output #0: loss = 5653.14 (* 1 = 5653.14 loss)
I0315 06:38:42.721642 29479 solver.cpp:610] Iteration 28260, lr = 8.71881e-09
I0315 06:38:42.721655 29479 solver.cpp:613] Iteration 28260, avg_grad_norm = 676517
I0315 06:39:08.318104 29479 solver.cpp:214] Iteration 28280, loss = 6603.4
I0315 06:39:08.318281 29479 solver.cpp:229]     Train net output #0: loss = 6370.83 (* 1 = 6370.83 loss)
I0315 06:39:08.432749 29479 solver.cpp:610] Iteration 28280, lr = 8.7179e-09
I0315 06:39:08.432763 29479 solver.cpp:613] Iteration 28280, avg_grad_norm = 646035
I0315 06:39:33.979286 29479 solver.cpp:214] Iteration 28300, loss = 6962.59
I0315 06:39:33.979336 29479 solver.cpp:229]     Train net output #0: loss = 6282.76 (* 1 = 6282.76 loss)
I0315 06:39:34.092226 29479 solver.cpp:610] Iteration 28300, lr = 8.71698e-09
I0315 06:39:34.092239 29479 solver.cpp:613] Iteration 28300, avg_grad_norm = 541865
I0315 06:40:12.360620 29479 solver.cpp:214] Iteration 28320, loss = 6604.56
I0315 06:40:12.360726 29479 solver.cpp:229]     Train net output #0: loss = 6116.52 (* 1 = 6116.52 loss)
I0315 06:40:12.465911 29479 solver.cpp:610] Iteration 28320, lr = 8.71607e-09
I0315 06:40:12.465924 29479 solver.cpp:613] Iteration 28320, avg_grad_norm = 635193
I0315 06:40:35.916007 29479 solver.cpp:214] Iteration 28340, loss = 6355.91
I0315 06:40:35.916080 29479 solver.cpp:229]     Train net output #0: loss = 4244.95 (* 1 = 4244.95 loss)
I0315 06:40:36.020295 29479 solver.cpp:610] Iteration 28340, lr = 8.71516e-09
I0315 06:40:36.020309 29479 solver.cpp:613] Iteration 28340, avg_grad_norm = 611116
I0315 06:41:01.068967 29479 solver.cpp:214] Iteration 28360, loss = 6588.2
I0315 06:41:01.069191 29479 solver.cpp:229]     Train net output #0: loss = 5154.73 (* 1 = 5154.73 loss)
I0315 06:41:01.183353 29479 solver.cpp:610] Iteration 28360, lr = 8.71424e-09
I0315 06:41:01.183367 29479 solver.cpp:613] Iteration 28360, avg_grad_norm = 604865
I0315 06:41:26.776358 29479 solver.cpp:214] Iteration 28380, loss = 6538.2
I0315 06:41:26.776407 29479 solver.cpp:229]     Train net output #0: loss = 8283.35 (* 1 = 8283.35 loss)
I0315 06:41:26.890965 29479 solver.cpp:610] Iteration 28380, lr = 8.71333e-09
I0315 06:41:26.890979 29479 solver.cpp:613] Iteration 28380, avg_grad_norm = 633346
I0315 06:41:52.489827 29479 solver.cpp:214] Iteration 28400, loss = 6374.53
I0315 06:41:52.489946 29479 solver.cpp:229]     Train net output #0: loss = 5628.31 (* 1 = 5628.31 loss)
I0315 06:41:52.604552 29479 solver.cpp:610] Iteration 28400, lr = 8.71241e-09
I0315 06:41:52.604564 29479 solver.cpp:613] Iteration 28400, avg_grad_norm = 601837
I0315 06:42:18.166460 29479 solver.cpp:214] Iteration 28420, loss = 6352.71
I0315 06:42:18.166539 29479 solver.cpp:229]     Train net output #0: loss = 7865.92 (* 1 = 7865.92 loss)
I0315 06:42:18.281051 29479 solver.cpp:610] Iteration 28420, lr = 8.7115e-09
I0315 06:42:18.281064 29479 solver.cpp:613] Iteration 28420, avg_grad_norm = 616737
I0315 06:42:43.825265 29479 solver.cpp:214] Iteration 28440, loss = 6426.34
I0315 06:42:43.825400 29479 solver.cpp:229]     Train net output #0: loss = 11535.4 (* 1 = 11535.4 loss)
I0315 06:42:43.939820 29479 solver.cpp:610] Iteration 28440, lr = 8.71059e-09
I0315 06:42:43.939832 29479 solver.cpp:613] Iteration 28440, avg_grad_norm = 567472
I0315 06:43:21.014035 29479 solver.cpp:214] Iteration 28460, loss = 6629.64
I0315 06:43:21.014179 29479 solver.cpp:229]     Train net output #0: loss = 5083.43 (* 1 = 5083.43 loss)
I0315 06:43:21.119185 29479 solver.cpp:610] Iteration 28460, lr = 8.70967e-09
I0315 06:43:21.119199 29479 solver.cpp:613] Iteration 28460, avg_grad_norm = 605289
I0315 06:43:45.310235 29479 solver.cpp:214] Iteration 28480, loss = 6532.56
I0315 06:43:45.310319 29479 solver.cpp:229]     Train net output #0: loss = 11209.6 (* 1 = 11209.6 loss)
I0315 06:43:45.425041 29479 solver.cpp:610] Iteration 28480, lr = 8.70876e-09
I0315 06:43:45.425055 29479 solver.cpp:613] Iteration 28480, avg_grad_norm = 561669
I0315 06:44:11.015058 29479 solver.cpp:214] Iteration 28500, loss = 6155.43
I0315 06:44:11.015250 29479 solver.cpp:229]     Train net output #0: loss = 9516.12 (* 1 = 9516.12 loss)
I0315 06:44:11.129703 29479 solver.cpp:610] Iteration 28500, lr = 8.70785e-09
I0315 06:44:11.129741 29479 solver.cpp:613] Iteration 28500, avg_grad_norm = 517807
I0315 06:44:36.759016 29479 solver.cpp:214] Iteration 28520, loss = 6213.46
I0315 06:44:36.759079 29479 solver.cpp:229]     Train net output #0: loss = 10404.6 (* 1 = 10404.6 loss)
I0315 06:44:36.873669 29479 solver.cpp:610] Iteration 28520, lr = 8.70693e-09
I0315 06:44:36.873683 29479 solver.cpp:613] Iteration 28520, avg_grad_norm = 574037
I0315 06:45:02.476197 29479 solver.cpp:214] Iteration 28540, loss = 6434.91
I0315 06:45:02.476378 29479 solver.cpp:229]     Train net output #0: loss = 6944.53 (* 1 = 6944.53 loss)
I0315 06:45:02.590744 29479 solver.cpp:610] Iteration 28540, lr = 8.70602e-09
I0315 06:45:02.590757 29479 solver.cpp:613] Iteration 28540, avg_grad_norm = 564258
I0315 06:45:28.200484 29479 solver.cpp:214] Iteration 28560, loss = 6586.66
I0315 06:45:28.200534 29479 solver.cpp:229]     Train net output #0: loss = 6848.18 (* 1 = 6848.18 loss)
I0315 06:45:28.315004 29479 solver.cpp:610] Iteration 28560, lr = 8.7051e-09
I0315 06:45:28.315018 29479 solver.cpp:613] Iteration 28560, avg_grad_norm = 523218
I0315 06:46:21.401651 29479 solver.cpp:214] Iteration 28580, loss = 6397.95
I0315 06:46:21.401912 29479 solver.cpp:229]     Train net output #0: loss = 8614.44 (* 1 = 8614.44 loss)
I0315 06:46:21.506888 29479 solver.cpp:610] Iteration 28580, lr = 8.70419e-09
I0315 06:46:21.506902 29479 solver.cpp:613] Iteration 28580, avg_grad_norm = 522725
I0315 06:46:44.920959 29479 solver.cpp:214] Iteration 28600, loss = 6637.42
I0315 06:46:44.921006 29479 solver.cpp:229]     Train net output #0: loss = 6030.59 (* 1 = 6030.59 loss)
I0315 06:46:45.026211 29479 solver.cpp:610] Iteration 28600, lr = 8.70328e-09
I0315 06:46:45.026223 29479 solver.cpp:613] Iteration 28600, avg_grad_norm = 529793
I0315 06:47:08.521796 29479 solver.cpp:214] Iteration 28620, loss = 6589.21
I0315 06:47:08.521991 29479 solver.cpp:229]     Train net output #0: loss = 5970.72 (* 1 = 5970.72 loss)
I0315 06:47:08.631283 29479 solver.cpp:610] Iteration 28620, lr = 8.70236e-09
I0315 06:47:08.631296 29479 solver.cpp:613] Iteration 28620, avg_grad_norm = 655461
I0315 06:47:34.212976 29479 solver.cpp:214] Iteration 28640, loss = 6223.46
I0315 06:47:34.213044 29479 solver.cpp:229]     Train net output #0: loss = 4600.18 (* 1 = 4600.18 loss)
I0315 06:47:34.327689 29479 solver.cpp:610] Iteration 28640, lr = 8.70145e-09
I0315 06:47:34.327702 29479 solver.cpp:613] Iteration 28640, avg_grad_norm = 564714
I0315 06:47:59.500147 29479 solver.cpp:214] Iteration 28660, loss = 6590.72
I0315 06:47:59.500267 29479 solver.cpp:229]     Train net output #0: loss = 7319.59 (* 1 = 7319.59 loss)
I0315 06:47:59.611747 29479 solver.cpp:610] Iteration 28660, lr = 8.70053e-09
I0315 06:47:59.611760 29479 solver.cpp:613] Iteration 28660, avg_grad_norm = 598121
I0315 06:48:24.539444 29479 solver.cpp:214] Iteration 28680, loss = 6358.59
I0315 06:48:24.539515 29479 solver.cpp:229]     Train net output #0: loss = 4894.27 (* 1 = 4894.27 loss)
I0315 06:48:24.650934 29479 solver.cpp:610] Iteration 28680, lr = 8.69962e-09
I0315 06:48:24.650965 29479 solver.cpp:613] Iteration 28680, avg_grad_norm = 544743
I0315 06:49:18.028614 29479 solver.cpp:214] Iteration 28700, loss = 6576.25
I0315 06:49:18.028774 29479 solver.cpp:229]     Train net output #0: loss = 5822.03 (* 1 = 5822.03 loss)
I0315 06:49:18.132256 29479 solver.cpp:610] Iteration 28700, lr = 8.69871e-09
I0315 06:49:18.132279 29479 solver.cpp:613] Iteration 28700, avg_grad_norm = 560593
I0315 06:49:41.560742 29479 solver.cpp:214] Iteration 28720, loss = 6209.86
I0315 06:49:41.560806 29479 solver.cpp:229]     Train net output #0: loss = 3023.92 (* 1 = 3023.92 loss)
I0315 06:49:41.666026 29479 solver.cpp:610] Iteration 28720, lr = 8.69779e-09
I0315 06:49:41.666039 29479 solver.cpp:613] Iteration 28720, avg_grad_norm = 619016
I0315 06:50:05.172778 29479 solver.cpp:214] Iteration 28740, loss = 6431.15
I0315 06:50:05.172951 29479 solver.cpp:229]     Train net output #0: loss = 10350.1 (* 1 = 10350.1 loss)
I0315 06:50:05.278059 29479 solver.cpp:610] Iteration 28740, lr = 8.69688e-09
I0315 06:50:05.278074 29479 solver.cpp:613] Iteration 28740, avg_grad_norm = 646476
I0315 06:50:29.886454 29479 solver.cpp:214] Iteration 28760, loss = 6761.99
I0315 06:50:29.886512 29479 solver.cpp:229]     Train net output #0: loss = 3324.04 (* 1 = 3324.04 loss)
I0315 06:50:29.999640 29479 solver.cpp:610] Iteration 28760, lr = 8.69596e-09
I0315 06:50:29.999653 29479 solver.cpp:613] Iteration 28760, avg_grad_norm = 620233
I0315 06:50:55.374927 29479 solver.cpp:214] Iteration 28780, loss = 6609.12
I0315 06:50:55.375149 29479 solver.cpp:229]     Train net output #0: loss = 11676.4 (* 1 = 11676.4 loss)
I0315 06:50:55.489513 29479 solver.cpp:610] Iteration 28780, lr = 8.69505e-09
I0315 06:50:55.489527 29479 solver.cpp:613] Iteration 28780, avg_grad_norm = 569454
I0315 06:51:21.065438 29479 solver.cpp:214] Iteration 28800, loss = 6474.46
I0315 06:51:21.065536 29479 solver.cpp:229]     Train net output #0: loss = 3511.64 (* 1 = 3511.64 loss)
I0315 06:51:21.180075 29479 solver.cpp:610] Iteration 28800, lr = 8.69414e-09
I0315 06:51:21.180110 29479 solver.cpp:613] Iteration 28800, avg_grad_norm = 595613
I0315 06:51:46.763185 29479 solver.cpp:214] Iteration 28820, loss = 6736.05
I0315 06:51:46.763314 29479 solver.cpp:229]     Train net output #0: loss = 4184.45 (* 1 = 4184.45 loss)
I0315 06:51:46.877818 29479 solver.cpp:610] Iteration 28820, lr = 8.69322e-09
I0315 06:51:46.877833 29479 solver.cpp:613] Iteration 28820, avg_grad_norm = 614458
I0315 06:52:24.384837 29479 solver.cpp:214] Iteration 28840, loss = 6681.54
I0315 06:52:24.385057 29479 solver.cpp:229]     Train net output #0: loss = 6508.27 (* 1 = 6508.27 loss)
I0315 06:52:24.490175 29479 solver.cpp:610] Iteration 28840, lr = 8.69231e-09
I0315 06:52:24.490190 29479 solver.cpp:613] Iteration 28840, avg_grad_norm = 527404
I0315 06:52:48.349735 29479 solver.cpp:214] Iteration 28860, loss = 6509.42
I0315 06:52:48.349787 29479 solver.cpp:229]     Train net output #0: loss = 6545.06 (* 1 = 6545.06 loss)
I0315 06:52:48.464296 29479 solver.cpp:610] Iteration 28860, lr = 8.69139e-09
I0315 06:52:48.464308 29479 solver.cpp:613] Iteration 28860, avg_grad_norm = 541251
I0315 06:53:14.050693 29479 solver.cpp:214] Iteration 28880, loss = 6482.25
I0315 06:53:14.050849 29479 solver.cpp:229]     Train net output #0: loss = 10824.4 (* 1 = 10824.4 loss)
I0315 06:53:14.165273 29479 solver.cpp:610] Iteration 28880, lr = 8.69048e-09
I0315 06:53:14.165288 29479 solver.cpp:613] Iteration 28880, avg_grad_norm = 620275
I0315 06:53:39.740097 29479 solver.cpp:214] Iteration 28900, loss = 6317.81
I0315 06:53:39.740152 29479 solver.cpp:229]     Train net output #0: loss = 4436.03 (* 1 = 4436.03 loss)
I0315 06:53:39.854754 29479 solver.cpp:610] Iteration 28900, lr = 8.68956e-09
I0315 06:53:39.854768 29479 solver.cpp:613] Iteration 28900, avg_grad_norm = 557115
I0315 06:54:05.279678 29479 solver.cpp:214] Iteration 28920, loss = 6831.69
I0315 06:54:05.279814 29479 solver.cpp:229]     Train net output #0: loss = 4804.51 (* 1 = 4804.51 loss)
I0315 06:54:05.392791 29479 solver.cpp:610] Iteration 28920, lr = 8.68865e-09
I0315 06:54:05.392806 29479 solver.cpp:613] Iteration 28920, avg_grad_norm = 529342
I0315 06:54:30.792052 29479 solver.cpp:214] Iteration 28940, loss = 6610.93
I0315 06:54:30.792127 29479 solver.cpp:229]     Train net output #0: loss = 11997.4 (* 1 = 11997.4 loss)
I0315 06:54:30.906684 29479 solver.cpp:610] Iteration 28940, lr = 8.68774e-09
I0315 06:54:30.906734 29479 solver.cpp:613] Iteration 28940, avg_grad_norm = 567982
I0315 06:55:08.629628 29479 solver.cpp:214] Iteration 28960, loss = 6715.55
I0315 06:55:08.629834 29479 solver.cpp:229]     Train net output #0: loss = 4125.25 (* 1 = 4125.25 loss)
I0315 06:55:08.734694 29479 solver.cpp:610] Iteration 28960, lr = 8.68682e-09
I0315 06:55:08.734709 29479 solver.cpp:613] Iteration 28960, avg_grad_norm = 599950
I0315 06:55:32.327672 29479 solver.cpp:214] Iteration 28980, loss = 6519.15
I0315 06:55:32.327726 29479 solver.cpp:229]     Train net output #0: loss = 13841.6 (* 1 = 13841.6 loss)
I0315 06:55:32.439404 29479 solver.cpp:610] Iteration 28980, lr = 8.68591e-09
I0315 06:55:32.439417 29479 solver.cpp:613] Iteration 28980, avg_grad_norm = 562288
I0315 06:55:58.039788 29479 solver.cpp:214] Iteration 29000, loss = 6331.84
I0315 06:55:58.040046 29479 solver.cpp:229]     Train net output #0: loss = 4389.18 (* 1 = 4389.18 loss)
I0315 06:55:58.154664 29479 solver.cpp:610] Iteration 29000, lr = 8.68499e-09
I0315 06:55:58.154678 29479 solver.cpp:613] Iteration 29000, avg_grad_norm = 557398
I0315 06:56:23.747586 29479 solver.cpp:214] Iteration 29020, loss = 6825.32
I0315 06:56:23.747635 29479 solver.cpp:229]     Train net output #0: loss = 7106.91 (* 1 = 7106.91 loss)
I0315 06:56:23.860472 29479 solver.cpp:610] Iteration 29020, lr = 8.68408e-09
I0315 06:56:23.860486 29479 solver.cpp:613] Iteration 29020, avg_grad_norm = 692460
I0315 06:56:49.157299 29479 solver.cpp:214] Iteration 29040, loss = 6132.12
I0315 06:56:49.157433 29479 solver.cpp:229]     Train net output #0: loss = 4674.85 (* 1 = 4674.85 loss)
I0315 06:56:49.270211 29479 solver.cpp:610] Iteration 29040, lr = 8.68317e-09
I0315 06:56:49.270226 29479 solver.cpp:613] Iteration 29040, avg_grad_norm = 543753
I0315 06:57:14.778856 29479 solver.cpp:214] Iteration 29060, loss = 6563.05
I0315 06:57:14.778904 29479 solver.cpp:229]     Train net output #0: loss = 8431.42 (* 1 = 8431.42 loss)
I0315 06:57:14.894920 29479 solver.cpp:610] Iteration 29060, lr = 8.68225e-09
I0315 06:57:14.894934 29479 solver.cpp:613] Iteration 29060, avg_grad_norm = 636011
I0315 06:57:40.749002 29479 solver.cpp:214] Iteration 29080, loss = 6508.9
I0315 06:57:40.749141 29479 solver.cpp:229]     Train net output #0: loss = 2819.89 (* 1 = 2819.89 loss)
I0315 06:57:40.863780 29479 solver.cpp:610] Iteration 29080, lr = 8.68134e-09
I0315 06:57:40.863792 29479 solver.cpp:613] Iteration 29080, avg_grad_norm = 556192
I0315 06:58:17.394512 29479 solver.cpp:214] Iteration 29100, loss = 6195.55
I0315 06:58:17.394645 29479 solver.cpp:229]     Train net output #0: loss = 7074.23 (* 1 = 7074.23 loss)
I0315 06:58:17.499605 29479 solver.cpp:610] Iteration 29100, lr = 8.68042e-09
I0315 06:58:17.499619 29479 solver.cpp:613] Iteration 29100, avg_grad_norm = 602999
I0315 06:58:42.223669 29479 solver.cpp:214] Iteration 29120, loss = 6312.86
I0315 06:58:42.223738 29479 solver.cpp:229]     Train net output #0: loss = 5965.56 (* 1 = 5965.56 loss)
I0315 06:58:42.338241 29479 solver.cpp:610] Iteration 29120, lr = 8.67951e-09
I0315 06:58:42.338254 29479 solver.cpp:613] Iteration 29120, avg_grad_norm = 540422
I0315 06:59:07.877856 29479 solver.cpp:214] Iteration 29140, loss = 6320.43
I0315 06:59:07.878006 29479 solver.cpp:229]     Train net output #0: loss = 8939.53 (* 1 = 8939.53 loss)
I0315 06:59:07.992396 29479 solver.cpp:610] Iteration 29140, lr = 8.67859e-09
I0315 06:59:07.992409 29479 solver.cpp:613] Iteration 29140, avg_grad_norm = 557619
I0315 06:59:33.616478 29479 solver.cpp:214] Iteration 29160, loss = 6804.46
I0315 06:59:33.616531 29479 solver.cpp:229]     Train net output #0: loss = 6000.65 (* 1 = 6000.65 loss)
I0315 06:59:33.731580 29479 solver.cpp:610] Iteration 29160, lr = 8.67768e-09
I0315 06:59:33.731592 29479 solver.cpp:613] Iteration 29160, avg_grad_norm = 601598
I0315 06:59:59.318580 29479 solver.cpp:214] Iteration 29180, loss = 6356.95
I0315 06:59:59.318718 29479 solver.cpp:229]     Train net output #0: loss = 3968.05 (* 1 = 3968.05 loss)
I0315 06:59:59.431470 29479 solver.cpp:610] Iteration 29180, lr = 8.67677e-09
I0315 06:59:59.431484 29479 solver.cpp:613] Iteration 29180, avg_grad_norm = 590614
I0315 07:00:24.731709 29479 solver.cpp:214] Iteration 29200, loss = 6652.4
I0315 07:00:24.731770 29479 solver.cpp:229]     Train net output #0: loss = 3626.28 (* 1 = 3626.28 loss)
I0315 07:00:24.844688 29479 solver.cpp:610] Iteration 29200, lr = 8.67585e-09
I0315 07:00:24.844702 29479 solver.cpp:613] Iteration 29200, avg_grad_norm = 623035
I0315 07:01:04.806054 29479 solver.cpp:214] Iteration 29220, loss = 6669.32
I0315 07:01:04.806234 29479 solver.cpp:229]     Train net output #0: loss = 6396.59 (* 1 = 6396.59 loss)
I0315 07:01:04.911095 29479 solver.cpp:610] Iteration 29220, lr = 8.67494e-09
I0315 07:01:04.911108 29479 solver.cpp:613] Iteration 29220, avg_grad_norm = 547742
I0315 07:01:28.740942 29479 solver.cpp:214] Iteration 29240, loss = 6558.44
I0315 07:01:28.740996 29479 solver.cpp:229]     Train net output #0: loss = 8329.11 (* 1 = 8329.11 loss)
I0315 07:01:28.855628 29479 solver.cpp:610] Iteration 29240, lr = 8.67402e-09
I0315 07:01:28.855641 29479 solver.cpp:613] Iteration 29240, avg_grad_norm = 623086
I0315 07:01:54.450608 29479 solver.cpp:214] Iteration 29260, loss = 6156.37
I0315 07:01:54.450743 29479 solver.cpp:229]     Train net output #0: loss = 6050.38 (* 1 = 6050.38 loss)
I0315 07:01:54.565176 29479 solver.cpp:610] Iteration 29260, lr = 8.67311e-09
I0315 07:01:54.565189 29479 solver.cpp:613] Iteration 29260, avg_grad_norm = 539191
I0315 07:02:20.158895 29479 solver.cpp:214] Iteration 29280, loss = 6043.28
I0315 07:02:20.158959 29479 solver.cpp:229]     Train net output #0: loss = 5381.1 (* 1 = 5381.1 loss)
I0315 07:02:20.273473 29479 solver.cpp:610] Iteration 29280, lr = 8.67219e-09
I0315 07:02:20.273488 29479 solver.cpp:613] Iteration 29280, avg_grad_norm = 592101
I0315 07:02:45.590556 29479 solver.cpp:214] Iteration 29300, loss = 6471.98
I0315 07:02:45.590690 29479 solver.cpp:229]     Train net output #0: loss = 6739.01 (* 1 = 6739.01 loss)
I0315 07:02:45.703795 29479 solver.cpp:610] Iteration 29300, lr = 8.67128e-09
I0315 07:02:45.703809 29479 solver.cpp:613] Iteration 29300, avg_grad_norm = 685899
I0315 07:03:11.234936 29479 solver.cpp:214] Iteration 29320, loss = 6463.55
I0315 07:03:11.234984 29479 solver.cpp:229]     Train net output #0: loss = 4498.66 (* 1 = 4498.66 loss)
I0315 07:03:11.349496 29479 solver.cpp:610] Iteration 29320, lr = 8.67036e-09
I0315 07:03:11.349509 29479 solver.cpp:613] Iteration 29320, avg_grad_norm = 573837
I0315 07:04:06.183725 29479 solver.cpp:214] Iteration 29340, loss = 6637.46
I0315 07:04:06.183871 29479 solver.cpp:229]     Train net output #0: loss = 3207.43 (* 1 = 3207.43 loss)
I0315 07:04:06.289077 29479 solver.cpp:610] Iteration 29340, lr = 8.66945e-09
I0315 07:04:06.289114 29479 solver.cpp:613] Iteration 29340, avg_grad_norm = 571607
I0315 07:04:29.762218 29479 solver.cpp:214] Iteration 29360, loss = 6496.67
I0315 07:04:29.762285 29479 solver.cpp:229]     Train net output #0: loss = 5490.56 (* 1 = 5490.56 loss)
I0315 07:04:29.867624 29479 solver.cpp:610] Iteration 29360, lr = 8.66854e-09
I0315 07:04:29.867637 29479 solver.cpp:613] Iteration 29360, avg_grad_norm = 543489
I0315 07:04:53.396018 29479 solver.cpp:214] Iteration 29380, loss = 6455.57
I0315 07:04:53.396122 29479 solver.cpp:229]     Train net output #0: loss = 10839 (* 1 = 10839 loss)
I0315 07:04:53.501283 29479 solver.cpp:610] Iteration 29380, lr = 8.66762e-09
I0315 07:04:53.501296 29479 solver.cpp:613] Iteration 29380, avg_grad_norm = 625974
I0315 07:05:18.286025 29479 solver.cpp:214] Iteration 29400, loss = 7090.73
I0315 07:05:18.286075 29479 solver.cpp:229]     Train net output #0: loss = 5521.88 (* 1 = 5521.88 loss)
I0315 07:05:18.398965 29479 solver.cpp:610] Iteration 29400, lr = 8.66671e-09
I0315 07:05:18.398979 29479 solver.cpp:613] Iteration 29400, avg_grad_norm = 593895
I0315 07:05:43.945444 29479 solver.cpp:214] Iteration 29420, loss = 6578
I0315 07:05:43.945571 29479 solver.cpp:229]     Train net output #0: loss = 4014.64 (* 1 = 4014.64 loss)
I0315 07:05:44.060042 29479 solver.cpp:610] Iteration 29420, lr = 8.66579e-09
I0315 07:05:44.060055 29479 solver.cpp:613] Iteration 29420, avg_grad_norm = 580669
I0315 07:06:09.642951 29479 solver.cpp:214] Iteration 29440, loss = 6692.11
I0315 07:06:09.643024 29479 solver.cpp:229]     Train net output #0: loss = 6038.09 (* 1 = 6038.09 loss)
I0315 07:06:09.757725 29479 solver.cpp:610] Iteration 29440, lr = 8.66488e-09
I0315 07:06:09.757757 29479 solver.cpp:613] Iteration 29440, avg_grad_norm = 613895
I0315 07:06:35.115855 29479 solver.cpp:214] Iteration 29460, loss = 6160.44
I0315 07:06:35.116104 29479 solver.cpp:229]     Train net output #0: loss = 6432.6 (* 1 = 6432.6 loss)
I0315 07:06:35.228737 29479 solver.cpp:610] Iteration 29460, lr = 8.66396e-09
I0315 07:06:35.228751 29479 solver.cpp:613] Iteration 29460, avg_grad_norm = 557466
I0315 07:07:12.125385 29479 solver.cpp:214] Iteration 29480, loss = 6404.16
I0315 07:07:12.125598 29479 solver.cpp:229]     Train net output #0: loss = 5265.12 (* 1 = 5265.12 loss)
I0315 07:07:12.230553 29479 solver.cpp:610] Iteration 29480, lr = 8.66305e-09
I0315 07:07:12.230567 29479 solver.cpp:613] Iteration 29480, avg_grad_norm = 602886
I0315 07:07:36.730826 29479 solver.cpp:214] Iteration 29500, loss = 6564.4
I0315 07:07:36.730892 29479 solver.cpp:229]     Train net output #0: loss = 5024.53 (* 1 = 5024.53 loss)
I0315 07:07:36.845749 29479 solver.cpp:610] Iteration 29500, lr = 8.66214e-09
I0315 07:07:36.845762 29479 solver.cpp:613] Iteration 29500, avg_grad_norm = 555379
I0315 07:08:02.389945 29479 solver.cpp:214] Iteration 29520, loss = 6576.11
I0315 07:08:02.390072 29479 solver.cpp:229]     Train net output #0: loss = 6932.79 (* 1 = 6932.79 loss)
I0315 07:08:02.504539 29479 solver.cpp:610] Iteration 29520, lr = 8.66122e-09
I0315 07:08:02.504552 29479 solver.cpp:613] Iteration 29520, avg_grad_norm = 538388
I0315 07:08:27.928360 29479 solver.cpp:214] Iteration 29540, loss = 6138.42
I0315 07:08:27.928421 29479 solver.cpp:229]     Train net output #0: loss = 5132.02 (* 1 = 5132.02 loss)
I0315 07:08:28.041328 29479 solver.cpp:610] Iteration 29540, lr = 8.66031e-09
I0315 07:08:28.041342 29479 solver.cpp:613] Iteration 29540, avg_grad_norm = 605731
I0315 07:08:53.317211 29479 solver.cpp:214] Iteration 29560, loss = 6389.83
I0315 07:08:53.317389 29479 solver.cpp:229]     Train net output #0: loss = 9423.17 (* 1 = 9423.17 loss)
I0315 07:08:53.430187 29479 solver.cpp:610] Iteration 29560, lr = 8.65939e-09
I0315 07:08:53.430200 29479 solver.cpp:613] Iteration 29560, avg_grad_norm = 738442
I0315 07:09:18.996955 29479 solver.cpp:214] Iteration 29580, loss = 6483.62
I0315 07:09:18.997057 29479 solver.cpp:229]     Train net output #0: loss = 6176.9 (* 1 = 6176.9 loss)
I0315 07:09:19.111687 29479 solver.cpp:610] Iteration 29580, lr = 8.65848e-09
I0315 07:09:19.111702 29479 solver.cpp:613] Iteration 29580, avg_grad_norm = 775372
I0315 07:09:56.615711 29479 solver.cpp:214] Iteration 29600, loss = 6338.2
I0315 07:09:56.615844 29479 solver.cpp:229]     Train net output #0: loss = 4974.28 (* 1 = 4974.28 loss)
I0315 07:09:56.720877 29479 solver.cpp:610] Iteration 29600, lr = 8.65756e-09
I0315 07:09:56.720891 29479 solver.cpp:613] Iteration 29600, avg_grad_norm = 658827
I0315 07:10:20.758456 29479 solver.cpp:214] Iteration 29620, loss = 6160.54
I0315 07:10:20.758509 29479 solver.cpp:229]     Train net output #0: loss = 7768.03 (* 1 = 7768.03 loss)
I0315 07:10:20.873215 29479 solver.cpp:610] Iteration 29620, lr = 8.65665e-09
I0315 07:10:20.873229 29479 solver.cpp:613] Iteration 29620, avg_grad_norm = 496622
I0315 07:10:46.464401 29479 solver.cpp:214] Iteration 29640, loss = 6399.28
I0315 07:10:46.464583 29479 solver.cpp:229]     Train net output #0: loss = 8636.93 (* 1 = 8636.93 loss)
I0315 07:10:46.579102 29479 solver.cpp:610] Iteration 29640, lr = 8.65573e-09
I0315 07:10:46.579116 29479 solver.cpp:613] Iteration 29640, avg_grad_norm = 648258
I0315 07:11:12.175233 29479 solver.cpp:214] Iteration 29660, loss = 6550.2
I0315 07:11:12.175283 29479 solver.cpp:229]     Train net output #0: loss = 6478.03 (* 1 = 6478.03 loss)
I0315 07:11:12.289891 29479 solver.cpp:610] Iteration 29660, lr = 8.65482e-09
I0315 07:11:12.289903 29479 solver.cpp:613] Iteration 29660, avg_grad_norm = 614893
I0315 07:11:37.884966 29479 solver.cpp:214] Iteration 29680, loss = 6393.5
I0315 07:11:37.885184 29479 solver.cpp:229]     Train net output #0: loss = 11851.7 (* 1 = 11851.7 loss)
I0315 07:11:37.999631 29479 solver.cpp:610] Iteration 29680, lr = 8.6539e-09
I0315 07:11:37.999645 29479 solver.cpp:613] Iteration 29680, avg_grad_norm = 502611
I0315 07:12:03.593533 29479 solver.cpp:214] Iteration 29700, loss = 6464.87
I0315 07:12:03.593585 29479 solver.cpp:229]     Train net output #0: loss = 5436.15 (* 1 = 5436.15 loss)
I0315 07:12:03.708161 29479 solver.cpp:610] Iteration 29700, lr = 8.65299e-09
I0315 07:12:03.708176 29479 solver.cpp:613] Iteration 29700, avg_grad_norm = 598780
I0315 07:12:41.980593 29479 solver.cpp:214] Iteration 29720, loss = 6456.11
I0315 07:12:41.980767 29479 solver.cpp:229]     Train net output #0: loss = 5004.47 (* 1 = 5004.47 loss)
I0315 07:12:42.085973 29479 solver.cpp:610] Iteration 29720, lr = 8.65208e-09
I0315 07:12:42.085988 29479 solver.cpp:613] Iteration 29720, avg_grad_norm = 606652
I0315 07:13:05.594602 29479 solver.cpp:214] Iteration 29740, loss = 6447.62
I0315 07:13:05.594643 29479 solver.cpp:229]     Train net output #0: loss = 5314.09 (* 1 = 5314.09 loss)
I0315 07:13:05.699762 29479 solver.cpp:610] Iteration 29740, lr = 8.65116e-09
I0315 07:13:05.699775 29479 solver.cpp:613] Iteration 29740, avg_grad_norm = 543297
I0315 07:13:31.020249 29479 solver.cpp:214] Iteration 29760, loss = 6635.55
I0315 07:13:31.020370 29479 solver.cpp:229]     Train net output #0: loss = 5760.62 (* 1 = 5760.62 loss)
I0315 07:13:31.134747 29479 solver.cpp:610] Iteration 29760, lr = 8.65025e-09
I0315 07:13:31.134759 29479 solver.cpp:613] Iteration 29760, avg_grad_norm = 656595
I0315 07:13:56.735539 29479 solver.cpp:214] Iteration 29780, loss = 6239.77
I0315 07:13:56.735601 29479 solver.cpp:229]     Train net output #0: loss = 10591.8 (* 1 = 10591.8 loss)
I0315 07:13:56.850276 29479 solver.cpp:610] Iteration 29780, lr = 8.64933e-09
I0315 07:13:56.850327 29479 solver.cpp:613] Iteration 29780, avg_grad_norm = 530228
I0315 07:14:22.474825 29479 solver.cpp:214] Iteration 29800, loss = 6314.71
I0315 07:14:22.474936 29479 solver.cpp:229]     Train net output #0: loss = 10940.2 (* 1 = 10940.2 loss)
I0315 07:14:22.589411 29479 solver.cpp:610] Iteration 29800, lr = 8.64842e-09
I0315 07:14:22.589424 29479 solver.cpp:613] Iteration 29800, avg_grad_norm = 546809
I0315 07:14:48.186771 29479 solver.cpp:214] Iteration 29820, loss = 6388.02
I0315 07:14:48.186827 29479 solver.cpp:229]     Train net output #0: loss = 4718.22 (* 1 = 4718.22 loss)
I0315 07:14:48.301468 29479 solver.cpp:610] Iteration 29820, lr = 8.6475e-09
I0315 07:14:48.301481 29479 solver.cpp:613] Iteration 29820, avg_grad_norm = 526550
I0315 07:15:13.908627 29479 solver.cpp:214] Iteration 29840, loss = 6321.99
I0315 07:15:13.908763 29479 solver.cpp:229]     Train net output #0: loss = 5859.11 (* 1 = 5859.11 loss)
I0315 07:15:14.023282 29479 solver.cpp:610] Iteration 29840, lr = 8.64659e-09
I0315 07:15:14.023295 29479 solver.cpp:613] Iteration 29840, avg_grad_norm = 571592
I0315 07:15:56.277878 29479 solver.cpp:214] Iteration 29860, loss = 6408.77
I0315 07:15:56.278086 29479 solver.cpp:229]     Train net output #0: loss = 6491.27 (* 1 = 6491.27 loss)
I0315 07:15:56.383059 29479 solver.cpp:610] Iteration 29860, lr = 8.64567e-09
I0315 07:15:56.383074 29479 solver.cpp:613] Iteration 29860, avg_grad_norm = 528319
I0315 07:16:20.156651 29479 solver.cpp:214] Iteration 29880, loss = 6510.16
I0315 07:16:20.156705 29479 solver.cpp:229]     Train net output #0: loss = 5783.35 (* 1 = 5783.35 loss)
I0315 07:16:20.269731 29479 solver.cpp:610] Iteration 29880, lr = 8.64476e-09
I0315 07:16:20.269744 29479 solver.cpp:613] Iteration 29880, avg_grad_norm = 572838
I0315 07:16:45.791522 29479 solver.cpp:214] Iteration 29900, loss = 6639.67
I0315 07:16:45.791671 29479 solver.cpp:229]     Train net output #0: loss = 10697.3 (* 1 = 10697.3 loss)
I0315 07:16:45.907444 29479 solver.cpp:610] Iteration 29900, lr = 8.64384e-09
I0315 07:16:45.907459 29479 solver.cpp:613] Iteration 29900, avg_grad_norm = 548077
I0315 07:17:11.382364 29479 solver.cpp:214] Iteration 29920, loss = 6558.57
I0315 07:17:11.382457 29479 solver.cpp:229]     Train net output #0: loss = 6372.35 (* 1 = 6372.35 loss)
I0315 07:17:11.495383 29479 solver.cpp:610] Iteration 29920, lr = 8.64293e-09
I0315 07:17:11.495398 29479 solver.cpp:613] Iteration 29920, avg_grad_norm = 569445
I0315 07:17:36.702905 29479 solver.cpp:214] Iteration 29940, loss = 6429.83
I0315 07:17:36.703060 29479 solver.cpp:229]     Train net output #0: loss = 6650.68 (* 1 = 6650.68 loss)
I0315 07:17:36.817469 29479 solver.cpp:610] Iteration 29940, lr = 8.64201e-09
I0315 07:17:36.817487 29479 solver.cpp:613] Iteration 29940, avg_grad_norm = 542132
I0315 07:18:02.407831 29479 solver.cpp:214] Iteration 29960, loss = 6593.78
I0315 07:18:02.407882 29479 solver.cpp:229]     Train net output #0: loss = 5503.18 (* 1 = 5503.18 loss)
I0315 07:18:02.522354 29479 solver.cpp:610] Iteration 29960, lr = 8.6411e-09
I0315 07:18:02.522367 29479 solver.cpp:613] Iteration 29960, avg_grad_norm = 523476
I0315 07:18:46.790766 29479 solver.cpp:214] Iteration 29980, loss = 6588.99
I0315 07:18:46.790930 29479 solver.cpp:229]     Train net output #0: loss = 4163.77 (* 1 = 4163.77 loss)
I0315 07:18:46.896118 29479 solver.cpp:610] Iteration 29980, lr = 8.64018e-09
I0315 07:18:46.896131 29479 solver.cpp:613] Iteration 29980, avg_grad_norm = 619178
I0315 07:19:09.431821 29479 solver.cpp:458] Snapshotting to models/pnet/VGG_VOC2012ext_iter_30000.caffemodel
I0315 07:19:16.164862 29479 solver.cpp:466] Snapshotting solver state to models/pnet/VGG_VOC2012ext_iter_30000.solverstate
I0315 07:19:19.718986 29479 solver.cpp:214] Iteration 30000, loss = 6489.96
I0315 07:19:19.719112 29479 solver.cpp:229]     Train net output #0: loss = 6168.53 (* 1 = 6168.53 loss)
I0315 07:19:19.824251 29479 solver.cpp:610] Iteration 30000, lr = 8.63927e-09
I0315 07:19:19.824265 29479 solver.cpp:613] Iteration 30000, avg_grad_norm = 563969
I0315 07:19:43.346921 29479 solver.cpp:214] Iteration 30020, loss = 6459.04
I0315 07:19:43.346973 29479 solver.cpp:229]     Train net output #0: loss = 5248.4 (* 1 = 5248.4 loss)
I0315 07:19:43.451268 29479 solver.cpp:610] Iteration 30020, lr = 8.63835e-09
I0315 07:19:43.451282 29479 solver.cpp:613] Iteration 30020, avg_grad_norm = 530566
I0315 07:20:08.467412 29479 solver.cpp:214] Iteration 30040, loss = 6583.68
I0315 07:20:08.467617 29479 solver.cpp:229]     Train net output #0: loss = 6345.12 (* 1 = 6345.12 loss)
I0315 07:20:08.582130 29479 solver.cpp:610] Iteration 30040, lr = 8.63744e-09
I0315 07:20:08.582167 29479 solver.cpp:613] Iteration 30040, avg_grad_norm = 551541
I0315 07:20:34.181659 29479 solver.cpp:214] Iteration 30060, loss = 6329.56
I0315 07:20:34.181727 29479 solver.cpp:229]     Train net output #0: loss = 7571.99 (* 1 = 7571.99 loss)
I0315 07:20:34.296165 29479 solver.cpp:610] Iteration 30060, lr = 8.63653e-09
I0315 07:20:34.296181 29479 solver.cpp:613] Iteration 30060, avg_grad_norm = 543305
I0315 07:20:59.695739 29479 solver.cpp:214] Iteration 30080, loss = 6550.83
I0315 07:20:59.695854 29479 solver.cpp:229]     Train net output #0: loss = 6331.65 (* 1 = 6331.65 loss)
I0315 07:20:59.808728 29479 solver.cpp:610] Iteration 30080, lr = 8.63561e-09
I0315 07:20:59.808745 29479 solver.cpp:613] Iteration 30080, avg_grad_norm = 574510
I0315 07:21:37.987591 29479 solver.cpp:214] Iteration 30100, loss = 6305.25
I0315 07:21:37.987725 29479 solver.cpp:229]     Train net output #0: loss = 4678.79 (* 1 = 4678.79 loss)
I0315 07:21:38.092946 29479 solver.cpp:610] Iteration 30100, lr = 8.6347e-09
I0315 07:21:38.092958 29479 solver.cpp:613] Iteration 30100, avg_grad_norm = 570146
I0315 07:22:01.566440 29479 solver.cpp:214] Iteration 30120, loss = 6258.22
I0315 07:22:01.566506 29479 solver.cpp:229]     Train net output #0: loss = 6931.92 (* 1 = 6931.92 loss)
I0315 07:22:01.671794 29479 solver.cpp:610] Iteration 30120, lr = 8.63378e-09
I0315 07:22:01.671808 29479 solver.cpp:613] Iteration 30120, avg_grad_norm = 585253
I0315 07:22:26.879948 29479 solver.cpp:214] Iteration 30140, loss = 6307.2
I0315 07:22:26.880082 29479 solver.cpp:229]     Train net output #0: loss = 8244.45 (* 1 = 8244.45 loss)
I0315 07:22:26.994619 29479 solver.cpp:610] Iteration 30140, lr = 8.63287e-09
I0315 07:22:26.994632 29479 solver.cpp:613] Iteration 30140, avg_grad_norm = 523234
I0315 07:22:52.588028 29479 solver.cpp:214] Iteration 30160, loss = 6420.49
I0315 07:22:52.588083 29479 solver.cpp:229]     Train net output #0: loss = 8742.81 (* 1 = 8742.81 loss)
I0315 07:22:52.702739 29479 solver.cpp:610] Iteration 30160, lr = 8.63195e-09
I0315 07:22:52.702751 29479 solver.cpp:613] Iteration 30160, avg_grad_norm = 550838
I0315 07:23:18.307539 29479 solver.cpp:214] Iteration 30180, loss = 6431.54
I0315 07:23:18.307783 29479 solver.cpp:229]     Train net output #0: loss = 8109.39 (* 1 = 8109.39 loss)
I0315 07:23:18.422174 29479 solver.cpp:610] Iteration 30180, lr = 8.63104e-09
I0315 07:23:18.422188 29479 solver.cpp:613] Iteration 30180, avg_grad_norm = 562995
I0315 07:23:44.024271 29479 solver.cpp:214] Iteration 30200, loss = 6938.9
I0315 07:23:44.024328 29479 solver.cpp:229]     Train net output #0: loss = 5830.75 (* 1 = 5830.75 loss)
I0315 07:23:44.138932 29479 solver.cpp:610] Iteration 30200, lr = 8.63012e-09
I0315 07:23:44.138945 29479 solver.cpp:613] Iteration 30200, avg_grad_norm = 551046
I0315 07:24:09.718485 29479 solver.cpp:214] Iteration 30220, loss = 6250.39
I0315 07:24:09.718626 29479 solver.cpp:229]     Train net output #0: loss = 5559.42 (* 1 = 5559.42 loss)
I0315 07:24:09.831374 29479 solver.cpp:610] Iteration 30220, lr = 8.62921e-09
I0315 07:24:09.831410 29479 solver.cpp:613] Iteration 30220, avg_grad_norm = 570224
I0315 07:24:46.955502 29479 solver.cpp:214] Iteration 30240, loss = 6517.6
I0315 07:24:46.955649 29479 solver.cpp:229]     Train net output #0: loss = 6876.61 (* 1 = 6876.61 loss)
I0315 07:24:47.060709 29479 solver.cpp:610] Iteration 30240, lr = 8.62829e-09
I0315 07:24:47.060741 29479 solver.cpp:613] Iteration 30240, avg_grad_norm = 652082
I0315 07:25:11.458062 29479 solver.cpp:214] Iteration 30260, loss = 6561.43
I0315 07:25:11.458127 29479 solver.cpp:229]     Train net output #0: loss = 6123.06 (* 1 = 6123.06 loss)
I0315 07:25:11.572630 29479 solver.cpp:610] Iteration 30260, lr = 8.62738e-09
I0315 07:25:11.572648 29479 solver.cpp:613] Iteration 30260, avg_grad_norm = 545437
I0315 07:25:37.181740 29479 solver.cpp:214] Iteration 30280, loss = 6427.71
I0315 07:25:37.181929 29479 solver.cpp:229]     Train net output #0: loss = 10403.7 (* 1 = 10403.7 loss)
I0315 07:25:37.296418 29479 solver.cpp:610] Iteration 30280, lr = 8.62646e-09
I0315 07:25:37.296437 29479 solver.cpp:613] Iteration 30280, avg_grad_norm = 561582
I0315 07:26:02.900851 29479 solver.cpp:214] Iteration 30300, loss = 6418.79
I0315 07:26:02.900918 29479 solver.cpp:229]     Train net output #0: loss = 9954.89 (* 1 = 9954.89 loss)
I0315 07:26:03.015449 29479 solver.cpp:610] Iteration 30300, lr = 8.62555e-09
I0315 07:26:03.015465 29479 solver.cpp:613] Iteration 30300, avg_grad_norm = 542105
I0315 07:26:28.574370 29479 solver.cpp:214] Iteration 30320, loss = 6516.22
I0315 07:26:28.574502 29479 solver.cpp:229]     Train net output #0: loss = 5163.94 (* 1 = 5163.94 loss)
I0315 07:26:28.688969 29479 solver.cpp:610] Iteration 30320, lr = 8.62463e-09
I0315 07:26:28.688982 29479 solver.cpp:613] Iteration 30320, avg_grad_norm = 506980
I0315 07:26:53.992985 29479 solver.cpp:214] Iteration 30340, loss = 6462.57
I0315 07:26:53.993080 29479 solver.cpp:229]     Train net output #0: loss = 5938.24 (* 1 = 5938.24 loss)
I0315 07:26:54.106166 29479 solver.cpp:610] Iteration 30340, lr = 8.62372e-09
I0315 07:26:54.106180 29479 solver.cpp:613] Iteration 30340, avg_grad_norm = 567997
I0315 07:27:31.740953 29479 solver.cpp:214] Iteration 30360, loss = 6167.59
I0315 07:27:31.741076 29479 solver.cpp:229]     Train net output #0: loss = 10339.6 (* 1 = 10339.6 loss)
I0315 07:27:31.846155 29479 solver.cpp:610] Iteration 30360, lr = 8.6228e-09
I0315 07:27:31.846168 29479 solver.cpp:613] Iteration 30360, avg_grad_norm = 523103
I0315 07:27:55.552968 29479 solver.cpp:214] Iteration 30380, loss = 6511.82
I0315 07:27:55.553030 29479 solver.cpp:229]     Train net output #0: loss = 6105.23 (* 1 = 6105.23 loss)
I0315 07:27:55.665940 29479 solver.cpp:610] Iteration 30380, lr = 8.62189e-09
I0315 07:27:55.665953 29479 solver.cpp:613] Iteration 30380, avg_grad_norm = 571397
I0315 07:28:21.179996 29479 solver.cpp:214] Iteration 30400, loss = 6738.43
I0315 07:28:21.180240 29479 solver.cpp:229]     Train net output #0: loss = 5805.38 (* 1 = 5805.38 loss)
I0315 07:28:21.294420 29479 solver.cpp:610] Iteration 30400, lr = 8.62097e-09
I0315 07:28:21.294433 29479 solver.cpp:613] Iteration 30400, avg_grad_norm = 515363
I0315 07:28:46.837712 29479 solver.cpp:214] Iteration 30420, loss = 6372.1
I0315 07:28:46.837779 29479 solver.cpp:229]     Train net output #0: loss = 3619.38 (* 1 = 3619.38 loss)
I0315 07:28:46.951915 29479 solver.cpp:610] Iteration 30420, lr = 8.62006e-09
I0315 07:28:46.951927 29479 solver.cpp:613] Iteration 30420, avg_grad_norm = 745629
I0315 07:29:12.189553 29479 solver.cpp:214] Iteration 30440, loss = 6570.81
I0315 07:29:12.189666 29479 solver.cpp:229]     Train net output #0: loss = 6369.72 (* 1 = 6369.72 loss)
I0315 07:29:12.302578 29479 solver.cpp:610] Iteration 30440, lr = 8.61914e-09
I0315 07:29:12.302592 29479 solver.cpp:613] Iteration 30440, avg_grad_norm = 626492
I0315 07:29:37.756175 29479 solver.cpp:214] Iteration 30460, loss = 6390.42
I0315 07:29:37.756243 29479 solver.cpp:229]     Train net output #0: loss = 4246.31 (* 1 = 4246.31 loss)
I0315 07:29:37.872298 29479 solver.cpp:610] Iteration 30460, lr = 8.61823e-09
I0315 07:29:37.872311 29479 solver.cpp:613] Iteration 30460, avg_grad_norm = 583938
I0315 07:30:20.114146 29479 solver.cpp:214] Iteration 30480, loss = 6479.92
I0315 07:30:20.114290 29479 solver.cpp:229]     Train net output #0: loss = 7532.16 (* 1 = 7532.16 loss)
I0315 07:30:20.219358 29479 solver.cpp:610] Iteration 30480, lr = 8.61731e-09
I0315 07:30:20.219372 29479 solver.cpp:613] Iteration 30480, avg_grad_norm = 550905
I0315 07:30:43.698034 29479 solver.cpp:214] Iteration 30500, loss = 6320.03
I0315 07:30:43.698109 29479 solver.cpp:229]     Train net output #0: loss = 4693.14 (* 1 = 4693.14 loss)
I0315 07:30:43.803525 29479 solver.cpp:610] Iteration 30500, lr = 8.6164e-09
I0315 07:30:43.803539 29479 solver.cpp:613] Iteration 30500, avg_grad_norm = 542801
I0315 07:31:08.367305 29479 solver.cpp:214] Iteration 30520, loss = 6699.23
I0315 07:31:08.367455 29479 solver.cpp:229]     Train net output #0: loss = 9428.16 (* 1 = 9428.16 loss)
I0315 07:31:08.482049 29479 solver.cpp:610] Iteration 30520, lr = 8.61548e-09
I0315 07:31:08.482062 29479 solver.cpp:613] Iteration 30520, avg_grad_norm = 533612
I0315 07:31:34.059029 29479 solver.cpp:214] Iteration 30540, loss = 6559.47
I0315 07:31:34.059077 29479 solver.cpp:229]     Train net output #0: loss = 11456.1 (* 1 = 11456.1 loss)
I0315 07:31:34.173796 29479 solver.cpp:610] Iteration 30540, lr = 8.61457e-09
I0315 07:31:34.173810 29479 solver.cpp:613] Iteration 30540, avg_grad_norm = 602335
I0315 07:31:59.766419 29479 solver.cpp:214] Iteration 30560, loss = 6822.75
I0315 07:31:59.766567 29479 solver.cpp:229]     Train net output #0: loss = 6197.04 (* 1 = 6197.04 loss)
I0315 07:31:59.880980 29479 solver.cpp:610] Iteration 30560, lr = 8.61365e-09
I0315 07:31:59.880995 29479 solver.cpp:613] Iteration 30560, avg_grad_norm = 562662
I0315 07:32:25.242584 29479 solver.cpp:214] Iteration 30580, loss = 6631.57
I0315 07:32:25.242650 29479 solver.cpp:229]     Train net output #0: loss = 3918.73 (* 1 = 3918.73 loss)
I0315 07:32:25.355613 29479 solver.cpp:610] Iteration 30580, lr = 8.61274e-09
I0315 07:32:25.355628 29479 solver.cpp:613] Iteration 30580, avg_grad_norm = 540526
I0315 07:32:50.653061 29479 solver.cpp:214] Iteration 30600, loss = 6571.27
I0315 07:32:50.653283 29479 solver.cpp:229]     Train net output #0: loss = 6055.57 (* 1 = 6055.57 loss)
I0315 07:32:50.767559 29479 solver.cpp:610] Iteration 30600, lr = 8.61182e-09
I0315 07:32:50.767573 29479 solver.cpp:613] Iteration 30600, avg_grad_norm = 546168
I0315 07:33:33.311703 29479 solver.cpp:214] Iteration 30620, loss = 6641.73
I0315 07:33:33.311849 29479 solver.cpp:229]     Train net output #0: loss = 6384.63 (* 1 = 6384.63 loss)
I0315 07:33:33.416936 29479 solver.cpp:610] Iteration 30620, lr = 8.61091e-09
I0315 07:33:33.416963 29479 solver.cpp:613] Iteration 30620, avg_grad_norm = 563120
I0315 07:33:57.091969 29479 solver.cpp:214] Iteration 30640, loss = 6581.16
I0315 07:33:57.092031 29479 solver.cpp:229]     Train net output #0: loss = 5286.74 (* 1 = 5286.74 loss)
I0315 07:33:57.203686 29479 solver.cpp:610] Iteration 30640, lr = 8.60999e-09
I0315 07:33:57.203735 29479 solver.cpp:613] Iteration 30640, avg_grad_norm = 529559
I0315 07:34:22.787518 29479 solver.cpp:214] Iteration 30660, loss = 6446.25
I0315 07:34:22.787694 29479 solver.cpp:229]     Train net output #0: loss = 11565.7 (* 1 = 11565.7 loss)
I0315 07:34:22.902173 29479 solver.cpp:610] Iteration 30660, lr = 8.60908e-09
I0315 07:34:22.902187 29479 solver.cpp:613] Iteration 30660, avg_grad_norm = 616649
I0315 07:34:48.462818 29479 solver.cpp:214] Iteration 30680, loss = 6497.57
I0315 07:34:48.462882 29479 solver.cpp:229]     Train net output #0: loss = 4004.23 (* 1 = 4004.23 loss)
I0315 07:34:48.577442 29479 solver.cpp:610] Iteration 30680, lr = 8.60816e-09
I0315 07:34:48.577457 29479 solver.cpp:613] Iteration 30680, avg_grad_norm = 567830
I0315 07:35:14.133316 29479 solver.cpp:214] Iteration 30700, loss = 6689.24
I0315 07:35:14.133468 29479 solver.cpp:229]     Train net output #0: loss = 2866.92 (* 1 = 2866.92 loss)
I0315 07:35:14.247766 29479 solver.cpp:610] Iteration 30700, lr = 8.60725e-09
I0315 07:35:14.247778 29479 solver.cpp:613] Iteration 30700, avg_grad_norm = 559919
I0315 07:35:39.602403 29479 solver.cpp:214] Iteration 30720, loss = 6307.13
I0315 07:35:39.602470 29479 solver.cpp:229]     Train net output #0: loss = 8937.74 (* 1 = 8937.74 loss)
I0315 07:35:39.715502 29479 solver.cpp:610] Iteration 30720, lr = 8.60633e-09
I0315 07:35:39.715515 29479 solver.cpp:613] Iteration 30720, avg_grad_norm = 572591
I0315 07:36:17.574379 29479 solver.cpp:214] Iteration 30740, loss = 6556.47
I0315 07:36:17.574488 29479 solver.cpp:229]     Train net output #0: loss = 11556.8 (* 1 = 11556.8 loss)
I0315 07:36:17.679697 29479 solver.cpp:610] Iteration 30740, lr = 8.60542e-09
I0315 07:36:17.679711 29479 solver.cpp:613] Iteration 30740, avg_grad_norm = 548482
I0315 07:36:41.333349 29479 solver.cpp:214] Iteration 30760, loss = 6310.33
I0315 07:36:41.333412 29479 solver.cpp:229]     Train net output #0: loss = 6329.98 (* 1 = 6329.98 loss)
I0315 07:36:41.444977 29479 solver.cpp:610] Iteration 30760, lr = 8.6045e-09
I0315 07:36:41.444991 29479 solver.cpp:613] Iteration 30760, avg_grad_norm = 583608
I0315 07:37:06.916532 29479 solver.cpp:214] Iteration 30780, loss = 6276.72
I0315 07:37:06.916668 29479 solver.cpp:229]     Train net output #0: loss = 2763.44 (* 1 = 2763.44 loss)
I0315 07:37:07.031172 29479 solver.cpp:610] Iteration 30780, lr = 8.60359e-09
I0315 07:37:07.031186 29479 solver.cpp:613] Iteration 30780, avg_grad_norm = 640267
I0315 07:37:32.630410 29479 solver.cpp:214] Iteration 30800, loss = 6596.43
I0315 07:37:32.630475 29479 solver.cpp:229]     Train net output #0: loss = 12587.8 (* 1 = 12587.8 loss)
I0315 07:37:32.745177 29479 solver.cpp:610] Iteration 30800, lr = 8.60267e-09
I0315 07:37:32.745190 29479 solver.cpp:613] Iteration 30800, avg_grad_norm = 607645
I0315 07:37:58.344377 29479 solver.cpp:214] Iteration 30820, loss = 6569.34
I0315 07:37:58.344568 29479 solver.cpp:229]     Train net output #0: loss = 4726.07 (* 1 = 4726.07 loss)
I0315 07:37:58.458925 29479 solver.cpp:610] Iteration 30820, lr = 8.60176e-09
I0315 07:37:58.458938 29479 solver.cpp:613] Iteration 30820, avg_grad_norm = 525073
I0315 07:38:24.038959 29479 solver.cpp:214] Iteration 30840, loss = 6695.71
I0315 07:38:24.039026 29479 solver.cpp:229]     Train net output #0: loss = 9309.53 (* 1 = 9309.53 loss)
I0315 07:38:24.153692 29479 solver.cpp:610] Iteration 30840, lr = 8.60084e-09
I0315 07:38:24.153705 29479 solver.cpp:613] Iteration 30840, avg_grad_norm = 605524
I0315 07:39:02.098127 29479 solver.cpp:214] Iteration 30860, loss = 6556.6
I0315 07:39:02.098248 29479 solver.cpp:229]     Train net output #0: loss = 8962.56 (* 1 = 8962.56 loss)
I0315 07:39:02.202294 29479 solver.cpp:610] Iteration 30860, lr = 8.59993e-09
I0315 07:39:02.202307 29479 solver.cpp:613] Iteration 30860, avg_grad_norm = 663124
I0315 07:39:25.714301 29479 solver.cpp:214] Iteration 30880, loss = 6628.81
I0315 07:39:25.714365 29479 solver.cpp:229]     Train net output #0: loss = 6831.05 (* 1 = 6831.05 loss)
I0315 07:39:25.819677 29479 solver.cpp:610] Iteration 30880, lr = 8.59901e-09
I0315 07:39:25.819691 29479 solver.cpp:613] Iteration 30880, avg_grad_norm = 645553
I0315 07:39:50.948616 29479 solver.cpp:214] Iteration 30900, loss = 6419.01
I0315 07:39:50.948763 29479 solver.cpp:229]     Train net output #0: loss = 5280.51 (* 1 = 5280.51 loss)
I0315 07:39:51.063155 29479 solver.cpp:610] Iteration 30900, lr = 8.5981e-09
I0315 07:39:51.063169 29479 solver.cpp:613] Iteration 30900, avg_grad_norm = 580299
I0315 07:40:16.602829 29479 solver.cpp:214] Iteration 30920, loss = 6649.01
I0315 07:40:16.602890 29479 solver.cpp:229]     Train net output #0: loss = 5750.35 (* 1 = 5750.35 loss)
I0315 07:40:16.717505 29479 solver.cpp:610] Iteration 30920, lr = 8.59718e-09
I0315 07:40:16.717517 29479 solver.cpp:613] Iteration 30920, avg_grad_norm = 606842
I0315 07:40:42.255730 29479 solver.cpp:214] Iteration 30940, loss = 6341.64
I0315 07:40:42.255867 29479 solver.cpp:229]     Train net output #0: loss = 10877.4 (* 1 = 10877.4 loss)
I0315 07:40:42.370388 29479 solver.cpp:610] Iteration 30940, lr = 8.59627e-09
I0315 07:40:42.370400 29479 solver.cpp:613] Iteration 30940, avg_grad_norm = 527440
I0315 07:41:07.813285 29479 solver.cpp:214] Iteration 30960, loss = 6488.97
I0315 07:41:07.813345 29479 solver.cpp:229]     Train net output #0: loss = 8278.14 (* 1 = 8278.14 loss)
I0315 07:41:07.926187 29479 solver.cpp:610] Iteration 30960, lr = 8.59535e-09
I0315 07:41:07.926201 29479 solver.cpp:613] Iteration 30960, avg_grad_norm = 612256
I0315 07:41:33.375630 29479 solver.cpp:214] Iteration 30980, loss = 6431.74
I0315 07:41:33.375766 29479 solver.cpp:229]     Train net output #0: loss = 8107.16 (* 1 = 8107.16 loss)
I0315 07:41:33.490244 29479 solver.cpp:610] Iteration 30980, lr = 8.59443e-09
I0315 07:41:33.490258 29479 solver.cpp:613] Iteration 30980, avg_grad_norm = 521545
I0315 07:42:10.223139 29479 solver.cpp:214] Iteration 31000, loss = 6834.72
I0315 07:42:10.223351 29479 solver.cpp:229]     Train net output #0: loss = 8953.11 (* 1 = 8953.11 loss)
I0315 07:42:10.328284 29479 solver.cpp:610] Iteration 31000, lr = 8.59352e-09
I0315 07:42:10.328297 29479 solver.cpp:613] Iteration 31000, avg_grad_norm = 595227
I0315 07:42:34.612185 29479 solver.cpp:214] Iteration 31020, loss = 6497.44
I0315 07:42:34.612231 29479 solver.cpp:229]     Train net output #0: loss = 8579.22 (* 1 = 8579.22 loss)
I0315 07:42:34.728360 29479 solver.cpp:610] Iteration 31020, lr = 8.5926e-09
I0315 07:42:34.728374 29479 solver.cpp:613] Iteration 31020, avg_grad_norm = 619220
I0315 07:43:00.540544 29479 solver.cpp:214] Iteration 31040, loss = 6121.2
I0315 07:43:00.540695 29479 solver.cpp:229]     Train net output #0: loss = 6379.48 (* 1 = 6379.48 loss)
I0315 07:43:00.655038 29479 solver.cpp:610] Iteration 31040, lr = 8.59169e-09
I0315 07:43:00.655052 29479 solver.cpp:613] Iteration 31040, avg_grad_norm = 577807
I0315 07:43:25.925869 29479 solver.cpp:214] Iteration 31060, loss = 6537.44
I0315 07:43:25.925928 29479 solver.cpp:229]     Train net output #0: loss = 3896.96 (* 1 = 3896.96 loss)
I0315 07:43:26.038976 29479 solver.cpp:610] Iteration 31060, lr = 8.59077e-09
I0315 07:43:26.038990 29479 solver.cpp:613] Iteration 31060, avg_grad_norm = 617264
I0315 07:43:51.414937 29479 solver.cpp:214] Iteration 31080, loss = 6410.26
I0315 07:43:51.415084 29479 solver.cpp:229]     Train net output #0: loss = 12180.8 (* 1 = 12180.8 loss)
I0315 07:43:51.529245 29479 solver.cpp:610] Iteration 31080, lr = 8.58986e-09
I0315 07:43:51.529259 29479 solver.cpp:613] Iteration 31080, avg_grad_norm = 533352
I0315 07:44:17.118630 29479 solver.cpp:214] Iteration 31100, loss = 6333.63
I0315 07:44:17.118692 29479 solver.cpp:229]     Train net output #0: loss = 7988.6 (* 1 = 7988.6 loss)
I0315 07:44:17.233217 29479 solver.cpp:610] Iteration 31100, lr = 8.58894e-09
I0315 07:44:17.233229 29479 solver.cpp:613] Iteration 31100, avg_grad_norm = 512662
I0315 07:44:54.838609 29479 solver.cpp:214] Iteration 31120, loss = 6505.38
I0315 07:44:54.838757 29479 solver.cpp:229]     Train net output #0: loss = 3450.28 (* 1 = 3450.28 loss)
I0315 07:44:54.943594 29479 solver.cpp:610] Iteration 31120, lr = 8.58803e-09
I0315 07:44:54.943608 29479 solver.cpp:613] Iteration 31120, avg_grad_norm = 533700
I0315 07:45:18.537781 29479 solver.cpp:214] Iteration 31140, loss = 6542.94
I0315 07:45:18.537844 29479 solver.cpp:229]     Train net output #0: loss = 6072.64 (* 1 = 6072.64 loss)
I0315 07:45:18.650668 29479 solver.cpp:610] Iteration 31140, lr = 8.58711e-09
I0315 07:45:18.650681 29479 solver.cpp:613] Iteration 31140, avg_grad_norm = 644598
I0315 07:45:44.223383 29479 solver.cpp:214] Iteration 31160, loss = 6688.55
I0315 07:45:44.223534 29479 solver.cpp:229]     Train net output #0: loss = 9117.02 (* 1 = 9117.02 loss)
I0315 07:45:44.337937 29479 solver.cpp:610] Iteration 31160, lr = 8.5862e-09
I0315 07:45:44.337950 29479 solver.cpp:613] Iteration 31160, avg_grad_norm = 540533
I0315 07:46:09.931272 29479 solver.cpp:214] Iteration 31180, loss = 6619.39
I0315 07:46:09.931349 29479 solver.cpp:229]     Train net output #0: loss = 4381.08 (* 1 = 4381.08 loss)
I0315 07:46:10.045825 29479 solver.cpp:610] Iteration 31180, lr = 8.58528e-09
I0315 07:46:10.045837 29479 solver.cpp:613] Iteration 31180, avg_grad_norm = 567796
I0315 07:46:35.651383 29479 solver.cpp:214] Iteration 31200, loss = 6526.74
I0315 07:46:35.651513 29479 solver.cpp:229]     Train net output #0: loss = 4403.46 (* 1 = 4403.46 loss)
I0315 07:46:35.766032 29479 solver.cpp:610] Iteration 31200, lr = 8.58437e-09
I0315 07:46:35.766046 29479 solver.cpp:613] Iteration 31200, avg_grad_norm = 578134
I0315 07:47:01.371328 29479 solver.cpp:214] Iteration 31220, loss = 6566.38
I0315 07:47:01.371376 29479 solver.cpp:229]     Train net output #0: loss = 4709.81 (* 1 = 4709.81 loss)
I0315 07:47:01.486075 29479 solver.cpp:610] Iteration 31220, lr = 8.58345e-09
I0315 07:47:01.486088 29479 solver.cpp:613] Iteration 31220, avg_grad_norm = 527238
I0315 07:47:54.143640 29479 solver.cpp:214] Iteration 31240, loss = 6486.83
I0315 07:47:54.143744 29479 solver.cpp:229]     Train net output #0: loss = 3787.67 (* 1 = 3787.67 loss)
I0315 07:47:54.247174 29479 solver.cpp:610] Iteration 31240, lr = 8.58253e-09
I0315 07:47:54.247186 29479 solver.cpp:613] Iteration 31240, avg_grad_norm = 686109
I0315 07:48:17.634354 29479 solver.cpp:214] Iteration 31260, loss = 6343.65
I0315 07:48:17.634450 29479 solver.cpp:229]     Train net output #0: loss = 5023.97 (* 1 = 5023.97 loss)
I0315 07:48:17.739753 29479 solver.cpp:610] Iteration 31260, lr = 8.58162e-09
I0315 07:48:17.739768 29479 solver.cpp:613] Iteration 31260, avg_grad_norm = 599804
I0315 07:48:41.250697 29479 solver.cpp:214] Iteration 31280, loss = 6374.78
I0315 07:48:41.250844 29479 solver.cpp:229]     Train net output #0: loss = 8427.96 (* 1 = 8427.96 loss)
I0315 07:48:41.355890 29479 solver.cpp:610] Iteration 31280, lr = 8.5807e-09
I0315 07:48:41.355903 29479 solver.cpp:613] Iteration 31280, avg_grad_norm = 630504
I0315 07:49:06.167717 29479 solver.cpp:214] Iteration 31300, loss = 6219.37
I0315 07:49:06.167793 29479 solver.cpp:229]     Train net output #0: loss = 5453.13 (* 1 = 5453.13 loss)
I0315 07:49:06.280797 29479 solver.cpp:610] Iteration 31300, lr = 8.57979e-09
I0315 07:49:06.280835 29479 solver.cpp:613] Iteration 31300, avg_grad_norm = 658945
I0315 07:49:31.679811 29479 solver.cpp:214] Iteration 31320, loss = 6198.64
I0315 07:49:31.679927 29479 solver.cpp:229]     Train net output #0: loss = 10274.6 (* 1 = 10274.6 loss)
I0315 07:49:31.794869 29479 solver.cpp:610] Iteration 31320, lr = 8.57887e-09
I0315 07:49:31.794883 29479 solver.cpp:613] Iteration 31320, avg_grad_norm = 656799
I0315 07:49:57.392665 29479 solver.cpp:214] Iteration 31340, loss = 6337.24
I0315 07:49:57.392740 29479 solver.cpp:229]     Train net output #0: loss = 4931.39 (* 1 = 4931.39 loss)
I0315 07:49:57.507275 29479 solver.cpp:610] Iteration 31340, lr = 8.57796e-09
I0315 07:49:57.507288 29479 solver.cpp:613] Iteration 31340, avg_grad_norm = 550300
I0315 07:50:22.973896 29479 solver.cpp:214] Iteration 31360, loss = 6543.1
I0315 07:50:22.974081 29479 solver.cpp:229]     Train net output #0: loss = 3926.62 (* 1 = 3926.62 loss)
I0315 07:50:23.086674 29479 solver.cpp:610] Iteration 31360, lr = 8.57704e-09
I0315 07:50:23.086688 29479 solver.cpp:613] Iteration 31360, avg_grad_norm = 607655
I0315 07:51:00.067764 29479 solver.cpp:214] Iteration 31380, loss = 6525.47
I0315 07:51:00.067958 29479 solver.cpp:229]     Train net output #0: loss = 12242 (* 1 = 12242 loss)
I0315 07:51:00.172374 29479 solver.cpp:610] Iteration 31380, lr = 8.57613e-09
I0315 07:51:00.172386 29479 solver.cpp:613] Iteration 31380, avg_grad_norm = 638096
I0315 07:51:24.434522 29479 solver.cpp:214] Iteration 31400, loss = 6516.9
I0315 07:51:24.434574 29479 solver.cpp:229]     Train net output #0: loss = 3208.15 (* 1 = 3208.15 loss)
I0315 07:51:24.549453 29479 solver.cpp:610] Iteration 31400, lr = 8.57521e-09
I0315 07:51:24.549466 29479 solver.cpp:613] Iteration 31400, avg_grad_norm = 547430
I0315 07:51:50.121459 29479 solver.cpp:214] Iteration 31420, loss = 6524.59
I0315 07:51:50.121675 29479 solver.cpp:229]     Train net output #0: loss = 4283.21 (* 1 = 4283.21 loss)
I0315 07:51:50.234304 29479 solver.cpp:610] Iteration 31420, lr = 8.5743e-09
I0315 07:51:50.234318 29479 solver.cpp:613] Iteration 31420, avg_grad_norm = 619376
I0315 07:52:15.426759 29479 solver.cpp:214] Iteration 31440, loss = 6533.81
I0315 07:52:15.426815 29479 solver.cpp:229]     Train net output #0: loss = 5217.8 (* 1 = 5217.8 loss)
I0315 07:52:15.539604 29479 solver.cpp:610] Iteration 31440, lr = 8.57338e-09
I0315 07:52:15.539618 29479 solver.cpp:613] Iteration 31440, avg_grad_norm = 610120
I0315 07:52:40.855473 29479 solver.cpp:214] Iteration 31460, loss = 6470.82
I0315 07:52:40.855692 29479 solver.cpp:229]     Train net output #0: loss = 7036.69 (* 1 = 7036.69 loss)
I0315 07:52:40.970156 29479 solver.cpp:610] Iteration 31460, lr = 8.57246e-09
I0315 07:52:40.970170 29479 solver.cpp:613] Iteration 31460, avg_grad_norm = 541781
I0315 07:53:06.562417 29479 solver.cpp:214] Iteration 31480, loss = 6545.6
I0315 07:53:06.562466 29479 solver.cpp:229]     Train net output #0: loss = 7327.29 (* 1 = 7327.29 loss)
I0315 07:53:06.676903 29479 solver.cpp:610] Iteration 31480, lr = 8.57155e-09
I0315 07:53:06.676916 29479 solver.cpp:613] Iteration 31480, avg_grad_norm = 608862
I0315 07:53:44.293241 29479 solver.cpp:214] Iteration 31500, loss = 6401.94
I0315 07:53:44.293330 29479 solver.cpp:229]     Train net output #0: loss = 2835.09 (* 1 = 2835.09 loss)
I0315 07:53:44.397617 29479 solver.cpp:610] Iteration 31500, lr = 8.57063e-09
I0315 07:53:44.397629 29479 solver.cpp:613] Iteration 31500, avg_grad_norm = 510728
I0315 07:54:07.907302 29479 solver.cpp:214] Iteration 31520, loss = 6351.51
I0315 07:54:07.907397 29479 solver.cpp:229]     Train net output #0: loss = 5117.4 (* 1 = 5117.4 loss)
I0315 07:54:08.018833 29479 solver.cpp:610] Iteration 31520, lr = 8.56972e-09
I0315 07:54:08.018905 29479 solver.cpp:613] Iteration 31520, avg_grad_norm = 703235
I0315 07:54:33.524410 29479 solver.cpp:214] Iteration 31540, loss = 6523.62
I0315 07:54:33.524557 29479 solver.cpp:229]     Train net output #0: loss = 4989.86 (* 1 = 4989.86 loss)
I0315 07:54:33.640413 29479 solver.cpp:610] Iteration 31540, lr = 8.5688e-09
I0315 07:54:33.640425 29479 solver.cpp:613] Iteration 31540, avg_grad_norm = 609859
I0315 07:54:59.290089 29479 solver.cpp:214] Iteration 31560, loss = 6711.84
I0315 07:54:59.290179 29479 solver.cpp:229]     Train net output #0: loss = 9299.76 (* 1 = 9299.76 loss)
I0315 07:54:59.403023 29479 solver.cpp:610] Iteration 31560, lr = 8.56789e-09
I0315 07:54:59.403036 29479 solver.cpp:613] Iteration 31560, avg_grad_norm = 613178
I0315 07:55:24.587194 29479 solver.cpp:214] Iteration 31580, loss = 6483.13
I0315 07:55:24.587312 29479 solver.cpp:229]     Train net output #0: loss = 7692.43 (* 1 = 7692.43 loss)
I0315 07:55:24.700206 29479 solver.cpp:610] Iteration 31580, lr = 8.56697e-09
I0315 07:55:24.700217 29479 solver.cpp:613] Iteration 31580, avg_grad_norm = 578409
I0315 07:55:50.216894 29479 solver.cpp:214] Iteration 31600, loss = 6149.73
I0315 07:55:50.216965 29479 solver.cpp:229]     Train net output #0: loss = 7264.68 (* 1 = 7264.68 loss)
I0315 07:55:50.331483 29479 solver.cpp:610] Iteration 31600, lr = 8.56606e-09
I0315 07:55:50.331496 29479 solver.cpp:613] Iteration 31600, avg_grad_norm = 526837
I0315 07:56:15.883824 29479 solver.cpp:214] Iteration 31620, loss = 6099.91
I0315 07:56:15.884071 29479 solver.cpp:229]     Train net output #0: loss = 8043.15 (* 1 = 8043.15 loss)
I0315 07:56:15.998625 29479 solver.cpp:610] Iteration 31620, lr = 8.56514e-09
I0315 07:56:15.998638 29479 solver.cpp:613] Iteration 31620, avg_grad_norm = 587049
I0315 07:56:53.500928 29479 solver.cpp:214] Iteration 31640, loss = 6222.71
I0315 07:56:53.501072 29479 solver.cpp:229]     Train net output #0: loss = 6283.62 (* 1 = 6283.62 loss)
I0315 07:56:53.606154 29479 solver.cpp:610] Iteration 31640, lr = 8.56422e-09
I0315 07:56:53.606168 29479 solver.cpp:613] Iteration 31640, avg_grad_norm = 538526
I0315 07:57:18.253634 29479 solver.cpp:214] Iteration 31660, loss = 6361.4
I0315 07:57:18.253689 29479 solver.cpp:229]     Train net output #0: loss = 4269.79 (* 1 = 4269.79 loss)
I0315 07:57:18.368223 29479 solver.cpp:610] Iteration 31660, lr = 8.56331e-09
I0315 07:57:18.368237 29479 solver.cpp:613] Iteration 31660, avg_grad_norm = 517429
I0315 07:57:43.965639 29479 solver.cpp:214] Iteration 31680, loss = 6253.85
I0315 07:57:43.965760 29479 solver.cpp:229]     Train net output #0: loss = 5865.16 (* 1 = 5865.16 loss)
I0315 07:57:44.080242 29479 solver.cpp:610] Iteration 31680, lr = 8.56239e-09
I0315 07:57:44.080255 29479 solver.cpp:613] Iteration 31680, avg_grad_norm = 589436
I0315 07:58:09.681272 29479 solver.cpp:214] Iteration 31700, loss = 6278.27
I0315 07:58:09.681321 29479 solver.cpp:229]     Train net output #0: loss = 4241.6 (* 1 = 4241.6 loss)
I0315 07:58:09.795958 29479 solver.cpp:610] Iteration 31700, lr = 8.56148e-09
I0315 07:58:09.795971 29479 solver.cpp:613] Iteration 31700, avg_grad_norm = 579544
I0315 07:58:35.361546 29479 solver.cpp:214] Iteration 31720, loss = 6302.41
I0315 07:58:35.361680 29479 solver.cpp:229]     Train net output #0: loss = 10237.3 (* 1 = 10237.3 loss)
I0315 07:58:35.476033 29479 solver.cpp:610] Iteration 31720, lr = 8.56056e-09
I0315 07:58:35.476047 29479 solver.cpp:613] Iteration 31720, avg_grad_norm = 539255
I0315 07:59:01.016216 29479 solver.cpp:214] Iteration 31740, loss = 6244.39
I0315 07:59:01.016261 29479 solver.cpp:229]     Train net output #0: loss = 4893.65 (* 1 = 4893.65 loss)
I0315 07:59:01.130765 29479 solver.cpp:610] Iteration 31740, lr = 8.55965e-09
I0315 07:59:01.130779 29479 solver.cpp:613] Iteration 31740, avg_grad_norm = 517203
I0315 07:59:38.078279 29479 solver.cpp:214] Iteration 31760, loss = 6370.19
I0315 07:59:38.078424 29479 solver.cpp:229]     Train net output #0: loss = 5456.02 (* 1 = 5456.02 loss)
I0315 07:59:38.183503 29479 solver.cpp:610] Iteration 31760, lr = 8.55873e-09
I0315 07:59:38.183517 29479 solver.cpp:613] Iteration 31760, avg_grad_norm = 560146
I0315 08:00:02.348150 29479 solver.cpp:214] Iteration 31780, loss = 6410.04
I0315 08:00:02.348198 29479 solver.cpp:229]     Train net output #0: loss = 5284.44 (* 1 = 5284.44 loss)
I0315 08:00:02.462702 29479 solver.cpp:610] Iteration 31780, lr = 8.55781e-09
I0315 08:00:02.462716 29479 solver.cpp:613] Iteration 31780, avg_grad_norm = 657156
I0315 08:00:28.060677 29479 solver.cpp:214] Iteration 31800, loss = 6199.66
I0315 08:00:28.060808 29479 solver.cpp:229]     Train net output #0: loss = 6382.4 (* 1 = 6382.4 loss)
I0315 08:00:28.175214 29479 solver.cpp:610] Iteration 31800, lr = 8.5569e-09
I0315 08:00:28.175227 29479 solver.cpp:613] Iteration 31800, avg_grad_norm = 570020
I0315 08:00:53.770171 29479 solver.cpp:214] Iteration 31820, loss = 6531.04
I0315 08:00:53.770242 29479 solver.cpp:229]     Train net output #0: loss = 4817.21 (* 1 = 4817.21 loss)
I0315 08:00:53.884573 29479 solver.cpp:610] Iteration 31820, lr = 8.55598e-09
I0315 08:00:53.884627 29479 solver.cpp:613] Iteration 31820, avg_grad_norm = 522270
I0315 08:01:19.436316 29479 solver.cpp:214] Iteration 31840, loss = 6153.27
I0315 08:01:19.436489 29479 solver.cpp:229]     Train net output #0: loss = 8592.24 (* 1 = 8592.24 loss)
I0315 08:01:19.550994 29479 solver.cpp:610] Iteration 31840, lr = 8.55507e-09
I0315 08:01:19.551007 29479 solver.cpp:613] Iteration 31840, avg_grad_norm = 607052
I0315 08:01:45.111654 29479 solver.cpp:214] Iteration 31860, loss = 6328.78
I0315 08:01:45.111724 29479 solver.cpp:229]     Train net output #0: loss = 5862.97 (* 1 = 5862.97 loss)
I0315 08:01:45.226233 29479 solver.cpp:610] Iteration 31860, lr = 8.55415e-09
I0315 08:01:45.226246 29479 solver.cpp:613] Iteration 31860, avg_grad_norm = 688604
I0315 08:02:31.465746 29479 solver.cpp:214] Iteration 31880, loss = 6243.68
I0315 08:02:31.465894 29479 solver.cpp:229]     Train net output #0: loss = 7689.61 (* 1 = 7689.61 loss)
I0315 08:02:31.570850 29479 solver.cpp:610] Iteration 31880, lr = 8.55324e-09
I0315 08:02:31.570863 29479 solver.cpp:613] Iteration 31880, avg_grad_norm = 608899
I0315 08:02:55.060585 29479 solver.cpp:214] Iteration 31900, loss = 6343.87
I0315 08:02:55.060647 29479 solver.cpp:229]     Train net output #0: loss = 4961.94 (* 1 = 4961.94 loss)
I0315 08:02:55.165850 29479 solver.cpp:610] Iteration 31900, lr = 8.55232e-09
I0315 08:02:55.165864 29479 solver.cpp:613] Iteration 31900, avg_grad_norm = 543514
I0315 08:03:19.320343 29479 solver.cpp:214] Iteration 31920, loss = 6588.67
I0315 08:03:19.320461 29479 solver.cpp:229]     Train net output #0: loss = 7904.13 (* 1 = 7904.13 loss)
I0315 08:03:19.433379 29479 solver.cpp:610] Iteration 31920, lr = 8.5514e-09
I0315 08:03:19.433394 29479 solver.cpp:613] Iteration 31920, avg_grad_norm = 542571
I0315 08:03:44.934836 29479 solver.cpp:214] Iteration 31940, loss = 6313.52
I0315 08:03:44.934900 29479 solver.cpp:229]     Train net output #0: loss = 9178.67 (* 1 = 9178.67 loss)
I0315 08:03:45.049314 29479 solver.cpp:610] Iteration 31940, lr = 8.55049e-09
I0315 08:03:45.049327 29479 solver.cpp:613] Iteration 31940, avg_grad_norm = 497739
I0315 08:04:10.591548 29479 solver.cpp:214] Iteration 31960, loss = 6181.28
I0315 08:04:10.591681 29479 solver.cpp:229]     Train net output #0: loss = 8735.53 (* 1 = 8735.53 loss)
I0315 08:04:10.704584 29479 solver.cpp:610] Iteration 31960, lr = 8.54957e-09
I0315 08:04:10.704617 29479 solver.cpp:613] Iteration 31960, avg_grad_norm = 503117
I0315 08:04:35.959209 29479 solver.cpp:214] Iteration 31980, loss = 6746.39
I0315 08:04:35.959271 29479 solver.cpp:229]     Train net output #0: loss = 3050.54 (* 1 = 3050.54 loss)
I0315 08:04:36.072438 29479 solver.cpp:610] Iteration 31980, lr = 8.54866e-09
I0315 08:04:36.072450 29479 solver.cpp:613] Iteration 31980, avg_grad_norm = 567043
I0315 08:05:01.455981 29479 solver.cpp:214] Iteration 32000, loss = 6462.53
I0315 08:05:01.456121 29479 solver.cpp:229]     Train net output #0: loss = 9857.04 (* 1 = 9857.04 loss)
I0315 08:05:01.570384 29479 solver.cpp:610] Iteration 32000, lr = 8.54774e-09
I0315 08:05:01.570395 29479 solver.cpp:613] Iteration 32000, avg_grad_norm = 654671
I0315 08:05:39.632098 29479 solver.cpp:214] Iteration 32020, loss = 6453.89
I0315 08:05:39.632242 29479 solver.cpp:229]     Train net output #0: loss = 10777.7 (* 1 = 10777.7 loss)
I0315 08:05:39.737465 29479 solver.cpp:610] Iteration 32020, lr = 8.54683e-09
I0315 08:05:39.737479 29479 solver.cpp:613] Iteration 32020, avg_grad_norm = 786733
I0315 08:06:04.033994 29479 solver.cpp:214] Iteration 32040, loss = 6349.14
I0315 08:06:04.034063 29479 solver.cpp:229]     Train net output #0: loss = 4243.58 (* 1 = 4243.58 loss)
I0315 08:06:04.148527 29479 solver.cpp:610] Iteration 32040, lr = 8.54591e-09
I0315 08:06:04.148540 29479 solver.cpp:613] Iteration 32040, avg_grad_norm = 536055
I0315 08:06:29.686563 29479 solver.cpp:214] Iteration 32060, loss = 6344.56
I0315 08:06:29.686692 29479 solver.cpp:229]     Train net output #0: loss = 6572.67 (* 1 = 6572.67 loss)
I0315 08:06:29.801188 29479 solver.cpp:610] Iteration 32060, lr = 8.54499e-09
I0315 08:06:29.801200 29479 solver.cpp:613] Iteration 32060, avg_grad_norm = 622392
I0315 08:06:55.338744 29479 solver.cpp:214] Iteration 32080, loss = 6564.69
I0315 08:06:55.338796 29479 solver.cpp:229]     Train net output #0: loss = 11629.5 (* 1 = 11629.5 loss)
I0315 08:06:55.453380 29479 solver.cpp:610] Iteration 32080, lr = 8.54408e-09
I0315 08:06:55.453395 29479 solver.cpp:613] Iteration 32080, avg_grad_norm = 533580
I0315 08:07:20.997727 29479 solver.cpp:214] Iteration 32100, loss = 6234.46
I0315 08:07:20.997983 29479 solver.cpp:229]     Train net output #0: loss = 5225.51 (* 1 = 5225.51 loss)
I0315 08:07:21.112205 29479 solver.cpp:610] Iteration 32100, lr = 8.54316e-09
I0315 08:07:21.112221 29479 solver.cpp:613] Iteration 32100, avg_grad_norm = 489807
I0315 08:07:46.610101 29479 solver.cpp:214] Iteration 32120, loss = 6287.48
I0315 08:07:46.610167 29479 solver.cpp:229]     Train net output #0: loss = 7690.76 (* 1 = 7690.76 loss)
I0315 08:07:46.723112 29479 solver.cpp:610] Iteration 32120, lr = 8.54225e-09
I0315 08:07:46.723125 29479 solver.cpp:613] Iteration 32120, avg_grad_norm = 523497
I0315 08:08:44.888080 29479 solver.cpp:214] Iteration 32140, loss = 6564.96
I0315 08:08:44.888299 29479 solver.cpp:229]     Train net output #0: loss = 3355.5 (* 1 = 3355.5 loss)
I0315 08:08:44.993626 29479 solver.cpp:610] Iteration 32140, lr = 8.54133e-09
I0315 08:08:44.993640 29479 solver.cpp:613] Iteration 32140, avg_grad_norm = 553616
I0315 08:09:08.455034 29479 solver.cpp:214] Iteration 32160, loss = 6346.28
I0315 08:09:08.455101 29479 solver.cpp:229]     Train net output #0: loss = 4884.35 (* 1 = 4884.35 loss)
I0315 08:09:08.560493 29479 solver.cpp:610] Iteration 32160, lr = 8.54041e-09
I0315 08:09:08.560547 29479 solver.cpp:613] Iteration 32160, avg_grad_norm = 553896
I0315 08:09:32.093713 29479 solver.cpp:214] Iteration 32180, loss = 6567.31
I0315 08:09:32.093955 29479 solver.cpp:229]     Train net output #0: loss = 5080.98 (* 1 = 5080.98 loss)
I0315 08:09:32.199133 29479 solver.cpp:610] Iteration 32180, lr = 8.5395e-09
I0315 08:09:32.199146 29479 solver.cpp:613] Iteration 32180, avg_grad_norm = 574798
I0315 08:09:57.228031 29479 solver.cpp:214] Iteration 32200, loss = 6713.21
I0315 08:09:57.228086 29479 solver.cpp:229]     Train net output #0: loss = 6338.76 (* 1 = 6338.76 loss)
I0315 08:09:57.342639 29479 solver.cpp:610] Iteration 32200, lr = 8.53858e-09
I0315 08:09:57.342653 29479 solver.cpp:613] Iteration 32200, avg_grad_norm = 604999
I0315 08:10:22.648665 29479 solver.cpp:214] Iteration 32220, loss = 6529
I0315 08:10:22.648844 29479 solver.cpp:229]     Train net output #0: loss = 9011.44 (* 1 = 9011.44 loss)
I0315 08:10:22.761646 29479 solver.cpp:610] Iteration 32220, lr = 8.53767e-09
I0315 08:10:22.761658 29479 solver.cpp:613] Iteration 32220, avg_grad_norm = 591634
I0315 08:10:47.962208 29479 solver.cpp:214] Iteration 32240, loss = 6337.04
I0315 08:10:47.962257 29479 solver.cpp:229]     Train net output #0: loss = 5650.88 (* 1 = 5650.88 loss)
I0315 08:10:48.075208 29479 solver.cpp:610] Iteration 32240, lr = 8.53675e-09
I0315 08:10:48.075220 29479 solver.cpp:613] Iteration 32240, avg_grad_norm = 549820
I0315 08:11:25.615706 29479 solver.cpp:214] Iteration 32260, loss = 6738.47
I0315 08:11:25.615851 29479 solver.cpp:229]     Train net output #0: loss = 4171.46 (* 1 = 4171.46 loss)
I0315 08:11:25.720095 29479 solver.cpp:610] Iteration 32260, lr = 8.53583e-09
I0315 08:11:25.720109 29479 solver.cpp:613] Iteration 32260, avg_grad_norm = 576729
I0315 08:11:49.166805 29479 solver.cpp:214] Iteration 32280, loss = 6165.35
I0315 08:11:49.166858 29479 solver.cpp:229]     Train net output #0: loss = 3587.77 (* 1 = 3587.77 loss)
I0315 08:11:49.271672 29479 solver.cpp:610] Iteration 32280, lr = 8.53492e-09
I0315 08:11:49.271689 29479 solver.cpp:613] Iteration 32280, avg_grad_norm = 578472
I0315 08:12:14.457267 29479 solver.cpp:214] Iteration 32300, loss = 6239.63
I0315 08:12:14.457392 29479 solver.cpp:229]     Train net output #0: loss = 5507.06 (* 1 = 5507.06 loss)
I0315 08:12:14.571874 29479 solver.cpp:610] Iteration 32300, lr = 8.534e-09
I0315 08:12:14.571889 29479 solver.cpp:613] Iteration 32300, avg_grad_norm = 552646
I0315 08:12:40.186182 29479 solver.cpp:214] Iteration 32320, loss = 6478.89
I0315 08:12:40.186249 29479 solver.cpp:229]     Train net output #0: loss = 5927.58 (* 1 = 5927.58 loss)
I0315 08:12:40.300941 29479 solver.cpp:610] Iteration 32320, lr = 8.53309e-09
I0315 08:12:40.300956 29479 solver.cpp:613] Iteration 32320, avg_grad_norm = 595076
I0315 08:13:05.686733 29479 solver.cpp:214] Iteration 32340, loss = 6694.76
I0315 08:13:05.686916 29479 solver.cpp:229]     Train net output #0: loss = 5977.67 (* 1 = 5977.67 loss)
I0315 08:13:05.799772 29479 solver.cpp:610] Iteration 32340, lr = 8.53217e-09
I0315 08:13:05.799785 29479 solver.cpp:613] Iteration 32340, avg_grad_norm = 610667
I0315 08:13:31.153635 29479 solver.cpp:214] Iteration 32360, loss = 6605.01
I0315 08:13:31.153682 29479 solver.cpp:229]     Train net output #0: loss = 4411.73 (* 1 = 4411.73 loss)
I0315 08:13:31.268121 29479 solver.cpp:610] Iteration 32360, lr = 8.53125e-09
I0315 08:13:31.268134 29479 solver.cpp:613] Iteration 32360, avg_grad_norm = 551232
I0315 08:13:56.852586 29479 solver.cpp:214] Iteration 32380, loss = 6166.45
I0315 08:13:56.852767 29479 solver.cpp:229]     Train net output #0: loss = 5163.46 (* 1 = 5163.46 loss)
I0315 08:13:56.967448 29479 solver.cpp:610] Iteration 32380, lr = 8.53034e-09
I0315 08:13:56.967500 29479 solver.cpp:613] Iteration 32380, avg_grad_norm = 581904
I0315 08:14:37.853626 29479 solver.cpp:214] Iteration 32400, loss = 6226.68
I0315 08:14:37.853772 29479 solver.cpp:229]     Train net output #0: loss = 3324.71 (* 1 = 3324.71 loss)
I0315 08:14:37.958729 29479 solver.cpp:610] Iteration 32400, lr = 8.52942e-09
I0315 08:14:37.958742 29479 solver.cpp:613] Iteration 32400, avg_grad_norm = 535116
I0315 08:15:02.020079 29479 solver.cpp:214] Iteration 32420, loss = 6231.73
I0315 08:15:02.020138 29479 solver.cpp:229]     Train net output #0: loss = 4809.19 (* 1 = 4809.19 loss)
I0315 08:15:02.134615 29479 solver.cpp:610] Iteration 32420, lr = 8.52851e-09
I0315 08:15:02.134629 29479 solver.cpp:613] Iteration 32420, avg_grad_norm = 483135
I0315 08:15:27.733208 29479 solver.cpp:214] Iteration 32440, loss = 6214.29
I0315 08:15:27.733351 29479 solver.cpp:229]     Train net output #0: loss = 10861.8 (* 1 = 10861.8 loss)
I0315 08:15:27.847702 29479 solver.cpp:610] Iteration 32440, lr = 8.52759e-09
I0315 08:15:27.847717 29479 solver.cpp:613] Iteration 32440, avg_grad_norm = 609847
I0315 08:15:53.391345 29479 solver.cpp:214] Iteration 32460, loss = 6684.55
I0315 08:15:53.391407 29479 solver.cpp:229]     Train net output #0: loss = 3582.01 (* 1 = 3582.01 loss)
I0315 08:15:53.504384 29479 solver.cpp:610] Iteration 32460, lr = 8.52667e-09
I0315 08:15:53.504400 29479 solver.cpp:613] Iteration 32460, avg_grad_norm = 713322
I0315 08:16:18.790215 29479 solver.cpp:214] Iteration 32480, loss = 6350.36
I0315 08:16:18.790348 29479 solver.cpp:229]     Train net output #0: loss = 4408.08 (* 1 = 4408.08 loss)
I0315 08:16:18.903096 29479 solver.cpp:610] Iteration 32480, lr = 8.52576e-09
I0315 08:16:18.903110 29479 solver.cpp:613] Iteration 32480, avg_grad_norm = 554976
I0315 08:16:44.437202 29479 solver.cpp:214] Iteration 32500, loss = 6480.43
I0315 08:16:44.437264 29479 solver.cpp:229]     Train net output #0: loss = 5246.73 (* 1 = 5246.73 loss)
I0315 08:16:44.551707 29479 solver.cpp:610] Iteration 32500, lr = 8.52484e-09
I0315 08:16:44.551722 29479 solver.cpp:613] Iteration 32500, avg_grad_norm = 573390
I0315 08:17:32.195518 29479 solver.cpp:214] Iteration 32520, loss = 6606.59
I0315 08:17:32.195725 29479 solver.cpp:229]     Train net output #0: loss = 4297.26 (* 1 = 4297.26 loss)
I0315 08:17:32.299998 29479 solver.cpp:610] Iteration 32520, lr = 8.52393e-09
I0315 08:17:32.300014 29479 solver.cpp:613] Iteration 32520, avg_grad_norm = 522609
I0315 08:17:55.748237 29479 solver.cpp:214] Iteration 32540, loss = 5996.88
I0315 08:17:55.748301 29479 solver.cpp:229]     Train net output #0: loss = 6860.26 (* 1 = 6860.26 loss)
I0315 08:17:55.853487 29479 solver.cpp:610] Iteration 32540, lr = 8.52301e-09
I0315 08:17:55.853500 29479 solver.cpp:613] Iteration 32540, avg_grad_norm = 530764
I0315 08:18:20.262609 29479 solver.cpp:214] Iteration 32560, loss = 6491.74
I0315 08:18:20.262778 29479 solver.cpp:229]     Train net output #0: loss = 7842.35 (* 1 = 7842.35 loss)
I0315 08:18:20.377252 29479 solver.cpp:610] Iteration 32560, lr = 8.52209e-09
I0315 08:18:20.377266 29479 solver.cpp:613] Iteration 32560, avg_grad_norm = 576045
I0315 08:18:45.969336 29479 solver.cpp:214] Iteration 32580, loss = 6540.59
I0315 08:18:45.969396 29479 solver.cpp:229]     Train net output #0: loss = 4622.81 (* 1 = 4622.81 loss)
I0315 08:18:46.083896 29479 solver.cpp:610] Iteration 32580, lr = 8.52118e-09
I0315 08:18:46.083910 29479 solver.cpp:613] Iteration 32580, avg_grad_norm = 663017
I0315 08:19:11.646466 29479 solver.cpp:214] Iteration 32600, loss = 6557.55
I0315 08:19:11.646603 29479 solver.cpp:229]     Train net output #0: loss = 6110.04 (* 1 = 6110.04 loss)
I0315 08:19:11.759460 29479 solver.cpp:610] Iteration 32600, lr = 8.52026e-09
I0315 08:19:11.759477 29479 solver.cpp:613] Iteration 32600, avg_grad_norm = 570218
I0315 08:19:36.998399 29479 solver.cpp:214] Iteration 32620, loss = 6263.71
I0315 08:19:36.998461 29479 solver.cpp:229]     Train net output #0: loss = 6405.91 (* 1 = 6405.91 loss)
I0315 08:19:37.111294 29479 solver.cpp:610] Iteration 32620, lr = 8.51935e-09
I0315 08:19:37.111307 29479 solver.cpp:613] Iteration 32620, avg_grad_norm = 571681
I0315 08:20:14.890945 29479 solver.cpp:214] Iteration 32640, loss = 6252.7
I0315 08:20:14.891160 29479 solver.cpp:229]     Train net output #0: loss = 5616.08 (* 1 = 5616.08 loss)
I0315 08:20:14.995137 29479 solver.cpp:610] Iteration 32640, lr = 8.51843e-09
I0315 08:20:14.995151 29479 solver.cpp:613] Iteration 32640, avg_grad_norm = 521299
I0315 08:20:38.441679 29479 solver.cpp:214] Iteration 32660, loss = 6452.66
I0315 08:20:38.441731 29479 solver.cpp:229]     Train net output #0: loss = 9114.12 (* 1 = 9114.12 loss)
I0315 08:20:38.546831 29479 solver.cpp:610] Iteration 32660, lr = 8.51751e-09
I0315 08:20:38.546849 29479 solver.cpp:613] Iteration 32660, avg_grad_norm = 544061
I0315 08:21:03.617763 29479 solver.cpp:214] Iteration 32680, loss = 6038.61
I0315 08:21:03.617913 29479 solver.cpp:229]     Train net output #0: loss = 6851.76 (* 1 = 6851.76 loss)
I0315 08:21:03.732208 29479 solver.cpp:610] Iteration 32680, lr = 8.5166e-09
I0315 08:21:03.732220 29479 solver.cpp:613] Iteration 32680, avg_grad_norm = 579788
I0315 08:21:29.283952 29479 solver.cpp:214] Iteration 32700, loss = 6524.28
I0315 08:21:29.284013 29479 solver.cpp:229]     Train net output #0: loss = 6900.9 (* 1 = 6900.9 loss)
I0315 08:21:29.398514 29479 solver.cpp:610] Iteration 32700, lr = 8.51568e-09
I0315 08:21:29.398526 29479 solver.cpp:613] Iteration 32700, avg_grad_norm = 542474
I0315 08:21:54.935750 29479 solver.cpp:214] Iteration 32720, loss = 6520.94
I0315 08:21:54.935907 29479 solver.cpp:229]     Train net output #0: loss = 3294.68 (* 1 = 3294.68 loss)
I0315 08:21:55.050365 29479 solver.cpp:610] Iteration 32720, lr = 8.51476e-09
I0315 08:21:55.050379 29479 solver.cpp:613] Iteration 32720, avg_grad_norm = 504349
I0315 08:22:20.607360 29479 solver.cpp:214] Iteration 32740, loss = 6080.22
I0315 08:22:20.607411 29479 solver.cpp:229]     Train net output #0: loss = 8812.67 (* 1 = 8812.67 loss)
I0315 08:22:20.721848 29479 solver.cpp:610] Iteration 32740, lr = 8.51385e-09
I0315 08:22:20.721863 29479 solver.cpp:613] Iteration 32740, avg_grad_norm = 537780
I0315 08:22:46.317275 29479 solver.cpp:214] Iteration 32760, loss = 6493.78
I0315 08:22:46.317405 29479 solver.cpp:229]     Train net output #0: loss = 3621.71 (* 1 = 3621.71 loss)
I0315 08:22:46.431694 29479 solver.cpp:610] Iteration 32760, lr = 8.51293e-09
I0315 08:22:46.431707 29479 solver.cpp:613] Iteration 32760, avg_grad_norm = 577195
I0315 08:23:22.996413 29479 solver.cpp:214] Iteration 32780, loss = 6683.47
I0315 08:23:22.996557 29479 solver.cpp:229]     Train net output #0: loss = 5049.48 (* 1 = 5049.48 loss)
I0315 08:23:23.101671 29479 solver.cpp:610] Iteration 32780, lr = 8.51202e-09
I0315 08:23:23.101685 29479 solver.cpp:613] Iteration 32780, avg_grad_norm = 559805
I0315 08:23:47.606185 29479 solver.cpp:214] Iteration 32800, loss = 6597.01
I0315 08:23:47.606250 29479 solver.cpp:229]     Train net output #0: loss = 7989.15 (* 1 = 7989.15 loss)
I0315 08:23:47.720811 29479 solver.cpp:610] Iteration 32800, lr = 8.5111e-09
I0315 08:23:47.720824 29479 solver.cpp:613] Iteration 32800, avg_grad_norm = 597571
I0315 08:24:13.347674 29479 solver.cpp:214] Iteration 32820, loss = 6654.24
I0315 08:24:13.347841 29479 solver.cpp:229]     Train net output #0: loss = 6970.34 (* 1 = 6970.34 loss)
I0315 08:24:13.462232 29479 solver.cpp:610] Iteration 32820, lr = 8.51018e-09
I0315 08:24:13.462247 29479 solver.cpp:613] Iteration 32820, avg_grad_norm = 638830
I0315 08:24:38.998885 29479 solver.cpp:214] Iteration 32840, loss = 6591.98
I0315 08:24:38.998952 29479 solver.cpp:229]     Train net output #0: loss = 7649.99 (* 1 = 7649.99 loss)
I0315 08:24:39.112061 29479 solver.cpp:610] Iteration 32840, lr = 8.50927e-09
I0315 08:24:39.112077 29479 solver.cpp:613] Iteration 32840, avg_grad_norm = 545245
I0315 08:25:04.404173 29479 solver.cpp:214] Iteration 32860, loss = 6114.33
I0315 08:25:04.404317 29479 solver.cpp:229]     Train net output #0: loss = 5555.5 (* 1 = 5555.5 loss)
I0315 08:25:04.517093 29479 solver.cpp:610] Iteration 32860, lr = 8.50835e-09
I0315 08:25:04.517108 29479 solver.cpp:613] Iteration 32860, avg_grad_norm = 560507
I0315 08:25:30.257875 29479 solver.cpp:214] Iteration 32880, loss = 6597.21
I0315 08:25:30.257931 29479 solver.cpp:229]     Train net output #0: loss = 5215.65 (* 1 = 5215.65 loss)
I0315 08:25:30.373911 29479 solver.cpp:610] Iteration 32880, lr = 8.50743e-09
I0315 08:25:30.373924 29479 solver.cpp:613] Iteration 32880, avg_grad_norm = 545103
I0315 08:26:08.101292 29479 solver.cpp:214] Iteration 32900, loss = 6239.74
I0315 08:26:08.101445 29479 solver.cpp:229]     Train net output #0: loss = 5794.89 (* 1 = 5794.89 loss)
I0315 08:26:08.206431 29479 solver.cpp:610] Iteration 32900, lr = 8.50652e-09
I0315 08:26:08.206445 29479 solver.cpp:613] Iteration 32900, avg_grad_norm = 557300
I0315 08:26:31.934643 29479 solver.cpp:214] Iteration 32920, loss = 6345.45
I0315 08:26:31.934705 29479 solver.cpp:229]     Train net output #0: loss = 6513.64 (* 1 = 6513.64 loss)
I0315 08:26:32.049299 29479 solver.cpp:610] Iteration 32920, lr = 8.5056e-09
I0315 08:26:32.049311 29479 solver.cpp:613] Iteration 32920, avg_grad_norm = 648556
I0315 08:26:57.584681 29479 solver.cpp:214] Iteration 32940, loss = 6652.95
I0315 08:26:57.584839 29479 solver.cpp:229]     Train net output #0: loss = 5733.55 (* 1 = 5733.55 loss)
I0315 08:26:57.699529 29479 solver.cpp:610] Iteration 32940, lr = 8.50468e-09
I0315 08:26:57.699542 29479 solver.cpp:613] Iteration 32940, avg_grad_norm = 556729
I0315 08:27:23.238584 29479 solver.cpp:214] Iteration 32960, loss = 6377.12
I0315 08:27:23.238651 29479 solver.cpp:229]     Train net output #0: loss = 8061.93 (* 1 = 8061.93 loss)
I0315 08:27:23.353065 29479 solver.cpp:610] Iteration 32960, lr = 8.50377e-09
I0315 08:27:23.353077 29479 solver.cpp:613] Iteration 32960, avg_grad_norm = 551737
I0315 08:27:48.937196 29479 solver.cpp:214] Iteration 32980, loss = 6287.07
I0315 08:27:48.937319 29479 solver.cpp:229]     Train net output #0: loss = 5462.23 (* 1 = 5462.23 loss)
I0315 08:27:49.051923 29479 solver.cpp:610] Iteration 32980, lr = 8.50285e-09
I0315 08:27:49.051937 29479 solver.cpp:613] Iteration 32980, avg_grad_norm = 547004
I0315 08:28:14.653892 29479 solver.cpp:214] Iteration 33000, loss = 6110.71
I0315 08:28:14.653945 29479 solver.cpp:229]     Train net output #0: loss = 12322.7 (* 1 = 12322.7 loss)
I0315 08:28:14.768481 29479 solver.cpp:610] Iteration 33000, lr = 8.50194e-09
I0315 08:28:14.768494 29479 solver.cpp:613] Iteration 33000, avg_grad_norm = 516760
I0315 08:28:56.557745 29479 solver.cpp:214] Iteration 33020, loss = 6379.8
I0315 08:28:56.557901 29479 solver.cpp:229]     Train net output #0: loss = 4429.09 (* 1 = 4429.09 loss)
I0315 08:28:56.661792 29479 solver.cpp:610] Iteration 33020, lr = 8.50102e-09
I0315 08:28:56.661830 29479 solver.cpp:613] Iteration 33020, avg_grad_norm = 533350
I0315 08:29:20.169492 29479 solver.cpp:214] Iteration 33040, loss = 6143.66
I0315 08:29:20.169543 29479 solver.cpp:229]     Train net output #0: loss = 6278.06 (* 1 = 6278.06 loss)
I0315 08:29:20.274685 29479 solver.cpp:610] Iteration 33040, lr = 8.5001e-09
I0315 08:29:20.274698 29479 solver.cpp:613] Iteration 33040, avg_grad_norm = 550565
I0315 08:29:44.831660 29479 solver.cpp:214] Iteration 33060, loss = 6209.76
I0315 08:29:44.831897 29479 solver.cpp:229]     Train net output #0: loss = 4210.55 (* 1 = 4210.55 loss)
I0315 08:29:44.946293 29479 solver.cpp:610] Iteration 33060, lr = 8.49919e-09
I0315 08:29:44.946308 29479 solver.cpp:613] Iteration 33060, avg_grad_norm = 528632
I0315 08:30:10.549090 29479 solver.cpp:214] Iteration 33080, loss = 6313.08
I0315 08:30:10.549146 29479 solver.cpp:229]     Train net output #0: loss = 3331.49 (* 1 = 3331.49 loss)
I0315 08:30:10.663617 29479 solver.cpp:610] Iteration 33080, lr = 8.49827e-09
I0315 08:30:10.663630 29479 solver.cpp:613] Iteration 33080, avg_grad_norm = 512846
I0315 08:30:36.263473 29479 solver.cpp:214] Iteration 33100, loss = 6293.52
I0315 08:30:36.263612 29479 solver.cpp:229]     Train net output #0: loss = 5431.48 (* 1 = 5431.48 loss)
I0315 08:30:36.378140 29479 solver.cpp:610] Iteration 33100, lr = 8.49735e-09
I0315 08:30:36.378154 29479 solver.cpp:613] Iteration 33100, avg_grad_norm = 556042
I0315 08:31:01.735898 29479 solver.cpp:214] Iteration 33120, loss = 6229.41
I0315 08:31:01.735966 29479 solver.cpp:229]     Train net output #0: loss = 2759.81 (* 1 = 2759.81 loss)
I0315 08:31:01.848860 29479 solver.cpp:610] Iteration 33120, lr = 8.49644e-09
I0315 08:31:01.848872 29479 solver.cpp:613] Iteration 33120, avg_grad_norm = 568337
I0315 08:31:27.100479 29479 solver.cpp:214] Iteration 33140, loss = 6237.82
I0315 08:31:27.100617 29479 solver.cpp:229]     Train net output #0: loss = 5853.04 (* 1 = 5853.04 loss)
I0315 08:31:27.214978 29479 solver.cpp:610] Iteration 33140, lr = 8.49552e-09
I0315 08:31:27.214992 29479 solver.cpp:613] Iteration 33140, avg_grad_norm = 593809
I0315 08:32:07.434629 29479 solver.cpp:214] Iteration 33160, loss = 6224.16
I0315 08:32:07.434762 29479 solver.cpp:229]     Train net output #0: loss = 4367.89 (* 1 = 4367.89 loss)
I0315 08:32:07.539762 29479 solver.cpp:610] Iteration 33160, lr = 8.49461e-09
I0315 08:32:07.539775 29479 solver.cpp:613] Iteration 33160, avg_grad_norm = 574100
I0315 08:32:31.517444 29479 solver.cpp:214] Iteration 33180, loss = 6287.6
I0315 08:32:31.517508 29479 solver.cpp:229]     Train net output #0: loss = 7739.71 (* 1 = 7739.71 loss)
I0315 08:32:31.632129 29479 solver.cpp:610] Iteration 33180, lr = 8.49369e-09
I0315 08:32:31.632143 29479 solver.cpp:613] Iteration 33180, avg_grad_norm = 520119
I0315 08:32:57.171773 29479 solver.cpp:214] Iteration 33200, loss = 6225.89
I0315 08:32:57.171926 29479 solver.cpp:229]     Train net output #0: loss = 3542.54 (* 1 = 3542.54 loss)
I0315 08:32:57.286373 29479 solver.cpp:610] Iteration 33200, lr = 8.49277e-09
I0315 08:32:57.286389 29479 solver.cpp:613] Iteration 33200, avg_grad_norm = 626484
I0315 08:33:22.831017 29479 solver.cpp:214] Iteration 33220, loss = 6301.43
I0315 08:33:22.831084 29479 solver.cpp:229]     Train net output #0: loss = 5244.84 (* 1 = 5244.84 loss)
I0315 08:33:22.944077 29479 solver.cpp:610] Iteration 33220, lr = 8.49186e-09
I0315 08:33:22.944092 29479 solver.cpp:613] Iteration 33220, avg_grad_norm = 576962
I0315 08:33:48.174213 29479 solver.cpp:214] Iteration 33240, loss = 6378.93
I0315 08:33:48.174348 29479 solver.cpp:229]     Train net output #0: loss = 7266.62 (* 1 = 7266.62 loss)
I0315 08:33:48.287498 29479 solver.cpp:610] Iteration 33240, lr = 8.49094e-09
I0315 08:33:48.287549 29479 solver.cpp:613] Iteration 33240, avg_grad_norm = 519740
I0315 08:34:13.799163 29479 solver.cpp:214] Iteration 33260, loss = 6593.82
I0315 08:34:13.799221 29479 solver.cpp:229]     Train net output #0: loss = 5373.07 (* 1 = 5373.07 loss)
I0315 08:34:13.915601 29479 solver.cpp:610] Iteration 33260, lr = 8.49002e-09
I0315 08:34:13.915616 29479 solver.cpp:613] Iteration 33260, avg_grad_norm = 579470
I0315 08:34:51.644139 29479 solver.cpp:214] Iteration 33280, loss = 6352.29
I0315 08:34:51.644316 29479 solver.cpp:229]     Train net output #0: loss = 6474.18 (* 1 = 6474.18 loss)
I0315 08:34:51.749243 29479 solver.cpp:610] Iteration 33280, lr = 8.48911e-09
I0315 08:34:51.749256 29479 solver.cpp:613] Iteration 33280, avg_grad_norm = 582036
I0315 08:35:15.485404 29479 solver.cpp:214] Iteration 33300, loss = 6056.9
I0315 08:35:15.485471 29479 solver.cpp:229]     Train net output #0: loss = 6849.2 (* 1 = 6849.2 loss)
I0315 08:35:15.598494 29479 solver.cpp:610] Iteration 33300, lr = 8.48819e-09
I0315 08:35:15.598507 29479 solver.cpp:613] Iteration 33300, avg_grad_norm = 663472
I0315 08:35:41.199396 29479 solver.cpp:214] Iteration 33320, loss = 6825.21
I0315 08:35:41.199514 29479 solver.cpp:229]     Train net output #0: loss = 3568.61 (* 1 = 3568.61 loss)
I0315 08:35:41.314013 29479 solver.cpp:610] Iteration 33320, lr = 8.48727e-09
I0315 08:35:41.314026 29479 solver.cpp:613] Iteration 33320, avg_grad_norm = 612376
I0315 08:36:06.914665 29479 solver.cpp:214] Iteration 33340, loss = 6498.02
I0315 08:36:06.914741 29479 solver.cpp:229]     Train net output #0: loss = 4363.65 (* 1 = 4363.65 loss)
I0315 08:36:07.029225 29479 solver.cpp:610] Iteration 33340, lr = 8.48636e-09
I0315 08:36:07.029239 29479 solver.cpp:613] Iteration 33340, avg_grad_norm = 570959
I0315 08:36:32.626560 29479 solver.cpp:214] Iteration 33360, loss = 6006.23
I0315 08:36:32.626713 29479 solver.cpp:229]     Train net output #0: loss = 5097.68 (* 1 = 5097.68 loss)
I0315 08:36:32.741075 29479 solver.cpp:610] Iteration 33360, lr = 8.48544e-09
I0315 08:36:32.741091 29479 solver.cpp:613] Iteration 33360, avg_grad_norm = 518134
I0315 08:36:58.066419 29479 solver.cpp:214] Iteration 33380, loss = 6457.68
I0315 08:36:58.066488 29479 solver.cpp:229]     Train net output #0: loss = 5027.52 (* 1 = 5027.52 loss)
I0315 08:36:58.179338 29479 solver.cpp:610] Iteration 33380, lr = 8.48452e-09
I0315 08:36:58.179358 29479 solver.cpp:613] Iteration 33380, avg_grad_norm = 571119
I0315 08:37:36.587792 29479 solver.cpp:214] Iteration 33400, loss = 6166.79
I0315 08:37:36.587921 29479 solver.cpp:229]     Train net output #0: loss = 5549.83 (* 1 = 5549.83 loss)
I0315 08:37:36.693019 29479 solver.cpp:610] Iteration 33400, lr = 8.48361e-09
I0315 08:37:36.693045 29479 solver.cpp:613] Iteration 33400, avg_grad_norm = 556133
I0315 08:38:00.138015 29479 solver.cpp:214] Iteration 33420, loss = 6638.38
I0315 08:38:00.138106 29479 solver.cpp:229]     Train net output #0: loss = 11012.6 (* 1 = 11012.6 loss)
I0315 08:38:00.243157 29479 solver.cpp:610] Iteration 33420, lr = 8.48269e-09
I0315 08:38:00.243170 29479 solver.cpp:613] Iteration 33420, avg_grad_norm = 569294
I0315 08:38:25.294697 29479 solver.cpp:214] Iteration 33440, loss = 6155.82
I0315 08:38:25.294819 29479 solver.cpp:229]     Train net output #0: loss = 5716.3 (* 1 = 5716.3 loss)
I0315 08:38:25.409198 29479 solver.cpp:610] Iteration 33440, lr = 8.48177e-09
I0315 08:38:25.409212 29479 solver.cpp:613] Iteration 33440, avg_grad_norm = 612548
I0315 08:38:51.018537 29479 solver.cpp:214] Iteration 33460, loss = 6119.75
I0315 08:38:51.018635 29479 solver.cpp:229]     Train net output #0: loss = 8076.74 (* 1 = 8076.74 loss)
I0315 08:38:51.133045 29479 solver.cpp:610] Iteration 33460, lr = 8.48086e-09
I0315 08:38:51.133095 29479 solver.cpp:613] Iteration 33460, avg_grad_norm = 648548
I0315 08:39:16.752894 29479 solver.cpp:214] Iteration 33480, loss = 6112.64
I0315 08:39:16.753028 29479 solver.cpp:229]     Train net output #0: loss = 5261.56 (* 1 = 5261.56 loss)
I0315 08:39:16.867696 29479 solver.cpp:610] Iteration 33480, lr = 8.47994e-09
I0315 08:39:16.867708 29479 solver.cpp:613] Iteration 33480, avg_grad_norm = 584317
I0315 08:39:42.472246 29479 solver.cpp:214] Iteration 33500, loss = 6318.33
I0315 08:39:42.472296 29479 solver.cpp:229]     Train net output #0: loss = 8917.33 (* 1 = 8917.33 loss)
I0315 08:39:42.586807 29479 solver.cpp:610] Iteration 33500, lr = 8.47902e-09
I0315 08:39:42.586822 29479 solver.cpp:613] Iteration 33500, avg_grad_norm = 589821
I0315 08:40:08.190894 29479 solver.cpp:214] Iteration 33520, loss = 6135.06
I0315 08:40:08.191053 29479 solver.cpp:229]     Train net output #0: loss = 8457.88 (* 1 = 8457.88 loss)
I0315 08:40:08.305491 29479 solver.cpp:610] Iteration 33520, lr = 8.47811e-09
I0315 08:40:08.305505 29479 solver.cpp:613] Iteration 33520, avg_grad_norm = 573373
I0315 08:40:46.739859 29479 solver.cpp:214] Iteration 33540, loss = 6293.89
I0315 08:40:46.740077 29479 solver.cpp:229]     Train net output #0: loss = 10503.7 (* 1 = 10503.7 loss)
I0315 08:40:46.844395 29479 solver.cpp:610] Iteration 33540, lr = 8.47719e-09
I0315 08:40:46.844408 29479 solver.cpp:613] Iteration 33540, avg_grad_norm = 541428
I0315 08:41:11.001521 29479 solver.cpp:214] Iteration 33560, loss = 6259.26
I0315 08:41:11.001572 29479 solver.cpp:229]     Train net output #0: loss = 3896.33 (* 1 = 3896.33 loss)
I0315 08:41:11.116140 29479 solver.cpp:610] Iteration 33560, lr = 8.47627e-09
I0315 08:41:11.116154 29479 solver.cpp:613] Iteration 33560, avg_grad_norm = 512557
I0315 08:41:36.712818 29479 solver.cpp:214] Iteration 33580, loss = 6076.17
I0315 08:41:36.712936 29479 solver.cpp:229]     Train net output #0: loss = 8218.03 (* 1 = 8218.03 loss)
I0315 08:41:36.827457 29479 solver.cpp:610] Iteration 33580, lr = 8.47536e-09
I0315 08:41:36.827471 29479 solver.cpp:613] Iteration 33580, avg_grad_norm = 640503
I0315 08:42:02.406080 29479 solver.cpp:214] Iteration 33600, loss = 6529.76
I0315 08:42:02.406158 29479 solver.cpp:229]     Train net output #0: loss = 10990.2 (* 1 = 10990.2 loss)
I0315 08:42:02.520642 29479 solver.cpp:610] Iteration 33600, lr = 8.47444e-09
I0315 08:42:02.520684 29479 solver.cpp:613] Iteration 33600, avg_grad_norm = 668568
I0315 08:42:28.102078 29479 solver.cpp:214] Iteration 33620, loss = 6315.11
I0315 08:42:28.102247 29479 solver.cpp:229]     Train net output #0: loss = 6534.22 (* 1 = 6534.22 loss)
I0315 08:42:28.216646 29479 solver.cpp:610] Iteration 33620, lr = 8.47352e-09
I0315 08:42:28.216660 29479 solver.cpp:613] Iteration 33620, avg_grad_norm = 636951
I0315 08:42:53.671375 29479 solver.cpp:214] Iteration 33640, loss = 6624.76
I0315 08:42:53.671442 29479 solver.cpp:229]     Train net output #0: loss = 5164.78 (* 1 = 5164.78 loss)
I0315 08:42:53.784425 29479 solver.cpp:610] Iteration 33640, lr = 8.47261e-09
I0315 08:42:53.784440 29479 solver.cpp:613] Iteration 33640, avg_grad_norm = 621836
I0315 08:43:31.256916 29479 solver.cpp:214] Iteration 33660, loss = 6060.67
I0315 08:43:31.257061 29479 solver.cpp:229]     Train net output #0: loss = 7477.79 (* 1 = 7477.79 loss)
I0315 08:43:31.362036 29479 solver.cpp:610] Iteration 33660, lr = 8.47169e-09
I0315 08:43:31.362051 29479 solver.cpp:613] Iteration 33660, avg_grad_norm = 521784
I0315 08:43:55.094656 29479 solver.cpp:214] Iteration 33680, loss = 6544.01
I0315 08:43:55.094719 29479 solver.cpp:229]     Train net output #0: loss = 3613.12 (* 1 = 3613.12 loss)
I0315 08:43:55.209311 29479 solver.cpp:610] Iteration 33680, lr = 8.47077e-09
I0315 08:43:55.209353 29479 solver.cpp:613] Iteration 33680, avg_grad_norm = 601406
I0315 08:44:20.784061 29479 solver.cpp:214] Iteration 33700, loss = 6367.15
I0315 08:44:20.784252 29479 solver.cpp:229]     Train net output #0: loss = 6633.54 (* 1 = 6633.54 loss)
I0315 08:44:20.898689 29479 solver.cpp:610] Iteration 33700, lr = 8.46986e-09
I0315 08:44:20.898704 29479 solver.cpp:613] Iteration 33700, avg_grad_norm = 617038
I0315 08:44:46.486604 29479 solver.cpp:214] Iteration 33720, loss = 6231.42
I0315 08:44:46.486677 29479 solver.cpp:229]     Train net output #0: loss = 8475.3 (* 1 = 8475.3 loss)
I0315 08:44:46.601135 29479 solver.cpp:610] Iteration 33720, lr = 8.46894e-09
I0315 08:44:46.601150 29479 solver.cpp:613] Iteration 33720, avg_grad_norm = 601499
I0315 08:45:12.017556 29479 solver.cpp:214] Iteration 33740, loss = 6565.67
I0315 08:45:12.017750 29479 solver.cpp:229]     Train net output #0: loss = 4822.52 (* 1 = 4822.52 loss)
I0315 08:45:12.130476 29479 solver.cpp:610] Iteration 33740, lr = 8.46802e-09
I0315 08:45:12.130491 29479 solver.cpp:613] Iteration 33740, avg_grad_norm = 523071
I0315 08:45:37.603814 29479 solver.cpp:214] Iteration 33760, loss = 6512.46
I0315 08:45:37.603868 29479 solver.cpp:229]     Train net output #0: loss = 4035.19 (* 1 = 4035.19 loss)
I0315 08:45:37.718350 29479 solver.cpp:610] Iteration 33760, lr = 8.46711e-09
I0315 08:45:37.718364 29479 solver.cpp:613] Iteration 33760, avg_grad_norm = 536679
I0315 08:46:25.575520 29479 solver.cpp:214] Iteration 33780, loss = 6192.82
I0315 08:46:25.575671 29479 solver.cpp:229]     Train net output #0: loss = 4424.89 (* 1 = 4424.89 loss)
I0315 08:46:25.680186 29479 solver.cpp:610] Iteration 33780, lr = 8.46619e-09
I0315 08:46:25.680202 29479 solver.cpp:613] Iteration 33780, avg_grad_norm = 553682
I0315 08:46:49.103945 29479 solver.cpp:214] Iteration 33800, loss = 6752.35
I0315 08:46:49.104017 29479 solver.cpp:229]     Train net output #0: loss = 9397.63 (* 1 = 9397.63 loss)
I0315 08:46:49.209095 29479 solver.cpp:610] Iteration 33800, lr = 8.46527e-09
I0315 08:46:49.209108 29479 solver.cpp:613] Iteration 33800, avg_grad_norm = 553692
I0315 08:47:12.853665 29479 solver.cpp:214] Iteration 33820, loss = 6097.07
I0315 08:47:12.853802 29479 solver.cpp:229]     Train net output #0: loss = 7430.31 (* 1 = 7430.31 loss)
I0315 08:47:12.965376 29479 solver.cpp:610] Iteration 33820, lr = 8.46436e-09
I0315 08:47:12.965389 29479 solver.cpp:613] Iteration 33820, avg_grad_norm = 562079
I0315 08:47:38.398906 29479 solver.cpp:214] Iteration 33840, loss = 6362.16
I0315 08:47:38.398964 29479 solver.cpp:229]     Train net output #0: loss = 4114.33 (* 1 = 4114.33 loss)
I0315 08:47:38.513314 29479 solver.cpp:610] Iteration 33840, lr = 8.46344e-09
I0315 08:47:38.513329 29479 solver.cpp:613] Iteration 33840, avg_grad_norm = 572085
I0315 08:48:04.007969 29479 solver.cpp:214] Iteration 33860, loss = 6481.89
I0315 08:48:04.008060 29479 solver.cpp:229]     Train net output #0: loss = 5838.21 (* 1 = 5838.21 loss)
I0315 08:48:04.120990 29479 solver.cpp:610] Iteration 33860, lr = 8.46252e-09
I0315 08:48:04.121003 29479 solver.cpp:613] Iteration 33860, avg_grad_norm = 535464
I0315 08:48:29.392022 29479 solver.cpp:214] Iteration 33880, loss = 6343.66
I0315 08:48:29.392093 29479 solver.cpp:229]     Train net output #0: loss = 5093.65 (* 1 = 5093.65 loss)
I0315 08:48:29.505084 29479 solver.cpp:610] Iteration 33880, lr = 8.4616e-09
I0315 08:48:29.505103 29479 solver.cpp:613] Iteration 33880, avg_grad_norm = 510013
I0315 08:48:55.149447 29479 solver.cpp:214] Iteration 33900, loss = 6361.79
I0315 08:48:55.149682 29479 solver.cpp:229]     Train net output #0: loss = 6408.47 (* 1 = 6408.47 loss)
I0315 08:48:55.264034 29479 solver.cpp:610] Iteration 33900, lr = 8.46069e-09
I0315 08:48:55.264047 29479 solver.cpp:613] Iteration 33900, avg_grad_norm = 554851
I0315 08:49:37.991524 29479 solver.cpp:214] Iteration 33920, loss = 6218.13
I0315 08:49:37.991668 29479 solver.cpp:229]     Train net output #0: loss = 8102.51 (* 1 = 8102.51 loss)
I0315 08:49:38.096778 29479 solver.cpp:610] Iteration 33920, lr = 8.45977e-09
I0315 08:49:38.096792 29479 solver.cpp:613] Iteration 33920, avg_grad_norm = 516805
I0315 08:50:01.629436 29479 solver.cpp:214] Iteration 33940, loss = 5829.54
I0315 08:50:01.629500 29479 solver.cpp:229]     Train net output #0: loss = 7150.38 (* 1 = 7150.38 loss)
I0315 08:50:01.734567 29479 solver.cpp:610] Iteration 33940, lr = 8.45885e-09
I0315 08:50:01.734580 29479 solver.cpp:613] Iteration 33940, avg_grad_norm = 537556
I0315 08:50:27.036304 29479 solver.cpp:214] Iteration 33960, loss = 6268.52
I0315 08:50:27.036418 29479 solver.cpp:229]     Train net output #0: loss = 6403.8 (* 1 = 6403.8 loss)
I0315 08:50:27.151190 29479 solver.cpp:610] Iteration 33960, lr = 8.45794e-09
I0315 08:50:27.151204 29479 solver.cpp:613] Iteration 33960, avg_grad_norm = 485033
I0315 08:50:52.751641 29479 solver.cpp:214] Iteration 33980, loss = 6361.5
I0315 08:50:52.751701 29479 solver.cpp:229]     Train net output #0: loss = 13203.8 (* 1 = 13203.8 loss)
I0315 08:50:52.866360 29479 solver.cpp:610] Iteration 33980, lr = 8.45702e-09
I0315 08:50:52.866372 29479 solver.cpp:613] Iteration 33980, avg_grad_norm = 559358
I0315 08:51:18.471923 29479 solver.cpp:214] Iteration 34000, loss = 6426.82
I0315 08:51:18.472095 29479 solver.cpp:229]     Train net output #0: loss = 9298.53 (* 1 = 9298.53 loss)
I0315 08:51:18.586642 29479 solver.cpp:610] Iteration 34000, lr = 8.4561e-09
I0315 08:51:18.586657 29479 solver.cpp:613] Iteration 34000, avg_grad_norm = 600531
I0315 08:51:44.058590 29479 solver.cpp:214] Iteration 34020, loss = 6343.36
I0315 08:51:44.058640 29479 solver.cpp:229]     Train net output #0: loss = 6210.04 (* 1 = 6210.04 loss)
I0315 08:51:44.171602 29479 solver.cpp:610] Iteration 34020, lr = 8.45519e-09
I0315 08:51:44.171615 29479 solver.cpp:613] Iteration 34020, avg_grad_norm = 548300
I0315 08:52:21.789496 29479 solver.cpp:214] Iteration 34040, loss = 6533.66
I0315 08:52:21.789623 29479 solver.cpp:229]     Train net output #0: loss = 6586.03 (* 1 = 6586.03 loss)
I0315 08:52:21.894881 29479 solver.cpp:610] Iteration 34040, lr = 8.45427e-09
I0315 08:52:21.894896 29479 solver.cpp:613] Iteration 34040, avg_grad_norm = 574631
I0315 08:52:45.442749 29479 solver.cpp:214] Iteration 34060, loss = 6377.33
I0315 08:52:45.442819 29479 solver.cpp:229]     Train net output #0: loss = 4895.75 (* 1 = 4895.75 loss)
I0315 08:52:45.555794 29479 solver.cpp:610] Iteration 34060, lr = 8.45335e-09
I0315 08:52:45.555809 29479 solver.cpp:613] Iteration 34060, avg_grad_norm = 595028
I0315 08:53:11.131041 29479 solver.cpp:214] Iteration 34080, loss = 6381.28
I0315 08:53:11.131207 29479 solver.cpp:229]     Train net output #0: loss = 4880.8 (* 1 = 4880.8 loss)
I0315 08:53:11.245663 29479 solver.cpp:610] Iteration 34080, lr = 8.45244e-09
I0315 08:53:11.245676 29479 solver.cpp:613] Iteration 34080, avg_grad_norm = 596460
I0315 08:53:36.769052 29479 solver.cpp:214] Iteration 34100, loss = 6220.17
I0315 08:53:36.769104 29479 solver.cpp:229]     Train net output #0: loss = 6518.52 (* 1 = 6518.52 loss)
I0315 08:53:36.881947 29479 solver.cpp:610] Iteration 34100, lr = 8.45152e-09
I0315 08:53:36.881959 29479 solver.cpp:613] Iteration 34100, avg_grad_norm = 501707
I0315 08:54:02.183586 29479 solver.cpp:214] Iteration 34120, loss = 6419.16
I0315 08:54:02.183698 29479 solver.cpp:229]     Train net output #0: loss = 8230.44 (* 1 = 8230.44 loss)
I0315 08:54:02.296412 29479 solver.cpp:610] Iteration 34120, lr = 8.4506e-09
I0315 08:54:02.296425 29479 solver.cpp:613] Iteration 34120, avg_grad_norm = 580218
I0315 08:54:27.835297 29479 solver.cpp:214] Iteration 34140, loss = 6285.03
I0315 08:54:27.835357 29479 solver.cpp:229]     Train net output #0: loss = 5799.1 (* 1 = 5799.1 loss)
I0315 08:54:27.949817 29479 solver.cpp:610] Iteration 34140, lr = 8.44968e-09
I0315 08:54:27.949831 29479 solver.cpp:613] Iteration 34140, avg_grad_norm = 653860
I0315 08:54:53.555964 29479 solver.cpp:214] Iteration 34160, loss = 6455.05
I0315 08:54:53.556078 29479 solver.cpp:229]     Train net output #0: loss = 6076.6 (* 1 = 6076.6 loss)
I0315 08:54:53.670564 29479 solver.cpp:610] Iteration 34160, lr = 8.44877e-09
I0315 08:54:53.670578 29479 solver.cpp:613] Iteration 34160, avg_grad_norm = 584794
I0315 08:55:29.831298 29479 solver.cpp:214] Iteration 34180, loss = 6200.06
I0315 08:55:29.831495 29479 solver.cpp:229]     Train net output #0: loss = 4325.36 (* 1 = 4325.36 loss)
I0315 08:55:29.935564 29479 solver.cpp:610] Iteration 34180, lr = 8.44785e-09
I0315 08:55:29.935576 29479 solver.cpp:613] Iteration 34180, avg_grad_norm = 528577
I0315 08:55:54.779985 29479 solver.cpp:214] Iteration 34200, loss = 6203.31
I0315 08:55:54.780062 29479 solver.cpp:229]     Train net output #0: loss = 6641.51 (* 1 = 6641.51 loss)
I0315 08:55:54.894629 29479 solver.cpp:610] Iteration 34200, lr = 8.44693e-09
I0315 08:55:54.894640 29479 solver.cpp:613] Iteration 34200, avg_grad_norm = 624093
I0315 08:56:20.429863 29479 solver.cpp:214] Iteration 34220, loss = 6280.91
I0315 08:56:20.430030 29479 solver.cpp:229]     Train net output #0: loss = 6926.2 (* 1 = 6926.2 loss)
I0315 08:56:20.544498 29479 solver.cpp:610] Iteration 34220, lr = 8.44602e-09
I0315 08:56:20.544510 29479 solver.cpp:613] Iteration 34220, avg_grad_norm = 558392
I0315 08:56:46.081419 29479 solver.cpp:214] Iteration 34240, loss = 6747.28
I0315 08:56:46.081486 29479 solver.cpp:229]     Train net output #0: loss = 4021.92 (* 1 = 4021.92 loss)
I0315 08:56:46.196013 29479 solver.cpp:610] Iteration 34240, lr = 8.4451e-09
I0315 08:56:46.196029 29479 solver.cpp:613] Iteration 34240, avg_grad_norm = 590313
I0315 08:57:11.746356 29479 solver.cpp:214] Iteration 34260, loss = 6119.88
I0315 08:57:11.746480 29479 solver.cpp:229]     Train net output #0: loss = 5399.96 (* 1 = 5399.96 loss)
I0315 08:57:11.860883 29479 solver.cpp:610] Iteration 34260, lr = 8.44418e-09
I0315 08:57:11.860898 29479 solver.cpp:613] Iteration 34260, avg_grad_norm = 753444
I0315 08:57:37.400070 29479 solver.cpp:214] Iteration 34280, loss = 6462.22
I0315 08:57:37.400140 29479 solver.cpp:229]     Train net output #0: loss = 7450.69 (* 1 = 7450.69 loss)
I0315 08:57:37.514657 29479 solver.cpp:610] Iteration 34280, lr = 8.44326e-09
I0315 08:57:37.514669 29479 solver.cpp:613] Iteration 34280, avg_grad_norm = 622486
I0315 08:58:14.487260 29479 solver.cpp:214] Iteration 34300, loss = 6337.51
I0315 08:58:14.487381 29479 solver.cpp:229]     Train net output #0: loss = 5066.87 (* 1 = 5066.87 loss)
I0315 08:58:14.591116 29479 solver.cpp:610] Iteration 34300, lr = 8.44235e-09
I0315 08:58:14.591130 29479 solver.cpp:613] Iteration 34300, avg_grad_norm = 540695
I0315 08:58:38.751829 29479 solver.cpp:214] Iteration 34320, loss = 6191.04
I0315 08:58:38.751873 29479 solver.cpp:229]     Train net output #0: loss = 5575.77 (* 1 = 5575.77 loss)
I0315 08:58:38.866431 29479 solver.cpp:610] Iteration 34320, lr = 8.44143e-09
I0315 08:58:38.866444 29479 solver.cpp:613] Iteration 34320, avg_grad_norm = 553228
I0315 08:59:04.491236 29479 solver.cpp:214] Iteration 34340, loss = 6303.85
I0315 08:59:04.491394 29479 solver.cpp:229]     Train net output #0: loss = 8422 (* 1 = 8422 loss)
I0315 08:59:04.605729 29479 solver.cpp:610] Iteration 34340, lr = 8.44051e-09
I0315 08:59:04.605742 29479 solver.cpp:613] Iteration 34340, avg_grad_norm = 606768
I0315 08:59:30.202528 29479 solver.cpp:214] Iteration 34360, loss = 6440.21
I0315 08:59:30.202579 29479 solver.cpp:229]     Train net output #0: loss = 4457.39 (* 1 = 4457.39 loss)
I0315 08:59:30.317050 29479 solver.cpp:610] Iteration 34360, lr = 8.4396e-09
I0315 08:59:30.317065 29479 solver.cpp:613] Iteration 34360, avg_grad_norm = 609033
I0315 08:59:55.903933 29479 solver.cpp:214] Iteration 34380, loss = 6170.79
I0315 08:59:55.904078 29479 solver.cpp:229]     Train net output #0: loss = 5576.35 (* 1 = 5576.35 loss)
I0315 08:59:56.018329 29479 solver.cpp:610] Iteration 34380, lr = 8.43868e-09
I0315 08:59:56.018342 29479 solver.cpp:613] Iteration 34380, avg_grad_norm = 610711
I0315 09:00:21.554581 29479 solver.cpp:214] Iteration 34400, loss = 6579.75
I0315 09:00:21.554663 29479 solver.cpp:229]     Train net output #0: loss = 11007.4 (* 1 = 11007.4 loss)
I0315 09:00:21.669198 29479 solver.cpp:610] Iteration 34400, lr = 8.43776e-09
I0315 09:00:21.669210 29479 solver.cpp:613] Iteration 34400, avg_grad_norm = 607942
I0315 09:01:01.882021 29479 solver.cpp:214] Iteration 34420, loss = 6282.91
I0315 09:01:01.882158 29479 solver.cpp:229]     Train net output #0: loss = 9010.71 (* 1 = 9010.71 loss)
I0315 09:01:01.986670 29479 solver.cpp:610] Iteration 34420, lr = 8.43685e-09
I0315 09:01:01.986683 29479 solver.cpp:613] Iteration 34420, avg_grad_norm = 565760
I0315 09:01:25.497880 29479 solver.cpp:214] Iteration 34440, loss = 6245.35
I0315 09:01:25.497946 29479 solver.cpp:229]     Train net output #0: loss = 5689.69 (* 1 = 5689.69 loss)
I0315 09:01:25.603250 29479 solver.cpp:610] Iteration 34440, lr = 8.43593e-09
I0315 09:01:25.603265 29479 solver.cpp:613] Iteration 34440, avg_grad_norm = 547280
I0315 09:01:50.681035 29479 solver.cpp:214] Iteration 34460, loss = 6407.99
I0315 09:01:50.681212 29479 solver.cpp:229]     Train net output #0: loss = 9334.07 (* 1 = 9334.07 loss)
I0315 09:01:50.795740 29479 solver.cpp:610] Iteration 34460, lr = 8.43501e-09
I0315 09:01:50.795754 29479 solver.cpp:613] Iteration 34460, avg_grad_norm = 542241
I0315 09:02:16.445583 29479 solver.cpp:214] Iteration 34480, loss = 6534.42
I0315 09:02:16.445650 29479 solver.cpp:229]     Train net output #0: loss = 4246.93 (* 1 = 4246.93 loss)
I0315 09:02:16.560255 29479 solver.cpp:610] Iteration 34480, lr = 8.43409e-09
I0315 09:02:16.560267 29479 solver.cpp:613] Iteration 34480, avg_grad_norm = 583804
I0315 09:02:42.002882 29479 solver.cpp:214] Iteration 34500, loss = 6253.58
I0315 09:02:42.003012 29479 solver.cpp:229]     Train net output #0: loss = 6030.2 (* 1 = 6030.2 loss)
I0315 09:02:42.115741 29479 solver.cpp:610] Iteration 34500, lr = 8.43318e-09
I0315 09:02:42.115754 29479 solver.cpp:613] Iteration 34500, avg_grad_norm = 568216
I0315 09:03:07.385705 29479 solver.cpp:214] Iteration 34520, loss = 6334.11
I0315 09:03:07.385772 29479 solver.cpp:229]     Train net output #0: loss = 5222.32 (* 1 = 5222.32 loss)
I0315 09:03:07.498973 29479 solver.cpp:610] Iteration 34520, lr = 8.43226e-09
I0315 09:03:07.498986 29479 solver.cpp:613] Iteration 34520, avg_grad_norm = 544073
I0315 09:03:33.108208 29479 solver.cpp:214] Iteration 34540, loss = 6459.04
I0315 09:03:33.108338 29479 solver.cpp:229]     Train net output #0: loss = 3094.09 (* 1 = 3094.09 loss)
I0315 09:03:33.222749 29479 solver.cpp:610] Iteration 34540, lr = 8.43134e-09
I0315 09:03:33.222762 29479 solver.cpp:613] Iteration 34540, avg_grad_norm = 570394
I0315 09:04:42.005077 29479 solver.cpp:214] Iteration 34560, loss = 6170.36
I0315 09:04:42.005195 29479 solver.cpp:229]     Train net output #0: loss = 3133.2 (* 1 = 3133.2 loss)
I0315 09:04:42.109132 29479 solver.cpp:610] Iteration 34560, lr = 8.43043e-09
I0315 09:04:42.109144 29479 solver.cpp:613] Iteration 34560, avg_grad_norm = 575605
I0315 09:05:05.563176 29479 solver.cpp:214] Iteration 34580, loss = 6462.42
I0315 09:05:05.563238 29479 solver.cpp:229]     Train net output #0: loss = 7486.61 (* 1 = 7486.61 loss)
I0315 09:05:05.666988 29479 solver.cpp:610] Iteration 34580, lr = 8.42951e-09
I0315 09:05:05.667001 29479 solver.cpp:613] Iteration 34580, avg_grad_norm = 644846
I0315 09:05:29.184448 29479 solver.cpp:214] Iteration 34600, loss = 6198.85
I0315 09:05:29.184640 29479 solver.cpp:229]     Train net output #0: loss = 3769.7 (* 1 = 3769.7 loss)
I0315 09:05:29.289930 29479 solver.cpp:610] Iteration 34600, lr = 8.42859e-09
I0315 09:05:29.289943 29479 solver.cpp:613] Iteration 34600, avg_grad_norm = 506713
I0315 09:05:53.742310 29479 solver.cpp:214] Iteration 34620, loss = 6256.67
I0315 09:05:53.742360 29479 solver.cpp:229]     Train net output #0: loss = 5737.34 (* 1 = 5737.34 loss)
I0315 09:05:53.855180 29479 solver.cpp:610] Iteration 34620, lr = 8.42767e-09
I0315 09:05:53.855193 29479 solver.cpp:613] Iteration 34620, avg_grad_norm = 541213
I0315 09:06:19.152307 29479 solver.cpp:214] Iteration 34640, loss = 6337.13
I0315 09:06:19.152442 29479 solver.cpp:229]     Train net output #0: loss = 4616.54 (* 1 = 4616.54 loss)
I0315 09:06:19.265329 29479 solver.cpp:610] Iteration 34640, lr = 8.42676e-09
I0315 09:06:19.265342 29479 solver.cpp:613] Iteration 34640, avg_grad_norm = 576318
I0315 09:06:44.803544 29479 solver.cpp:214] Iteration 34660, loss = 6267.73
I0315 09:06:44.803611 29479 solver.cpp:229]     Train net output #0: loss = 4310.83 (* 1 = 4310.83 loss)
I0315 09:06:44.918102 29479 solver.cpp:610] Iteration 34660, lr = 8.42584e-09
I0315 09:06:44.918114 29479 solver.cpp:613] Iteration 34660, avg_grad_norm = 560571
I0315 09:07:22.108516 29479 solver.cpp:214] Iteration 34680, loss = 6173.54
I0315 09:07:22.108659 29479 solver.cpp:229]     Train net output #0: loss = 4077.27 (* 1 = 4077.27 loss)
I0315 09:07:22.213798 29479 solver.cpp:610] Iteration 34680, lr = 8.42492e-09
I0315 09:07:22.213810 29479 solver.cpp:613] Iteration 34680, avg_grad_norm = 510650
I0315 09:07:46.144670 29479 solver.cpp:214] Iteration 34700, loss = 6332.54
I0315 09:07:46.144716 29479 solver.cpp:229]     Train net output #0: loss = 5087.3 (* 1 = 5087.3 loss)
I0315 09:07:46.259565 29479 solver.cpp:610] Iteration 34700, lr = 8.424e-09
I0315 09:07:46.259578 29479 solver.cpp:613] Iteration 34700, avg_grad_norm = 579117
I0315 09:08:11.857383 29479 solver.cpp:214] Iteration 34720, loss = 6642.42
I0315 09:08:11.857560 29479 solver.cpp:229]     Train net output #0: loss = 9802.76 (* 1 = 9802.76 loss)
I0315 09:08:11.972076 29479 solver.cpp:610] Iteration 34720, lr = 8.42309e-09
I0315 09:08:11.972090 29479 solver.cpp:613] Iteration 34720, avg_grad_norm = 595566
I0315 09:08:37.358011 29479 solver.cpp:214] Iteration 34740, loss = 6122.77
I0315 09:08:37.358069 29479 solver.cpp:229]     Train net output #0: loss = 5819.97 (* 1 = 5819.97 loss)
I0315 09:08:37.471081 29479 solver.cpp:610] Iteration 34740, lr = 8.42217e-09
I0315 09:08:37.471093 29479 solver.cpp:613] Iteration 34740, avg_grad_norm = 536141
I0315 09:09:02.752708 29479 solver.cpp:214] Iteration 34760, loss = 6682.96
I0315 09:09:02.752923 29479 solver.cpp:229]     Train net output #0: loss = 4787.86 (* 1 = 4787.86 loss)
I0315 09:09:02.865806 29479 solver.cpp:610] Iteration 34760, lr = 8.42125e-09
I0315 09:09:02.865855 29479 solver.cpp:613] Iteration 34760, avg_grad_norm = 549526
I0315 09:09:28.365490 29479 solver.cpp:214] Iteration 34780, loss = 6134.72
I0315 09:09:28.365563 29479 solver.cpp:229]     Train net output #0: loss = 5505.82 (* 1 = 5505.82 loss)
I0315 09:09:28.480048 29479 solver.cpp:610] Iteration 34780, lr = 8.42033e-09
I0315 09:09:28.480063 29479 solver.cpp:613] Iteration 34780, avg_grad_norm = 560469
I0315 09:10:06.490905 29479 solver.cpp:214] Iteration 34800, loss = 6503.21
I0315 09:10:06.491029 29479 solver.cpp:229]     Train net output #0: loss = 5758.03 (* 1 = 5758.03 loss)
I0315 09:10:06.596117 29479 solver.cpp:610] Iteration 34800, lr = 8.41942e-09
I0315 09:10:06.596132 29479 solver.cpp:613] Iteration 34800, avg_grad_norm = 561012
I0315 09:10:30.112135 29479 solver.cpp:214] Iteration 34820, loss = 6134.04
I0315 09:10:30.112207 29479 solver.cpp:229]     Train net output #0: loss = 5270.25 (* 1 = 5270.25 loss)
I0315 09:10:30.217362 29479 solver.cpp:610] Iteration 34820, lr = 8.4185e-09
I0315 09:10:30.217376 29479 solver.cpp:613] Iteration 34820, avg_grad_norm = 521593
I0315 09:10:55.567744 29479 solver.cpp:214] Iteration 34840, loss = 6842.74
I0315 09:10:55.567862 29479 solver.cpp:229]     Train net output #0: loss = 8246.98 (* 1 = 8246.98 loss)
I0315 09:10:55.682358 29479 solver.cpp:610] Iteration 34840, lr = 8.41758e-09
I0315 09:10:55.682371 29479 solver.cpp:613] Iteration 34840, avg_grad_norm = 560333
I0315 09:11:21.263366 29479 solver.cpp:214] Iteration 34860, loss = 6338.55
I0315 09:11:21.263450 29479 solver.cpp:229]     Train net output #0: loss = 4794.42 (* 1 = 4794.42 loss)
I0315 09:11:21.378173 29479 solver.cpp:610] Iteration 34860, lr = 8.41666e-09
I0315 09:11:21.378226 29479 solver.cpp:613] Iteration 34860, avg_grad_norm = 599646
I0315 09:11:46.923405 29479 solver.cpp:214] Iteration 34880, loss = 6682.68
I0315 09:11:46.923547 29479 solver.cpp:229]     Train net output #0: loss = 7371.73 (* 1 = 7371.73 loss)
I0315 09:11:47.038035 29479 solver.cpp:610] Iteration 34880, lr = 8.41575e-09
I0315 09:11:47.038048 29479 solver.cpp:613] Iteration 34880, avg_grad_norm = 606502
I0315 09:12:12.535161 29479 solver.cpp:214] Iteration 34900, loss = 6682.08
I0315 09:12:12.535230 29479 solver.cpp:229]     Train net output #0: loss = 9093.13 (* 1 = 9093.13 loss)
I0315 09:12:12.648131 29479 solver.cpp:610] Iteration 34900, lr = 8.41483e-09
I0315 09:12:12.648144 29479 solver.cpp:613] Iteration 34900, avg_grad_norm = 597359
I0315 09:12:37.847167 29479 solver.cpp:214] Iteration 34920, loss = 6258.08
I0315 09:12:37.847332 29479 solver.cpp:229]     Train net output #0: loss = 4269.55 (* 1 = 4269.55 loss)
I0315 09:12:37.961735 29479 solver.cpp:610] Iteration 34920, lr = 8.41391e-09
I0315 09:12:37.961748 29479 solver.cpp:613] Iteration 34920, avg_grad_norm = 540897
I0315 09:13:14.372622 29479 solver.cpp:214] Iteration 34940, loss = 6454.03
I0315 09:13:14.372838 29479 solver.cpp:229]     Train net output #0: loss = 10593.3 (* 1 = 10593.3 loss)
I0315 09:13:14.477695 29479 solver.cpp:610] Iteration 34940, lr = 8.413e-09
I0315 09:13:14.477710 29479 solver.cpp:613] Iteration 34940, avg_grad_norm = 593884
I0315 09:13:39.137223 29479 solver.cpp:214] Iteration 34960, loss = 6158.74
I0315 09:13:39.137289 29479 solver.cpp:229]     Train net output #0: loss = 3722.71 (* 1 = 3722.71 loss)
I0315 09:13:39.251832 29479 solver.cpp:610] Iteration 34960, lr = 8.41208e-09
I0315 09:13:39.251868 29479 solver.cpp:613] Iteration 34960, avg_grad_norm = 568338
I0315 09:14:04.862004 29479 solver.cpp:214] Iteration 34980, loss = 6057.7
I0315 09:14:04.862131 29479 solver.cpp:229]     Train net output #0: loss = 5253.17 (* 1 = 5253.17 loss)
I0315 09:14:04.976471 29479 solver.cpp:610] Iteration 34980, lr = 8.41116e-09
I0315 09:14:04.976513 29479 solver.cpp:613] Iteration 34980, avg_grad_norm = 563060
I0315 09:14:30.570116 29479 solver.cpp:214] Iteration 35000, loss = 6208.97
I0315 09:14:30.570209 29479 solver.cpp:229]     Train net output #0: loss = 6157.6 (* 1 = 6157.6 loss)
I0315 09:14:30.684734 29479 solver.cpp:610] Iteration 35000, lr = 8.41024e-09
I0315 09:14:30.684749 29479 solver.cpp:613] Iteration 35000, avg_grad_norm = 513505
I0315 09:14:56.228932 29479 solver.cpp:214] Iteration 35020, loss = 6186.48
I0315 09:14:56.229084 29479 solver.cpp:229]     Train net output #0: loss = 5181.47 (* 1 = 5181.47 loss)
I0315 09:14:56.343557 29479 solver.cpp:610] Iteration 35020, lr = 8.40933e-09
I0315 09:14:56.343570 29479 solver.cpp:613] Iteration 35020, avg_grad_norm = 556146
I0315 09:15:21.890038 29479 solver.cpp:214] Iteration 35040, loss = 6097.17
I0315 09:15:21.890126 29479 solver.cpp:229]     Train net output #0: loss = 5236.79 (* 1 = 5236.79 loss)
I0315 09:15:22.004847 29479 solver.cpp:610] Iteration 35040, lr = 8.40841e-09
I0315 09:15:22.004860 29479 solver.cpp:613] Iteration 35040, avg_grad_norm = 519533
I0315 09:16:11.389840 29479 solver.cpp:214] Iteration 35060, loss = 6413.68
I0315 09:16:11.389981 29479 solver.cpp:229]     Train net output #0: loss = 6487.28 (* 1 = 6487.28 loss)
I0315 09:16:11.495031 29479 solver.cpp:610] Iteration 35060, lr = 8.40749e-09
I0315 09:16:11.495079 29479 solver.cpp:613] Iteration 35060, avg_grad_norm = 479156
I0315 09:16:34.988898 29479 solver.cpp:214] Iteration 35080, loss = 6116.58
I0315 09:16:34.988987 29479 solver.cpp:229]     Train net output #0: loss = 5966.73 (* 1 = 5966.73 loss)
I0315 09:16:35.093302 29479 solver.cpp:610] Iteration 35080, lr = 8.40657e-09
I0315 09:16:35.093315 29479 solver.cpp:613] Iteration 35080, avg_grad_norm = 528548
I0315 09:16:59.376175 29479 solver.cpp:214] Iteration 35100, loss = 6405.19
I0315 09:16:59.376318 29479 solver.cpp:229]     Train net output #0: loss = 5355.54 (* 1 = 5355.54 loss)
I0315 09:16:59.489073 29479 solver.cpp:610] Iteration 35100, lr = 8.40566e-09
I0315 09:16:59.489086 29479 solver.cpp:613] Iteration 35100, avg_grad_norm = 577796
I0315 09:17:24.833294 29479 solver.cpp:214] Iteration 35120, loss = 6234.15
I0315 09:17:24.833369 29479 solver.cpp:229]     Train net output #0: loss = 9388.26 (* 1 = 9388.26 loss)
I0315 09:17:24.947690 29479 solver.cpp:610] Iteration 35120, lr = 8.40474e-09
I0315 09:17:24.947702 29479 solver.cpp:613] Iteration 35120, avg_grad_norm = 555404
I0315 09:17:50.483450 29479 solver.cpp:214] Iteration 35140, loss = 6466.92
I0315 09:17:50.483600 29479 solver.cpp:229]     Train net output #0: loss = 5441.52 (* 1 = 5441.52 loss)
I0315 09:17:50.598086 29479 solver.cpp:610] Iteration 35140, lr = 8.40382e-09
I0315 09:17:50.598099 29479 solver.cpp:613] Iteration 35140, avg_grad_norm = 604560
I0315 09:18:16.071257 29479 solver.cpp:214] Iteration 35160, loss = 6568.05
I0315 09:18:16.071322 29479 solver.cpp:229]     Train net output #0: loss = 5032.73 (* 1 = 5032.73 loss)
I0315 09:18:16.184378 29479 solver.cpp:610] Iteration 35160, lr = 8.4029e-09
I0315 09:18:16.184391 29479 solver.cpp:613] Iteration 35160, avg_grad_norm = 602585
I0315 09:19:13.042472 29479 solver.cpp:214] Iteration 35180, loss = 6549.39
I0315 09:19:13.042657 29479 solver.cpp:229]     Train net output #0: loss = 4557.99 (* 1 = 4557.99 loss)
I0315 09:19:13.147698 29479 solver.cpp:610] Iteration 35180, lr = 8.40199e-09
I0315 09:19:13.147737 29479 solver.cpp:613] Iteration 35180, avg_grad_norm = 566338
I0315 09:19:36.634785 29479 solver.cpp:214] Iteration 35200, loss = 6095.98
I0315 09:19:36.634836 29479 solver.cpp:229]     Train net output #0: loss = 6347.51 (* 1 = 6347.51 loss)
I0315 09:19:36.739972 29479 solver.cpp:610] Iteration 35200, lr = 8.40107e-09
I0315 09:19:36.739985 29479 solver.cpp:613] Iteration 35200, avg_grad_norm = 608175
I0315 09:20:00.240814 29479 solver.cpp:214] Iteration 35220, loss = 6273.05
I0315 09:20:00.240996 29479 solver.cpp:229]     Train net output #0: loss = 7497.53 (* 1 = 7497.53 loss)
I0315 09:20:00.345254 29479 solver.cpp:610] Iteration 35220, lr = 8.40015e-09
I0315 09:20:00.345268 29479 solver.cpp:613] Iteration 35220, avg_grad_norm = 601036
I0315 09:20:24.845711 29479 solver.cpp:214] Iteration 35240, loss = 6278.78
I0315 09:20:24.845780 29479 solver.cpp:229]     Train net output #0: loss = 5167.06 (* 1 = 5167.06 loss)
I0315 09:20:24.958753 29479 solver.cpp:610] Iteration 35240, lr = 8.39923e-09
I0315 09:20:24.958767 29479 solver.cpp:613] Iteration 35240, avg_grad_norm = 634043
I0315 09:20:50.504819 29479 solver.cpp:214] Iteration 35260, loss = 6470.38
I0315 09:20:50.504966 29479 solver.cpp:229]     Train net output #0: loss = 5535.25 (* 1 = 5535.25 loss)
I0315 09:20:50.619397 29479 solver.cpp:610] Iteration 35260, lr = 8.39831e-09
I0315 09:20:50.619410 29479 solver.cpp:613] Iteration 35260, avg_grad_norm = 575756
I0315 09:21:16.189334 29479 solver.cpp:214] Iteration 35280, loss = 6446.5
I0315 09:21:16.189402 29479 solver.cpp:229]     Train net output #0: loss = 9450.34 (* 1 = 9450.34 loss)
I0315 09:21:16.302276 29479 solver.cpp:610] Iteration 35280, lr = 8.3974e-09
I0315 09:21:16.302291 29479 solver.cpp:613] Iteration 35280, avg_grad_norm = 624791
I0315 09:21:41.495427 29479 solver.cpp:214] Iteration 35300, loss = 6484.08
I0315 09:21:41.495532 29479 solver.cpp:229]     Train net output #0: loss = 8076.97 (* 1 = 8076.97 loss)
I0315 09:21:41.608335 29479 solver.cpp:610] Iteration 35300, lr = 8.39648e-09
I0315 09:21:41.608348 29479 solver.cpp:613] Iteration 35300, avg_grad_norm = 606774
I0315 09:22:18.114658 29479 solver.cpp:214] Iteration 35320, loss = 6353.36
I0315 09:22:18.114874 29479 solver.cpp:229]     Train net output #0: loss = 5437.98 (* 1 = 5437.98 loss)
I0315 09:22:18.219898 29479 solver.cpp:610] Iteration 35320, lr = 8.39556e-09
I0315 09:22:18.219912 29479 solver.cpp:613] Iteration 35320, avg_grad_norm = 574392
I0315 09:22:42.763396 29479 solver.cpp:214] Iteration 35340, loss = 6687.43
I0315 09:22:42.763460 29479 solver.cpp:229]     Train net output #0: loss = 4764.48 (* 1 = 4764.48 loss)
I0315 09:22:42.877830 29479 solver.cpp:610] Iteration 35340, lr = 8.39464e-09
I0315 09:22:42.877843 29479 solver.cpp:613] Iteration 35340, avg_grad_norm = 612942
I0315 09:23:08.418412 29479 solver.cpp:214] Iteration 35360, loss = 6470.13
I0315 09:23:08.418534 29479 solver.cpp:229]     Train net output #0: loss = 6068.7 (* 1 = 6068.7 loss)
I0315 09:23:08.533015 29479 solver.cpp:610] Iteration 35360, lr = 8.39373e-09
I0315 09:23:08.533041 29479 solver.cpp:613] Iteration 35360, avg_grad_norm = 619364
I0315 09:23:34.072499 29479 solver.cpp:214] Iteration 35380, loss = 6656.21
I0315 09:23:34.072562 29479 solver.cpp:229]     Train net output #0: loss = 4538.93 (* 1 = 4538.93 loss)
I0315 09:23:34.187001 29479 solver.cpp:610] Iteration 35380, lr = 8.39281e-09
I0315 09:23:34.187014 29479 solver.cpp:613] Iteration 35380, avg_grad_norm = 575431
I0315 09:23:59.725863 29479 solver.cpp:214] Iteration 35400, loss = 6109.23
I0315 09:23:59.725996 29479 solver.cpp:229]     Train net output #0: loss = 8822.93 (* 1 = 8822.93 loss)
I0315 09:23:59.840418 29479 solver.cpp:610] Iteration 35400, lr = 8.39189e-09
I0315 09:23:59.840431 29479 solver.cpp:613] Iteration 35400, avg_grad_norm = 650986
I0315 09:24:25.447299 29479 solver.cpp:214] Iteration 35420, loss = 6386.84
I0315 09:24:25.447350 29479 solver.cpp:229]     Train net output #0: loss = 5820.36 (* 1 = 5820.36 loss)
I0315 09:24:25.560209 29479 solver.cpp:610] Iteration 35420, lr = 8.39097e-09
I0315 09:24:25.560221 29479 solver.cpp:613] Iteration 35420, avg_grad_norm = 614916
I0315 09:25:02.829955 29479 solver.cpp:214] Iteration 35440, loss = 6088.78
I0315 09:25:02.830138 29479 solver.cpp:229]     Train net output #0: loss = 7144.28 (* 1 = 7144.28 loss)
I0315 09:25:02.935299 29479 solver.cpp:610] Iteration 35440, lr = 8.39006e-09
I0315 09:25:02.935312 29479 solver.cpp:613] Iteration 35440, avg_grad_norm = 611318
I0315 09:25:26.605887 29479 solver.cpp:214] Iteration 35460, loss = 6228.66
I0315 09:25:26.605937 29479 solver.cpp:229]     Train net output #0: loss = 6862.33 (* 1 = 6862.33 loss)
I0315 09:25:26.717623 29479 solver.cpp:610] Iteration 35460, lr = 8.38914e-09
I0315 09:25:26.717636 29479 solver.cpp:613] Iteration 35460, avg_grad_norm = 614977
I0315 09:25:52.494443 29479 solver.cpp:214] Iteration 35480, loss = 6451.14
I0315 09:25:52.494575 29479 solver.cpp:229]     Train net output #0: loss = 4876.73 (* 1 = 4876.73 loss)
I0315 09:25:52.609146 29479 solver.cpp:610] Iteration 35480, lr = 8.38822e-09
I0315 09:25:52.609161 29479 solver.cpp:613] Iteration 35480, avg_grad_norm = 577932
I0315 09:26:17.851730 29479 solver.cpp:214] Iteration 35500, loss = 5994.67
I0315 09:26:17.851795 29479 solver.cpp:229]     Train net output #0: loss = 3832.26 (* 1 = 3832.26 loss)
I0315 09:26:17.964779 29479 solver.cpp:610] Iteration 35500, lr = 8.3873e-09
I0315 09:26:17.964793 29479 solver.cpp:613] Iteration 35500, avg_grad_norm = 527062
I0315 09:26:43.277884 29479 solver.cpp:214] Iteration 35520, loss = 6442.6
I0315 09:26:43.278048 29479 solver.cpp:229]     Train net output #0: loss = 11412.3 (* 1 = 11412.3 loss)
I0315 09:26:43.392518 29479 solver.cpp:610] Iteration 35520, lr = 8.38638e-09
I0315 09:26:43.392531 29479 solver.cpp:613] Iteration 35520, avg_grad_norm = 684241
I0315 09:27:08.980203 29479 solver.cpp:214] Iteration 35540, loss = 6583.52
I0315 09:27:08.980258 29479 solver.cpp:229]     Train net output #0: loss = 6798.05 (* 1 = 6798.05 loss)
I0315 09:27:09.094678 29479 solver.cpp:610] Iteration 35540, lr = 8.38547e-09
I0315 09:27:09.094692 29479 solver.cpp:613] Iteration 35540, avg_grad_norm = 671052
I0315 09:27:47.329901 29479 solver.cpp:214] Iteration 35560, loss = 6544.98
I0315 09:27:47.330078 29479 solver.cpp:229]     Train net output #0: loss = 9999.79 (* 1 = 9999.79 loss)
I0315 09:27:47.434934 29479 solver.cpp:610] Iteration 35560, lr = 8.38455e-09
I0315 09:27:47.434947 29479 solver.cpp:613] Iteration 35560, avg_grad_norm = 572693
I0315 09:28:10.930130 29479 solver.cpp:214] Iteration 35580, loss = 6158.31
I0315 09:28:10.930198 29479 solver.cpp:229]     Train net output #0: loss = 6043.17 (* 1 = 6043.17 loss)
I0315 09:28:11.035432 29479 solver.cpp:610] Iteration 35580, lr = 8.38363e-09
I0315 09:28:11.035445 29479 solver.cpp:613] Iteration 35580, avg_grad_norm = 631773
I0315 09:28:36.209789 29479 solver.cpp:214] Iteration 35600, loss = 6390.67
I0315 09:28:36.209899 29479 solver.cpp:229]     Train net output #0: loss = 6729.12 (* 1 = 6729.12 loss)
I0315 09:28:36.324318 29479 solver.cpp:610] Iteration 35600, lr = 8.38271e-09
I0315 09:28:36.324332 29479 solver.cpp:613] Iteration 35600, avg_grad_norm = 524891
I0315 09:29:01.930135 29479 solver.cpp:214] Iteration 35620, loss = 6013.39
I0315 09:29:01.930205 29479 solver.cpp:229]     Train net output #0: loss = 6429.17 (* 1 = 6429.17 loss)
I0315 09:29:02.044608 29479 solver.cpp:610] Iteration 35620, lr = 8.3818e-09
I0315 09:29:02.044661 29479 solver.cpp:613] Iteration 35620, avg_grad_norm = 513842
I0315 09:29:27.633496 29479 solver.cpp:214] Iteration 35640, loss = 6100.92
I0315 09:29:27.633599 29479 solver.cpp:229]     Train net output #0: loss = 5787.51 (* 1 = 5787.51 loss)
I0315 09:29:27.747992 29479 solver.cpp:610] Iteration 35640, lr = 8.38088e-09
I0315 09:29:27.748005 29479 solver.cpp:613] Iteration 35640, avg_grad_norm = 604590
I0315 09:29:53.028249 29479 solver.cpp:214] Iteration 35660, loss = 6001.35
I0315 09:29:53.028307 29479 solver.cpp:229]     Train net output #0: loss = 10097.6 (* 1 = 10097.6 loss)
I0315 09:29:53.141201 29479 solver.cpp:610] Iteration 35660, lr = 8.37996e-09
I0315 09:29:53.141213 29479 solver.cpp:613] Iteration 35660, avg_grad_norm = 657624
I0315 09:30:18.608649 29479 solver.cpp:214] Iteration 35680, loss = 6397.22
I0315 09:30:18.608853 29479 solver.cpp:229]     Train net output #0: loss = 4462.17 (* 1 = 4462.17 loss)
I0315 09:30:18.724853 29479 solver.cpp:610] Iteration 35680, lr = 8.37904e-09
I0315 09:30:18.724869 29479 solver.cpp:613] Iteration 35680, avg_grad_norm = 586852
I0315 09:31:03.197937 29479 solver.cpp:214] Iteration 35700, loss = 6194.22
I0315 09:31:03.198084 29479 solver.cpp:229]     Train net output #0: loss = 8948.07 (* 1 = 8948.07 loss)
I0315 09:31:03.302588 29479 solver.cpp:610] Iteration 35700, lr = 8.37812e-09
I0315 09:31:03.302602 29479 solver.cpp:613] Iteration 35700, avg_grad_norm = 657397
I0315 09:31:26.762747 29479 solver.cpp:214] Iteration 35720, loss = 6220.6
I0315 09:31:26.762804 29479 solver.cpp:229]     Train net output #0: loss = 6979.9 (* 1 = 6979.9 loss)
I0315 09:31:26.875504 29479 solver.cpp:610] Iteration 35720, lr = 8.37721e-09
I0315 09:31:26.875519 29479 solver.cpp:613] Iteration 35720, avg_grad_norm = 715829
I0315 09:31:52.250398 29479 solver.cpp:214] Iteration 35740, loss = 6238.89
I0315 09:31:52.250602 29479 solver.cpp:229]     Train net output #0: loss = 5795.45 (* 1 = 5795.45 loss)
I0315 09:31:52.365078 29479 solver.cpp:610] Iteration 35740, lr = 8.37629e-09
I0315 09:31:52.365092 29479 solver.cpp:613] Iteration 35740, avg_grad_norm = 621995
I0315 09:32:17.908031 29479 solver.cpp:214] Iteration 35760, loss = 6393.68
I0315 09:32:17.908100 29479 solver.cpp:229]     Train net output #0: loss = 8079.92 (* 1 = 8079.92 loss)
I0315 09:32:18.022753 29479 solver.cpp:610] Iteration 35760, lr = 8.37537e-09
I0315 09:32:18.022769 29479 solver.cpp:613] Iteration 35760, avg_grad_norm = 519082
I0315 09:32:43.459229 29479 solver.cpp:214] Iteration 35780, loss = 5924.53
I0315 09:32:43.459381 29479 solver.cpp:229]     Train net output #0: loss = 6863.74 (* 1 = 6863.74 loss)
I0315 09:32:43.572175 29479 solver.cpp:610] Iteration 35780, lr = 8.37445e-09
I0315 09:32:43.572188 29479 solver.cpp:613] Iteration 35780, avg_grad_norm = 544058
I0315 09:33:08.765369 29479 solver.cpp:214] Iteration 35800, loss = 6303.56
I0315 09:33:08.765427 29479 solver.cpp:229]     Train net output #0: loss = 10785 (* 1 = 10785 loss)
I0315 09:33:08.878345 29479 solver.cpp:610] Iteration 35800, lr = 8.37353e-09
I0315 09:33:08.878358 29479 solver.cpp:613] Iteration 35800, avg_grad_norm = 499208
I0315 09:33:52.751787 29479 solver.cpp:214] Iteration 35820, loss = 6282.8
I0315 09:33:52.751919 29479 solver.cpp:229]     Train net output #0: loss = 3721.16 (* 1 = 3721.16 loss)
I0315 09:33:52.855522 29479 solver.cpp:610] Iteration 35820, lr = 8.37262e-09
I0315 09:33:52.855535 29479 solver.cpp:613] Iteration 35820, avg_grad_norm = 546062
I0315 09:34:16.301000 29479 solver.cpp:214] Iteration 35840, loss = 6464.55
I0315 09:34:16.301081 29479 solver.cpp:229]     Train net output #0: loss = 7405.5 (* 1 = 7405.5 loss)
I0315 09:34:16.406394 29479 solver.cpp:610] Iteration 35840, lr = 8.3717e-09
I0315 09:34:16.406407 29479 solver.cpp:613] Iteration 35840, avg_grad_norm = 530636
I0315 09:34:41.365924 29479 solver.cpp:214] Iteration 35860, loss = 6182.88
I0315 09:34:41.366065 29479 solver.cpp:229]     Train net output #0: loss = 7325.03 (* 1 = 7325.03 loss)
I0315 09:34:41.480520 29479 solver.cpp:610] Iteration 35860, lr = 8.37078e-09
I0315 09:34:41.480535 29479 solver.cpp:613] Iteration 35860, avg_grad_norm = 537333
I0315 09:35:06.876540 29479 solver.cpp:214] Iteration 35880, loss = 6285.42
I0315 09:35:06.876605 29479 solver.cpp:229]     Train net output #0: loss = 4482.66 (* 1 = 4482.66 loss)
I0315 09:35:06.989503 29479 solver.cpp:610] Iteration 35880, lr = 8.36986e-09
I0315 09:35:06.989516 29479 solver.cpp:613] Iteration 35880, avg_grad_norm = 664550
I0315 09:35:32.211638 29479 solver.cpp:214] Iteration 35900, loss = 6401.48
I0315 09:35:32.211827 29479 solver.cpp:229]     Train net output #0: loss = 4121.91 (* 1 = 4121.91 loss)
I0315 09:35:32.326261 29479 solver.cpp:610] Iteration 35900, lr = 8.36895e-09
I0315 09:35:32.326274 29479 solver.cpp:613] Iteration 35900, avg_grad_norm = 639027
I0315 09:35:57.883617 29479 solver.cpp:214] Iteration 35920, loss = 6753.25
I0315 09:35:57.883682 29479 solver.cpp:229]     Train net output #0: loss = 4180.01 (* 1 = 4180.01 loss)
I0315 09:35:57.998196 29479 solver.cpp:610] Iteration 35920, lr = 8.36803e-09
I0315 09:35:57.998209 29479 solver.cpp:613] Iteration 35920, avg_grad_norm = 543454
I0315 09:36:36.534301 29479 solver.cpp:214] Iteration 35940, loss = 6394.39
I0315 09:36:36.534451 29479 solver.cpp:229]     Train net output #0: loss = 2986.35 (* 1 = 2986.35 loss)
I0315 09:36:36.639539 29479 solver.cpp:610] Iteration 35940, lr = 8.36711e-09
I0315 09:36:36.639552 29479 solver.cpp:613] Iteration 35940, avg_grad_norm = 523977
I0315 09:37:00.067703 29479 solver.cpp:214] Iteration 35960, loss = 6170.42
I0315 09:37:00.067750 29479 solver.cpp:229]     Train net output #0: loss = 4959.72 (* 1 = 4959.72 loss)
I0315 09:37:00.172940 29479 solver.cpp:610] Iteration 35960, lr = 8.36619e-09
I0315 09:37:00.172952 29479 solver.cpp:613] Iteration 35960, avg_grad_norm = 629476
I0315 09:37:24.970021 29479 solver.cpp:214] Iteration 35980, loss = 6340.04
I0315 09:37:24.970150 29479 solver.cpp:229]     Train net output #0: loss = 5760.14 (* 1 = 5760.14 loss)
I0315 09:37:25.084666 29479 solver.cpp:610] Iteration 35980, lr = 8.36527e-09
I0315 09:37:25.084678 29479 solver.cpp:613] Iteration 35980, avg_grad_norm = 697626
I0315 09:37:50.624876 29479 solver.cpp:214] Iteration 36000, loss = 6397.42
I0315 09:37:50.624920 29479 solver.cpp:229]     Train net output #0: loss = 3615.2 (* 1 = 3615.2 loss)
I0315 09:37:50.739411 29479 solver.cpp:610] Iteration 36000, lr = 8.36436e-09
I0315 09:37:50.739423 29479 solver.cpp:613] Iteration 36000, avg_grad_norm = 783500
I0315 09:38:16.273305 29479 solver.cpp:214] Iteration 36020, loss = 6110.61
I0315 09:38:16.273427 29479 solver.cpp:229]     Train net output #0: loss = 6999.85 (* 1 = 6999.85 loss)
I0315 09:38:16.387730 29479 solver.cpp:610] Iteration 36020, lr = 8.36344e-09
I0315 09:38:16.387743 29479 solver.cpp:613] Iteration 36020, avg_grad_norm = 593629
I0315 09:38:41.929725 29479 solver.cpp:214] Iteration 36040, loss = 6137.89
I0315 09:38:41.929775 29479 solver.cpp:229]     Train net output #0: loss = 6302.37 (* 1 = 6302.37 loss)
I0315 09:38:42.044270 29479 solver.cpp:610] Iteration 36040, lr = 8.36252e-09
I0315 09:38:42.044283 29479 solver.cpp:613] Iteration 36040, avg_grad_norm = 511847
I0315 09:39:07.597666 29479 solver.cpp:214] Iteration 36060, loss = 6242.76
I0315 09:39:07.597816 29479 solver.cpp:229]     Train net output #0: loss = 5641.3 (* 1 = 5641.3 loss)
I0315 09:39:07.712096 29479 solver.cpp:610] Iteration 36060, lr = 8.3616e-09
I0315 09:39:07.712152 29479 solver.cpp:613] Iteration 36060, avg_grad_norm = 563221
I0315 09:39:46.948094 29479 solver.cpp:214] Iteration 36080, loss = 6371.72
I0315 09:39:46.948230 29479 solver.cpp:229]     Train net output #0: loss = 7076.66 (* 1 = 7076.66 loss)
I0315 09:39:47.053436 29479 solver.cpp:610] Iteration 36080, lr = 8.36068e-09
I0315 09:39:47.053448 29479 solver.cpp:613] Iteration 36080, avg_grad_norm = 574675
I0315 09:40:11.071142 29479 solver.cpp:214] Iteration 36100, loss = 6275.82
I0315 09:40:11.071199 29479 solver.cpp:229]     Train net output #0: loss = 5732.93 (* 1 = 5732.93 loss)
I0315 09:40:11.184180 29479 solver.cpp:610] Iteration 36100, lr = 8.35976e-09
I0315 09:40:11.184195 29479 solver.cpp:613] Iteration 36100, avg_grad_norm = 538130
I0315 09:40:36.876552 29479 solver.cpp:214] Iteration 36120, loss = 5944.46
I0315 09:40:36.876693 29479 solver.cpp:229]     Train net output #0: loss = 5574.86 (* 1 = 5574.86 loss)
I0315 09:40:36.989531 29479 solver.cpp:610] Iteration 36120, lr = 8.35885e-09
I0315 09:40:36.989547 29479 solver.cpp:613] Iteration 36120, avg_grad_norm = 517457
I0315 09:41:01.970609 29479 solver.cpp:214] Iteration 36140, loss = 6028.03
I0315 09:41:01.970681 29479 solver.cpp:229]     Train net output #0: loss = 3972.93 (* 1 = 3972.93 loss)
I0315 09:41:02.082136 29479 solver.cpp:610] Iteration 36140, lr = 8.35793e-09
I0315 09:41:02.082149 29479 solver.cpp:613] Iteration 36140, avg_grad_norm = 609491
I0315 09:41:27.477818 29479 solver.cpp:214] Iteration 36160, loss = 6246.35
I0315 09:41:27.478000 29479 solver.cpp:229]     Train net output #0: loss = 5290.59 (* 1 = 5290.59 loss)
I0315 09:41:27.592461 29479 solver.cpp:610] Iteration 36160, lr = 8.35701e-09
I0315 09:41:27.592475 29479 solver.cpp:613] Iteration 36160, avg_grad_norm = 554722
I0315 09:41:53.199363 29479 solver.cpp:214] Iteration 36180, loss = 6396.36
I0315 09:41:53.199432 29479 solver.cpp:229]     Train net output #0: loss = 5338.48 (* 1 = 5338.48 loss)
I0315 09:41:53.314064 29479 solver.cpp:610] Iteration 36180, lr = 8.35609e-09
I0315 09:41:53.314076 29479 solver.cpp:613] Iteration 36180, avg_grad_norm = 519253
I0315 09:42:31.304996 29479 solver.cpp:214] Iteration 36200, loss = 6160.22
I0315 09:42:31.305233 29479 solver.cpp:229]     Train net output #0: loss = 2307.3 (* 1 = 2307.3 loss)
I0315 09:42:31.410020 29479 solver.cpp:610] Iteration 36200, lr = 8.35517e-09
I0315 09:42:31.410035 29479 solver.cpp:613] Iteration 36200, avg_grad_norm = 506626
I0315 09:42:55.012419 29479 solver.cpp:214] Iteration 36220, loss = 6459.33
I0315 09:42:55.012487 29479 solver.cpp:229]     Train net output #0: loss = 6149.32 (* 1 = 6149.32 loss)
I0315 09:42:55.124071 29479 solver.cpp:610] Iteration 36220, lr = 8.35426e-09
I0315 09:42:55.124084 29479 solver.cpp:613] Iteration 36220, avg_grad_norm = 538442
I0315 09:43:20.632573 29479 solver.cpp:214] Iteration 36240, loss = 6336.32
I0315 09:43:20.632761 29479 solver.cpp:229]     Train net output #0: loss = 5911.08 (* 1 = 5911.08 loss)
I0315 09:43:20.747089 29479 solver.cpp:610] Iteration 36240, lr = 8.35334e-09
I0315 09:43:20.747102 29479 solver.cpp:613] Iteration 36240, avg_grad_norm = 576392
I0315 09:43:46.339315 29479 solver.cpp:214] Iteration 36260, loss = 6014.84
I0315 09:43:46.339375 29479 solver.cpp:229]     Train net output #0: loss = 5029.81 (* 1 = 5029.81 loss)
I0315 09:43:46.453915 29479 solver.cpp:610] Iteration 36260, lr = 8.35242e-09
I0315 09:43:46.453928 29479 solver.cpp:613] Iteration 36260, avg_grad_norm = 560550
I0315 09:44:12.071542 29479 solver.cpp:214] Iteration 36280, loss = 6445.45
I0315 09:44:12.071671 29479 solver.cpp:229]     Train net output #0: loss = 14181.9 (* 1 = 14181.9 loss)
I0315 09:44:12.186177 29479 solver.cpp:610] Iteration 36280, lr = 8.3515e-09
I0315 09:44:12.186190 29479 solver.cpp:613] Iteration 36280, avg_grad_norm = 568206
I0315 09:44:37.784384 29479 solver.cpp:214] Iteration 36300, loss = 6082.44
I0315 09:44:37.784430 29479 solver.cpp:229]     Train net output #0: loss = 4676.22 (* 1 = 4676.22 loss)
I0315 09:44:37.898978 29479 solver.cpp:610] Iteration 36300, lr = 8.35058e-09
I0315 09:44:37.898991 29479 solver.cpp:613] Iteration 36300, avg_grad_norm = 562081
I0315 09:45:20.017932 29479 solver.cpp:214] Iteration 36320, loss = 6369.32
I0315 09:45:20.018052 29479 solver.cpp:229]     Train net output #0: loss = 4163.82 (* 1 = 4163.82 loss)
I0315 09:45:20.122977 29479 solver.cpp:610] Iteration 36320, lr = 8.34966e-09
I0315 09:45:20.122990 29479 solver.cpp:613] Iteration 36320, avg_grad_norm = 554080
I0315 09:45:43.534729 29479 solver.cpp:214] Iteration 36340, loss = 6053.47
I0315 09:45:43.534781 29479 solver.cpp:229]     Train net output #0: loss = 10102.7 (* 1 = 10102.7 loss)
I0315 09:45:43.640033 29479 solver.cpp:610] Iteration 36340, lr = 8.34875e-09
I0315 09:45:43.640045 29479 solver.cpp:613] Iteration 36340, avg_grad_norm = 648409
I0315 09:46:07.994571 29479 solver.cpp:214] Iteration 36360, loss = 6215.17
I0315 09:46:07.994727 29479 solver.cpp:229]     Train net output #0: loss = 5611.37 (* 1 = 5611.37 loss)
I0315 09:46:08.109273 29479 solver.cpp:610] Iteration 36360, lr = 8.34783e-09
I0315 09:46:08.109287 29479 solver.cpp:613] Iteration 36360, avg_grad_norm = 554479
I0315 09:46:33.664037 29479 solver.cpp:214] Iteration 36380, loss = 6487.96
I0315 09:46:33.664108 29479 solver.cpp:229]     Train net output #0: loss = 4549.37 (* 1 = 4549.37 loss)
I0315 09:46:33.778620 29479 solver.cpp:610] Iteration 36380, lr = 8.34691e-09
I0315 09:46:33.778635 29479 solver.cpp:613] Iteration 36380, avg_grad_norm = 533332
I0315 09:46:59.356536 29479 solver.cpp:214] Iteration 36400, loss = 6389.9
I0315 09:46:59.356751 29479 solver.cpp:229]     Train net output #0: loss = 6597 (* 1 = 6597 loss)
I0315 09:46:59.471179 29479 solver.cpp:610] Iteration 36400, lr = 8.34599e-09
I0315 09:46:59.471192 29479 solver.cpp:613] Iteration 36400, avg_grad_norm = 528308
I0315 09:47:25.011530 29479 solver.cpp:214] Iteration 36420, loss = 6334.64
I0315 09:47:25.011601 29479 solver.cpp:229]     Train net output #0: loss = 11395 (* 1 = 11395 loss)
I0315 09:47:25.126143 29479 solver.cpp:610] Iteration 36420, lr = 8.34507e-09
I0315 09:47:25.126157 29479 solver.cpp:613] Iteration 36420, avg_grad_norm = 555256
I0315 09:47:50.708042 29479 solver.cpp:214] Iteration 36440, loss = 6437.08
I0315 09:47:50.708226 29479 solver.cpp:229]     Train net output #0: loss = 3403.81 (* 1 = 3403.81 loss)
I0315 09:47:50.822800 29479 solver.cpp:610] Iteration 36440, lr = 8.34416e-09
I0315 09:47:50.822813 29479 solver.cpp:613] Iteration 36440, avg_grad_norm = 574040
I0315 09:48:33.891089 29479 solver.cpp:214] Iteration 36460, loss = 6524.53
I0315 09:48:33.891247 29479 solver.cpp:229]     Train net output #0: loss = 10156.3 (* 1 = 10156.3 loss)
I0315 09:48:33.995360 29479 solver.cpp:610] Iteration 36460, lr = 8.34324e-09
I0315 09:48:33.995373 29479 solver.cpp:613] Iteration 36460, avg_grad_norm = 646087
I0315 09:48:57.450232 29479 solver.cpp:214] Iteration 36480, loss = 6276.79
I0315 09:48:57.450309 29479 solver.cpp:229]     Train net output #0: loss = 4361.71 (* 1 = 4361.71 loss)
I0315 09:48:57.554985 29479 solver.cpp:610] Iteration 36480, lr = 8.34232e-09
I0315 09:48:57.555032 29479 solver.cpp:613] Iteration 36480, avg_grad_norm = 603996
I0315 09:49:22.897392 29479 solver.cpp:214] Iteration 36500, loss = 6285.75
I0315 09:49:22.897593 29479 solver.cpp:229]     Train net output #0: loss = 4524.27 (* 1 = 4524.27 loss)
I0315 09:49:23.012053 29479 solver.cpp:610] Iteration 36500, lr = 8.3414e-09
I0315 09:49:23.012066 29479 solver.cpp:613] Iteration 36500, avg_grad_norm = 549566
I0315 09:49:48.483281 29479 solver.cpp:214] Iteration 36520, loss = 6094.31
I0315 09:49:48.483340 29479 solver.cpp:229]     Train net output #0: loss = 5020.67 (* 1 = 5020.67 loss)
I0315 09:49:48.596308 29479 solver.cpp:610] Iteration 36520, lr = 8.34048e-09
I0315 09:49:48.596324 29479 solver.cpp:613] Iteration 36520, avg_grad_norm = 498652
I0315 09:50:13.915010 29479 solver.cpp:214] Iteration 36540, loss = 6625.36
I0315 09:50:13.915176 29479 solver.cpp:229]     Train net output #0: loss = 5402.81 (* 1 = 5402.81 loss)
I0315 09:50:14.029517 29479 solver.cpp:610] Iteration 36540, lr = 8.33956e-09
I0315 09:50:14.029537 29479 solver.cpp:613] Iteration 36540, avg_grad_norm = 505507
I0315 09:50:39.644424 29479 solver.cpp:214] Iteration 36560, loss = 6474.44
I0315 09:50:39.644496 29479 solver.cpp:229]     Train net output #0: loss = 5723.62 (* 1 = 5723.62 loss)
I0315 09:50:39.758975 29479 solver.cpp:610] Iteration 36560, lr = 8.33865e-09
I0315 09:50:39.758991 29479 solver.cpp:613] Iteration 36560, avg_grad_norm = 595826
I0315 09:51:18.070273 29479 solver.cpp:214] Iteration 36580, loss = 6460.65
I0315 09:51:18.070386 29479 solver.cpp:229]     Train net output #0: loss = 5233.57 (* 1 = 5233.57 loss)
I0315 09:51:18.175474 29479 solver.cpp:610] Iteration 36580, lr = 8.33773e-09
I0315 09:51:18.175487 29479 solver.cpp:613] Iteration 36580, avg_grad_norm = 556753
I0315 09:51:41.624761 29479 solver.cpp:214] Iteration 36600, loss = 6279.64
I0315 09:51:41.624838 29479 solver.cpp:229]     Train net output #0: loss = 5383.2 (* 1 = 5383.2 loss)
I0315 09:51:41.734854 29479 solver.cpp:610] Iteration 36600, lr = 8.33681e-09
I0315 09:51:41.734868 29479 solver.cpp:613] Iteration 36600, avg_grad_norm = 551751
I0315 09:52:07.441622 29479 solver.cpp:214] Iteration 36620, loss = 6218.62
I0315 09:52:07.441877 29479 solver.cpp:229]     Train net output #0: loss = 9884.96 (* 1 = 9884.96 loss)
I0315 09:52:07.556109 29479 solver.cpp:610] Iteration 36620, lr = 8.33589e-09
I0315 09:52:07.556123 29479 solver.cpp:613] Iteration 36620, avg_grad_norm = 530541
I0315 09:52:32.760777 29479 solver.cpp:214] Iteration 36640, loss = 6566.58
I0315 09:52:32.760841 29479 solver.cpp:229]     Train net output #0: loss = 8201.39 (* 1 = 8201.39 loss)
I0315 09:52:32.873795 29479 solver.cpp:610] Iteration 36640, lr = 8.33497e-09
I0315 09:52:32.873808 29479 solver.cpp:613] Iteration 36640, avg_grad_norm = 587594
I0315 09:52:58.219182 29479 solver.cpp:214] Iteration 36660, loss = 5936.96
I0315 09:52:58.219333 29479 solver.cpp:229]     Train net output #0: loss = 5612.69 (* 1 = 5612.69 loss)
I0315 09:52:58.333726 29479 solver.cpp:610] Iteration 36660, lr = 8.33405e-09
I0315 09:52:58.333739 29479 solver.cpp:613] Iteration 36660, avg_grad_norm = 546805
I0315 09:53:23.892874 29479 solver.cpp:214] Iteration 36680, loss = 6381.67
I0315 09:53:23.892933 29479 solver.cpp:229]     Train net output #0: loss = 6482.93 (* 1 = 6482.93 loss)
I0315 09:53:24.007354 29479 solver.cpp:610] Iteration 36680, lr = 8.33314e-09
I0315 09:53:24.007369 29479 solver.cpp:613] Iteration 36680, avg_grad_norm = 595082
I0315 09:53:49.558472 29479 solver.cpp:214] Iteration 36700, loss = 6325.09
I0315 09:53:49.558688 29479 solver.cpp:229]     Train net output #0: loss = 8681.87 (* 1 = 8681.87 loss)
I0315 09:53:49.672966 29479 solver.cpp:610] Iteration 36700, lr = 8.33222e-09
I0315 09:53:49.672979 29479 solver.cpp:613] Iteration 36700, avg_grad_norm = 512887
I0315 09:54:31.075274 29479 solver.cpp:214] Iteration 36720, loss = 5938.32
I0315 09:54:31.075399 29479 solver.cpp:229]     Train net output #0: loss = 4926.49 (* 1 = 4926.49 loss)
I0315 09:54:31.180011 29479 solver.cpp:610] Iteration 36720, lr = 8.3313e-09
I0315 09:54:31.180025 29479 solver.cpp:613] Iteration 36720, avg_grad_norm = 532164
I0315 09:54:55.369017 29479 solver.cpp:214] Iteration 36740, loss = 6091.04
I0315 09:54:55.369112 29479 solver.cpp:229]     Train net output #0: loss = 6004.83 (* 1 = 6004.83 loss)
I0315 09:54:55.483475 29479 solver.cpp:610] Iteration 36740, lr = 8.33038e-09
I0315 09:54:55.483489 29479 solver.cpp:613] Iteration 36740, avg_grad_norm = 497683
I0315 09:55:21.084903 29479 solver.cpp:214] Iteration 36760, loss = 6124.33
I0315 09:55:21.085041 29479 solver.cpp:229]     Train net output #0: loss = 6336.32 (* 1 = 6336.32 loss)
I0315 09:55:21.199470 29479 solver.cpp:610] Iteration 36760, lr = 8.32946e-09
I0315 09:55:21.199483 29479 solver.cpp:613] Iteration 36760, avg_grad_norm = 517858
I0315 09:55:46.795603 29479 solver.cpp:214] Iteration 36780, loss = 6541.13
I0315 09:55:46.795665 29479 solver.cpp:229]     Train net output #0: loss = 4038.8 (* 1 = 4038.8 loss)
I0315 09:55:46.910106 29479 solver.cpp:610] Iteration 36780, lr = 8.32854e-09
I0315 09:55:46.910120 29479 solver.cpp:613] Iteration 36780, avg_grad_norm = 554723
I0315 09:56:12.505264 29479 solver.cpp:214] Iteration 36800, loss = 6177.97
I0315 09:56:12.505472 29479 solver.cpp:229]     Train net output #0: loss = 4392.52 (* 1 = 4392.52 loss)
I0315 09:56:12.619915 29479 solver.cpp:610] Iteration 36800, lr = 8.32762e-09
I0315 09:56:12.619930 29479 solver.cpp:613] Iteration 36800, avg_grad_norm = 496108
I0315 09:56:38.187842 29479 solver.cpp:214] Iteration 36820, loss = 6511.74
I0315 09:56:38.187914 29479 solver.cpp:229]     Train net output #0: loss = 11316 (* 1 = 11316 loss)
I0315 09:56:38.302500 29479 solver.cpp:610] Iteration 36820, lr = 8.32671e-09
I0315 09:56:38.302515 29479 solver.cpp:613] Iteration 36820, avg_grad_norm = 569911
I0315 09:57:16.115708 29479 solver.cpp:214] Iteration 36840, loss = 6469.73
I0315 09:57:16.115810 29479 solver.cpp:229]     Train net output #0: loss = 11504.3 (* 1 = 11504.3 loss)
I0315 09:57:16.220963 29479 solver.cpp:610] Iteration 36840, lr = 8.32579e-09
I0315 09:57:16.220978 29479 solver.cpp:613] Iteration 36840, avg_grad_norm = 559970
I0315 09:57:40.116972 29479 solver.cpp:214] Iteration 36860, loss = 6255
I0315 09:57:40.117069 29479 solver.cpp:229]     Train net output #0: loss = 4219.84 (* 1 = 4219.84 loss)
I0315 09:57:40.229951 29479 solver.cpp:610] Iteration 36860, lr = 8.32487e-09
I0315 09:57:40.229964 29479 solver.cpp:613] Iteration 36860, avg_grad_norm = 600856
I0315 09:58:05.748546 29479 solver.cpp:214] Iteration 36880, loss = 5942.7
I0315 09:58:05.748711 29479 solver.cpp:229]     Train net output #0: loss = 4215.33 (* 1 = 4215.33 loss)
I0315 09:58:05.863162 29479 solver.cpp:610] Iteration 36880, lr = 8.32395e-09
I0315 09:58:05.863175 29479 solver.cpp:613] Iteration 36880, avg_grad_norm = 543118
I0315 09:58:31.404142 29479 solver.cpp:214] Iteration 36900, loss = 5857.61
I0315 09:58:31.404206 29479 solver.cpp:229]     Train net output #0: loss = 3670.19 (* 1 = 3670.19 loss)
I0315 09:58:31.518676 29479 solver.cpp:610] Iteration 36900, lr = 8.32303e-09
I0315 09:58:31.518689 29479 solver.cpp:613] Iteration 36900, avg_grad_norm = 589696
I0315 09:58:57.061936 29479 solver.cpp:214] Iteration 36920, loss = 6256.26
I0315 09:58:57.062089 29479 solver.cpp:229]     Train net output #0: loss = 4976.65 (* 1 = 4976.65 loss)
I0315 09:58:57.176429 29479 solver.cpp:610] Iteration 36920, lr = 8.32211e-09
I0315 09:58:57.176441 29479 solver.cpp:613] Iteration 36920, avg_grad_norm = 720300
I0315 09:59:22.729329 29479 solver.cpp:214] Iteration 36940, loss = 6302.13
I0315 09:59:22.729375 29479 solver.cpp:229]     Train net output #0: loss = 8338.04 (* 1 = 8338.04 loss)
I0315 09:59:22.843858 29479 solver.cpp:610] Iteration 36940, lr = 8.3212e-09
I0315 09:59:22.843869 29479 solver.cpp:613] Iteration 36940, avg_grad_norm = 559625
I0315 10:00:01.094651 29479 solver.cpp:214] Iteration 36960, loss = 6408.8
I0315 10:00:01.094768 29479 solver.cpp:229]     Train net output #0: loss = 4593.51 (* 1 = 4593.51 loss)
I0315 10:00:01.199947 29479 solver.cpp:610] Iteration 36960, lr = 8.32028e-09
I0315 10:00:01.199960 29479 solver.cpp:613] Iteration 36960, avg_grad_norm = 535410
I0315 10:00:24.651175 29479 solver.cpp:214] Iteration 36980, loss = 6299.19
I0315 10:00:24.651224 29479 solver.cpp:229]     Train net output #0: loss = 3587.45 (* 1 = 3587.45 loss)
I0315 10:00:24.756203 29479 solver.cpp:610] Iteration 36980, lr = 8.31936e-09
I0315 10:00:24.756216 29479 solver.cpp:613] Iteration 36980, avg_grad_norm = 513431
I0315 10:00:50.004947 29479 solver.cpp:214] Iteration 37000, loss = 6288.7
I0315 10:00:50.005167 29479 solver.cpp:229]     Train net output #0: loss = 11319.9 (* 1 = 11319.9 loss)
I0315 10:00:50.119530 29479 solver.cpp:610] Iteration 37000, lr = 8.31844e-09
I0315 10:00:50.119544 29479 solver.cpp:613] Iteration 37000, avg_grad_norm = 588680
I0315 10:01:15.721712 29479 solver.cpp:214] Iteration 37020, loss = 6770.49
I0315 10:01:15.721761 29479 solver.cpp:229]     Train net output #0: loss = 7180.93 (* 1 = 7180.93 loss)
I0315 10:01:15.836210 29479 solver.cpp:610] Iteration 37020, lr = 8.31752e-09
I0315 10:01:15.836222 29479 solver.cpp:613] Iteration 37020, avg_grad_norm = 578085
I0315 10:01:41.440628 29479 solver.cpp:214] Iteration 37040, loss = 6364.07
I0315 10:01:41.440845 29479 solver.cpp:229]     Train net output #0: loss = 3503.41 (* 1 = 3503.41 loss)
I0315 10:01:41.555261 29479 solver.cpp:610] Iteration 37040, lr = 8.3166e-09
I0315 10:01:41.555276 29479 solver.cpp:613] Iteration 37040, avg_grad_norm = 536040
I0315 10:02:07.159370 29479 solver.cpp:214] Iteration 37060, loss = 6502.84
I0315 10:02:07.159436 29479 solver.cpp:229]     Train net output #0: loss = 6117.26 (* 1 = 6117.26 loss)
I0315 10:02:07.273946 29479 solver.cpp:610] Iteration 37060, lr = 8.31568e-09
I0315 10:02:07.273960 29479 solver.cpp:613] Iteration 37060, avg_grad_norm = 652376
I0315 10:02:32.880003 29479 solver.cpp:214] Iteration 37080, loss = 6018.29
I0315 10:02:32.880198 29479 solver.cpp:229]     Train net output #0: loss = 4344.68 (* 1 = 4344.68 loss)
I0315 10:02:32.994628 29479 solver.cpp:610] Iteration 37080, lr = 8.31476e-09
I0315 10:02:32.994642 29479 solver.cpp:613] Iteration 37080, avg_grad_norm = 820713
I0315 10:03:17.578552 29479 solver.cpp:214] Iteration 37100, loss = 6245.14
I0315 10:03:17.578734 29479 solver.cpp:229]     Train net output #0: loss = 9567.17 (* 1 = 9567.17 loss)
I0315 10:03:17.683782 29479 solver.cpp:610] Iteration 37100, lr = 8.31385e-09
I0315 10:03:17.683796 29479 solver.cpp:613] Iteration 37100, avg_grad_norm = 597391
I0315 10:03:41.285504 29479 solver.cpp:214] Iteration 37120, loss = 6305.92
I0315 10:03:41.285586 29479 solver.cpp:229]     Train net output #0: loss = 6118.91 (* 1 = 6118.91 loss)
I0315 10:03:41.398578 29479 solver.cpp:610] Iteration 37120, lr = 8.31293e-09
I0315 10:03:41.398591 29479 solver.cpp:613] Iteration 37120, avg_grad_norm = 548125
I0315 10:04:06.896663 29479 solver.cpp:214] Iteration 37140, loss = 6342.36
I0315 10:04:06.896826 29479 solver.cpp:229]     Train net output #0: loss = 4594.51 (* 1 = 4594.51 loss)
I0315 10:04:07.011299 29479 solver.cpp:610] Iteration 37140, lr = 8.31201e-09
I0315 10:04:07.011314 29479 solver.cpp:613] Iteration 37140, avg_grad_norm = 522216
I0315 10:04:32.625326 29479 solver.cpp:214] Iteration 37160, loss = 5934.39
I0315 10:04:32.625396 29479 solver.cpp:229]     Train net output #0: loss = 4275.42 (* 1 = 4275.42 loss)
I0315 10:04:32.740171 29479 solver.cpp:610] Iteration 37160, lr = 8.31109e-09
I0315 10:04:32.740186 29479 solver.cpp:613] Iteration 37160, avg_grad_norm = 605123
I0315 10:04:58.105675 29479 solver.cpp:214] Iteration 37180, loss = 6200.52
I0315 10:04:58.105859 29479 solver.cpp:229]     Train net output #0: loss = 7276.87 (* 1 = 7276.87 loss)
I0315 10:04:58.218513 29479 solver.cpp:610] Iteration 37180, lr = 8.31017e-09
I0315 10:04:58.218526 29479 solver.cpp:613] Iteration 37180, avg_grad_norm = 525857
I0315 10:05:23.588354 29479 solver.cpp:214] Iteration 37200, loss = 6217.16
I0315 10:05:23.588417 29479 solver.cpp:229]     Train net output #0: loss = 7317.29 (* 1 = 7317.29 loss)
I0315 10:05:23.702766 29479 solver.cpp:610] Iteration 37200, lr = 8.30925e-09
I0315 10:05:23.702780 29479 solver.cpp:613] Iteration 37200, avg_grad_norm = 553080
I0315 10:06:01.045056 29479 solver.cpp:214] Iteration 37220, loss = 6071.05
I0315 10:06:01.045183 29479 solver.cpp:229]     Train net output #0: loss = 3175.09 (* 1 = 3175.09 loss)
I0315 10:06:01.149282 29479 solver.cpp:610] Iteration 37220, lr = 8.30833e-09
I0315 10:06:01.149296 29479 solver.cpp:613] Iteration 37220, avg_grad_norm = 530327
I0315 10:06:25.235175 29479 solver.cpp:214] Iteration 37240, loss = 6021.18
I0315 10:06:25.235244 29479 solver.cpp:229]     Train net output #0: loss = 7196.76 (* 1 = 7196.76 loss)
I0315 10:06:25.351120 29479 solver.cpp:610] Iteration 37240, lr = 8.30742e-09
I0315 10:06:25.351133 29479 solver.cpp:613] Iteration 37240, avg_grad_norm = 581414
I0315 10:06:51.019913 29479 solver.cpp:214] Iteration 37260, loss = 6208.27
I0315 10:06:51.020023 29479 solver.cpp:229]     Train net output #0: loss = 6167.7 (* 1 = 6167.7 loss)
I0315 10:06:51.132885 29479 solver.cpp:610] Iteration 37260, lr = 8.3065e-09
I0315 10:06:51.132899 29479 solver.cpp:613] Iteration 37260, avg_grad_norm = 566142
I0315 10:07:16.325543 29479 solver.cpp:214] Iteration 37280, loss = 6308.24
I0315 10:07:16.325609 29479 solver.cpp:229]     Train net output #0: loss = 6118.25 (* 1 = 6118.25 loss)
I0315 10:07:16.438415 29479 solver.cpp:610] Iteration 37280, lr = 8.30558e-09
I0315 10:07:16.438427 29479 solver.cpp:613] Iteration 37280, avg_grad_norm = 551113
I0315 10:07:41.871117 29479 solver.cpp:214] Iteration 37300, loss = 6200.73
I0315 10:07:41.871256 29479 solver.cpp:229]     Train net output #0: loss = 9144.36 (* 1 = 9144.36 loss)
I0315 10:07:41.985659 29479 solver.cpp:610] Iteration 37300, lr = 8.30466e-09
I0315 10:07:41.985672 29479 solver.cpp:613] Iteration 37300, avg_grad_norm = 483976
I0315 10:08:07.515377 29479 solver.cpp:214] Iteration 37320, loss = 6232.56
I0315 10:08:07.515441 29479 solver.cpp:229]     Train net output #0: loss = 5969.89 (* 1 = 5969.89 loss)
I0315 10:08:07.629950 29479 solver.cpp:610] Iteration 37320, lr = 8.30374e-09
I0315 10:08:07.629962 29479 solver.cpp:613] Iteration 37320, avg_grad_norm = 580067
I0315 10:08:47.713146 29479 solver.cpp:214] Iteration 37340, loss = 6265.75
I0315 10:08:47.713301 29479 solver.cpp:229]     Train net output #0: loss = 5644.58 (* 1 = 5644.58 loss)
I0315 10:08:47.818274 29479 solver.cpp:610] Iteration 37340, lr = 8.30282e-09
I0315 10:08:47.818287 29479 solver.cpp:613] Iteration 37340, avg_grad_norm = 630175
I0315 10:09:11.312813 29479 solver.cpp:214] Iteration 37360, loss = 6226.7
I0315 10:09:11.312886 29479 solver.cpp:229]     Train net output #0: loss = 4963.13 (* 1 = 4963.13 loss)
I0315 10:09:11.417963 29479 solver.cpp:610] Iteration 37360, lr = 8.3019e-09
I0315 10:09:11.417978 29479 solver.cpp:613] Iteration 37360, avg_grad_norm = 519665
I0315 10:09:36.431787 29479 solver.cpp:214] Iteration 37380, loss = 6465.84
I0315 10:09:36.432008 29479 solver.cpp:229]     Train net output #0: loss = 11037.9 (* 1 = 11037.9 loss)
I0315 10:09:36.546311 29479 solver.cpp:610] Iteration 37380, lr = 8.30098e-09
I0315 10:09:36.546325 29479 solver.cpp:613] Iteration 37380, avg_grad_norm = 555448
I0315 10:10:02.121078 29479 solver.cpp:214] Iteration 37400, loss = 6036.22
I0315 10:10:02.121145 29479 solver.cpp:229]     Train net output #0: loss = 5861.19 (* 1 = 5861.19 loss)
I0315 10:10:02.235579 29479 solver.cpp:610] Iteration 37400, lr = 8.30006e-09
I0315 10:10:02.235592 29479 solver.cpp:613] Iteration 37400, avg_grad_norm = 532343
I0315 10:10:27.814954 29479 solver.cpp:214] Iteration 37420, loss = 6068.91
I0315 10:10:27.815100 29479 solver.cpp:229]     Train net output #0: loss = 6408.63 (* 1 = 6408.63 loss)
I0315 10:10:27.929635 29479 solver.cpp:610] Iteration 37420, lr = 8.29915e-09
I0315 10:10:27.929648 29479 solver.cpp:613] Iteration 37420, avg_grad_norm = 538713
I0315 10:10:53.486043 29479 solver.cpp:214] Iteration 37440, loss = 6197.43
I0315 10:10:53.486110 29479 solver.cpp:229]     Train net output #0: loss = 7805.63 (* 1 = 7805.63 loss)
I0315 10:10:53.600561 29479 solver.cpp:610] Iteration 37440, lr = 8.29823e-09
I0315 10:10:53.600575 29479 solver.cpp:613] Iteration 37440, avg_grad_norm = 540323
I0315 10:11:19.144690 29479 solver.cpp:214] Iteration 37460, loss = 6187.12
I0315 10:11:19.144840 29479 solver.cpp:229]     Train net output #0: loss = 10317.7 (* 1 = 10317.7 loss)
I0315 10:11:19.259302 29479 solver.cpp:610] Iteration 37460, lr = 8.29731e-09
I0315 10:11:19.259316 29479 solver.cpp:613] Iteration 37460, avg_grad_norm = 620423
I0315 10:11:57.902945 29479 solver.cpp:214] Iteration 37480, loss = 6193.21
I0315 10:11:57.903089 29479 solver.cpp:229]     Train net output #0: loss = 5150.55 (* 1 = 5150.55 loss)
I0315 10:11:58.008064 29479 solver.cpp:610] Iteration 37480, lr = 8.29639e-09
I0315 10:11:58.008076 29479 solver.cpp:613] Iteration 37480, avg_grad_norm = 593906
I0315 10:12:22.191823 29479 solver.cpp:214] Iteration 37500, loss = 6277.41
I0315 10:12:22.191893 29479 solver.cpp:229]     Train net output #0: loss = 7403.29 (* 1 = 7403.29 loss)
I0315 10:12:22.306396 29479 solver.cpp:610] Iteration 37500, lr = 8.29547e-09
I0315 10:12:22.306408 29479 solver.cpp:613] Iteration 37500, avg_grad_norm = 586533
I0315 10:12:47.869698 29479 solver.cpp:214] Iteration 37520, loss = 6524.88
I0315 10:12:47.869818 29479 solver.cpp:229]     Train net output #0: loss = 13660.3 (* 1 = 13660.3 loss)
I0315 10:12:47.984271 29479 solver.cpp:610] Iteration 37520, lr = 8.29455e-09
I0315 10:12:47.984285 29479 solver.cpp:613] Iteration 37520, avg_grad_norm = 583810
I0315 10:13:13.571030 29479 solver.cpp:214] Iteration 37540, loss = 6334.23
I0315 10:13:13.571110 29479 solver.cpp:229]     Train net output #0: loss = 5305.95 (* 1 = 5305.95 loss)
I0315 10:13:13.685580 29479 solver.cpp:610] Iteration 37540, lr = 8.29363e-09
I0315 10:13:13.685593 29479 solver.cpp:613] Iteration 37540, avg_grad_norm = 564440
I0315 10:13:39.043329 29479 solver.cpp:214] Iteration 37560, loss = 6218.18
I0315 10:13:39.043478 29479 solver.cpp:229]     Train net output #0: loss = 3454 (* 1 = 3454 loss)
I0315 10:13:39.156340 29479 solver.cpp:610] Iteration 37560, lr = 8.29271e-09
I0315 10:13:39.156354 29479 solver.cpp:613] Iteration 37560, avg_grad_norm = 505282
I0315 10:14:04.600020 29479 solver.cpp:214] Iteration 37580, loss = 6449.18
I0315 10:14:04.600091 29479 solver.cpp:229]     Train net output #0: loss = 5736.75 (* 1 = 5736.75 loss)
I0315 10:14:04.714630 29479 solver.cpp:610] Iteration 37580, lr = 8.29179e-09
I0315 10:14:04.714648 29479 solver.cpp:613] Iteration 37580, avg_grad_norm = 520445
I0315 10:14:42.117079 29479 solver.cpp:214] Iteration 37600, loss = 6325.71
I0315 10:14:42.117271 29479 solver.cpp:229]     Train net output #0: loss = 3742.76 (* 1 = 3742.76 loss)
I0315 10:14:42.221660 29479 solver.cpp:610] Iteration 37600, lr = 8.29088e-09
I0315 10:14:42.221678 29479 solver.cpp:613] Iteration 37600, avg_grad_norm = 599446
I0315 10:15:06.244927 29479 solver.cpp:214] Iteration 37620, loss = 6362.07
I0315 10:15:06.244990 29479 solver.cpp:229]     Train net output #0: loss = 7762.57 (* 1 = 7762.57 loss)
I0315 10:15:06.357966 29479 solver.cpp:610] Iteration 37620, lr = 8.28996e-09
I0315 10:15:06.357980 29479 solver.cpp:613] Iteration 37620, avg_grad_norm = 581599
I0315 10:15:31.962105 29479 solver.cpp:214] Iteration 37640, loss = 6344.43
I0315 10:15:31.962234 29479 solver.cpp:229]     Train net output #0: loss = 8132.77 (* 1 = 8132.77 loss)
I0315 10:15:32.076650 29479 solver.cpp:610] Iteration 37640, lr = 8.28904e-09
I0315 10:15:32.076664 29479 solver.cpp:613] Iteration 37640, avg_grad_norm = 541043
I0315 10:15:57.675519 29479 solver.cpp:214] Iteration 37660, loss = 6314.64
I0315 10:15:57.675578 29479 solver.cpp:229]     Train net output #0: loss = 7005.41 (* 1 = 7005.41 loss)
I0315 10:15:57.790153 29479 solver.cpp:610] Iteration 37660, lr = 8.28812e-09
I0315 10:15:57.790169 29479 solver.cpp:613] Iteration 37660, avg_grad_norm = 557694
I0315 10:16:23.385288 29479 solver.cpp:214] Iteration 37680, loss = 6081.87
I0315 10:16:23.385428 29479 solver.cpp:229]     Train net output #0: loss = 5495.62 (* 1 = 5495.62 loss)
I0315 10:16:23.499909 29479 solver.cpp:610] Iteration 37680, lr = 8.2872e-09
I0315 10:16:23.499923 29479 solver.cpp:613] Iteration 37680, avg_grad_norm = 510167
I0315 10:16:49.110321 29479 solver.cpp:214] Iteration 37700, loss = 6325.47
I0315 10:16:49.110368 29479 solver.cpp:229]     Train net output #0: loss = 5016.03 (* 1 = 5016.03 loss)
I0315 10:16:49.224798 29479 solver.cpp:610] Iteration 37700, lr = 8.28628e-09
I0315 10:16:49.224812 29479 solver.cpp:613] Iteration 37700, avg_grad_norm = 569544
I0315 10:17:41.882714 29479 solver.cpp:214] Iteration 37720, loss = 6180.15
I0315 10:17:41.882828 29479 solver.cpp:229]     Train net output #0: loss = 4458.32 (* 1 = 4458.32 loss)
I0315 10:17:41.987964 29479 solver.cpp:610] Iteration 37720, lr = 8.28536e-09
I0315 10:17:41.987993 29479 solver.cpp:613] Iteration 37720, avg_grad_norm = 566937
I0315 10:18:05.390092 29479 solver.cpp:214] Iteration 37740, loss = 6032.17
I0315 10:18:05.390162 29479 solver.cpp:229]     Train net output #0: loss = 9292.11 (* 1 = 9292.11 loss)
I0315 10:18:05.494379 29479 solver.cpp:610] Iteration 37740, lr = 8.28444e-09
I0315 10:18:05.494393 29479 solver.cpp:613] Iteration 37740, avg_grad_norm = 625668
I0315 10:18:28.958784 29479 solver.cpp:214] Iteration 37760, loss = 6201.25
I0315 10:18:28.958920 29479 solver.cpp:229]     Train net output #0: loss = 2315.68 (* 1 = 2315.68 loss)
I0315 10:18:29.065834 29479 solver.cpp:610] Iteration 37760, lr = 8.28352e-09
I0315 10:18:29.065848 29479 solver.cpp:613] Iteration 37760, avg_grad_norm = 590756
I0315 10:18:54.304059 29479 solver.cpp:214] Iteration 37780, loss = 6168.03
I0315 10:18:54.304134 29479 solver.cpp:229]     Train net output #0: loss = 4147.37 (* 1 = 4147.37 loss)
I0315 10:18:54.417012 29479 solver.cpp:610] Iteration 37780, lr = 8.2826e-09
I0315 10:18:54.417029 29479 solver.cpp:613] Iteration 37780, avg_grad_norm = 514186
I0315 10:19:20.045001 29479 solver.cpp:214] Iteration 37800, loss = 6230.68
I0315 10:19:20.045135 29479 solver.cpp:229]     Train net output #0: loss = 5960.05 (* 1 = 5960.05 loss)
I0315 10:19:20.159631 29479 solver.cpp:610] Iteration 37800, lr = 8.28169e-09
I0315 10:19:20.159643 29479 solver.cpp:613] Iteration 37800, avg_grad_norm = 498844
I0315 10:19:45.785053 29479 solver.cpp:214] Iteration 37820, loss = 6735.75
I0315 10:19:45.785109 29479 solver.cpp:229]     Train net output #0: loss = 4508.69 (* 1 = 4508.69 loss)
I0315 10:19:45.899677 29479 solver.cpp:610] Iteration 37820, lr = 8.28077e-09
I0315 10:19:45.899691 29479 solver.cpp:613] Iteration 37820, avg_grad_norm = 523939
I0315 10:20:11.475919 29479 solver.cpp:214] Iteration 37840, loss = 6062.51
I0315 10:20:11.476163 29479 solver.cpp:229]     Train net output #0: loss = 11026.5 (* 1 = 11026.5 loss)
I0315 10:20:11.590701 29479 solver.cpp:610] Iteration 37840, lr = 8.27985e-09
I0315 10:20:11.590715 29479 solver.cpp:613] Iteration 37840, avg_grad_norm = 520208
I0315 10:20:48.573765 29479 solver.cpp:214] Iteration 37860, loss = 6277.57
I0315 10:20:48.573917 29479 solver.cpp:229]     Train net output #0: loss = 4861.84 (* 1 = 4861.84 loss)
I0315 10:20:48.678855 29479 solver.cpp:610] Iteration 37860, lr = 8.27893e-09
I0315 10:20:48.678869 29479 solver.cpp:613] Iteration 37860, avg_grad_norm = 566824
I0315 10:21:12.944286 29479 solver.cpp:214] Iteration 37880, loss = 6382.6
I0315 10:21:12.944373 29479 solver.cpp:229]     Train net output #0: loss = 12180.1 (* 1 = 12180.1 loss)
I0315 10:21:13.057327 29479 solver.cpp:610] Iteration 37880, lr = 8.27801e-09
I0315 10:21:13.057384 29479 solver.cpp:613] Iteration 37880, avg_grad_norm = 550148
I0315 10:21:38.538178 29479 solver.cpp:214] Iteration 37900, loss = 6256.73
I0315 10:21:38.538316 29479 solver.cpp:229]     Train net output #0: loss = 10893.5 (* 1 = 10893.5 loss)
I0315 10:21:38.652649 29479 solver.cpp:610] Iteration 37900, lr = 8.27709e-09
I0315 10:21:38.652663 29479 solver.cpp:613] Iteration 37900, avg_grad_norm = 508285
I0315 10:22:04.238018 29479 solver.cpp:214] Iteration 37920, loss = 6180.35
I0315 10:22:04.238090 29479 solver.cpp:229]     Train net output #0: loss = 7152.55 (* 1 = 7152.55 loss)
I0315 10:22:04.352571 29479 solver.cpp:610] Iteration 37920, lr = 8.27617e-09
I0315 10:22:04.352584 29479 solver.cpp:613] Iteration 37920, avg_grad_norm = 497186
I0315 10:22:29.887764 29479 solver.cpp:214] Iteration 37940, loss = 6273.62
I0315 10:22:29.887994 29479 solver.cpp:229]     Train net output #0: loss = 4767.78 (* 1 = 4767.78 loss)
I0315 10:22:30.002252 29479 solver.cpp:610] Iteration 37940, lr = 8.27525e-09
I0315 10:22:30.002266 29479 solver.cpp:613] Iteration 37940, avg_grad_norm = 519932
I0315 10:22:55.574965 29479 solver.cpp:214] Iteration 37960, loss = 6306.24
I0315 10:22:55.575031 29479 solver.cpp:229]     Train net output #0: loss = 4460.32 (* 1 = 4460.32 loss)
I0315 10:22:55.689375 29479 solver.cpp:610] Iteration 37960, lr = 8.27433e-09
I0315 10:22:55.689389 29479 solver.cpp:613] Iteration 37960, avg_grad_norm = 553481
I0315 10:23:32.818830 29479 solver.cpp:214] Iteration 37980, loss = 6003.25
I0315 10:23:32.818976 29479 solver.cpp:229]     Train net output #0: loss = 4879.55 (* 1 = 4879.55 loss)
I0315 10:23:32.923123 29479 solver.cpp:610] Iteration 37980, lr = 8.27341e-09
I0315 10:23:32.923136 29479 solver.cpp:613] Iteration 37980, avg_grad_norm = 546135
I0315 10:23:56.689642 29479 solver.cpp:214] Iteration 38000, loss = 6242.89
I0315 10:23:56.689705 29479 solver.cpp:229]     Train net output #0: loss = 4854.61 (* 1 = 4854.61 loss)
I0315 10:23:56.804111 29479 solver.cpp:610] Iteration 38000, lr = 8.27249e-09
I0315 10:23:56.804122 29479 solver.cpp:613] Iteration 38000, avg_grad_norm = 546608
I0315 10:24:22.439160 29479 solver.cpp:214] Iteration 38020, loss = 6551.86
I0315 10:24:22.439339 29479 solver.cpp:229]     Train net output #0: loss = 5651.06 (* 1 = 5651.06 loss)
I0315 10:24:22.553938 29479 solver.cpp:610] Iteration 38020, lr = 8.27158e-09
I0315 10:24:22.553951 29479 solver.cpp:613] Iteration 38020, avg_grad_norm = 559532
I0315 10:24:48.155076 29479 solver.cpp:214] Iteration 38040, loss = 6200.22
I0315 10:24:48.155119 29479 solver.cpp:229]     Train net output #0: loss = 4777.89 (* 1 = 4777.89 loss)
I0315 10:24:48.269712 29479 solver.cpp:610] Iteration 38040, lr = 8.27066e-09
I0315 10:24:48.269731 29479 solver.cpp:613] Iteration 38040, avg_grad_norm = 775960
I0315 10:25:13.644543 29479 solver.cpp:214] Iteration 38060, loss = 6366.71
I0315 10:25:13.644765 29479 solver.cpp:229]     Train net output #0: loss = 6550.59 (* 1 = 6550.59 loss)
I0315 10:25:13.757561 29479 solver.cpp:610] Iteration 38060, lr = 8.26974e-09
I0315 10:25:13.757575 29479 solver.cpp:613] Iteration 38060, avg_grad_norm = 586816
I0315 10:25:39.055562 29479 solver.cpp:214] Iteration 38080, loss = 6216.06
I0315 10:25:39.055624 29479 solver.cpp:229]     Train net output #0: loss = 11547.7 (* 1 = 11547.7 loss)
I0315 10:25:39.168560 29479 solver.cpp:610] Iteration 38080, lr = 8.26882e-09
I0315 10:25:39.168573 29479 solver.cpp:613] Iteration 38080, avg_grad_norm = 561151
I0315 10:26:21.309341 29479 solver.cpp:214] Iteration 38100, loss = 6272.47
I0315 10:26:21.309453 29479 solver.cpp:229]     Train net output #0: loss = 3631.4 (* 1 = 3631.4 loss)
I0315 10:26:21.414477 29479 solver.cpp:610] Iteration 38100, lr = 8.2679e-09
I0315 10:26:21.414505 29479 solver.cpp:613] Iteration 38100, avg_grad_norm = 594961
I0315 10:26:44.846377 29479 solver.cpp:214] Iteration 38120, loss = 6106.94
I0315 10:26:44.846451 29479 solver.cpp:229]     Train net output #0: loss = 4705.86 (* 1 = 4705.86 loss)
I0315 10:26:44.951632 29479 solver.cpp:610] Iteration 38120, lr = 8.26698e-09
I0315 10:26:44.951645 29479 solver.cpp:613] Iteration 38120, avg_grad_norm = 529861
I0315 10:27:09.713575 29479 solver.cpp:214] Iteration 38140, loss = 6479.96
I0315 10:27:09.713690 29479 solver.cpp:229]     Train net output #0: loss = 5028.52 (* 1 = 5028.52 loss)
I0315 10:27:09.829396 29479 solver.cpp:610] Iteration 38140, lr = 8.26606e-09
I0315 10:27:09.829408 29479 solver.cpp:613] Iteration 38140, avg_grad_norm = 506649
I0315 10:27:35.330672 29479 solver.cpp:214] Iteration 38160, loss = 6447.04
I0315 10:27:35.330741 29479 solver.cpp:229]     Train net output #0: loss = 9859.79 (* 1 = 9859.79 loss)
I0315 10:27:35.443645 29479 solver.cpp:610] Iteration 38160, lr = 8.26514e-09
I0315 10:27:35.443658 29479 solver.cpp:613] Iteration 38160, avg_grad_norm = 571582
I0315 10:28:00.633885 29479 solver.cpp:214] Iteration 38180, loss = 6658.14
I0315 10:28:00.633988 29479 solver.cpp:229]     Train net output #0: loss = 11401.6 (* 1 = 11401.6 loss)
I0315 10:28:00.748405 29479 solver.cpp:610] Iteration 38180, lr = 8.26422e-09
I0315 10:28:00.748419 29479 solver.cpp:613] Iteration 38180, avg_grad_norm = 597157
I0315 10:28:26.280263 29479 solver.cpp:214] Iteration 38200, loss = 6380.18
I0315 10:28:26.280315 29479 solver.cpp:229]     Train net output #0: loss = 10510.5 (* 1 = 10510.5 loss)
I0315 10:28:26.394731 29479 solver.cpp:610] Iteration 38200, lr = 8.2633e-09
I0315 10:28:26.394744 29479 solver.cpp:613] Iteration 38200, avg_grad_norm = 601801
I0315 10:28:51.928465 29479 solver.cpp:214] Iteration 38220, loss = 6344.52
I0315 10:28:51.928599 29479 solver.cpp:229]     Train net output #0: loss = 8280.83 (* 1 = 8280.83 loss)
I0315 10:28:52.043102 29479 solver.cpp:610] Iteration 38220, lr = 8.26238e-09
I0315 10:28:52.043117 29479 solver.cpp:613] Iteration 38220, avg_grad_norm = 522809
I0315 10:29:38.119889 29479 solver.cpp:214] Iteration 38240, loss = 6382.87
I0315 10:29:38.120026 29479 solver.cpp:229]     Train net output #0: loss = 5414.02 (* 1 = 5414.02 loss)
I0315 10:29:38.225145 29479 solver.cpp:610] Iteration 38240, lr = 8.26146e-09
I0315 10:29:38.225163 29479 solver.cpp:613] Iteration 38240, avg_grad_norm = 557285
I0315 10:30:01.756997 29479 solver.cpp:214] Iteration 38260, loss = 6414.8
I0315 10:30:01.757072 29479 solver.cpp:229]     Train net output #0: loss = 5570.89 (* 1 = 5570.89 loss)
I0315 10:30:01.862120 29479 solver.cpp:610] Iteration 38260, lr = 8.26054e-09
I0315 10:30:01.862135 29479 solver.cpp:613] Iteration 38260, avg_grad_norm = 505832
I0315 10:30:26.991756 29479 solver.cpp:214] Iteration 38280, loss = 6230.14
I0315 10:30:26.991888 29479 solver.cpp:229]     Train net output #0: loss = 4241.95 (* 1 = 4241.95 loss)
I0315 10:30:27.106387 29479 solver.cpp:610] Iteration 38280, lr = 8.25963e-09
I0315 10:30:27.106403 29479 solver.cpp:613] Iteration 38280, avg_grad_norm = 571476
I0315 10:30:52.747854 29479 solver.cpp:214] Iteration 38300, loss = 6267.3
I0315 10:30:52.747905 29479 solver.cpp:229]     Train net output #0: loss = 2253.77 (* 1 = 2253.77 loss)
I0315 10:30:52.862390 29479 solver.cpp:610] Iteration 38300, lr = 8.25871e-09
I0315 10:30:52.862406 29479 solver.cpp:613] Iteration 38300, avg_grad_norm = 603202
I0315 10:31:18.500368 29479 solver.cpp:214] Iteration 38320, loss = 6551.26
I0315 10:31:18.500555 29479 solver.cpp:229]     Train net output #0: loss = 8408.28 (* 1 = 8408.28 loss)
I0315 10:31:18.615011 29479 solver.cpp:610] Iteration 38320, lr = 8.25779e-09
I0315 10:31:18.615027 29479 solver.cpp:613] Iteration 38320, avg_grad_norm = 566112
I0315 10:31:44.255744 29479 solver.cpp:214] Iteration 38340, loss = 6098.13
I0315 10:31:44.255795 29479 solver.cpp:229]     Train net output #0: loss = 7932.44 (* 1 = 7932.44 loss)
I0315 10:31:44.370179 29479 solver.cpp:610] Iteration 38340, lr = 8.25687e-09
I0315 10:31:44.370193 29479 solver.cpp:613] Iteration 38340, avg_grad_norm = 560523
I0315 10:32:28.971246 29479 solver.cpp:214] Iteration 38360, loss = 6342.29
I0315 10:32:28.971369 29479 solver.cpp:229]     Train net output #0: loss = 5659.23 (* 1 = 5659.23 loss)
I0315 10:32:29.075248 29479 solver.cpp:610] Iteration 38360, lr = 8.25595e-09
I0315 10:32:29.075265 29479 solver.cpp:613] Iteration 38360, avg_grad_norm = 555193
I0315 10:32:52.585077 29479 solver.cpp:214] Iteration 38380, loss = 6099.67
I0315 10:32:52.585141 29479 solver.cpp:229]     Train net output #0: loss = 4477.24 (* 1 = 4477.24 loss)
I0315 10:32:52.690224 29479 solver.cpp:610] Iteration 38380, lr = 8.25503e-09
I0315 10:32:52.690237 29479 solver.cpp:613] Iteration 38380, avg_grad_norm = 528672
I0315 10:33:17.327805 29479 solver.cpp:214] Iteration 38400, loss = 6050.28
I0315 10:33:17.327940 29479 solver.cpp:229]     Train net output #0: loss = 7171.3 (* 1 = 7171.3 loss)
I0315 10:33:17.442466 29479 solver.cpp:610] Iteration 38400, lr = 8.25411e-09
I0315 10:33:17.442481 29479 solver.cpp:613] Iteration 38400, avg_grad_norm = 500860
I0315 10:33:43.037875 29479 solver.cpp:214] Iteration 38420, loss = 6374.56
I0315 10:33:43.037932 29479 solver.cpp:229]     Train net output #0: loss = 4543.86 (* 1 = 4543.86 loss)
I0315 10:33:43.152501 29479 solver.cpp:610] Iteration 38420, lr = 8.25319e-09
I0315 10:33:43.152515 29479 solver.cpp:613] Iteration 38420, avg_grad_norm = 548355
I0315 10:34:08.596242 29479 solver.cpp:214] Iteration 38440, loss = 6395.08
I0315 10:34:08.596382 29479 solver.cpp:229]     Train net output #0: loss = 4490.59 (* 1 = 4490.59 loss)
I0315 10:34:08.709352 29479 solver.cpp:610] Iteration 38440, lr = 8.25227e-09
I0315 10:34:08.709403 29479 solver.cpp:613] Iteration 38440, avg_grad_norm = 559376
I0315 10:34:33.995188 29479 solver.cpp:214] Iteration 38460, loss = 6495.17
I0315 10:34:33.995260 29479 solver.cpp:229]     Train net output #0: loss = 4945.39 (* 1 = 4945.39 loss)
I0315 10:34:34.109849 29479 solver.cpp:610] Iteration 38460, lr = 8.25135e-09
I0315 10:34:34.109863 29479 solver.cpp:613] Iteration 38460, avg_grad_norm = 576185
I0315 10:35:12.425654 29479 solver.cpp:214] Iteration 38480, loss = 6361.14
I0315 10:35:12.425773 29479 solver.cpp:229]     Train net output #0: loss = 3203 (* 1 = 3203 loss)
I0315 10:35:12.530828 29479 solver.cpp:610] Iteration 38480, lr = 8.25043e-09
I0315 10:35:12.530843 29479 solver.cpp:613] Iteration 38480, avg_grad_norm = 640720
I0315 10:35:35.964406 29479 solver.cpp:214] Iteration 38500, loss = 6442.86
I0315 10:35:35.964471 29479 solver.cpp:229]     Train net output #0: loss = 5750.07 (* 1 = 5750.07 loss)
I0315 10:35:36.069633 29479 solver.cpp:610] Iteration 38500, lr = 8.24951e-09
I0315 10:35:36.069646 29479 solver.cpp:613] Iteration 38500, avg_grad_norm = 532450
I0315 10:36:01.146787 29479 solver.cpp:214] Iteration 38520, loss = 6198.79
I0315 10:36:01.146991 29479 solver.cpp:229]     Train net output #0: loss = 4244.61 (* 1 = 4244.61 loss)
I0315 10:36:01.261417 29479 solver.cpp:610] Iteration 38520, lr = 8.24859e-09
I0315 10:36:01.261432 29479 solver.cpp:613] Iteration 38520, avg_grad_norm = 630749
I0315 10:36:26.819270 29479 solver.cpp:214] Iteration 38540, loss = 6478.53
I0315 10:36:26.819336 29479 solver.cpp:229]     Train net output #0: loss = 8290.79 (* 1 = 8290.79 loss)
I0315 10:36:26.933756 29479 solver.cpp:610] Iteration 38540, lr = 8.24767e-09
I0315 10:36:26.933771 29479 solver.cpp:613] Iteration 38540, avg_grad_norm = 597763
I0315 10:36:52.508452 29479 solver.cpp:214] Iteration 38560, loss = 6148.87
I0315 10:36:52.508690 29479 solver.cpp:229]     Train net output #0: loss = 6648.21 (* 1 = 6648.21 loss)
I0315 10:36:52.623576 29479 solver.cpp:610] Iteration 38560, lr = 8.24675e-09
I0315 10:36:52.623589 29479 solver.cpp:613] Iteration 38560, avg_grad_norm = 598491
I0315 10:37:18.159905 29479 solver.cpp:214] Iteration 38580, loss = 6352.93
I0315 10:37:18.159955 29479 solver.cpp:229]     Train net output #0: loss = 5805.64 (* 1 = 5805.64 loss)
I0315 10:37:18.274559 29479 solver.cpp:610] Iteration 38580, lr = 8.24583e-09
I0315 10:37:18.274572 29479 solver.cpp:613] Iteration 38580, avg_grad_norm = 629465
I0315 10:37:43.666584 29479 solver.cpp:214] Iteration 38600, loss = 6214.39
I0315 10:37:43.666695 29479 solver.cpp:229]     Train net output #0: loss = 4832.72 (* 1 = 4832.72 loss)
I0315 10:37:43.779837 29479 solver.cpp:610] Iteration 38600, lr = 8.24491e-09
I0315 10:37:43.779850 29479 solver.cpp:613] Iteration 38600, avg_grad_norm = 557582
I0315 10:38:20.352226 29479 solver.cpp:214] Iteration 38620, loss = 6690.67
I0315 10:38:20.352340 29479 solver.cpp:229]     Train net output #0: loss = 5924.77 (* 1 = 5924.77 loss)
I0315 10:38:20.457352 29479 solver.cpp:610] Iteration 38620, lr = 8.244e-09
I0315 10:38:20.457365 29479 solver.cpp:613] Iteration 38620, avg_grad_norm = 578320
I0315 10:38:44.862778 29479 solver.cpp:214] Iteration 38640, loss = 6269.2
I0315 10:38:44.862846 29479 solver.cpp:229]     Train net output #0: loss = 2503.68 (* 1 = 2503.68 loss)
I0315 10:38:44.977444 29479 solver.cpp:610] Iteration 38640, lr = 8.24308e-09
I0315 10:38:44.977458 29479 solver.cpp:613] Iteration 38640, avg_grad_norm = 644437
I0315 10:39:10.526098 29479 solver.cpp:214] Iteration 38660, loss = 5977.99
I0315 10:39:10.526237 29479 solver.cpp:229]     Train net output #0: loss = 10281.7 (* 1 = 10281.7 loss)
I0315 10:39:10.640816 29479 solver.cpp:610] Iteration 38660, lr = 8.24216e-09
I0315 10:39:10.640859 29479 solver.cpp:613] Iteration 38660, avg_grad_norm = 621318
I0315 10:39:36.248450 29479 solver.cpp:214] Iteration 38680, loss = 6307.79
I0315 10:39:36.248520 29479 solver.cpp:229]     Train net output #0: loss = 6594.79 (* 1 = 6594.79 loss)
I0315 10:39:36.362957 29479 solver.cpp:610] Iteration 38680, lr = 8.24124e-09
I0315 10:39:36.362970 29479 solver.cpp:613] Iteration 38680, avg_grad_norm = 580447
I0315 10:40:01.961061 29479 solver.cpp:214] Iteration 38700, loss = 6194.16
I0315 10:40:01.961243 29479 solver.cpp:229]     Train net output #0: loss = 3708.22 (* 1 = 3708.22 loss)
I0315 10:40:02.075616 29479 solver.cpp:610] Iteration 38700, lr = 8.24032e-09
I0315 10:40:02.075629 29479 solver.cpp:613] Iteration 38700, avg_grad_norm = 515564
I0315 10:40:27.677320 29479 solver.cpp:214] Iteration 38720, loss = 6168.92
I0315 10:40:27.677372 29479 solver.cpp:229]     Train net output #0: loss = 5594.41 (* 1 = 5594.41 loss)
I0315 10:40:27.791950 29479 solver.cpp:610] Iteration 38720, lr = 8.2394e-09
I0315 10:40:27.791963 29479 solver.cpp:613] Iteration 38720, avg_grad_norm = 525175
I0315 10:41:05.275662 29479 solver.cpp:214] Iteration 38740, loss = 6291.32
I0315 10:41:05.275887 29479 solver.cpp:229]     Train net output #0: loss = 4784.77 (* 1 = 4784.77 loss)
I0315 10:41:05.380812 29479 solver.cpp:610] Iteration 38740, lr = 8.23848e-09
I0315 10:41:05.380827 29479 solver.cpp:613] Iteration 38740, avg_grad_norm = 500786
I0315 10:41:29.140235 29479 solver.cpp:214] Iteration 38760, loss = 6349.64
I0315 10:41:29.140295 29479 solver.cpp:229]     Train net output #0: loss = 3634.57 (* 1 = 3634.57 loss)
I0315 10:41:29.253279 29479 solver.cpp:610] Iteration 38760, lr = 8.23756e-09
I0315 10:41:29.253291 29479 solver.cpp:613] Iteration 38760, avg_grad_norm = 529927
I0315 10:41:54.841379 29479 solver.cpp:214] Iteration 38780, loss = 6480.96
I0315 10:41:54.841544 29479 solver.cpp:229]     Train net output #0: loss = 5964.39 (* 1 = 5964.39 loss)
I0315 10:41:54.956099 29479 solver.cpp:610] Iteration 38780, lr = 8.23664e-09
I0315 10:41:54.956112 29479 solver.cpp:613] Iteration 38780, avg_grad_norm = 527439
I0315 10:42:20.548701 29479 solver.cpp:214] Iteration 38800, loss = 6513.11
I0315 10:42:20.548768 29479 solver.cpp:229]     Train net output #0: loss = 8179.68 (* 1 = 8179.68 loss)
I0315 10:42:20.663180 29479 solver.cpp:610] Iteration 38800, lr = 8.23572e-09
I0315 10:42:20.663194 29479 solver.cpp:613] Iteration 38800, avg_grad_norm = 570287
I0315 10:42:46.261466 29479 solver.cpp:214] Iteration 38820, loss = 6224.55
I0315 10:42:46.261607 29479 solver.cpp:229]     Train net output #0: loss = 2639.96 (* 1 = 2639.96 loss)
I0315 10:42:46.376080 29479 solver.cpp:610] Iteration 38820, lr = 8.2348e-09
I0315 10:42:46.376096 29479 solver.cpp:613] Iteration 38820, avg_grad_norm = 558731
I0315 10:43:11.985504 29479 solver.cpp:214] Iteration 38840, loss = 6448.95
I0315 10:43:11.985555 29479 solver.cpp:229]     Train net output #0: loss = 8760.3 (* 1 = 8760.3 loss)
I0315 10:43:12.100260 29479 solver.cpp:610] Iteration 38840, lr = 8.23388e-09
I0315 10:43:12.100275 29479 solver.cpp:613] Iteration 38840, avg_grad_norm = 591240
I0315 10:43:50.470959 29479 solver.cpp:214] Iteration 38860, loss = 6231.61
I0315 10:43:50.471072 29479 solver.cpp:229]     Train net output #0: loss = 6435.6 (* 1 = 6435.6 loss)
I0315 10:43:50.576100 29479 solver.cpp:610] Iteration 38860, lr = 8.23296e-09
I0315 10:43:50.576114 29479 solver.cpp:613] Iteration 38860, avg_grad_norm = 586260
I0315 10:44:14.074543 29479 solver.cpp:214] Iteration 38880, loss = 6145.73
I0315 10:44:14.074632 29479 solver.cpp:229]     Train net output #0: loss = 4040.68 (* 1 = 4040.68 loss)
I0315 10:44:14.179675 29479 solver.cpp:610] Iteration 38880, lr = 8.23204e-09
I0315 10:44:14.179690 29479 solver.cpp:613] Iteration 38880, avg_grad_norm = 537081
I0315 10:44:39.233682 29479 solver.cpp:214] Iteration 38900, loss = 6187.25
I0315 10:44:39.233889 29479 solver.cpp:229]     Train net output #0: loss = 4165.31 (* 1 = 4165.31 loss)
I0315 10:44:39.348359 29479 solver.cpp:610] Iteration 38900, lr = 8.23112e-09
I0315 10:44:39.348373 29479 solver.cpp:613] Iteration 38900, avg_grad_norm = 545537
I0315 10:45:04.882715 29479 solver.cpp:214] Iteration 38920, loss = 6051.71
I0315 10:45:04.882781 29479 solver.cpp:229]     Train net output #0: loss = 6751.62 (* 1 = 6751.62 loss)
I0315 10:45:04.997395 29479 solver.cpp:610] Iteration 38920, lr = 8.2302e-09
I0315 10:45:04.997408 29479 solver.cpp:613] Iteration 38920, avg_grad_norm = 555109
I0315 10:45:30.566102 29479 solver.cpp:214] Iteration 38940, loss = 5949.91
I0315 10:45:30.566251 29479 solver.cpp:229]     Train net output #0: loss = 9279.4 (* 1 = 9279.4 loss)
I0315 10:45:30.680763 29479 solver.cpp:610] Iteration 38940, lr = 8.22928e-09
I0315 10:45:30.680775 29479 solver.cpp:613] Iteration 38940, avg_grad_norm = 567736
I0315 10:45:56.210623 29479 solver.cpp:214] Iteration 38960, loss = 6210.83
I0315 10:45:56.210688 29479 solver.cpp:229]     Train net output #0: loss = 5837.95 (* 1 = 5837.95 loss)
I0315 10:45:56.325186 29479 solver.cpp:610] Iteration 38960, lr = 8.22836e-09
I0315 10:45:56.325198 29479 solver.cpp:613] Iteration 38960, avg_grad_norm = 522858
I0315 10:46:21.858837 29479 solver.cpp:214] Iteration 38980, loss = 6288.48
I0315 10:46:21.858958 29479 solver.cpp:229]     Train net output #0: loss = 6658.93 (* 1 = 6658.93 loss)
I0315 10:46:21.973532 29479 solver.cpp:610] Iteration 38980, lr = 8.22744e-09
I0315 10:46:21.973546 29479 solver.cpp:613] Iteration 38980, avg_grad_norm = 567819
I0315 10:47:03.900934 29479 solver.cpp:214] Iteration 39000, loss = 6336.4
I0315 10:47:03.901134 29479 solver.cpp:229]     Train net output #0: loss = 2368.69 (* 1 = 2368.69 loss)
I0315 10:47:04.005256 29479 solver.cpp:610] Iteration 39000, lr = 8.22652e-09
I0315 10:47:04.005270 29479 solver.cpp:613] Iteration 39000, avg_grad_norm = 623205
I0315 10:47:27.586581 29479 solver.cpp:214] Iteration 39020, loss = 6407.43
I0315 10:47:27.586643 29479 solver.cpp:229]     Train net output #0: loss = 10073.4 (* 1 = 10073.4 loss)
I0315 10:47:27.701275 29479 solver.cpp:610] Iteration 39020, lr = 8.2256e-09
I0315 10:47:27.701289 29479 solver.cpp:613] Iteration 39020, avg_grad_norm = 553736
I0315 10:47:53.250857 29479 solver.cpp:214] Iteration 39040, loss = 6297.64
I0315 10:47:53.251039 29479 solver.cpp:229]     Train net output #0: loss = 3646.33 (* 1 = 3646.33 loss)
I0315 10:47:53.365649 29479 solver.cpp:610] Iteration 39040, lr = 8.22468e-09
I0315 10:47:53.365664 29479 solver.cpp:613] Iteration 39040, avg_grad_norm = 538275
I0315 10:48:18.909449 29479 solver.cpp:214] Iteration 39060, loss = 6289.48
I0315 10:48:18.909507 29479 solver.cpp:229]     Train net output #0: loss = 7798.78 (* 1 = 7798.78 loss)
I0315 10:48:19.024003 29479 solver.cpp:610] Iteration 39060, lr = 8.22376e-09
I0315 10:48:19.024016 29479 solver.cpp:613] Iteration 39060, avg_grad_norm = 522379
I0315 10:48:44.566519 29479 solver.cpp:214] Iteration 39080, loss = 6294.97
I0315 10:48:44.566669 29479 solver.cpp:229]     Train net output #0: loss = 10338.8 (* 1 = 10338.8 loss)
I0315 10:48:44.681318 29479 solver.cpp:610] Iteration 39080, lr = 8.22284e-09
I0315 10:48:44.681330 29479 solver.cpp:613] Iteration 39080, avg_grad_norm = 523109
I0315 10:49:10.276052 29479 solver.cpp:214] Iteration 39100, loss = 6368.19
I0315 10:49:10.276126 29479 solver.cpp:229]     Train net output #0: loss = 6394.46 (* 1 = 6394.46 loss)
I0315 10:49:10.390599 29479 solver.cpp:610] Iteration 39100, lr = 8.22192e-09
I0315 10:49:10.390647 29479 solver.cpp:613] Iteration 39100, avg_grad_norm = 517190
I0315 10:49:48.175890 29479 solver.cpp:214] Iteration 39120, loss = 6193.51
I0315 10:49:48.176033 29479 solver.cpp:229]     Train net output #0: loss = 8199.4 (* 1 = 8199.4 loss)
I0315 10:49:48.279487 29479 solver.cpp:610] Iteration 39120, lr = 8.221e-09
I0315 10:49:48.279501 29479 solver.cpp:613] Iteration 39120, avg_grad_norm = 503854
I0315 10:50:11.740559 29479 solver.cpp:214] Iteration 39140, loss = 6099.1
I0315 10:50:11.740622 29479 solver.cpp:229]     Train net output #0: loss = 4161.16 (* 1 = 4161.16 loss)
I0315 10:50:11.852582 29479 solver.cpp:610] Iteration 39140, lr = 8.22008e-09
I0315 10:50:11.852597 29479 solver.cpp:613] Iteration 39140, avg_grad_norm = 596510
I0315 10:50:37.376368 29479 solver.cpp:214] Iteration 39160, loss = 6403.63
I0315 10:50:37.376521 29479 solver.cpp:229]     Train net output #0: loss = 9006.37 (* 1 = 9006.37 loss)
I0315 10:50:37.491003 29479 solver.cpp:610] Iteration 39160, lr = 8.21916e-09
I0315 10:50:37.491015 29479 solver.cpp:613] Iteration 39160, avg_grad_norm = 605723
I0315 10:51:03.088547 29479 solver.cpp:214] Iteration 39180, loss = 6445.69
I0315 10:51:03.088603 29479 solver.cpp:229]     Train net output #0: loss = 2368.49 (* 1 = 2368.49 loss)
I0315 10:51:03.203141 29479 solver.cpp:610] Iteration 39180, lr = 8.21824e-09
I0315 10:51:03.203155 29479 solver.cpp:613] Iteration 39180, avg_grad_norm = 602867
I0315 10:51:28.797953 29479 solver.cpp:214] Iteration 39200, loss = 6303.65
I0315 10:51:28.798104 29479 solver.cpp:229]     Train net output #0: loss = 6983.62 (* 1 = 6983.62 loss)
I0315 10:51:28.912569 29479 solver.cpp:610] Iteration 39200, lr = 8.21732e-09
I0315 10:51:28.912583 29479 solver.cpp:613] Iteration 39200, avg_grad_norm = 530280
I0315 10:51:54.507567 29479 solver.cpp:214] Iteration 39220, loss = 5959.53
I0315 10:51:54.507613 29479 solver.cpp:229]     Train net output #0: loss = 4265.03 (* 1 = 4265.03 loss)
I0315 10:51:54.621975 29479 solver.cpp:610] Iteration 39220, lr = 8.2164e-09
I0315 10:51:54.621989 29479 solver.cpp:613] Iteration 39220, avg_grad_norm = 494938
I0315 10:52:20.240257 29479 solver.cpp:214] Iteration 39240, loss = 5932.69
I0315 10:52:20.240362 29479 solver.cpp:229]     Train net output #0: loss = 7229.67 (* 1 = 7229.67 loss)
I0315 10:52:20.354948 29479 solver.cpp:610] Iteration 39240, lr = 8.21549e-09
I0315 10:52:20.354961 29479 solver.cpp:613] Iteration 39240, avg_grad_norm = 506040
I0315 10:52:57.178053 29479 solver.cpp:214] Iteration 39260, loss = 6067.92
I0315 10:52:57.178217 29479 solver.cpp:229]     Train net output #0: loss = 5551.34 (* 1 = 5551.34 loss)
I0315 10:52:57.283259 29479 solver.cpp:610] Iteration 39260, lr = 8.21457e-09
I0315 10:52:57.283273 29479 solver.cpp:613] Iteration 39260, avg_grad_norm = 503506
I0315 10:53:22.091446 29479 solver.cpp:214] Iteration 39280, loss = 6150.17
I0315 10:53:22.091517 29479 solver.cpp:229]     Train net output #0: loss = 5975.98 (* 1 = 5975.98 loss)
I0315 10:53:22.206156 29479 solver.cpp:610] Iteration 39280, lr = 8.21364e-09
I0315 10:53:22.206169 29479 solver.cpp:613] Iteration 39280, avg_grad_norm = 580643
I0315 10:53:47.806658 29479 solver.cpp:214] Iteration 39300, loss = 6096.23
I0315 10:53:47.806803 29479 solver.cpp:229]     Train net output #0: loss = 5689.23 (* 1 = 5689.23 loss)
I0315 10:53:47.921363 29479 solver.cpp:610] Iteration 39300, lr = 8.21273e-09
I0315 10:53:47.921378 29479 solver.cpp:613] Iteration 39300, avg_grad_norm = 603215
I0315 10:54:13.544026 29479 solver.cpp:214] Iteration 39320, loss = 6072.3
I0315 10:54:13.544072 29479 solver.cpp:229]     Train net output #0: loss = 3187.14 (* 1 = 3187.14 loss)
I0315 10:54:13.658516 29479 solver.cpp:610] Iteration 39320, lr = 8.21181e-09
I0315 10:54:13.658531 29479 solver.cpp:613] Iteration 39320, avg_grad_norm = 697312
I0315 10:54:39.178371 29479 solver.cpp:214] Iteration 39340, loss = 6135.65
I0315 10:54:39.178514 29479 solver.cpp:229]     Train net output #0: loss = 4618.15 (* 1 = 4618.15 loss)
I0315 10:54:39.291419 29479 solver.cpp:610] Iteration 39340, lr = 8.21089e-09
I0315 10:54:39.291431 29479 solver.cpp:613] Iteration 39340, avg_grad_norm = 585285
I0315 10:55:04.652463 29479 solver.cpp:214] Iteration 39360, loss = 6056.13
I0315 10:55:04.652529 29479 solver.cpp:229]     Train net output #0: loss = 5060.57 (* 1 = 5060.57 loss)
I0315 10:55:04.767072 29479 solver.cpp:610] Iteration 39360, lr = 8.20997e-09
I0315 10:55:04.767086 29479 solver.cpp:613] Iteration 39360, avg_grad_norm = 582677
I0315 10:55:41.726886 29479 solver.cpp:214] Iteration 39380, loss = 6241.21
I0315 10:55:41.727035 29479 solver.cpp:229]     Train net output #0: loss = 10540.5 (* 1 = 10540.5 loss)
I0315 10:55:41.831959 29479 solver.cpp:610] Iteration 39380, lr = 8.20904e-09
I0315 10:55:41.831971 29479 solver.cpp:613] Iteration 39380, avg_grad_norm = 686516
I0315 10:56:06.118288 29479 solver.cpp:214] Iteration 39400, loss = 6208.22
I0315 10:56:06.118355 29479 solver.cpp:229]     Train net output #0: loss = 5911.92 (* 1 = 5911.92 loss)
I0315 10:56:06.232815 29479 solver.cpp:610] Iteration 39400, lr = 8.20813e-09
I0315 10:56:06.232828 29479 solver.cpp:613] Iteration 39400, avg_grad_norm = 601574
I0315 10:56:32.035845 29479 solver.cpp:214] Iteration 39420, loss = 6013.8
I0315 10:56:32.035990 29479 solver.cpp:229]     Train net output #0: loss = 5739.3 (* 1 = 5739.3 loss)
I0315 10:56:32.151970 29479 solver.cpp:610] Iteration 39420, lr = 8.20721e-09
I0315 10:56:32.151983 29479 solver.cpp:613] Iteration 39420, avg_grad_norm = 531729
I0315 10:56:57.500267 29479 solver.cpp:214] Iteration 39440, loss = 6405.4
I0315 10:56:57.500314 29479 solver.cpp:229]     Train net output #0: loss = 7421.57 (* 1 = 7421.57 loss)
I0315 10:56:57.613229 29479 solver.cpp:610] Iteration 39440, lr = 8.20629e-09
I0315 10:56:57.613241 29479 solver.cpp:613] Iteration 39440, avg_grad_norm = 565328
I0315 10:57:23.018002 29479 solver.cpp:214] Iteration 39460, loss = 5874.03
I0315 10:57:23.018149 29479 solver.cpp:229]     Train net output #0: loss = 4495.77 (* 1 = 4495.77 loss)
I0315 10:57:23.132469 29479 solver.cpp:610] Iteration 39460, lr = 8.20537e-09
I0315 10:57:23.132483 29479 solver.cpp:613] Iteration 39460, avg_grad_norm = 567503
I0315 10:57:48.670706 29479 solver.cpp:214] Iteration 39480, loss = 6110.43
I0315 10:57:48.670758 29479 solver.cpp:229]     Train net output #0: loss = 4116.03 (* 1 = 4116.03 loss)
I0315 10:57:48.785323 29479 solver.cpp:610] Iteration 39480, lr = 8.20445e-09
I0315 10:57:48.785336 29479 solver.cpp:613] Iteration 39480, avg_grad_norm = 552864
I0315 10:58:32.194538 29479 solver.cpp:214] Iteration 39500, loss = 6090.42
I0315 10:58:32.194665 29479 solver.cpp:229]     Train net output #0: loss = 4637.68 (* 1 = 4637.68 loss)
I0315 10:58:32.298823 29479 solver.cpp:610] Iteration 39500, lr = 8.20353e-09
I0315 10:58:32.298837 29479 solver.cpp:613] Iteration 39500, avg_grad_norm = 604796
I0315 10:58:55.787533 29479 solver.cpp:214] Iteration 39520, loss = 6143.89
I0315 10:58:55.787601 29479 solver.cpp:229]     Train net output #0: loss = 5415.33 (* 1 = 5415.33 loss)
I0315 10:58:55.892837 29479 solver.cpp:610] Iteration 39520, lr = 8.20261e-09
I0315 10:58:55.892890 29479 solver.cpp:613] Iteration 39520, avg_grad_norm = 571941
I0315 10:59:20.857311 29479 solver.cpp:214] Iteration 39540, loss = 6383.92
I0315 10:59:20.857431 29479 solver.cpp:229]     Train net output #0: loss = 5620.01 (* 1 = 5620.01 loss)
I0315 10:59:20.971964 29479 solver.cpp:610] Iteration 39540, lr = 8.20169e-09
I0315 10:59:20.971977 29479 solver.cpp:613] Iteration 39540, avg_grad_norm = 552437
I0315 10:59:46.573122 29479 solver.cpp:214] Iteration 39560, loss = 6153.08
I0315 10:59:46.573181 29479 solver.cpp:229]     Train net output #0: loss = 8546.79 (* 1 = 8546.79 loss)
I0315 10:59:46.687671 29479 solver.cpp:610] Iteration 39560, lr = 8.20077e-09
I0315 10:59:46.687685 29479 solver.cpp:613] Iteration 39560, avg_grad_norm = 529618
I0315 11:00:12.286012 29479 solver.cpp:214] Iteration 39580, loss = 5964.91
I0315 11:00:12.286146 29479 solver.cpp:229]     Train net output #0: loss = 7513.64 (* 1 = 7513.64 loss)
I0315 11:00:12.400499 29479 solver.cpp:610] Iteration 39580, lr = 8.19985e-09
I0315 11:00:12.400512 29479 solver.cpp:613] Iteration 39580, avg_grad_norm = 515162
I0315 11:00:38.000888 29479 solver.cpp:214] Iteration 39600, loss = 6606.19
I0315 11:00:38.000933 29479 solver.cpp:229]     Train net output #0: loss = 8637.08 (* 1 = 8637.08 loss)
I0315 11:00:38.115500 29479 solver.cpp:610] Iteration 39600, lr = 8.19893e-09
I0315 11:00:38.115514 29479 solver.cpp:613] Iteration 39600, avg_grad_norm = 561490
I0315 11:01:03.728852 29479 solver.cpp:214] Iteration 39620, loss = 6271.94
I0315 11:01:03.729010 29479 solver.cpp:229]     Train net output #0: loss = 5240.73 (* 1 = 5240.73 loss)
I0315 11:01:03.843432 29479 solver.cpp:610] Iteration 39620, lr = 8.19801e-09
I0315 11:01:03.843446 29479 solver.cpp:613] Iteration 39620, avg_grad_norm = 627586
I0315 11:01:52.134560 29479 solver.cpp:214] Iteration 39640, loss = 6223.72
I0315 11:01:52.134749 29479 solver.cpp:229]     Train net output #0: loss = 7950.81 (* 1 = 7950.81 loss)
I0315 11:01:52.238322 29479 solver.cpp:610] Iteration 39640, lr = 8.19709e-09
I0315 11:01:52.238335 29479 solver.cpp:613] Iteration 39640, avg_grad_norm = 656930
I0315 11:02:15.682006 29479 solver.cpp:214] Iteration 39660, loss = 6179.9
I0315 11:02:15.682063 29479 solver.cpp:229]     Train net output #0: loss = 5010.36 (* 1 = 5010.36 loss)
I0315 11:02:15.787204 29479 solver.cpp:610] Iteration 39660, lr = 8.19616e-09
I0315 11:02:15.787216 29479 solver.cpp:613] Iteration 39660, avg_grad_norm = 585348
I0315 11:02:40.584018 29479 solver.cpp:214] Iteration 39680, loss = 6155.58
I0315 11:02:40.584154 29479 solver.cpp:229]     Train net output #0: loss = 3627.33 (* 1 = 3627.33 loss)
I0315 11:02:40.696987 29479 solver.cpp:610] Iteration 39680, lr = 8.19524e-09
I0315 11:02:40.697000 29479 solver.cpp:613] Iteration 39680, avg_grad_norm = 648808
I0315 11:03:06.198500 29479 solver.cpp:214] Iteration 39700, loss = 6387.57
I0315 11:03:06.198568 29479 solver.cpp:229]     Train net output #0: loss = 4750.76 (* 1 = 4750.76 loss)
I0315 11:03:06.313199 29479 solver.cpp:610] Iteration 39700, lr = 8.19432e-09
I0315 11:03:06.313212 29479 solver.cpp:613] Iteration 39700, avg_grad_norm = 608817
I0315 11:03:31.854396 29479 solver.cpp:214] Iteration 39720, loss = 6100.48
I0315 11:03:31.854562 29479 solver.cpp:229]     Train net output #0: loss = 5403.05 (* 1 = 5403.05 loss)
I0315 11:03:31.968827 29479 solver.cpp:610] Iteration 39720, lr = 8.19341e-09
I0315 11:03:31.968839 29479 solver.cpp:613] Iteration 39720, avg_grad_norm = 635624
I0315 11:03:57.555153 29479 solver.cpp:214] Iteration 39740, loss = 6186.06
I0315 11:03:57.555228 29479 solver.cpp:229]     Train net output #0: loss = 9553.92 (* 1 = 9553.92 loss)
I0315 11:03:57.669675 29479 solver.cpp:610] Iteration 39740, lr = 8.19248e-09
I0315 11:03:57.669688 29479 solver.cpp:613] Iteration 39740, avg_grad_norm = 527341
I0315 11:04:40.748961 29479 solver.cpp:214] Iteration 39760, loss = 6334.57
I0315 11:04:40.749210 29479 solver.cpp:229]     Train net output #0: loss = 5399.88 (* 1 = 5399.88 loss)
I0315 11:04:40.854146 29479 solver.cpp:610] Iteration 39760, lr = 8.19156e-09
I0315 11:04:40.854162 29479 solver.cpp:613] Iteration 39760, avg_grad_norm = 608889
I0315 11:05:04.290887 29479 solver.cpp:214] Iteration 39780, loss = 6188.54
I0315 11:05:04.290959 29479 solver.cpp:229]     Train net output #0: loss = 5266.07 (* 1 = 5266.07 loss)
I0315 11:05:04.396193 29479 solver.cpp:610] Iteration 39780, lr = 8.19064e-09
I0315 11:05:04.396206 29479 solver.cpp:613] Iteration 39780, avg_grad_norm = 559260
I0315 11:05:29.586598 29479 solver.cpp:214] Iteration 39800, loss = 6375.76
I0315 11:05:29.586737 29479 solver.cpp:229]     Train net output #0: loss = 6741.95 (* 1 = 6741.95 loss)
I0315 11:05:29.701088 29479 solver.cpp:610] Iteration 39800, lr = 8.18972e-09
I0315 11:05:29.701102 29479 solver.cpp:613] Iteration 39800, avg_grad_norm = 527959
I0315 11:05:54.988478 29479 solver.cpp:214] Iteration 39820, loss = 6549.33
I0315 11:05:54.988543 29479 solver.cpp:229]     Train net output #0: loss = 6336.39 (* 1 = 6336.39 loss)
I0315 11:05:55.101462 29479 solver.cpp:610] Iteration 39820, lr = 8.1888e-09
I0315 11:05:55.101487 29479 solver.cpp:613] Iteration 39820, avg_grad_norm = 568680
I0315 11:06:20.345530 29479 solver.cpp:214] Iteration 39840, loss = 6297.91
I0315 11:06:20.345676 29479 solver.cpp:229]     Train net output #0: loss = 5150.56 (* 1 = 5150.56 loss)
I0315 11:06:20.460065 29479 solver.cpp:610] Iteration 39840, lr = 8.18788e-09
I0315 11:06:20.460079 29479 solver.cpp:613] Iteration 39840, avg_grad_norm = 632290
I0315 11:06:46.043754 29479 solver.cpp:214] Iteration 39860, loss = 6190.77
I0315 11:06:46.043824 29479 solver.cpp:229]     Train net output #0: loss = 9843.45 (* 1 = 9843.45 loss)
I0315 11:06:46.158458 29479 solver.cpp:610] Iteration 39860, lr = 8.18696e-09
I0315 11:06:46.158471 29479 solver.cpp:613] Iteration 39860, avg_grad_norm = 540356
I0315 11:07:24.301651 29479 solver.cpp:214] Iteration 39880, loss = 6576.67
I0315 11:07:24.301750 29479 solver.cpp:229]     Train net output #0: loss = 6780.93 (* 1 = 6780.93 loss)
I0315 11:07:24.406728 29479 solver.cpp:610] Iteration 39880, lr = 8.18604e-09
I0315 11:07:24.406741 29479 solver.cpp:613] Iteration 39880, avg_grad_norm = 545753
I0315 11:07:47.838516 29479 solver.cpp:214] Iteration 39900, loss = 5939.69
I0315 11:07:47.838583 29479 solver.cpp:229]     Train net output #0: loss = 3494.53 (* 1 = 3494.53 loss)
I0315 11:07:47.943766 29479 solver.cpp:610] Iteration 39900, lr = 8.18512e-09
I0315 11:07:47.943779 29479 solver.cpp:613] Iteration 39900, avg_grad_norm = 538607
I0315 11:08:13.434545 29479 solver.cpp:214] Iteration 39920, loss = 6048.39
I0315 11:08:13.434718 29479 solver.cpp:229]     Train net output #0: loss = 5923.13 (* 1 = 5923.13 loss)
I0315 11:08:13.549219 29479 solver.cpp:610] Iteration 39920, lr = 8.1842e-09
I0315 11:08:13.549232 29479 solver.cpp:613] Iteration 39920, avg_grad_norm = 536518
I0315 11:08:39.105044 29479 solver.cpp:214] Iteration 39940, loss = 6312.28
I0315 11:08:39.105082 29479 solver.cpp:229]     Train net output #0: loss = 10286.1 (* 1 = 10286.1 loss)
I0315 11:08:39.219686 29479 solver.cpp:610] Iteration 39940, lr = 8.18328e-09
I0315 11:08:39.219699 29479 solver.cpp:613] Iteration 39940, avg_grad_norm = 587567
I0315 11:09:04.828619 29479 solver.cpp:214] Iteration 39960, loss = 6534.61
I0315 11:09:04.828812 29479 solver.cpp:229]     Train net output #0: loss = 13104 (* 1 = 13104 loss)
I0315 11:09:04.943326 29479 solver.cpp:610] Iteration 39960, lr = 8.18236e-09
I0315 11:09:04.943341 29479 solver.cpp:613] Iteration 39960, avg_grad_norm = 572046
I0315 11:09:30.304929 29479 solver.cpp:214] Iteration 39980, loss = 6433.14
I0315 11:09:30.304971 29479 solver.cpp:229]     Train net output #0: loss = 5666.31 (* 1 = 5666.31 loss)
I0315 11:09:30.417723 29479 solver.cpp:610] Iteration 39980, lr = 8.18144e-09
I0315 11:09:30.417737 29479 solver.cpp:613] Iteration 39980, avg_grad_norm = 541942
I0315 11:09:54.720355 29479 solver.cpp:458] Snapshotting to models/pnet/VGG_VOC2012ext_iter_40000.caffemodel
I0315 11:09:55.648655 29479 solver.cpp:466] Snapshotting solver state to models/pnet/VGG_VOC2012ext_iter_40000.solverstate
I0315 11:09:57.559768 29479 solver.cpp:214] Iteration 40000, loss = 6006.52
I0315 11:09:57.559833 29479 solver.cpp:229]     Train net output #0: loss = 10508.4 (* 1 = 10508.4 loss)
I0315 11:09:57.664963 29479 solver.cpp:610] Iteration 40000, lr = 8.18052e-09
I0315 11:09:57.664978 29479 solver.cpp:613] Iteration 40000, avg_grad_norm = 608417
I0315 11:10:34.268426 29479 solver.cpp:214] Iteration 40020, loss = 5997.16
I0315 11:10:34.268570 29479 solver.cpp:229]     Train net output #0: loss = 4361.89 (* 1 = 4361.89 loss)
I0315 11:10:34.373646 29479 solver.cpp:610] Iteration 40020, lr = 8.1796e-09
I0315 11:10:34.373661 29479 solver.cpp:613] Iteration 40020, avg_grad_norm = 564833
I0315 11:10:59.113201 29479 solver.cpp:214] Iteration 40040, loss = 6092.07
I0315 11:10:59.113258 29479 solver.cpp:229]     Train net output #0: loss = 5388.27 (* 1 = 5388.27 loss)
I0315 11:10:59.227780 29479 solver.cpp:610] Iteration 40040, lr = 8.17868e-09
I0315 11:10:59.227794 29479 solver.cpp:613] Iteration 40040, avg_grad_norm = 528143
I0315 11:11:24.818492 29479 solver.cpp:214] Iteration 40060, loss = 6036.42
I0315 11:11:24.818624 29479 solver.cpp:229]     Train net output #0: loss = 7976.27 (* 1 = 7976.27 loss)
I0315 11:11:24.933370 29479 solver.cpp:610] Iteration 40060, lr = 8.17776e-09
I0315 11:11:24.933383 29479 solver.cpp:613] Iteration 40060, avg_grad_norm = 526838
I0315 11:11:50.477836 29479 solver.cpp:214] Iteration 40080, loss = 6442.65
I0315 11:11:50.477888 29479 solver.cpp:229]     Train net output #0: loss = 6394.2 (* 1 = 6394.2 loss)
I0315 11:11:50.592488 29479 solver.cpp:610] Iteration 40080, lr = 8.17684e-09
I0315 11:11:50.592500 29479 solver.cpp:613] Iteration 40080, avg_grad_norm = 550184
I0315 11:12:16.154018 29479 solver.cpp:214] Iteration 40100, loss = 6201.84
I0315 11:12:16.154232 29479 solver.cpp:229]     Train net output #0: loss = 5862.91 (* 1 = 5862.91 loss)
I0315 11:12:16.268450 29479 solver.cpp:610] Iteration 40100, lr = 8.17592e-09
I0315 11:12:16.268462 29479 solver.cpp:613] Iteration 40100, avg_grad_norm = 588618
I0315 11:12:41.810508 29479 solver.cpp:214] Iteration 40120, loss = 6279.95
I0315 11:12:41.810570 29479 solver.cpp:229]     Train net output #0: loss = 6204.56 (* 1 = 6204.56 loss)
I0315 11:12:41.925019 29479 solver.cpp:610] Iteration 40120, lr = 8.175e-09
I0315 11:12:41.925045 29479 solver.cpp:613] Iteration 40120, avg_grad_norm = 539035
I0315 11:13:19.103622 29479 solver.cpp:214] Iteration 40140, loss = 6405.1
I0315 11:13:19.103730 29479 solver.cpp:229]     Train net output #0: loss = 4062.14 (* 1 = 4062.14 loss)
I0315 11:13:19.207867 29479 solver.cpp:610] Iteration 40140, lr = 8.17408e-09
I0315 11:13:19.207880 29479 solver.cpp:613] Iteration 40140, avg_grad_norm = 553749
I0315 11:13:43.178231 29479 solver.cpp:214] Iteration 40160, loss = 5888.09
I0315 11:13:43.178297 29479 solver.cpp:229]     Train net output #0: loss = 5144.42 (* 1 = 5144.42 loss)
I0315 11:13:43.291573 29479 solver.cpp:610] Iteration 40160, lr = 8.17316e-09
I0315 11:13:43.291586 29479 solver.cpp:613] Iteration 40160, avg_grad_norm = 511157
I0315 11:14:08.853699 29479 solver.cpp:214] Iteration 40180, loss = 6282.22
I0315 11:14:08.853842 29479 solver.cpp:229]     Train net output #0: loss = 8612.46 (* 1 = 8612.46 loss)
I0315 11:14:08.968189 29479 solver.cpp:610] Iteration 40180, lr = 8.17224e-09
I0315 11:14:08.968201 29479 solver.cpp:613] Iteration 40180, avg_grad_norm = 498042
I0315 11:14:34.564179 29479 solver.cpp:214] Iteration 40200, loss = 6333.14
I0315 11:14:34.564244 29479 solver.cpp:229]     Train net output #0: loss = 5991.57 (* 1 = 5991.57 loss)
I0315 11:14:34.678867 29479 solver.cpp:610] Iteration 40200, lr = 8.17132e-09
I0315 11:14:34.678880 29479 solver.cpp:613] Iteration 40200, avg_grad_norm = 582976
I0315 11:15:00.278115 29479 solver.cpp:214] Iteration 40220, loss = 6363.55
I0315 11:15:00.278287 29479 solver.cpp:229]     Train net output #0: loss = 5361.07 (* 1 = 5361.07 loss)
I0315 11:15:00.392693 29479 solver.cpp:610] Iteration 40220, lr = 8.1704e-09
I0315 11:15:00.392706 29479 solver.cpp:613] Iteration 40220, avg_grad_norm = 522127
I0315 11:15:25.995581 29479 solver.cpp:214] Iteration 40240, loss = 6097.54
I0315 11:15:25.995642 29479 solver.cpp:229]     Train net output #0: loss = 5795.28 (* 1 = 5795.28 loss)
I0315 11:15:26.110180 29479 solver.cpp:610] Iteration 40240, lr = 8.16948e-09
I0315 11:15:26.110194 29479 solver.cpp:613] Iteration 40240, avg_grad_norm = 560918
I0315 11:16:21.456015 29479 solver.cpp:214] Iteration 40260, loss = 6083.12
I0315 11:16:21.456115 29479 solver.cpp:229]     Train net output #0: loss = 5968.83 (* 1 = 5968.83 loss)
I0315 11:16:21.561314 29479 solver.cpp:610] Iteration 40260, lr = 8.16856e-09
I0315 11:16:21.561327 29479 solver.cpp:613] Iteration 40260, avg_grad_norm = 584666
I0315 11:16:44.962600 29479 solver.cpp:214] Iteration 40280, loss = 6289.6
I0315 11:16:44.962666 29479 solver.cpp:229]     Train net output #0: loss = 4654.6 (* 1 = 4654.6 loss)
I0315 11:16:45.067883 29479 solver.cpp:610] Iteration 40280, lr = 8.16764e-09
I0315 11:16:45.067896 29479 solver.cpp:613] Iteration 40280, avg_grad_norm = 579923
I0315 11:17:08.524004 29479 solver.cpp:214] Iteration 40300, loss = 5857.31
I0315 11:17:08.524133 29479 solver.cpp:229]     Train net output #0: loss = 5020.3 (* 1 = 5020.3 loss)
I0315 11:17:08.628466 29479 solver.cpp:610] Iteration 40300, lr = 8.16672e-09
I0315 11:17:08.628479 29479 solver.cpp:613] Iteration 40300, avg_grad_norm = 549432
I0315 11:17:33.150579 29479 solver.cpp:214] Iteration 40320, loss = 6338.44
I0315 11:17:33.150645 29479 solver.cpp:229]     Train net output #0: loss = 5082.46 (* 1 = 5082.46 loss)
I0315 11:17:33.262186 29479 solver.cpp:610] Iteration 40320, lr = 8.1658e-09
I0315 11:17:33.262207 29479 solver.cpp:613] Iteration 40320, avg_grad_norm = 539301
I0315 11:17:58.290300 29479 solver.cpp:214] Iteration 40340, loss = 6343.57
I0315 11:17:58.290415 29479 solver.cpp:229]     Train net output #0: loss = 3436.48 (* 1 = 3436.48 loss)
I0315 11:17:58.403503 29479 solver.cpp:610] Iteration 40340, lr = 8.16487e-09
I0315 11:17:58.403517 29479 solver.cpp:613] Iteration 40340, avg_grad_norm = 531952
I0315 11:18:23.909603 29479 solver.cpp:214] Iteration 40360, loss = 5944.05
I0315 11:18:23.909669 29479 solver.cpp:229]     Train net output #0: loss = 5725.08 (* 1 = 5725.08 loss)
I0315 11:18:24.024173 29479 solver.cpp:610] Iteration 40360, lr = 8.16395e-09
I0315 11:18:24.024185 29479 solver.cpp:613] Iteration 40360, avg_grad_norm = 491954
I0315 11:18:49.574903 29479 solver.cpp:214] Iteration 40380, loss = 6282.44
I0315 11:18:49.575016 29479 solver.cpp:229]     Train net output #0: loss = 5687.39 (* 1 = 5687.39 loss)
I0315 11:18:49.689579 29479 solver.cpp:610] Iteration 40380, lr = 8.16303e-09
I0315 11:18:49.689599 29479 solver.cpp:613] Iteration 40380, avg_grad_norm = 527334
I0315 11:19:44.374171 29479 solver.cpp:214] Iteration 40400, loss = 6556.17
I0315 11:19:44.374398 29479 solver.cpp:229]     Train net output #0: loss = 10052.4 (* 1 = 10052.4 loss)
I0315 11:19:44.478303 29479 solver.cpp:610] Iteration 40400, lr = 8.16211e-09
I0315 11:19:44.478317 29479 solver.cpp:613] Iteration 40400, avg_grad_norm = 543939
I0315 11:20:07.912014 29479 solver.cpp:214] Iteration 40420, loss = 6310.53
I0315 11:20:07.912086 29479 solver.cpp:229]     Train net output #0: loss = 4048.85 (* 1 = 4048.85 loss)
I0315 11:20:08.017206 29479 solver.cpp:610] Iteration 40420, lr = 8.16119e-09
I0315 11:20:08.017220 29479 solver.cpp:613] Iteration 40420, avg_grad_norm = 562660
I0315 11:20:32.094981 29479 solver.cpp:214] Iteration 40440, loss = 6504.16
I0315 11:20:32.095204 29479 solver.cpp:229]     Train net output #0: loss = 5969.29 (* 1 = 5969.29 loss)
I0315 11:20:32.208046 29479 solver.cpp:610] Iteration 40440, lr = 8.16027e-09
I0315 11:20:32.208060 29479 solver.cpp:613] Iteration 40440, avg_grad_norm = 677914
I0315 11:20:57.630079 29479 solver.cpp:214] Iteration 40460, loss = 6410.85
I0315 11:20:57.630131 29479 solver.cpp:229]     Train net output #0: loss = 7874.68 (* 1 = 7874.68 loss)
I0315 11:20:57.744740 29479 solver.cpp:610] Iteration 40460, lr = 8.15935e-09
I0315 11:20:57.744752 29479 solver.cpp:613] Iteration 40460, avg_grad_norm = 593134
I0315 11:21:23.018857 29479 solver.cpp:214] Iteration 40480, loss = 5948.33
I0315 11:21:23.018988 29479 solver.cpp:229]     Train net output #0: loss = 4553.23 (* 1 = 4553.23 loss)
I0315 11:21:23.131816 29479 solver.cpp:610] Iteration 40480, lr = 8.15843e-09
I0315 11:21:23.131829 29479 solver.cpp:613] Iteration 40480, avg_grad_norm = 584308
I0315 11:21:48.323333 29479 solver.cpp:214] Iteration 40500, loss = 6423.04
I0315 11:21:48.323400 29479 solver.cpp:229]     Train net output #0: loss = 2924.8 (* 1 = 2924.8 loss)
I0315 11:21:48.436329 29479 solver.cpp:610] Iteration 40500, lr = 8.15751e-09
I0315 11:21:48.436342 29479 solver.cpp:613] Iteration 40500, avg_grad_norm = 547274
I0315 11:22:25.596361 29479 solver.cpp:214] Iteration 40520, loss = 6136.58
I0315 11:22:25.596488 29479 solver.cpp:229]     Train net output #0: loss = 4582.26 (* 1 = 4582.26 loss)
I0315 11:22:25.701556 29479 solver.cpp:610] Iteration 40520, lr = 8.15659e-09
I0315 11:22:25.701570 29479 solver.cpp:613] Iteration 40520, avg_grad_norm = 559229
I0315 11:22:49.636149 29479 solver.cpp:214] Iteration 40540, loss = 6141.21
I0315 11:22:49.636204 29479 solver.cpp:229]     Train net output #0: loss = 8806.46 (* 1 = 8806.46 loss)
I0315 11:22:49.750880 29479 solver.cpp:610] Iteration 40540, lr = 8.15567e-09
I0315 11:22:49.750893 29479 solver.cpp:613] Iteration 40540, avg_grad_norm = 576995
I0315 11:23:15.302575 29479 solver.cpp:214] Iteration 40560, loss = 6441.89
I0315 11:23:15.302700 29479 solver.cpp:229]     Train net output #0: loss = 4113.55 (* 1 = 4113.55 loss)
I0315 11:23:15.417305 29479 solver.cpp:610] Iteration 40560, lr = 8.15475e-09
I0315 11:23:15.417318 29479 solver.cpp:613] Iteration 40560, avg_grad_norm = 503741
I0315 11:23:40.956590 29479 solver.cpp:214] Iteration 40580, loss = 6217.8
I0315 11:23:40.956650 29479 solver.cpp:229]     Train net output #0: loss = 3192.63 (* 1 = 3192.63 loss)
I0315 11:23:41.071159 29479 solver.cpp:610] Iteration 40580, lr = 8.15383e-09
I0315 11:23:41.071172 29479 solver.cpp:613] Iteration 40580, avg_grad_norm = 508286
I0315 11:24:06.643746 29479 solver.cpp:214] Iteration 40600, loss = 6153.28
I0315 11:24:06.643887 29479 solver.cpp:229]     Train net output #0: loss = 7619.08 (* 1 = 7619.08 loss)
I0315 11:24:06.758381 29479 solver.cpp:610] Iteration 40600, lr = 8.15291e-09
I0315 11:24:06.758431 29479 solver.cpp:613] Iteration 40600, avg_grad_norm = 510439
I0315 11:24:32.359714 29479 solver.cpp:214] Iteration 40620, loss = 5888.47
I0315 11:24:32.359760 29479 solver.cpp:229]     Train net output #0: loss = 7840.93 (* 1 = 7840.93 loss)
I0315 11:24:32.474187 29479 solver.cpp:610] Iteration 40620, lr = 8.15199e-09
I0315 11:24:32.474200 29479 solver.cpp:613] Iteration 40620, avg_grad_norm = 517742
I0315 11:25:10.938168 29479 solver.cpp:214] Iteration 40640, loss = 6195.77
I0315 11:25:10.938319 29479 solver.cpp:229]     Train net output #0: loss = 5409.21 (* 1 = 5409.21 loss)
I0315 11:25:11.043311 29479 solver.cpp:610] Iteration 40640, lr = 8.15107e-09
I0315 11:25:11.043325 29479 solver.cpp:613] Iteration 40640, avg_grad_norm = 529248
I0315 11:25:34.483126 29479 solver.cpp:214] Iteration 40660, loss = 6002.33
I0315 11:25:34.483187 29479 solver.cpp:229]     Train net output #0: loss = 5372.54 (* 1 = 5372.54 loss)
I0315 11:25:34.588376 29479 solver.cpp:610] Iteration 40660, lr = 8.15014e-09
I0315 11:25:34.588389 29479 solver.cpp:613] Iteration 40660, avg_grad_norm = 534968
I0315 11:25:59.382247 29479 solver.cpp:214] Iteration 40680, loss = 6018.14
I0315 11:25:59.382377 29479 solver.cpp:229]     Train net output #0: loss = 5937.26 (* 1 = 5937.26 loss)
I0315 11:25:59.496948 29479 solver.cpp:610] Iteration 40680, lr = 8.14922e-09
I0315 11:25:59.496960 29479 solver.cpp:613] Iteration 40680, avg_grad_norm = 564192
I0315 11:26:25.099932 29479 solver.cpp:214] Iteration 40700, loss = 6154.86
I0315 11:26:25.099989 29479 solver.cpp:229]     Train net output #0: loss = 5938.44 (* 1 = 5938.44 loss)
I0315 11:26:25.214637 29479 solver.cpp:610] Iteration 40700, lr = 8.1483e-09
I0315 11:26:25.214653 29479 solver.cpp:613] Iteration 40700, avg_grad_norm = 568994
I0315 11:26:50.852792 29479 solver.cpp:214] Iteration 40720, loss = 6139.05
I0315 11:26:50.853001 29479 solver.cpp:229]     Train net output #0: loss = 5541.5 (* 1 = 5541.5 loss)
I0315 11:26:50.967418 29479 solver.cpp:610] Iteration 40720, lr = 8.14738e-09
I0315 11:26:50.967432 29479 solver.cpp:613] Iteration 40720, avg_grad_norm = 580854
I0315 11:27:16.513473 29479 solver.cpp:214] Iteration 40740, loss = 6024.26
I0315 11:27:16.513533 29479 solver.cpp:229]     Train net output #0: loss = 4603.91 (* 1 = 4603.91 loss)
I0315 11:27:16.628268 29479 solver.cpp:610] Iteration 40740, lr = 8.14646e-09
I0315 11:27:16.628279 29479 solver.cpp:613] Iteration 40740, avg_grad_norm = 539459
I0315 11:27:42.278956 29479 solver.cpp:214] Iteration 40760, loss = 6071.59
I0315 11:27:42.279088 29479 solver.cpp:229]     Train net output #0: loss = 3885.46 (* 1 = 3885.46 loss)
I0315 11:27:42.393532 29479 solver.cpp:610] Iteration 40760, lr = 8.14554e-09
I0315 11:27:42.393544 29479 solver.cpp:613] Iteration 40760, avg_grad_norm = 524259
I0315 11:28:19.153831 29479 solver.cpp:214] Iteration 40780, loss = 6039.21
I0315 11:28:19.153973 29479 solver.cpp:229]     Train net output #0: loss = 5855.08 (* 1 = 5855.08 loss)
I0315 11:28:19.258914 29479 solver.cpp:610] Iteration 40780, lr = 8.14462e-09
I0315 11:28:19.258927 29479 solver.cpp:613] Iteration 40780, avg_grad_norm = 560087
I0315 11:28:43.774474 29479 solver.cpp:214] Iteration 40800, loss = 6107.23
I0315 11:28:43.774538 29479 solver.cpp:229]     Train net output #0: loss = 6299.38 (* 1 = 6299.38 loss)
I0315 11:28:43.889195 29479 solver.cpp:610] Iteration 40800, lr = 8.1437e-09
I0315 11:28:43.889209 29479 solver.cpp:613] Iteration 40800, avg_grad_norm = 559313
I0315 11:29:09.466153 29479 solver.cpp:214] Iteration 40820, loss = 6059.41
I0315 11:29:09.466271 29479 solver.cpp:229]     Train net output #0: loss = 9156.05 (* 1 = 9156.05 loss)
I0315 11:29:09.580484 29479 solver.cpp:610] Iteration 40820, lr = 8.14278e-09
I0315 11:29:09.580497 29479 solver.cpp:613] Iteration 40820, avg_grad_norm = 555171
I0315 11:29:35.107306 29479 solver.cpp:214] Iteration 40840, loss = 6089.14
I0315 11:29:35.107360 29479 solver.cpp:229]     Train net output #0: loss = 3749.57 (* 1 = 3749.57 loss)
I0315 11:29:35.221911 29479 solver.cpp:610] Iteration 40840, lr = 8.14186e-09
I0315 11:29:35.221926 29479 solver.cpp:613] Iteration 40840, avg_grad_norm = 553686
I0315 11:30:00.762974 29479 solver.cpp:214] Iteration 40860, loss = 6221.43
I0315 11:30:00.763121 29479 solver.cpp:229]     Train net output #0: loss = 7198.7 (* 1 = 7198.7 loss)
I0315 11:30:00.877568 29479 solver.cpp:610] Iteration 40860, lr = 8.14094e-09
I0315 11:30:00.877581 29479 solver.cpp:613] Iteration 40860, avg_grad_norm = 549251
I0315 11:30:26.464524 29479 solver.cpp:214] Iteration 40880, loss = 6466.44
I0315 11:30:26.464588 29479 solver.cpp:229]     Train net output #0: loss = 11751 (* 1 = 11751 loss)
I0315 11:30:26.578975 29479 solver.cpp:610] Iteration 40880, lr = 8.14002e-09
I0315 11:30:26.578990 29479 solver.cpp:613] Iteration 40880, avg_grad_norm = 554552
I0315 11:31:07.254549 29479 solver.cpp:214] Iteration 40900, loss = 6143.52
I0315 11:31:07.254694 29479 solver.cpp:229]     Train net output #0: loss = 8209.29 (* 1 = 8209.29 loss)
I0315 11:31:07.358942 29479 solver.cpp:610] Iteration 40900, lr = 8.1391e-09
I0315 11:31:07.358954 29479 solver.cpp:613] Iteration 40900, avg_grad_norm = 551972
I0315 11:31:30.802511 29479 solver.cpp:214] Iteration 40920, loss = 5860.08
I0315 11:31:30.802580 29479 solver.cpp:229]     Train net output #0: loss = 4380.31 (* 1 = 4380.31 loss)
I0315 11:31:30.907601 29479 solver.cpp:610] Iteration 40920, lr = 8.13818e-09
I0315 11:31:30.907637 29479 solver.cpp:613] Iteration 40920, avg_grad_norm = 656125
I0315 11:31:56.607668 29479 solver.cpp:214] Iteration 40940, loss = 6658.09
I0315 11:31:56.607857 29479 solver.cpp:229]     Train net output #0: loss = 5555.27 (* 1 = 5555.27 loss)
I0315 11:31:56.722215 29479 solver.cpp:610] Iteration 40940, lr = 8.13725e-09
I0315 11:31:56.722247 29479 solver.cpp:613] Iteration 40940, avg_grad_norm = 581529
I0315 11:32:22.108815 29479 solver.cpp:214] Iteration 40960, loss = 6360.4
I0315 11:32:22.108862 29479 solver.cpp:229]     Train net output #0: loss = 9764.12 (* 1 = 9764.12 loss)
I0315 11:32:22.222043 29479 solver.cpp:610] Iteration 40960, lr = 8.13633e-09
I0315 11:32:22.222056 29479 solver.cpp:613] Iteration 40960, avg_grad_norm = 526080
I0315 11:32:47.620766 29479 solver.cpp:214] Iteration 40980, loss = 5810.89
I0315 11:32:47.620903 29479 solver.cpp:229]     Train net output #0: loss = 8062.17 (* 1 = 8062.17 loss)
I0315 11:32:47.735385 29479 solver.cpp:610] Iteration 40980, lr = 8.13541e-09
I0315 11:32:47.735399 29479 solver.cpp:613] Iteration 40980, avg_grad_norm = 517497
I0315 11:33:13.384650 29479 solver.cpp:214] Iteration 41000, loss = 6245.36
I0315 11:33:13.384711 29479 solver.cpp:229]     Train net output #0: loss = 4435.77 (* 1 = 4435.77 loss)
I0315 11:33:13.499183 29479 solver.cpp:610] Iteration 41000, lr = 8.13449e-09
I0315 11:33:13.499197 29479 solver.cpp:613] Iteration 41000, avg_grad_norm = 546913
I0315 11:34:19.906946 29479 solver.cpp:214] Iteration 41020, loss = 6008.38
I0315 11:34:19.907095 29479 solver.cpp:229]     Train net output #0: loss = 10029.1 (* 1 = 10029.1 loss)
I0315 11:34:20.010830 29479 solver.cpp:610] Iteration 41020, lr = 8.13357e-09
I0315 11:34:20.010881 29479 solver.cpp:613] Iteration 41020, avg_grad_norm = 550685
I0315 11:34:43.427527 29479 solver.cpp:214] Iteration 41040, loss = 6413.89
I0315 11:34:43.427597 29479 solver.cpp:229]     Train net output #0: loss = 7586.31 (* 1 = 7586.31 loss)
I0315 11:34:43.531955 29479 solver.cpp:610] Iteration 41040, lr = 8.13265e-09
I0315 11:34:43.531968 29479 solver.cpp:613] Iteration 41040, avg_grad_norm = 590342
I0315 11:35:07.013609 29479 solver.cpp:214] Iteration 41060, loss = 6001.7
I0315 11:35:07.013809 29479 solver.cpp:229]     Train net output #0: loss = 7096.78 (* 1 = 7096.78 loss)
I0315 11:35:07.118782 29479 solver.cpp:610] Iteration 41060, lr = 8.13173e-09
I0315 11:35:07.118796 29479 solver.cpp:613] Iteration 41060, avg_grad_norm = 575208
I0315 11:35:30.647977 29479 solver.cpp:214] Iteration 41080, loss = 5925.17
I0315 11:35:30.648049 29479 solver.cpp:229]     Train net output #0: loss = 4059.06 (* 1 = 4059.06 loss)
I0315 11:35:30.754627 29479 solver.cpp:610] Iteration 41080, lr = 8.13081e-09
I0315 11:35:30.754640 29479 solver.cpp:613] Iteration 41080, avg_grad_norm = 529757
I0315 11:35:55.896227 29479 solver.cpp:214] Iteration 41100, loss = 5967.26
I0315 11:35:55.896364 29479 solver.cpp:229]     Train net output #0: loss = 4954.19 (* 1 = 4954.19 loss)
I0315 11:35:56.012333 29479 solver.cpp:610] Iteration 41100, lr = 8.12989e-09
I0315 11:35:56.012347 29479 solver.cpp:613] Iteration 41100, avg_grad_norm = 565370
I0315 11:36:21.684324 29479 solver.cpp:214] Iteration 41120, loss = 6090.11
I0315 11:36:21.684378 29479 solver.cpp:229]     Train net output #0: loss = 4553.54 (* 1 = 4553.54 loss)
I0315 11:36:21.797308 29479 solver.cpp:610] Iteration 41120, lr = 8.12897e-09
I0315 11:36:21.797322 29479 solver.cpp:613] Iteration 41120, avg_grad_norm = 546726
I0315 11:36:47.088199 29479 solver.cpp:214] Iteration 41140, loss = 5971.33
I0315 11:36:47.088363 29479 solver.cpp:229]     Train net output #0: loss = 4653.58 (* 1 = 4653.58 loss)
I0315 11:36:47.201208 29479 solver.cpp:610] Iteration 41140, lr = 8.12804e-09
I0315 11:36:47.201221 29479 solver.cpp:613] Iteration 41140, avg_grad_norm = 512473
I0315 11:37:23.999940 29479 solver.cpp:214] Iteration 41160, loss = 6150.12
I0315 11:37:24.000080 29479 solver.cpp:229]     Train net output #0: loss = 7967.3 (* 1 = 7967.3 loss)
I0315 11:37:24.105092 29479 solver.cpp:610] Iteration 41160, lr = 8.12712e-09
I0315 11:37:24.105105 29479 solver.cpp:613] Iteration 41160, avg_grad_norm = 499146
I0315 11:37:48.437166 29479 solver.cpp:214] Iteration 41180, loss = 6095.9
I0315 11:37:48.437228 29479 solver.cpp:229]     Train net output #0: loss = 6601.69 (* 1 = 6601.69 loss)
I0315 11:37:48.550173 29479 solver.cpp:610] Iteration 41180, lr = 8.1262e-09
I0315 11:37:48.550185 29479 solver.cpp:613] Iteration 41180, avg_grad_norm = 594854
I0315 11:38:14.124238 29479 solver.cpp:214] Iteration 41200, loss = 5898.88
I0315 11:38:14.124357 29479 solver.cpp:229]     Train net output #0: loss = 8333.31 (* 1 = 8333.31 loss)
I0315 11:38:14.240212 29479 solver.cpp:610] Iteration 41200, lr = 8.12528e-09
I0315 11:38:14.240226 29479 solver.cpp:613] Iteration 41200, avg_grad_norm = 646093
I0315 11:38:39.929075 29479 solver.cpp:214] Iteration 41220, loss = 6320.15
I0315 11:38:39.929137 29479 solver.cpp:229]     Train net output #0: loss = 3424.94 (* 1 = 3424.94 loss)
I0315 11:38:40.041965 29479 solver.cpp:610] Iteration 41220, lr = 8.12436e-09
I0315 11:38:40.041978 29479 solver.cpp:613] Iteration 41220, avg_grad_norm = 580543
I0315 11:39:05.318483 29479 solver.cpp:214] Iteration 41240, loss = 6171.18
I0315 11:39:05.318619 29479 solver.cpp:229]     Train net output #0: loss = 5703.53 (* 1 = 5703.53 loss)
I0315 11:39:05.431591 29479 solver.cpp:610] Iteration 41240, lr = 8.12344e-09
I0315 11:39:05.431627 29479 solver.cpp:613] Iteration 41240, avg_grad_norm = 601330
I0315 11:39:31.011972 29479 solver.cpp:214] Iteration 41260, loss = 6399.91
I0315 11:39:31.012023 29479 solver.cpp:229]     Train net output #0: loss = 6621.23 (* 1 = 6621.23 loss)
I0315 11:39:31.126652 29479 solver.cpp:610] Iteration 41260, lr = 8.12252e-09
I0315 11:39:31.126665 29479 solver.cpp:613] Iteration 41260, avg_grad_norm = 616797
I0315 11:40:09.429297 29479 solver.cpp:214] Iteration 41280, loss = 5965.13
I0315 11:40:09.429488 29479 solver.cpp:229]     Train net output #0: loss = 9850.04 (* 1 = 9850.04 loss)
I0315 11:40:09.534540 29479 solver.cpp:610] Iteration 41280, lr = 8.1216e-09
I0315 11:40:09.534554 29479 solver.cpp:613] Iteration 41280, avg_grad_norm = 542328
I0315 11:40:33.217749 29479 solver.cpp:214] Iteration 41300, loss = 6347.96
I0315 11:40:33.217821 29479 solver.cpp:229]     Train net output #0: loss = 8466.54 (* 1 = 8466.54 loss)
I0315 11:40:33.332383 29479 solver.cpp:610] Iteration 41300, lr = 8.12068e-09
I0315 11:40:33.332398 29479 solver.cpp:613] Iteration 41300, avg_grad_norm = 678395
I0315 11:40:58.875643 29479 solver.cpp:214] Iteration 41320, loss = 6177.72
I0315 11:40:58.875767 29479 solver.cpp:229]     Train net output #0: loss = 6027.72 (* 1 = 6027.72 loss)
I0315 11:40:58.990165 29479 solver.cpp:610] Iteration 41320, lr = 8.11976e-09
I0315 11:40:58.990178 29479 solver.cpp:613] Iteration 41320, avg_grad_norm = 618132
I0315 11:41:24.531821 29479 solver.cpp:214] Iteration 41340, loss = 6051.99
I0315 11:41:24.531918 29479 solver.cpp:229]     Train net output #0: loss = 4430.05 (* 1 = 4430.05 loss)
I0315 11:41:24.646387 29479 solver.cpp:610] Iteration 41340, lr = 8.11884e-09
I0315 11:41:24.646400 29479 solver.cpp:613] Iteration 41340, avg_grad_norm = 533353
I0315 11:41:50.185956 29479 solver.cpp:214] Iteration 41360, loss = 6422.47
I0315 11:41:50.186084 29479 solver.cpp:229]     Train net output #0: loss = 8132 (* 1 = 8132 loss)
I0315 11:41:50.300290 29479 solver.cpp:610] Iteration 41360, lr = 8.11791e-09
I0315 11:41:50.300303 29479 solver.cpp:613] Iteration 41360, avg_grad_norm = 571820
I0315 11:42:15.685833 29479 solver.cpp:214] Iteration 41380, loss = 6345.85
I0315 11:42:15.685901 29479 solver.cpp:229]     Train net output #0: loss = 3035.14 (* 1 = 3035.14 loss)
I0315 11:42:15.799074 29479 solver.cpp:610] Iteration 41380, lr = 8.11699e-09
I0315 11:42:15.799088 29479 solver.cpp:613] Iteration 41380, avg_grad_norm = 571175
I0315 11:42:54.097645 29479 solver.cpp:214] Iteration 41400, loss = 6043.28
I0315 11:42:54.097838 29479 solver.cpp:229]     Train net output #0: loss = 10464 (* 1 = 10464 loss)
I0315 11:42:54.201557 29479 solver.cpp:610] Iteration 41400, lr = 8.11607e-09
I0315 11:42:54.201570 29479 solver.cpp:613] Iteration 41400, avg_grad_norm = 552302
I0315 11:43:17.647076 29479 solver.cpp:214] Iteration 41420, loss = 6558.23
I0315 11:43:17.647136 29479 solver.cpp:229]     Train net output #0: loss = 3800.9 (* 1 = 3800.9 loss)
I0315 11:43:17.752149 29479 solver.cpp:610] Iteration 41420, lr = 8.11515e-09
I0315 11:43:17.752162 29479 solver.cpp:613] Iteration 41420, avg_grad_norm = 540146
I0315 11:43:42.877804 29479 solver.cpp:214] Iteration 41440, loss = 5950.06
I0315 11:43:42.877912 29479 solver.cpp:229]     Train net output #0: loss = 8074.46 (* 1 = 8074.46 loss)
I0315 11:43:42.992533 29479 solver.cpp:610] Iteration 41440, lr = 8.11423e-09
I0315 11:43:42.992545 29479 solver.cpp:613] Iteration 41440, avg_grad_norm = 543524
I0315 11:44:08.555698 29479 solver.cpp:214] Iteration 41460, loss = 6120.09
I0315 11:44:08.555752 29479 solver.cpp:229]     Train net output #0: loss = 2249.21 (* 1 = 2249.21 loss)
I0315 11:44:08.670315 29479 solver.cpp:610] Iteration 41460, lr = 8.11331e-09
I0315 11:44:08.670328 29479 solver.cpp:613] Iteration 41460, avg_grad_norm = 533423
I0315 11:44:34.258728 29479 solver.cpp:214] Iteration 41480, loss = 6367.12
I0315 11:44:34.258864 29479 solver.cpp:229]     Train net output #0: loss = 5123.78 (* 1 = 5123.78 loss)
I0315 11:44:34.373272 29479 solver.cpp:610] Iteration 41480, lr = 8.11239e-09
I0315 11:44:34.373286 29479 solver.cpp:613] Iteration 41480, avg_grad_norm = 499993
I0315 11:44:59.966472 29479 solver.cpp:214] Iteration 41500, loss = 6152.71
I0315 11:44:59.966522 29479 solver.cpp:229]     Train net output #0: loss = 6358.38 (* 1 = 6358.38 loss)
I0315 11:45:00.081198 29479 solver.cpp:610] Iteration 41500, lr = 8.11147e-09
I0315 11:45:00.081212 29479 solver.cpp:613] Iteration 41500, avg_grad_norm = 528034
I0315 11:45:25.686281 29479 solver.cpp:214] Iteration 41520, loss = 6216
I0315 11:45:25.686411 29479 solver.cpp:229]     Train net output #0: loss = 6044.49 (* 1 = 6044.49 loss)
I0315 11:45:25.800923 29479 solver.cpp:610] Iteration 41520, lr = 8.11055e-09
I0315 11:45:25.800936 29479 solver.cpp:613] Iteration 41520, avg_grad_norm = 559091
I0315 11:46:06.597803 29479 solver.cpp:214] Iteration 41540, loss = 6035.16
I0315 11:46:06.597904 29479 solver.cpp:229]     Train net output #0: loss = 3416.74 (* 1 = 3416.74 loss)
I0315 11:46:06.703109 29479 solver.cpp:610] Iteration 41540, lr = 8.10962e-09
I0315 11:46:06.703122 29479 solver.cpp:613] Iteration 41540, avg_grad_norm = 549894
I0315 11:46:30.435945 29479 solver.cpp:214] Iteration 41560, loss = 5736.61
I0315 11:46:30.436012 29479 solver.cpp:229]     Train net output #0: loss = 8851.61 (* 1 = 8851.61 loss)
I0315 11:46:30.549093 29479 solver.cpp:610] Iteration 41560, lr = 8.1087e-09
I0315 11:46:30.549106 29479 solver.cpp:613] Iteration 41560, avg_grad_norm = 503075
I0315 11:46:56.134920 29479 solver.cpp:214] Iteration 41580, loss = 6085.06
I0315 11:46:56.135005 29479 solver.cpp:229]     Train net output #0: loss = 8181.21 (* 1 = 8181.21 loss)
I0315 11:46:56.249405 29479 solver.cpp:610] Iteration 41580, lr = 8.10778e-09
I0315 11:46:56.249418 29479 solver.cpp:613] Iteration 41580, avg_grad_norm = 459676
I0315 11:47:21.847249 29479 solver.cpp:214] Iteration 41600, loss = 6231.05
I0315 11:47:21.847306 29479 solver.cpp:229]     Train net output #0: loss = 12905.6 (* 1 = 12905.6 loss)
I0315 11:47:21.962007 29479 solver.cpp:610] Iteration 41600, lr = 8.10686e-09
I0315 11:47:21.962020 29479 solver.cpp:613] Iteration 41600, avg_grad_norm = 586949
I0315 11:47:47.480149 29479 solver.cpp:214] Iteration 41620, loss = 6196.55
I0315 11:47:47.480334 29479 solver.cpp:229]     Train net output #0: loss = 4566.55 (* 1 = 4566.55 loss)
I0315 11:47:47.593034 29479 solver.cpp:610] Iteration 41620, lr = 8.10594e-09
I0315 11:47:47.593046 29479 solver.cpp:613] Iteration 41620, avg_grad_norm = 554323
I0315 11:48:13.005082 29479 solver.cpp:214] Iteration 41640, loss = 6156.97
I0315 11:48:13.005143 29479 solver.cpp:229]     Train net output #0: loss = 5138.75 (* 1 = 5138.75 loss)
I0315 11:48:13.121168 29479 solver.cpp:610] Iteration 41640, lr = 8.10502e-09
I0315 11:48:13.121182 29479 solver.cpp:613] Iteration 41640, avg_grad_norm = 491424
I0315 11:49:13.255072 29479 solver.cpp:214] Iteration 41660, loss = 6322.62
I0315 11:49:13.255233 29479 solver.cpp:229]     Train net output #0: loss = 6743.06 (* 1 = 6743.06 loss)
I0315 11:49:13.360417 29479 solver.cpp:610] Iteration 41660, lr = 8.1041e-09
I0315 11:49:13.360466 29479 solver.cpp:613] Iteration 41660, avg_grad_norm = 522399
I0315 11:49:36.813331 29479 solver.cpp:214] Iteration 41680, loss = 6197.93
I0315 11:49:36.813390 29479 solver.cpp:229]     Train net output #0: loss = 5719.18 (* 1 = 5719.18 loss)
I0315 11:49:36.918501 29479 solver.cpp:610] Iteration 41680, lr = 8.10318e-09
I0315 11:49:36.918514 29479 solver.cpp:613] Iteration 41680, avg_grad_norm = 573719
I0315 11:50:00.383100 29479 solver.cpp:214] Iteration 41700, loss = 6287.6
I0315 11:50:00.383216 29479 solver.cpp:229]     Train net output #0: loss = 11012.6 (* 1 = 11012.6 loss)
I0315 11:50:00.486995 29479 solver.cpp:610] Iteration 41700, lr = 8.10225e-09
I0315 11:50:00.487009 29479 solver.cpp:613] Iteration 41700, avg_grad_norm = 559944
I0315 11:50:24.726604 29479 solver.cpp:214] Iteration 41720, loss = 5948.15
I0315 11:50:24.726665 29479 solver.cpp:229]     Train net output #0: loss = 3952.72 (* 1 = 3952.72 loss)
I0315 11:50:24.839751 29479 solver.cpp:610] Iteration 41720, lr = 8.10133e-09
I0315 11:50:24.839766 29479 solver.cpp:613] Iteration 41720, avg_grad_norm = 514568
I0315 11:50:50.350352 29479 solver.cpp:214] Iteration 41740, loss = 6263.67
I0315 11:50:50.350518 29479 solver.cpp:229]     Train net output #0: loss = 7818.67 (* 1 = 7818.67 loss)
I0315 11:50:50.464978 29479 solver.cpp:610] Iteration 41740, lr = 8.10041e-09
I0315 11:50:50.464992 29479 solver.cpp:613] Iteration 41740, avg_grad_norm = 555457
I0315 11:51:16.015954 29479 solver.cpp:214] Iteration 41760, loss = 6080.32
I0315 11:51:16.016031 29479 solver.cpp:229]     Train net output #0: loss = 4538.48 (* 1 = 4538.48 loss)
I0315 11:51:16.130424 29479 solver.cpp:610] Iteration 41760, lr = 8.09949e-09
I0315 11:51:16.130437 29479 solver.cpp:613] Iteration 41760, avg_grad_norm = 573532
I0315 11:51:41.676517 29479 solver.cpp:214] Iteration 41780, loss = 6328.12
I0315 11:51:41.676628 29479 solver.cpp:229]     Train net output #0: loss = 6330.34 (* 1 = 6330.34 loss)
I0315 11:51:41.789394 29479 solver.cpp:610] Iteration 41780, lr = 8.09857e-09
I0315 11:51:41.789407 29479 solver.cpp:613] Iteration 41780, avg_grad_norm = 590661
I0315 11:52:20.013525 29479 solver.cpp:214] Iteration 41800, loss = 6015.31
I0315 11:52:20.013672 29479 solver.cpp:229]     Train net output #0: loss = 8783.15 (* 1 = 8783.15 loss)
I0315 11:52:20.118759 29479 solver.cpp:610] Iteration 41800, lr = 8.09765e-09
I0315 11:52:20.118772 29479 solver.cpp:613] Iteration 41800, avg_grad_norm = 525775
I0315 11:52:44.657194 29479 solver.cpp:214] Iteration 41820, loss = 6057
I0315 11:52:44.657256 29479 solver.cpp:229]     Train net output #0: loss = 3331.33 (* 1 = 3331.33 loss)
I0315 11:52:44.771842 29479 solver.cpp:610] Iteration 41820, lr = 8.09673e-09
I0315 11:52:44.771854 29479 solver.cpp:613] Iteration 41820, avg_grad_norm = 544114
I0315 11:53:10.301270 29479 solver.cpp:214] Iteration 41840, loss = 6052.47
I0315 11:53:10.301389 29479 solver.cpp:229]     Train net output #0: loss = 5296.25 (* 1 = 5296.25 loss)
I0315 11:53:10.415875 29479 solver.cpp:610] Iteration 41840, lr = 8.0958e-09
I0315 11:53:10.415889 29479 solver.cpp:613] Iteration 41840, avg_grad_norm = 535849
I0315 11:53:35.938722 29479 solver.cpp:214] Iteration 41860, loss = 6584.25
I0315 11:53:35.938786 29479 solver.cpp:229]     Train net output #0: loss = 4467.31 (* 1 = 4467.31 loss)
I0315 11:53:36.051797 29479 solver.cpp:610] Iteration 41860, lr = 8.09488e-09
I0315 11:53:36.051810 29479 solver.cpp:613] Iteration 41860, avg_grad_norm = 507488
I0315 11:54:01.252329 29479 solver.cpp:214] Iteration 41880, loss = 5928.14
I0315 11:54:01.252519 29479 solver.cpp:229]     Train net output #0: loss = 7873.59 (* 1 = 7873.59 loss)
I0315 11:54:01.365406 29479 solver.cpp:610] Iteration 41880, lr = 8.09396e-09
I0315 11:54:01.365460 29479 solver.cpp:613] Iteration 41880, avg_grad_norm = 574819
I0315 11:54:26.876484 29479 solver.cpp:214] Iteration 41900, loss = 6269.16
I0315 11:54:26.876543 29479 solver.cpp:229]     Train net output #0: loss = 9089.38 (* 1 = 9089.38 loss)
I0315 11:54:26.991178 29479 solver.cpp:610] Iteration 41900, lr = 8.09304e-09
I0315 11:54:26.991192 29479 solver.cpp:613] Iteration 41900, avg_grad_norm = 532876
I0315 11:55:04.373927 29479 solver.cpp:214] Iteration 41920, loss = 6143.15
I0315 11:55:04.374047 29479 solver.cpp:229]     Train net output #0: loss = 4409.61 (* 1 = 4409.61 loss)
I0315 11:55:04.479070 29479 solver.cpp:610] Iteration 41920, lr = 8.09212e-09
I0315 11:55:04.479084 29479 solver.cpp:613] Iteration 41920, avg_grad_norm = 544207
I0315 11:55:28.488557 29479 solver.cpp:214] Iteration 41940, loss = 6041.86
I0315 11:55:28.488620 29479 solver.cpp:229]     Train net output #0: loss = 5923.61 (* 1 = 5923.61 loss)
I0315 11:55:28.601461 29479 solver.cpp:610] Iteration 41940, lr = 8.0912e-09
I0315 11:55:28.601475 29479 solver.cpp:613] Iteration 41940, avg_grad_norm = 582632
I0315 11:55:54.133052 29479 solver.cpp:214] Iteration 41960, loss = 6123.02
I0315 11:55:54.133271 29479 solver.cpp:229]     Train net output #0: loss = 4907.7 (* 1 = 4907.7 loss)
I0315 11:55:54.247534 29479 solver.cpp:610] Iteration 41960, lr = 8.09028e-09
I0315 11:55:54.247552 29479 solver.cpp:613] Iteration 41960, avg_grad_norm = 530692
I0315 11:56:19.791223 29479 solver.cpp:214] Iteration 41980, loss = 6312.5
I0315 11:56:19.791292 29479 solver.cpp:229]     Train net output #0: loss = 3318.17 (* 1 = 3318.17 loss)
I0315 11:56:19.906100 29479 solver.cpp:610] Iteration 41980, lr = 8.08935e-09
I0315 11:56:19.906114 29479 solver.cpp:613] Iteration 41980, avg_grad_norm = 548304
I0315 11:56:45.482995 29479 solver.cpp:214] Iteration 42000, loss = 5961.99
I0315 11:56:45.483117 29479 solver.cpp:229]     Train net output #0: loss = 7575.29 (* 1 = 7575.29 loss)
I0315 11:56:45.597702 29479 solver.cpp:610] Iteration 42000, lr = 8.08843e-09
I0315 11:56:45.597717 29479 solver.cpp:613] Iteration 42000, avg_grad_norm = 549361
I0315 11:57:11.064637 29479 solver.cpp:214] Iteration 42020, loss = 6391.79
I0315 11:57:11.064697 29479 solver.cpp:229]     Train net output #0: loss = 5475.29 (* 1 = 5475.29 loss)
I0315 11:57:11.177762 29479 solver.cpp:610] Iteration 42020, lr = 8.08751e-09
I0315 11:57:11.177774 29479 solver.cpp:613] Iteration 42020, avg_grad_norm = 576650
I0315 11:57:48.732250 29479 solver.cpp:214] Iteration 42040, loss = 6158.42
I0315 11:57:48.732398 29479 solver.cpp:229]     Train net output #0: loss = 9834.84 (* 1 = 9834.84 loss)
I0315 11:57:48.836431 29479 solver.cpp:610] Iteration 42040, lr = 8.08659e-09
I0315 11:57:48.836443 29479 solver.cpp:613] Iteration 42040, avg_grad_norm = 604784
I0315 11:58:12.446110 29479 solver.cpp:214] Iteration 42060, loss = 6048.56
I0315 11:58:12.446187 29479 solver.cpp:229]     Train net output #0: loss = 9633.29 (* 1 = 9633.29 loss)
I0315 11:58:12.557770 29479 solver.cpp:610] Iteration 42060, lr = 8.08567e-09
I0315 11:58:12.557783 29479 solver.cpp:613] Iteration 42060, avg_grad_norm = 579910
I0315 11:58:37.921963 29479 solver.cpp:214] Iteration 42080, loss = 6298.48
I0315 11:58:37.922087 29479 solver.cpp:229]     Train net output #0: loss = 5677.83 (* 1 = 5677.83 loss)
I0315 11:58:38.036546 29479 solver.cpp:610] Iteration 42080, lr = 8.08475e-09
I0315 11:58:38.036561 29479 solver.cpp:613] Iteration 42080, avg_grad_norm = 576386
I0315 11:59:03.616878 29479 solver.cpp:214] Iteration 42100, loss = 6289.66
I0315 11:59:03.616953 29479 solver.cpp:229]     Train net output #0: loss = 6755.82 (* 1 = 6755.82 loss)
I0315 11:59:03.731933 29479 solver.cpp:610] Iteration 42100, lr = 8.08383e-09
I0315 11:59:03.731947 29479 solver.cpp:613] Iteration 42100, avg_grad_norm = 595569
I0315 11:59:29.327745 29479 solver.cpp:214] Iteration 42120, loss = 6071.89
I0315 11:59:29.327927 29479 solver.cpp:229]     Train net output #0: loss = 4039.6 (* 1 = 4039.6 loss)
I0315 11:59:29.442404 29479 solver.cpp:610] Iteration 42120, lr = 8.0829e-09
I0315 11:59:29.442419 29479 solver.cpp:613] Iteration 42120, avg_grad_norm = 555501
I0315 11:59:54.761657 29479 solver.cpp:214] Iteration 42140, loss = 6190.83
I0315 11:59:54.761726 29479 solver.cpp:229]     Train net output #0: loss = 4918.58 (* 1 = 4918.58 loss)
I0315 11:59:54.874580 29479 solver.cpp:610] Iteration 42140, lr = 8.08198e-09
I0315 11:59:54.874593 29479 solver.cpp:613] Iteration 42140, avg_grad_norm = 551916
I0315 12:00:20.112329 29479 solver.cpp:214] Iteration 42160, loss = 6394.24
I0315 12:00:20.112483 29479 solver.cpp:229]     Train net output #0: loss = 11509.1 (* 1 = 11509.1 loss)
I0315 12:00:20.227069 29479 solver.cpp:610] Iteration 42160, lr = 8.08106e-09
I0315 12:00:20.227082 29479 solver.cpp:613] Iteration 42160, avg_grad_norm = 548436
I0315 12:01:01.029295 29479 solver.cpp:214] Iteration 42180, loss = 5890.53
I0315 12:01:01.029412 29479 solver.cpp:229]     Train net output #0: loss = 4909.78 (* 1 = 4909.78 loss)
I0315 12:01:01.133695 29479 solver.cpp:610] Iteration 42180, lr = 8.08014e-09
I0315 12:01:01.133709 29479 solver.cpp:613] Iteration 42180, avg_grad_norm = 495574
I0315 12:01:25.147902 29479 solver.cpp:214] Iteration 42200, loss = 6260.02
I0315 12:01:25.147980 29479 solver.cpp:229]     Train net output #0: loss = 6205.41 (* 1 = 6205.41 loss)
I0315 12:01:25.262486 29479 solver.cpp:610] Iteration 42200, lr = 8.07922e-09
I0315 12:01:25.262500 29479 solver.cpp:613] Iteration 42200, avg_grad_norm = 539492
I0315 12:01:50.805887 29479 solver.cpp:214] Iteration 42220, loss = 6069.27
I0315 12:01:50.806020 29479 solver.cpp:229]     Train net output #0: loss = 4534.72 (* 1 = 4534.72 loss)
I0315 12:01:50.920464 29479 solver.cpp:610] Iteration 42220, lr = 8.0783e-09
I0315 12:01:50.920475 29479 solver.cpp:613] Iteration 42220, avg_grad_norm = 505907
I0315 12:02:16.298977 29479 solver.cpp:214] Iteration 42240, loss = 6118.13
I0315 12:02:16.299044 29479 solver.cpp:229]     Train net output #0: loss = 8694.94 (* 1 = 8694.94 loss)
I0315 12:02:16.411841 29479 solver.cpp:610] Iteration 42240, lr = 8.07737e-09
I0315 12:02:16.411854 29479 solver.cpp:613] Iteration 42240, avg_grad_norm = 557169
I0315 12:02:41.594439 29479 solver.cpp:214] Iteration 42260, loss = 6147.76
I0315 12:02:41.594555 29479 solver.cpp:229]     Train net output #0: loss = 5171.11 (* 1 = 5171.11 loss)
I0315 12:02:41.707442 29479 solver.cpp:610] Iteration 42260, lr = 8.07645e-09
I0315 12:02:41.707454 29479 solver.cpp:613] Iteration 42260, avg_grad_norm = 552848
I0315 12:03:07.076253 29479 solver.cpp:214] Iteration 42280, loss = 6091.56
I0315 12:03:07.076321 29479 solver.cpp:229]     Train net output #0: loss = 5936.49 (* 1 = 5936.49 loss)
I0315 12:03:07.190693 29479 solver.cpp:610] Iteration 42280, lr = 8.07553e-09
I0315 12:03:07.190706 29479 solver.cpp:613] Iteration 42280, avg_grad_norm = 509093
I0315 12:03:48.273646 29479 solver.cpp:214] Iteration 42300, loss = 6026.78
I0315 12:03:48.273859 29479 solver.cpp:229]     Train net output #0: loss = 4442.98 (* 1 = 4442.98 loss)
I0315 12:03:48.377490 29479 solver.cpp:610] Iteration 42300, lr = 8.07461e-09
I0315 12:03:48.377502 29479 solver.cpp:613] Iteration 42300, avg_grad_norm = 476115
I0315 12:04:11.904767 29479 solver.cpp:214] Iteration 42320, loss = 6188.55
I0315 12:04:11.904826 29479 solver.cpp:229]     Train net output #0: loss = 8176.45 (* 1 = 8176.45 loss)
I0315 12:04:12.009948 29479 solver.cpp:610] Iteration 42320, lr = 8.07369e-09
I0315 12:04:12.009961 29479 solver.cpp:613] Iteration 42320, avg_grad_norm = 568169
I0315 12:04:37.454025 29479 solver.cpp:214] Iteration 42340, loss = 6441.33
I0315 12:04:37.454183 29479 solver.cpp:229]     Train net output #0: loss = 5337.02 (* 1 = 5337.02 loss)
I0315 12:04:37.568791 29479 solver.cpp:610] Iteration 42340, lr = 8.07277e-09
I0315 12:04:37.568804 29479 solver.cpp:613] Iteration 42340, avg_grad_norm = 604969
I0315 12:05:03.128698 29479 solver.cpp:214] Iteration 42360, loss = 6009.61
I0315 12:05:03.128767 29479 solver.cpp:229]     Train net output #0: loss = 6737.55 (* 1 = 6737.55 loss)
I0315 12:05:03.243412 29479 solver.cpp:610] Iteration 42360, lr = 8.07184e-09
I0315 12:05:03.243424 29479 solver.cpp:613] Iteration 42360, avg_grad_norm = 535348
I0315 12:05:28.463618 29479 solver.cpp:214] Iteration 42380, loss = 6470.93
I0315 12:05:28.463759 29479 solver.cpp:229]     Train net output #0: loss = 8651.32 (* 1 = 8651.32 loss)
I0315 12:05:28.576578 29479 solver.cpp:610] Iteration 42380, lr = 8.07092e-09
I0315 12:05:28.576591 29479 solver.cpp:613] Iteration 42380, avg_grad_norm = 552674
I0315 12:05:53.825312 29479 solver.cpp:214] Iteration 42400, loss = 5951.22
I0315 12:05:53.825371 29479 solver.cpp:229]     Train net output #0: loss = 4729.87 (* 1 = 4729.87 loss)
I0315 12:05:53.940021 29479 solver.cpp:610] Iteration 42400, lr = 8.07e-09
I0315 12:05:53.940054 29479 solver.cpp:613] Iteration 42400, avg_grad_norm = 518614
I0315 12:06:41.886246 29479 solver.cpp:214] Iteration 42420, loss = 6287.5
I0315 12:06:41.886379 29479 solver.cpp:229]     Train net output #0: loss = 3905.67 (* 1 = 3905.67 loss)
I0315 12:06:41.990185 29479 solver.cpp:610] Iteration 42420, lr = 8.06908e-09
I0315 12:06:41.990234 29479 solver.cpp:613] Iteration 42420, avg_grad_norm = 515583
I0315 12:07:05.450754 29479 solver.cpp:214] Iteration 42440, loss = 6038.66
I0315 12:07:05.450810 29479 solver.cpp:229]     Train net output #0: loss = 9663.01 (* 1 = 9663.01 loss)
I0315 12:07:05.556234 29479 solver.cpp:610] Iteration 42440, lr = 8.06816e-09
I0315 12:07:05.556248 29479 solver.cpp:613] Iteration 42440, avg_grad_norm = 494903
I0315 12:07:29.502588 29479 solver.cpp:214] Iteration 42460, loss = 6627.55
I0315 12:07:29.502712 29479 solver.cpp:229]     Train net output #0: loss = 4555.04 (* 1 = 4555.04 loss)
I0315 12:07:29.615741 29479 solver.cpp:610] Iteration 42460, lr = 8.06724e-09
I0315 12:07:29.615756 29479 solver.cpp:613] Iteration 42460, avg_grad_norm = 574429
I0315 12:07:55.117316 29479 solver.cpp:214] Iteration 42480, loss = 6217.14
I0315 12:07:55.117386 29479 solver.cpp:229]     Train net output #0: loss = 7091.47 (* 1 = 7091.47 loss)
I0315 12:07:55.232044 29479 solver.cpp:610] Iteration 42480, lr = 8.06631e-09
I0315 12:07:55.232059 29479 solver.cpp:613] Iteration 42480, avg_grad_norm = 583274
I0315 12:08:20.772286 29479 solver.cpp:214] Iteration 42500, loss = 6423.12
I0315 12:08:20.772414 29479 solver.cpp:229]     Train net output #0: loss = 4299.54 (* 1 = 4299.54 loss)
I0315 12:08:20.886893 29479 solver.cpp:610] Iteration 42500, lr = 8.06539e-09
I0315 12:08:20.886905 29479 solver.cpp:613] Iteration 42500, avg_grad_norm = 560241
I0315 12:08:45.907369 29479 solver.cpp:214] Iteration 42520, loss = 6587.49
I0315 12:08:45.907431 29479 solver.cpp:229]     Train net output #0: loss = 10170.6 (* 1 = 10170.6 loss)
I0315 12:08:46.019052 29479 solver.cpp:610] Iteration 42520, lr = 8.06447e-09
I0315 12:08:46.019065 29479 solver.cpp:613] Iteration 42520, avg_grad_norm = 524878
I0315 12:09:11.294215 29479 solver.cpp:214] Iteration 42540, loss = 6007.04
I0315 12:09:11.294334 29479 solver.cpp:229]     Train net output #0: loss = 6298.72 (* 1 = 6298.72 loss)
I0315 12:09:11.408849 29479 solver.cpp:610] Iteration 42540, lr = 8.06355e-09
I0315 12:09:11.408861 29479 solver.cpp:613] Iteration 42540, avg_grad_norm = 521740
I0315 12:09:59.789415 29479 solver.cpp:214] Iteration 42560, loss = 6264.67
I0315 12:09:59.789531 29479 solver.cpp:229]     Train net output #0: loss = 5041.78 (* 1 = 5041.78 loss)
I0315 12:09:59.894616 29479 solver.cpp:610] Iteration 42560, lr = 8.06263e-09
I0315 12:09:59.894629 29479 solver.cpp:613] Iteration 42560, avg_grad_norm = 539313
I0315 12:10:23.330086 29479 solver.cpp:214] Iteration 42580, loss = 6081.58
I0315 12:10:23.330155 29479 solver.cpp:229]     Train net output #0: loss = 9095.67 (* 1 = 9095.67 loss)
I0315 12:10:23.435215 29479 solver.cpp:610] Iteration 42580, lr = 8.06171e-09
I0315 12:10:23.435230 29479 solver.cpp:613] Iteration 42580, avg_grad_norm = 521818
I0315 12:10:48.283399 29479 solver.cpp:214] Iteration 42600, loss = 5857.25
I0315 12:10:48.283552 29479 solver.cpp:229]     Train net output #0: loss = 6748.22 (* 1 = 6748.22 loss)
I0315 12:10:48.397975 29479 solver.cpp:610] Iteration 42600, lr = 8.06078e-09
I0315 12:10:48.397989 29479 solver.cpp:613] Iteration 42600, avg_grad_norm = 573460
I0315 12:11:13.841027 29479 solver.cpp:214] Iteration 42620, loss = 6020.83
I0315 12:11:13.841104 29479 solver.cpp:229]     Train net output #0: loss = 4232.91 (* 1 = 4232.91 loss)
I0315 12:11:13.954138 29479 solver.cpp:610] Iteration 42620, lr = 8.05986e-09
I0315 12:11:13.954150 29479 solver.cpp:613] Iteration 42620, avg_grad_norm = 543155
I0315 12:11:39.150393 29479 solver.cpp:214] Iteration 42640, loss = 6051.94
I0315 12:11:39.150524 29479 solver.cpp:229]     Train net output #0: loss = 5009.35 (* 1 = 5009.35 loss)
I0315 12:11:39.264904 29479 solver.cpp:610] Iteration 42640, lr = 8.05894e-09
I0315 12:11:39.264916 29479 solver.cpp:613] Iteration 42640, avg_grad_norm = 533147
I0315 12:12:04.870381 29479 solver.cpp:214] Iteration 42660, loss = 5925.23
I0315 12:12:04.870436 29479 solver.cpp:229]     Train net output #0: loss = 5431.54 (* 1 = 5431.54 loss)
I0315 12:12:04.984979 29479 solver.cpp:610] Iteration 42660, lr = 8.05802e-09
I0315 12:12:04.984993 29479 solver.cpp:613] Iteration 42660, avg_grad_norm = 566669
I0315 12:12:42.171401 29479 solver.cpp:214] Iteration 42680, loss = 6228.94
I0315 12:12:42.171505 29479 solver.cpp:229]     Train net output #0: loss = 5254.67 (* 1 = 5254.67 loss)
I0315 12:12:42.276398 29479 solver.cpp:610] Iteration 42680, lr = 8.0571e-09
I0315 12:12:42.276412 29479 solver.cpp:613] Iteration 42680, avg_grad_norm = 510717
I0315 12:13:06.291563 29479 solver.cpp:214] Iteration 42700, loss = 6022.62
I0315 12:13:06.291643 29479 solver.cpp:229]     Train net output #0: loss = 7876.83 (* 1 = 7876.83 loss)
I0315 12:13:06.406159 29479 solver.cpp:610] Iteration 42700, lr = 8.05617e-09
I0315 12:13:06.406172 29479 solver.cpp:613] Iteration 42700, avg_grad_norm = 559056
I0315 12:13:31.966823 29479 solver.cpp:214] Iteration 42720, loss = 6211.41
I0315 12:13:31.966969 29479 solver.cpp:229]     Train net output #0: loss = 5871.52 (* 1 = 5871.52 loss)
I0315 12:13:32.081372 29479 solver.cpp:610] Iteration 42720, lr = 8.05525e-09
I0315 12:13:32.081385 29479 solver.cpp:613] Iteration 42720, avg_grad_norm = 612109
I0315 12:13:57.689525 29479 solver.cpp:214] Iteration 42740, loss = 6055.3
I0315 12:13:57.689584 29479 solver.cpp:229]     Train net output #0: loss = 6344.63 (* 1 = 6344.63 loss)
I0315 12:13:57.804056 29479 solver.cpp:610] Iteration 42740, lr = 8.05433e-09
I0315 12:13:57.804070 29479 solver.cpp:613] Iteration 42740, avg_grad_norm = 545834
I0315 12:14:23.215191 29479 solver.cpp:214] Iteration 42760, loss = 6304.9
I0315 12:14:23.215315 29479 solver.cpp:229]     Train net output #0: loss = 6353.83 (* 1 = 6353.83 loss)
I0315 12:14:23.328202 29479 solver.cpp:610] Iteration 42760, lr = 8.05341e-09
I0315 12:14:23.328215 29479 solver.cpp:613] Iteration 42760, avg_grad_norm = 581623
I0315 12:14:48.782505 29479 solver.cpp:214] Iteration 42780, loss = 6377.77
I0315 12:14:48.782572 29479 solver.cpp:229]     Train net output #0: loss = 10547.1 (* 1 = 10547.1 loss)
I0315 12:14:48.897338 29479 solver.cpp:610] Iteration 42780, lr = 8.05249e-09
I0315 12:14:48.897352 29479 solver.cpp:613] Iteration 42780, avg_grad_norm = 519033
I0315 12:15:33.393867 29479 solver.cpp:214] Iteration 42800, loss = 6342.86
I0315 12:15:33.394026 29479 solver.cpp:229]     Train net output #0: loss = 4414.83 (* 1 = 4414.83 loss)
I0315 12:15:33.498986 29479 solver.cpp:610] Iteration 42800, lr = 8.05156e-09
I0315 12:15:33.498999 29479 solver.cpp:613] Iteration 42800, avg_grad_norm = 608949
I0315 12:15:56.912313 29479 solver.cpp:214] Iteration 42820, loss = 5936.19
I0315 12:15:56.912405 29479 solver.cpp:229]     Train net output #0: loss = 4272.84 (* 1 = 4272.84 loss)
I0315 12:15:57.017525 29479 solver.cpp:610] Iteration 42820, lr = 8.05064e-09
I0315 12:15:57.017539 29479 solver.cpp:613] Iteration 42820, avg_grad_norm = 631396
I0315 12:16:21.430191 29479 solver.cpp:214] Iteration 42840, loss = 6152.01
I0315 12:16:21.430397 29479 solver.cpp:229]     Train net output #0: loss = 5092 (* 1 = 5092 loss)
I0315 12:16:21.544867 29479 solver.cpp:610] Iteration 42840, lr = 8.04972e-09
I0315 12:16:21.544881 29479 solver.cpp:613] Iteration 42840, avg_grad_norm = 601234
I0315 12:16:47.129129 29479 solver.cpp:214] Iteration 42860, loss = 6141.98
I0315 12:16:47.129205 29479 solver.cpp:229]     Train net output #0: loss = 5176.2 (* 1 = 5176.2 loss)
I0315 12:16:47.243669 29479 solver.cpp:610] Iteration 42860, lr = 8.0488e-09
I0315 12:16:47.243685 29479 solver.cpp:613] Iteration 42860, avg_grad_norm = 526086
I0315 12:17:12.793153 29479 solver.cpp:214] Iteration 42880, loss = 6295.85
I0315 12:17:12.793355 29479 solver.cpp:229]     Train net output #0: loss = 9960.03 (* 1 = 9960.03 loss)
I0315 12:17:12.907867 29479 solver.cpp:610] Iteration 42880, lr = 8.04788e-09
I0315 12:17:12.907879 29479 solver.cpp:613] Iteration 42880, avg_grad_norm = 495299
I0315 12:17:38.452903 29479 solver.cpp:214] Iteration 42900, loss = 6250
I0315 12:17:38.452987 29479 solver.cpp:229]     Train net output #0: loss = 7197.14 (* 1 = 7197.14 loss)
I0315 12:17:38.567374 29479 solver.cpp:610] Iteration 42900, lr = 8.04696e-09
I0315 12:17:38.567386 29479 solver.cpp:613] Iteration 42900, avg_grad_norm = 569888
I0315 12:18:04.115180 29479 solver.cpp:214] Iteration 42920, loss = 6282.13
I0315 12:18:04.115357 29479 solver.cpp:229]     Train net output #0: loss = 5164 (* 1 = 5164 loss)
I0315 12:18:04.229661 29479 solver.cpp:610] Iteration 42920, lr = 8.04603e-09
I0315 12:18:04.229676 29479 solver.cpp:613] Iteration 42920, avg_grad_norm = 555599
I0315 12:18:47.130817 29479 solver.cpp:214] Iteration 42940, loss = 6187.3
I0315 12:18:47.130959 29479 solver.cpp:229]     Train net output #0: loss = 4223.56 (* 1 = 4223.56 loss)
I0315 12:18:47.236089 29479 solver.cpp:610] Iteration 42940, lr = 8.04511e-09
I0315 12:18:47.236140 29479 solver.cpp:613] Iteration 42940, avg_grad_norm = 513606
I0315 12:19:10.912633 29479 solver.cpp:214] Iteration 42960, loss = 6520.33
I0315 12:19:10.912744 29479 solver.cpp:229]     Train net output #0: loss = 5531.84 (* 1 = 5531.84 loss)
I0315 12:19:11.024266 29479 solver.cpp:610] Iteration 42960, lr = 8.04419e-09
I0315 12:19:11.024324 29479 solver.cpp:613] Iteration 42960, avg_grad_norm = 543158
I0315 12:19:36.405994 29479 solver.cpp:214] Iteration 42980, loss = 6307.83
I0315 12:19:36.406134 29479 solver.cpp:229]     Train net output #0: loss = 6282.36 (* 1 = 6282.36 loss)
I0315 12:19:36.520622 29479 solver.cpp:610] Iteration 42980, lr = 8.04327e-09
I0315 12:19:36.520635 29479 solver.cpp:613] Iteration 42980, avg_grad_norm = 624240
I0315 12:20:02.048863 29479 solver.cpp:214] Iteration 43000, loss = 6473.47
I0315 12:20:02.048924 29479 solver.cpp:229]     Train net output #0: loss = 3626.17 (* 1 = 3626.17 loss)
I0315 12:20:02.163389 29479 solver.cpp:610] Iteration 43000, lr = 8.04234e-09
I0315 12:20:02.163401 29479 solver.cpp:613] Iteration 43000, avg_grad_norm = 533150
I0315 12:20:27.526340 29479 solver.cpp:214] Iteration 43020, loss = 5972.12
I0315 12:20:27.526468 29479 solver.cpp:229]     Train net output #0: loss = 5865.19 (* 1 = 5865.19 loss)
I0315 12:20:27.639320 29479 solver.cpp:610] Iteration 43020, lr = 8.04142e-09
I0315 12:20:27.639335 29479 solver.cpp:613] Iteration 43020, avg_grad_norm = 645521
I0315 12:20:52.919751 29479 solver.cpp:214] Iteration 43040, loss = 6234.67
I0315 12:20:52.919821 29479 solver.cpp:229]     Train net output #0: loss = 4841.76 (* 1 = 4841.76 loss)
I0315 12:20:53.035712 29479 solver.cpp:610] Iteration 43040, lr = 8.0405e-09
I0315 12:20:53.035725 29479 solver.cpp:613] Iteration 43040, avg_grad_norm = 579380
I0315 12:21:30.613350 29479 solver.cpp:214] Iteration 43060, loss = 5934.09
I0315 12:21:30.613538 29479 solver.cpp:229]     Train net output #0: loss = 8814.4 (* 1 = 8814.4 loss)
I0315 12:21:30.718502 29479 solver.cpp:610] Iteration 43060, lr = 8.03958e-09
I0315 12:21:30.718514 29479 solver.cpp:613] Iteration 43060, avg_grad_norm = 589438
I0315 12:21:54.499013 29479 solver.cpp:214] Iteration 43080, loss = 6037.29
I0315 12:21:54.499105 29479 solver.cpp:229]     Train net output #0: loss = 3887.31 (* 1 = 3887.31 loss)
I0315 12:21:54.613585 29479 solver.cpp:610] Iteration 43080, lr = 8.03866e-09
I0315 12:21:54.613598 29479 solver.cpp:613] Iteration 43080, avg_grad_norm = 679828
I0315 12:22:20.169464 29479 solver.cpp:214] Iteration 43100, loss = 6267.69
I0315 12:22:20.169595 29479 solver.cpp:229]     Train net output #0: loss = 3603.48 (* 1 = 3603.48 loss)
I0315 12:22:20.284090 29479 solver.cpp:610] Iteration 43100, lr = 8.03773e-09
I0315 12:22:20.284102 29479 solver.cpp:613] Iteration 43100, avg_grad_norm = 608752
I0315 12:22:45.839316 29479 solver.cpp:214] Iteration 43120, loss = 5859.97
I0315 12:22:45.839372 29479 solver.cpp:229]     Train net output #0: loss = 6293.97 (* 1 = 6293.97 loss)
I0315 12:22:45.953984 29479 solver.cpp:610] Iteration 43120, lr = 8.03681e-09
I0315 12:22:45.953996 29479 solver.cpp:613] Iteration 43120, avg_grad_norm = 555042
I0315 12:23:11.505764 29479 solver.cpp:214] Iteration 43140, loss = 6326.6
I0315 12:23:11.505894 29479 solver.cpp:229]     Train net output #0: loss = 9070.27 (* 1 = 9070.27 loss)
I0315 12:23:11.620364 29479 solver.cpp:610] Iteration 43140, lr = 8.03589e-09
I0315 12:23:11.620378 29479 solver.cpp:613] Iteration 43140, avg_grad_norm = 688296
I0315 12:23:37.042675 29479 solver.cpp:214] Iteration 43160, loss = 6395.61
I0315 12:23:37.042747 29479 solver.cpp:229]     Train net output #0: loss = 5424.44 (* 1 = 5424.44 loss)
I0315 12:23:37.155704 29479 solver.cpp:610] Iteration 43160, lr = 8.03497e-09
I0315 12:23:37.155719 29479 solver.cpp:613] Iteration 43160, avg_grad_norm = 584997
I0315 12:24:14.860083 29479 solver.cpp:214] Iteration 43180, loss = 6437.08
I0315 12:24:14.860208 29479 solver.cpp:229]     Train net output #0: loss = 9938.83 (* 1 = 9938.83 loss)
I0315 12:24:14.965396 29479 solver.cpp:610] Iteration 43180, lr = 8.03405e-09
I0315 12:24:14.965409 29479 solver.cpp:613] Iteration 43180, avg_grad_norm = 565202
I0315 12:24:38.391687 29479 solver.cpp:214] Iteration 43200, loss = 5904.22
I0315 12:24:38.391754 29479 solver.cpp:229]     Train net output #0: loss = 8042.8 (* 1 = 8042.8 loss)
I0315 12:24:38.496943 29479 solver.cpp:610] Iteration 43200, lr = 8.03312e-09
I0315 12:24:38.496956 29479 solver.cpp:613] Iteration 43200, avg_grad_norm = 582865
I0315 12:25:03.798233 29479 solver.cpp:214] Iteration 43220, loss = 6223.12
I0315 12:25:03.798338 29479 solver.cpp:229]     Train net output #0: loss = 6072.63 (* 1 = 6072.63 loss)
I0315 12:25:03.912756 29479 solver.cpp:610] Iteration 43220, lr = 8.0322e-09
I0315 12:25:03.912770 29479 solver.cpp:613] Iteration 43220, avg_grad_norm = 557548
I0315 12:25:29.457876 29479 solver.cpp:214] Iteration 43240, loss = 5830.93
I0315 12:25:29.457944 29479 solver.cpp:229]     Train net output #0: loss = 4328.27 (* 1 = 4328.27 loss)
I0315 12:25:29.572441 29479 solver.cpp:610] Iteration 43240, lr = 8.03128e-09
I0315 12:25:29.572453 29479 solver.cpp:613] Iteration 43240, avg_grad_norm = 520617
I0315 12:25:55.116735 29479 solver.cpp:214] Iteration 43260, loss = 5979.42
I0315 12:25:55.116854 29479 solver.cpp:229]     Train net output #0: loss = 5164.17 (* 1 = 5164.17 loss)
I0315 12:25:55.231290 29479 solver.cpp:610] Iteration 43260, lr = 8.03036e-09
I0315 12:25:55.231303 29479 solver.cpp:613] Iteration 43260, avg_grad_norm = 565771
I0315 12:26:20.775187 29479 solver.cpp:214] Iteration 43280, loss = 5823.89
I0315 12:26:20.775252 29479 solver.cpp:229]     Train net output #0: loss = 3236.47 (* 1 = 3236.47 loss)
I0315 12:26:20.889832 29479 solver.cpp:610] Iteration 43280, lr = 8.02943e-09
I0315 12:26:20.889845 29479 solver.cpp:613] Iteration 43280, avg_grad_norm = 563547
I0315 12:26:46.443744 29479 solver.cpp:214] Iteration 43300, loss = 6177.4
I0315 12:26:46.443878 29479 solver.cpp:229]     Train net output #0: loss = 6991.1 (* 1 = 6991.1 loss)
I0315 12:26:46.558333 29479 solver.cpp:610] Iteration 43300, lr = 8.02851e-09
I0315 12:26:46.558346 29479 solver.cpp:613] Iteration 43300, avg_grad_norm = 508404
I0315 12:27:25.058977 29479 solver.cpp:214] Iteration 43320, loss = 6055.2
I0315 12:27:25.059186 29479 solver.cpp:229]     Train net output #0: loss = 6397.25 (* 1 = 6397.25 loss)
I0315 12:27:25.163468 29479 solver.cpp:610] Iteration 43320, lr = 8.02759e-09
I0315 12:27:25.163481 29479 solver.cpp:613] Iteration 43320, avg_grad_norm = 567693
I0315 12:27:49.373378 29479 solver.cpp:214] Iteration 43340, loss = 6011.45
I0315 12:27:49.373437 29479 solver.cpp:229]     Train net output #0: loss = 2969.95 (* 1 = 2969.95 loss)
I0315 12:27:49.487802 29479 solver.cpp:610] Iteration 43340, lr = 8.02667e-09
I0315 12:27:49.487813 29479 solver.cpp:613] Iteration 43340, avg_grad_norm = 611814
I0315 12:28:15.036016 29479 solver.cpp:214] Iteration 43360, loss = 6070.8
I0315 12:28:15.036160 29479 solver.cpp:229]     Train net output #0: loss = 6389.43 (* 1 = 6389.43 loss)
I0315 12:28:15.150763 29479 solver.cpp:610] Iteration 43360, lr = 8.02575e-09
I0315 12:28:15.150779 29479 solver.cpp:613] Iteration 43360, avg_grad_norm = 546227
I0315 12:28:40.704398 29479 solver.cpp:214] Iteration 43380, loss = 6213.58
I0315 12:28:40.704460 29479 solver.cpp:229]     Train net output #0: loss = 3121.86 (* 1 = 3121.86 loss)
I0315 12:28:40.818943 29479 solver.cpp:610] Iteration 43380, lr = 8.02482e-09
I0315 12:28:40.818985 29479 solver.cpp:613] Iteration 43380, avg_grad_norm = 523411
I0315 12:29:06.436882 29479 solver.cpp:214] Iteration 43400, loss = 5751.59
I0315 12:29:06.437078 29479 solver.cpp:229]     Train net output #0: loss = 3210.61 (* 1 = 3210.61 loss)
I0315 12:29:06.551507 29479 solver.cpp:610] Iteration 43400, lr = 8.0239e-09
I0315 12:29:06.551520 29479 solver.cpp:613] Iteration 43400, avg_grad_norm = 502631
I0315 12:29:32.107997 29479 solver.cpp:214] Iteration 43420, loss = 6139.34
I0315 12:29:32.108053 29479 solver.cpp:229]     Train net output #0: loss = 3383.56 (* 1 = 3383.56 loss)
I0315 12:29:32.221097 29479 solver.cpp:610] Iteration 43420, lr = 8.02298e-09
I0315 12:29:32.221110 29479 solver.cpp:613] Iteration 43420, avg_grad_norm = 525508
I0315 12:30:09.695256 29479 solver.cpp:214] Iteration 43440, loss = 6244.04
I0315 12:30:09.695412 29479 solver.cpp:229]     Train net output #0: loss = 11603.1 (* 1 = 11603.1 loss)
I0315 12:30:09.799774 29479 solver.cpp:610] Iteration 43440, lr = 8.02206e-09
I0315 12:30:09.799787 29479 solver.cpp:613] Iteration 43440, avg_grad_norm = 554960
I0315 12:30:33.490515 29479 solver.cpp:214] Iteration 43460, loss = 6248.29
I0315 12:30:33.490582 29479 solver.cpp:229]     Train net output #0: loss = 7656.79 (* 1 = 7656.79 loss)
I0315 12:30:33.603400 29479 solver.cpp:610] Iteration 43460, lr = 8.02113e-09
I0315 12:30:33.603412 29479 solver.cpp:613] Iteration 43460, avg_grad_norm = 586906
I0315 12:30:59.140147 29479 solver.cpp:214] Iteration 43480, loss = 6013.33
I0315 12:30:59.140276 29479 solver.cpp:229]     Train net output #0: loss = 6354.78 (* 1 = 6354.78 loss)
I0315 12:30:59.254549 29479 solver.cpp:610] Iteration 43480, lr = 8.02021e-09
I0315 12:30:59.254562 29479 solver.cpp:613] Iteration 43480, avg_grad_norm = 499172
I0315 12:31:24.797540 29479 solver.cpp:214] Iteration 43500, loss = 6142.86
I0315 12:31:24.797607 29479 solver.cpp:229]     Train net output #0: loss = 7207.23 (* 1 = 7207.23 loss)
I0315 12:31:24.911957 29479 solver.cpp:610] Iteration 43500, lr = 8.01929e-09
I0315 12:31:24.911969 29479 solver.cpp:613] Iteration 43500, avg_grad_norm = 692859
I0315 12:31:50.447329 29479 solver.cpp:214] Iteration 43520, loss = 6220.76
I0315 12:31:50.447455 29479 solver.cpp:229]     Train net output #0: loss = 5506.67 (* 1 = 5506.67 loss)
I0315 12:31:50.561898 29479 solver.cpp:610] Iteration 43520, lr = 8.01837e-09
I0315 12:31:50.561911 29479 solver.cpp:613] Iteration 43520, avg_grad_norm = 542069
I0315 12:32:16.129379 29479 solver.cpp:214] Iteration 43540, loss = 6570.7
I0315 12:32:16.129448 29479 solver.cpp:229]     Train net output #0: loss = 6436.89 (* 1 = 6436.89 loss)
I0315 12:32:16.244133 29479 solver.cpp:610] Iteration 43540, lr = 8.01745e-09
I0315 12:32:16.244148 29479 solver.cpp:613] Iteration 43540, avg_grad_norm = 488264
I0315 12:32:57.533138 29479 solver.cpp:214] Iteration 43560, loss = 6254.89
I0315 12:32:57.533326 29479 solver.cpp:229]     Train net output #0: loss = 4190.54 (* 1 = 4190.54 loss)
I0315 12:32:57.638331 29479 solver.cpp:610] Iteration 43560, lr = 8.01652e-09
I0315 12:32:57.638345 29479 solver.cpp:613] Iteration 43560, avg_grad_norm = 565029
I0315 12:33:21.054949 29479 solver.cpp:214] Iteration 43580, loss = 5975.83
I0315 12:33:21.054994 29479 solver.cpp:229]     Train net output #0: loss = 2622.52 (* 1 = 2622.52 loss)
I0315 12:33:21.160301 29479 solver.cpp:610] Iteration 43580, lr = 8.0156e-09
I0315 12:33:21.160315 29479 solver.cpp:613] Iteration 43580, avg_grad_norm = 578173
I0315 12:33:45.845635 29479 solver.cpp:214] Iteration 43600, loss = 6187.93
I0315 12:33:45.845775 29479 solver.cpp:229]     Train net output #0: loss = 8407.98 (* 1 = 8407.98 loss)
I0315 12:33:45.960132 29479 solver.cpp:610] Iteration 43600, lr = 8.01468e-09
I0315 12:33:45.960146 29479 solver.cpp:613] Iteration 43600, avg_grad_norm = 708588
I0315 12:34:11.558284 29479 solver.cpp:214] Iteration 43620, loss = 6214.44
I0315 12:34:11.558344 29479 solver.cpp:229]     Train net output #0: loss = 6140.2 (* 1 = 6140.2 loss)
I0315 12:34:11.672957 29479 solver.cpp:610] Iteration 43620, lr = 8.01376e-09
I0315 12:34:11.672971 29479 solver.cpp:613] Iteration 43620, avg_grad_norm = 691936
I0315 12:34:37.269229 29479 solver.cpp:214] Iteration 43640, loss = 5929.61
I0315 12:34:37.269354 29479 solver.cpp:229]     Train net output #0: loss = 3229.56 (* 1 = 3229.56 loss)
I0315 12:34:37.383754 29479 solver.cpp:610] Iteration 43640, lr = 8.01283e-09
I0315 12:34:37.383767 29479 solver.cpp:613] Iteration 43640, avg_grad_norm = 551417
I0315 12:35:02.984707 29479 solver.cpp:214] Iteration 43660, loss = 6000.08
I0315 12:35:02.984776 29479 solver.cpp:229]     Train net output #0: loss = 5305.7 (* 1 = 5305.7 loss)
I0315 12:35:03.099373 29479 solver.cpp:610] Iteration 43660, lr = 8.01191e-09
I0315 12:35:03.099387 29479 solver.cpp:613] Iteration 43660, avg_grad_norm = 513519
I0315 12:35:28.701377 29479 solver.cpp:214] Iteration 43680, loss = 6087.01
I0315 12:35:28.701467 29479 solver.cpp:229]     Train net output #0: loss = 7832.56 (* 1 = 7832.56 loss)
I0315 12:35:28.816028 29479 solver.cpp:610] Iteration 43680, lr = 8.01099e-09
I0315 12:35:28.816041 29479 solver.cpp:613] Iteration 43680, avg_grad_norm = 489331
I0315 12:36:05.792366 29479 solver.cpp:214] Iteration 43700, loss = 6179.84
I0315 12:36:05.792526 29479 solver.cpp:229]     Train net output #0: loss = 6241.38 (* 1 = 6241.38 loss)
I0315 12:36:05.896152 29479 solver.cpp:610] Iteration 43700, lr = 8.01007e-09
I0315 12:36:05.896164 29479 solver.cpp:613] Iteration 43700, avg_grad_norm = 537111
I0315 12:36:30.156108 29479 solver.cpp:214] Iteration 43720, loss = 6093.03
I0315 12:36:30.156174 29479 solver.cpp:229]     Train net output #0: loss = 3272.77 (* 1 = 3272.77 loss)
I0315 12:36:30.270798 29479 solver.cpp:610] Iteration 43720, lr = 8.00914e-09
I0315 12:36:30.270812 29479 solver.cpp:613] Iteration 43720, avg_grad_norm = 531960
I0315 12:36:55.816999 29479 solver.cpp:214] Iteration 43740, loss = 5840.02
I0315 12:36:55.817129 29479 solver.cpp:229]     Train net output #0: loss = 4364.12 (* 1 = 4364.12 loss)
I0315 12:36:55.931601 29479 solver.cpp:610] Iteration 43740, lr = 8.00822e-09
I0315 12:36:55.931614 29479 solver.cpp:613] Iteration 43740, avg_grad_norm = 497563
I0315 12:37:21.525986 29479 solver.cpp:214] Iteration 43760, loss = 5869.67
I0315 12:37:21.526063 29479 solver.cpp:229]     Train net output #0: loss = 12298.4 (* 1 = 12298.4 loss)
I0315 12:37:21.640590 29479 solver.cpp:610] Iteration 43760, lr = 8.0073e-09
I0315 12:37:21.640604 29479 solver.cpp:613] Iteration 43760, avg_grad_norm = 499832
I0315 12:37:47.240933 29479 solver.cpp:214] Iteration 43780, loss = 6067.09
I0315 12:37:47.241107 29479 solver.cpp:229]     Train net output #0: loss = 4753.37 (* 1 = 4753.37 loss)
I0315 12:37:47.355785 29479 solver.cpp:610] Iteration 43780, lr = 8.00638e-09
I0315 12:37:47.355798 29479 solver.cpp:613] Iteration 43780, avg_grad_norm = 532797
I0315 12:38:12.966353 29479 solver.cpp:214] Iteration 43800, loss = 6275.9
I0315 12:38:12.966400 29479 solver.cpp:229]     Train net output #0: loss = 5067.85 (* 1 = 5067.85 loss)
I0315 12:38:13.080855 29479 solver.cpp:610] Iteration 43800, lr = 8.00545e-09
I0315 12:38:13.080869 29479 solver.cpp:613] Iteration 43800, avg_grad_norm = 535442
I0315 12:38:52.071900 29479 solver.cpp:214] Iteration 43820, loss = 6011.43
I0315 12:38:52.072106 29479 solver.cpp:229]     Train net output #0: loss = 6898.79 (* 1 = 6898.79 loss)
I0315 12:38:52.177216 29479 solver.cpp:610] Iteration 43820, lr = 8.00453e-09
I0315 12:38:52.177263 29479 solver.cpp:613] Iteration 43820, avg_grad_norm = 533594
I0315 12:39:15.735755 29479 solver.cpp:214] Iteration 43840, loss = 6244.9
I0315 12:39:15.735805 29479 solver.cpp:229]     Train net output #0: loss = 4003.08 (* 1 = 4003.08 loss)
I0315 12:39:15.847369 29479 solver.cpp:610] Iteration 43840, lr = 8.00361e-09
I0315 12:39:15.847383 29479 solver.cpp:613] Iteration 43840, avg_grad_norm = 553131
I0315 12:39:41.434788 29479 solver.cpp:214] Iteration 43860, loss = 6173.9
I0315 12:39:41.434929 29479 solver.cpp:229]     Train net output #0: loss = 7422.75 (* 1 = 7422.75 loss)
I0315 12:39:41.549286 29479 solver.cpp:610] Iteration 43860, lr = 8.00269e-09
I0315 12:39:41.549324 29479 solver.cpp:613] Iteration 43860, avg_grad_norm = 585604
I0315 12:40:07.156570 29479 solver.cpp:214] Iteration 43880, loss = 5843.96
I0315 12:40:07.156622 29479 solver.cpp:229]     Train net output #0: loss = 5065.09 (* 1 = 5065.09 loss)
I0315 12:40:07.270997 29479 solver.cpp:610] Iteration 43880, lr = 8.00176e-09
I0315 12:40:07.271009 29479 solver.cpp:613] Iteration 43880, avg_grad_norm = 552876
I0315 12:40:32.868296 29479 solver.cpp:214] Iteration 43900, loss = 6263.47
I0315 12:40:32.868409 29479 solver.cpp:229]     Train net output #0: loss = 4642.29 (* 1 = 4642.29 loss)
I0315 12:40:32.982951 29479 solver.cpp:610] Iteration 43900, lr = 8.00084e-09
I0315 12:40:32.982965 29479 solver.cpp:613] Iteration 43900, avg_grad_norm = 588396
I0315 12:40:58.561488 29479 solver.cpp:214] Iteration 43920, loss = 5977.26
I0315 12:40:58.561556 29479 solver.cpp:229]     Train net output #0: loss = 7664.57 (* 1 = 7664.57 loss)
I0315 12:40:58.676005 29479 solver.cpp:610] Iteration 43920, lr = 7.99992e-09
I0315 12:40:58.676017 29479 solver.cpp:613] Iteration 43920, avg_grad_norm = 615865
I0315 12:41:45.632629 29479 solver.cpp:214] Iteration 43940, loss = 6176.17
I0315 12:41:45.632845 29479 solver.cpp:229]     Train net output #0: loss = 5017.48 (* 1 = 5017.48 loss)
I0315 12:41:45.736692 29479 solver.cpp:610] Iteration 43940, lr = 7.999e-09
I0315 12:41:45.736735 29479 solver.cpp:613] Iteration 43940, avg_grad_norm = 667281
I0315 12:42:09.152292 29479 solver.cpp:214] Iteration 43960, loss = 5976.79
I0315 12:42:09.152360 29479 solver.cpp:229]     Train net output #0: loss = 9558.81 (* 1 = 9558.81 loss)
I0315 12:42:09.257627 29479 solver.cpp:610] Iteration 43960, lr = 7.99807e-09
I0315 12:42:09.257642 29479 solver.cpp:613] Iteration 43960, avg_grad_norm = 600151
I0315 12:42:32.971976 29479 solver.cpp:214] Iteration 43980, loss = 6030.58
I0315 12:42:32.972187 29479 solver.cpp:229]     Train net output #0: loss = 4331.75 (* 1 = 4331.75 loss)
I0315 12:42:33.084998 29479 solver.cpp:610] Iteration 43980, lr = 7.99715e-09
I0315 12:42:33.085012 29479 solver.cpp:613] Iteration 43980, avg_grad_norm = 507526
I0315 12:42:58.492358 29479 solver.cpp:214] Iteration 44000, loss = 6316.59
I0315 12:42:58.492431 29479 solver.cpp:229]     Train net output #0: loss = 7181.7 (* 1 = 7181.7 loss)
I0315 12:42:58.606916 29479 solver.cpp:610] Iteration 44000, lr = 7.99623e-09
I0315 12:42:58.606930 29479 solver.cpp:613] Iteration 44000, avg_grad_norm = 589775
I0315 12:43:24.164361 29479 solver.cpp:214] Iteration 44020, loss = 6246.76
I0315 12:43:24.164594 29479 solver.cpp:229]     Train net output #0: loss = 4958.51 (* 1 = 4958.51 loss)
I0315 12:43:24.278750 29479 solver.cpp:610] Iteration 44020, lr = 7.9953e-09
I0315 12:43:24.278764 29479 solver.cpp:613] Iteration 44020, avg_grad_norm = 531697
I0315 12:43:49.885654 29479 solver.cpp:214] Iteration 44040, loss = 6175.27
I0315 12:43:49.885715 29479 solver.cpp:229]     Train net output #0: loss = 3541.4 (* 1 = 3541.4 loss)
I0315 12:43:50.000056 29479 solver.cpp:610] Iteration 44040, lr = 7.99438e-09
I0315 12:43:50.000071 29479 solver.cpp:613] Iteration 44040, avg_grad_norm = 561949
I0315 12:44:15.596482 29479 solver.cpp:214] Iteration 44060, loss = 6299.25
I0315 12:44:15.596633 29479 solver.cpp:229]     Train net output #0: loss = 3975.92 (* 1 = 3975.92 loss)
I0315 12:44:15.710947 29479 solver.cpp:610] Iteration 44060, lr = 7.99346e-09
I0315 12:44:15.710961 29479 solver.cpp:613] Iteration 44060, avg_grad_norm = 559900
I0315 12:44:52.837874 29479 solver.cpp:214] Iteration 44080, loss = 6336.51
I0315 12:44:52.838014 29479 solver.cpp:229]     Train net output #0: loss = 7464.25 (* 1 = 7464.25 loss)
I0315 12:44:52.942984 29479 solver.cpp:610] Iteration 44080, lr = 7.99254e-09
I0315 12:44:52.942998 29479 solver.cpp:613] Iteration 44080, avg_grad_norm = 521991
I0315 12:45:17.070307 29479 solver.cpp:214] Iteration 44100, loss = 6130.57
I0315 12:45:17.070353 29479 solver.cpp:229]     Train net output #0: loss = 11633.7 (* 1 = 11633.7 loss)
I0315 12:45:17.183243 29479 solver.cpp:610] Iteration 44100, lr = 7.99161e-09
I0315 12:45:17.183255 29479 solver.cpp:613] Iteration 44100, avg_grad_norm = 515223
I0315 12:45:42.637344 29479 solver.cpp:214] Iteration 44120, loss = 6088.31
I0315 12:45:42.637465 29479 solver.cpp:229]     Train net output #0: loss = 5454.95 (* 1 = 5454.95 loss)
I0315 12:45:42.751886 29479 solver.cpp:610] Iteration 44120, lr = 7.99069e-09
I0315 12:45:42.751899 29479 solver.cpp:613] Iteration 44120, avg_grad_norm = 517944
I0315 12:46:08.397217 29479 solver.cpp:214] Iteration 44140, loss = 5936.5
I0315 12:46:08.397279 29479 solver.cpp:229]     Train net output #0: loss = 4253.43 (* 1 = 4253.43 loss)
I0315 12:46:08.511842 29479 solver.cpp:610] Iteration 44140, lr = 7.98977e-09
I0315 12:46:08.511855 29479 solver.cpp:613] Iteration 44140, avg_grad_norm = 509062
I0315 12:46:34.152263 29479 solver.cpp:214] Iteration 44160, loss = 6450.93
I0315 12:46:34.152456 29479 solver.cpp:229]     Train net output #0: loss = 4880.66 (* 1 = 4880.66 loss)
I0315 12:46:34.266880 29479 solver.cpp:610] Iteration 44160, lr = 7.98885e-09
I0315 12:46:34.266893 29479 solver.cpp:613] Iteration 44160, avg_grad_norm = 539355
I0315 12:46:59.908854 29479 solver.cpp:214] Iteration 44180, loss = 6291.87
I0315 12:46:59.908912 29479 solver.cpp:229]     Train net output #0: loss = 4780.35 (* 1 = 4780.35 loss)
I0315 12:47:00.023414 29479 solver.cpp:610] Iteration 44180, lr = 7.98792e-09
I0315 12:47:00.023427 29479 solver.cpp:613] Iteration 44180, avg_grad_norm = 546790
I0315 12:47:50.108602 29479 solver.cpp:214] Iteration 44200, loss = 6322.29
I0315 12:47:50.108819 29479 solver.cpp:229]     Train net output #0: loss = 4151.55 (* 1 = 4151.55 loss)
I0315 12:47:50.213991 29479 solver.cpp:610] Iteration 44200, lr = 7.987e-09
I0315 12:47:50.214004 29479 solver.cpp:613] Iteration 44200, avg_grad_norm = 562015
I0315 12:48:13.695206 29479 solver.cpp:214] Iteration 44220, loss = 6158.65
I0315 12:48:13.695258 29479 solver.cpp:229]     Train net output #0: loss = 2487.81 (* 1 = 2487.81 loss)
I0315 12:48:13.799451 29479 solver.cpp:610] Iteration 44220, lr = 7.98608e-09
I0315 12:48:13.799464 29479 solver.cpp:613] Iteration 44220, avg_grad_norm = 578160
I0315 12:48:37.736090 29479 solver.cpp:214] Iteration 44240, loss = 6042.66
I0315 12:48:37.736220 29479 solver.cpp:229]     Train net output #0: loss = 4223.17 (* 1 = 4223.17 loss)
I0315 12:48:37.849125 29479 solver.cpp:610] Iteration 44240, lr = 7.98515e-09
I0315 12:48:37.849139 29479 solver.cpp:613] Iteration 44240, avg_grad_norm = 549494
I0315 12:49:03.178467 29479 solver.cpp:214] Iteration 44260, loss = 6423.88
I0315 12:49:03.178516 29479 solver.cpp:229]     Train net output #0: loss = 5092.03 (* 1 = 5092.03 loss)
I0315 12:49:03.293118 29479 solver.cpp:610] Iteration 44260, lr = 7.98423e-09
I0315 12:49:03.293130 29479 solver.cpp:613] Iteration 44260, avg_grad_norm = 543520
I0315 12:49:28.946473 29479 solver.cpp:214] Iteration 44280, loss = 5777.97
I0315 12:49:28.946643 29479 solver.cpp:229]     Train net output #0: loss = 3109.16 (* 1 = 3109.16 loss)
I0315 12:49:29.061059 29479 solver.cpp:610] Iteration 44280, lr = 7.98331e-09
I0315 12:49:29.061076 29479 solver.cpp:613] Iteration 44280, avg_grad_norm = 552163
I0315 12:49:54.722175 29479 solver.cpp:214] Iteration 44300, loss = 6167.84
I0315 12:49:54.722237 29479 solver.cpp:229]     Train net output #0: loss = 4437.47 (* 1 = 4437.47 loss)
I0315 12:49:54.836792 29479 solver.cpp:610] Iteration 44300, lr = 7.98239e-09
I0315 12:49:54.836809 29479 solver.cpp:613] Iteration 44300, avg_grad_norm = 565324
I0315 12:50:33.450829 29479 solver.cpp:214] Iteration 44320, loss = 6211.17
I0315 12:50:33.450937 29479 solver.cpp:229]     Train net output #0: loss = 5341.92 (* 1 = 5341.92 loss)
I0315 12:50:33.571707 29479 solver.cpp:610] Iteration 44320, lr = 7.98146e-09
I0315 12:50:33.571737 29479 solver.cpp:613] Iteration 44320, avg_grad_norm = 536057
I0315 12:50:57.085625 29479 solver.cpp:214] Iteration 44340, loss = 5791.9
I0315 12:50:57.085677 29479 solver.cpp:229]     Train net output #0: loss = 5991.65 (* 1 = 5991.65 loss)
I0315 12:50:57.189901 29479 solver.cpp:610] Iteration 44340, lr = 7.98054e-09
I0315 12:50:57.189918 29479 solver.cpp:613] Iteration 44340, avg_grad_norm = 536507
I0315 12:51:22.015370 29479 solver.cpp:214] Iteration 44360, loss = 5933.09
I0315 12:51:22.015581 29479 solver.cpp:229]     Train net output #0: loss = 4142.56 (* 1 = 4142.56 loss)
I0315 12:51:22.131537 29479 solver.cpp:610] Iteration 44360, lr = 7.97962e-09
I0315 12:51:22.131552 29479 solver.cpp:613] Iteration 44360, avg_grad_norm = 510792
I0315 12:51:47.752439 29479 solver.cpp:214] Iteration 44380, loss = 6052.02
I0315 12:51:47.752511 29479 solver.cpp:229]     Train net output #0: loss = 10226.9 (* 1 = 10226.9 loss)
I0315 12:51:47.863857 29479 solver.cpp:610] Iteration 44380, lr = 7.9787e-09
I0315 12:51:47.863869 29479 solver.cpp:613] Iteration 44380, avg_grad_norm = 529238
I0315 12:52:12.920881 29479 solver.cpp:214] Iteration 44400, loss = 6292.63
I0315 12:52:12.921051 29479 solver.cpp:229]     Train net output #0: loss = 3705.67 (* 1 = 3705.67 loss)
I0315 12:52:13.035362 29479 solver.cpp:610] Iteration 44400, lr = 7.97777e-09
I0315 12:52:13.035387 29479 solver.cpp:613] Iteration 44400, avg_grad_norm = 554166
I0315 12:52:38.599145 29479 solver.cpp:214] Iteration 44420, loss = 6050.06
I0315 12:52:38.599218 29479 solver.cpp:229]     Train net output #0: loss = 3318.87 (* 1 = 3318.87 loss)
I0315 12:52:38.713457 29479 solver.cpp:610] Iteration 44420, lr = 7.97685e-09
I0315 12:52:38.713471 29479 solver.cpp:613] Iteration 44420, avg_grad_norm = 542344
I0315 12:53:04.309331 29479 solver.cpp:214] Iteration 44440, loss = 6415.08
I0315 12:53:04.309530 29479 solver.cpp:229]     Train net output #0: loss = 11681.1 (* 1 = 11681.1 loss)
I0315 12:53:04.423949 29479 solver.cpp:610] Iteration 44440, lr = 7.97593e-09
I0315 12:53:04.423964 29479 solver.cpp:613] Iteration 44440, avg_grad_norm = 534451
I0315 12:53:41.578346 29479 solver.cpp:214] Iteration 44460, loss = 6283.29
I0315 12:53:41.578486 29479 solver.cpp:229]     Train net output #0: loss = 5315.3 (* 1 = 5315.3 loss)
I0315 12:53:41.683609 29479 solver.cpp:610] Iteration 44460, lr = 7.975e-09
I0315 12:53:41.683621 29479 solver.cpp:613] Iteration 44460, avg_grad_norm = 596700
I0315 12:54:05.921288 29479 solver.cpp:214] Iteration 44480, loss = 6156.3
I0315 12:54:05.921360 29479 solver.cpp:229]     Train net output #0: loss = 9091.12 (* 1 = 9091.12 loss)
I0315 12:54:06.035938 29479 solver.cpp:610] Iteration 44480, lr = 7.97408e-09
I0315 12:54:06.035950 29479 solver.cpp:613] Iteration 44480, avg_grad_norm = 654216
I0315 12:54:31.631701 29479 solver.cpp:214] Iteration 44500, loss = 5810.39
I0315 12:54:31.631872 29479 solver.cpp:229]     Train net output #0: loss = 10291 (* 1 = 10291 loss)
I0315 12:54:31.746392 29479 solver.cpp:610] Iteration 44500, lr = 7.97316e-09
I0315 12:54:31.746405 29479 solver.cpp:613] Iteration 44500, avg_grad_norm = 675879
I0315 12:54:57.343076 29479 solver.cpp:214] Iteration 44520, loss = 5673.97
I0315 12:54:57.343138 29479 solver.cpp:229]     Train net output #0: loss = 5039.59 (* 1 = 5039.59 loss)
I0315 12:54:57.457586 29479 solver.cpp:610] Iteration 44520, lr = 7.97224e-09
I0315 12:54:57.457598 29479 solver.cpp:613] Iteration 44520, avg_grad_norm = 602558
I0315 12:55:23.052979 29479 solver.cpp:214] Iteration 44540, loss = 6090.41
I0315 12:55:23.053222 29479 solver.cpp:229]     Train net output #0: loss = 4878.01 (* 1 = 4878.01 loss)
I0315 12:55:23.167567 29479 solver.cpp:610] Iteration 44540, lr = 7.97131e-09
I0315 12:55:23.167579 29479 solver.cpp:613] Iteration 44540, avg_grad_norm = 730546
I0315 12:55:48.714429 29479 solver.cpp:214] Iteration 44560, loss = 6173.9
I0315 12:55:48.714499 29479 solver.cpp:229]     Train net output #0: loss = 6866.46 (* 1 = 6866.46 loss)
I0315 12:55:48.829076 29479 solver.cpp:610] Iteration 44560, lr = 7.97039e-09
I0315 12:55:48.829087 29479 solver.cpp:613] Iteration 44560, avg_grad_norm = 572902
I0315 12:56:26.759738 29479 solver.cpp:214] Iteration 44580, loss = 6251.53
I0315 12:56:26.759866 29479 solver.cpp:229]     Train net output #0: loss = 2941.33 (* 1 = 2941.33 loss)
I0315 12:56:26.864799 29479 solver.cpp:610] Iteration 44580, lr = 7.96947e-09
I0315 12:56:26.864811 29479 solver.cpp:613] Iteration 44580, avg_grad_norm = 531718
I0315 12:56:50.327481 29479 solver.cpp:214] Iteration 44600, loss = 6138.29
I0315 12:56:50.327543 29479 solver.cpp:229]     Train net output #0: loss = 5067.12 (* 1 = 5067.12 loss)
I0315 12:56:50.436725 29479 solver.cpp:610] Iteration 44600, lr = 7.96854e-09
I0315 12:56:50.436751 29479 solver.cpp:613] Iteration 44600, avg_grad_norm = 576924
I0315 12:57:15.874600 29479 solver.cpp:214] Iteration 44620, loss = 6238.1
I0315 12:57:15.874730 29479 solver.cpp:229]     Train net output #0: loss = 7964.69 (* 1 = 7964.69 loss)
I0315 12:57:15.989176 29479 solver.cpp:610] Iteration 44620, lr = 7.96762e-09
I0315 12:57:15.989192 29479 solver.cpp:613] Iteration 44620, avg_grad_norm = 649089
I0315 12:57:41.537051 29479 solver.cpp:214] Iteration 44640, loss = 6571.19
I0315 12:57:41.537086 29479 solver.cpp:229]     Train net output #0: loss = 5181.57 (* 1 = 5181.57 loss)
I0315 12:57:41.651681 29479 solver.cpp:610] Iteration 44640, lr = 7.9667e-09
I0315 12:57:41.651695 29479 solver.cpp:613] Iteration 44640, avg_grad_norm = 619984
I0315 12:58:07.208314 29479 solver.cpp:214] Iteration 44660, loss = 6212.78
I0315 12:58:07.208468 29479 solver.cpp:229]     Train net output #0: loss = 6626.35 (* 1 = 6626.35 loss)
I0315 12:58:07.322887 29479 solver.cpp:610] Iteration 44660, lr = 7.96577e-09
I0315 12:58:07.322901 29479 solver.cpp:613] Iteration 44660, avg_grad_norm = 516846
I0315 12:58:32.910754 29479 solver.cpp:214] Iteration 44680, loss = 6264.84
I0315 12:58:32.910815 29479 solver.cpp:229]     Train net output #0: loss = 3180.43 (* 1 = 3180.43 loss)
I0315 12:58:33.025534 29479 solver.cpp:610] Iteration 44680, lr = 7.96485e-09
I0315 12:58:33.025578 29479 solver.cpp:613] Iteration 44680, avg_grad_norm = 520653
I0315 12:58:58.600461 29479 solver.cpp:214] Iteration 44700, loss = 5855.77
I0315 12:58:58.600605 29479 solver.cpp:229]     Train net output #0: loss = 6135.59 (* 1 = 6135.59 loss)
I0315 12:58:58.715070 29479 solver.cpp:610] Iteration 44700, lr = 7.96393e-09
I0315 12:58:58.715085 29479 solver.cpp:613] Iteration 44700, avg_grad_norm = 588966
I0315 12:59:35.592504 29479 solver.cpp:214] Iteration 44720, loss = 6104.87
I0315 12:59:35.592639 29479 solver.cpp:229]     Train net output #0: loss = 7979.86 (* 1 = 7979.86 loss)
I0315 12:59:35.697826 29479 solver.cpp:610] Iteration 44720, lr = 7.963e-09
I0315 12:59:35.697840 29479 solver.cpp:613] Iteration 44720, avg_grad_norm = 557498
I0315 13:00:00.424231 29479 solver.cpp:214] Iteration 44740, loss = 6170.53
I0315 13:00:00.424316 29479 solver.cpp:229]     Train net output #0: loss = 6729.55 (* 1 = 6729.55 loss)
I0315 13:00:00.538828 29479 solver.cpp:610] Iteration 44740, lr = 7.96208e-09
I0315 13:00:00.538842 29479 solver.cpp:613] Iteration 44740, avg_grad_norm = 536648
I0315 13:00:26.127385 29479 solver.cpp:214] Iteration 44760, loss = 6164.7
I0315 13:00:26.127540 29479 solver.cpp:229]     Train net output #0: loss = 4298.38 (* 1 = 4298.38 loss)
I0315 13:00:26.241861 29479 solver.cpp:610] Iteration 44760, lr = 7.96116e-09
I0315 13:00:26.241876 29479 solver.cpp:613] Iteration 44760, avg_grad_norm = 512665
I0315 13:00:51.811153 29479 solver.cpp:214] Iteration 44780, loss = 5730.43
I0315 13:00:51.811238 29479 solver.cpp:229]     Train net output #0: loss = 5007.68 (* 1 = 5007.68 loss)
I0315 13:00:51.925752 29479 solver.cpp:610] Iteration 44780, lr = 7.96024e-09
I0315 13:00:51.925767 29479 solver.cpp:613] Iteration 44780, avg_grad_norm = 507862
I0315 13:01:17.513417 29479 solver.cpp:214] Iteration 44800, loss = 6076.59
I0315 13:01:17.513589 29479 solver.cpp:229]     Train net output #0: loss = 9745.29 (* 1 = 9745.29 loss)
I0315 13:01:17.627972 29479 solver.cpp:610] Iteration 44800, lr = 7.95931e-09
I0315 13:01:17.627987 29479 solver.cpp:613] Iteration 44800, avg_grad_norm = 546002
I0315 13:01:43.170580 29479 solver.cpp:214] Iteration 44820, loss = 6100.84
I0315 13:01:43.170630 29479 solver.cpp:229]     Train net output #0: loss = 8569.55 (* 1 = 8569.55 loss)
I0315 13:01:43.285171 29479 solver.cpp:610] Iteration 44820, lr = 7.95839e-09
I0315 13:01:43.285183 29479 solver.cpp:613] Iteration 44820, avg_grad_norm = 664823
I0315 13:02:25.518506 29479 solver.cpp:214] Iteration 44840, loss = 5903.49
I0315 13:02:25.518606 29479 solver.cpp:229]     Train net output #0: loss = 7338.78 (* 1 = 7338.78 loss)
I0315 13:02:25.623697 29479 solver.cpp:610] Iteration 44840, lr = 7.95747e-09
I0315 13:02:25.623710 29479 solver.cpp:613] Iteration 44840, avg_grad_norm = 540673
I0315 13:02:49.070056 29479 solver.cpp:214] Iteration 44860, loss = 5900.28
I0315 13:02:49.070147 29479 solver.cpp:229]     Train net output #0: loss = 7234.27 (* 1 = 7234.27 loss)
I0315 13:02:49.175146 29479 solver.cpp:610] Iteration 44860, lr = 7.95654e-09
I0315 13:02:49.175159 29479 solver.cpp:613] Iteration 44860, avg_grad_norm = 570595
I0315 13:03:14.599030 29479 solver.cpp:214] Iteration 44880, loss = 6025.4
I0315 13:03:14.599138 29479 solver.cpp:229]     Train net output #0: loss = 9232.44 (* 1 = 9232.44 loss)
I0315 13:03:14.713670 29479 solver.cpp:610] Iteration 44880, lr = 7.95562e-09
I0315 13:03:14.713682 29479 solver.cpp:613] Iteration 44880, avg_grad_norm = 515236
I0315 13:03:40.286387 29479 solver.cpp:214] Iteration 44900, loss = 6117.84
I0315 13:03:40.286461 29479 solver.cpp:229]     Train net output #0: loss = 5557.86 (* 1 = 5557.86 loss)
I0315 13:03:40.400959 29479 solver.cpp:610] Iteration 44900, lr = 7.9547e-09
I0315 13:03:40.400974 29479 solver.cpp:613] Iteration 44900, avg_grad_norm = 527259
I0315 13:04:05.995767 29479 solver.cpp:214] Iteration 44920, loss = 6034.52
I0315 13:04:05.995915 29479 solver.cpp:229]     Train net output #0: loss = 4688.13 (* 1 = 4688.13 loss)
I0315 13:04:06.110649 29479 solver.cpp:610] Iteration 44920, lr = 7.95377e-09
I0315 13:04:06.110662 29479 solver.cpp:613] Iteration 44920, avg_grad_norm = 510902
I0315 13:04:31.743574 29479 solver.cpp:214] Iteration 44940, loss = 6101.32
I0315 13:04:31.743625 29479 solver.cpp:229]     Train net output #0: loss = 6120.07 (* 1 = 6120.07 loss)
I0315 13:04:31.856953 29479 solver.cpp:610] Iteration 44940, lr = 7.95285e-09
I0315 13:04:31.856966 29479 solver.cpp:613] Iteration 44940, avg_grad_norm = 556383
I0315 13:05:09.937183 29479 solver.cpp:214] Iteration 44960, loss = 6109.54
I0315 13:05:09.937330 29479 solver.cpp:229]     Train net output #0: loss = 5823.4 (* 1 = 5823.4 loss)
I0315 13:05:10.042330 29479 solver.cpp:610] Iteration 44960, lr = 7.95193e-09
I0315 13:05:10.042345 29479 solver.cpp:613] Iteration 44960, avg_grad_norm = 564939
I0315 13:05:33.486780 29479 solver.cpp:214] Iteration 44980, loss = 6060.64
I0315 13:05:33.486871 29479 solver.cpp:229]     Train net output #0: loss = 8771.04 (* 1 = 8771.04 loss)
I0315 13:05:33.591909 29479 solver.cpp:610] Iteration 44980, lr = 7.951e-09
I0315 13:05:33.591923 29479 solver.cpp:613] Iteration 44980, avg_grad_norm = 529591
I0315 13:05:59.144037 29479 solver.cpp:214] Iteration 45000, loss = 6350.45
I0315 13:05:59.144206 29479 solver.cpp:229]     Train net output #0: loss = 4791.14 (* 1 = 4791.14 loss)
I0315 13:05:59.258677 29479 solver.cpp:610] Iteration 45000, lr = 7.95008e-09
I0315 13:05:59.258690 29479 solver.cpp:613] Iteration 45000, avg_grad_norm = 564664
I0315 13:06:24.645229 29479 solver.cpp:214] Iteration 45020, loss = 5860.59
I0315 13:06:24.645284 29479 solver.cpp:229]     Train net output #0: loss = 6927.7 (* 1 = 6927.7 loss)
I0315 13:06:24.758319 29479 solver.cpp:610] Iteration 45020, lr = 7.94916e-09
I0315 13:06:24.758334 29479 solver.cpp:613] Iteration 45020, avg_grad_norm = 505332
I0315 13:06:50.081039 29479 solver.cpp:214] Iteration 45040, loss = 5968.7
I0315 13:06:50.081269 29479 solver.cpp:229]     Train net output #0: loss = 9812.57 (* 1 = 9812.57 loss)
I0315 13:06:50.197011 29479 solver.cpp:610] Iteration 45040, lr = 7.94823e-09
I0315 13:06:50.197052 29479 solver.cpp:613] Iteration 45040, avg_grad_norm = 576152
I0315 13:07:16.074093 29479 solver.cpp:214] Iteration 45060, loss = 5998.05
I0315 13:07:16.074146 29479 solver.cpp:229]     Train net output #0: loss = 7334.82 (* 1 = 7334.82 loss)
I0315 13:07:16.188578 29479 solver.cpp:610] Iteration 45060, lr = 7.94731e-09
I0315 13:07:16.188596 29479 solver.cpp:613] Iteration 45060, avg_grad_norm = 528438
I0315 13:07:41.591395 29479 solver.cpp:214] Iteration 45080, loss = 6000.47
I0315 13:07:41.591522 29479 solver.cpp:229]     Train net output #0: loss = 5027.98 (* 1 = 5027.98 loss)
I0315 13:07:41.704355 29479 solver.cpp:610] Iteration 45080, lr = 7.94639e-09
I0315 13:07:41.704368 29479 solver.cpp:613] Iteration 45080, avg_grad_norm = 534962
I0315 13:08:18.566306 29479 solver.cpp:214] Iteration 45100, loss = 6076.79
I0315 13:08:18.566520 29479 solver.cpp:229]     Train net output #0: loss = 3381.3 (* 1 = 3381.3 loss)
I0315 13:08:18.671413 29479 solver.cpp:610] Iteration 45100, lr = 7.94546e-09
I0315 13:08:18.671427 29479 solver.cpp:613] Iteration 45100, avg_grad_norm = 580672
I0315 13:08:43.352999 29479 solver.cpp:214] Iteration 45120, loss = 6125.34
I0315 13:08:43.353070 29479 solver.cpp:229]     Train net output #0: loss = 5250.72 (* 1 = 5250.72 loss)
I0315 13:08:43.467504 29479 solver.cpp:610] Iteration 45120, lr = 7.94454e-09
I0315 13:08:43.467541 29479 solver.cpp:613] Iteration 45120, avg_grad_norm = 618640
I0315 13:09:09.006995 29479 solver.cpp:214] Iteration 45140, loss = 6308.51
I0315 13:09:09.007154 29479 solver.cpp:229]     Train net output #0: loss = 4100.66 (* 1 = 4100.66 loss)
I0315 13:09:09.121609 29479 solver.cpp:610] Iteration 45140, lr = 7.94362e-09
I0315 13:09:09.121623 29479 solver.cpp:613] Iteration 45140, avg_grad_norm = 552038
I0315 13:09:34.661389 29479 solver.cpp:214] Iteration 45160, loss = 6194.21
I0315 13:09:34.661473 29479 solver.cpp:229]     Train net output #0: loss = 6118.49 (* 1 = 6118.49 loss)
I0315 13:09:34.775919 29479 solver.cpp:610] Iteration 45160, lr = 7.94269e-09
I0315 13:09:34.775933 29479 solver.cpp:613] Iteration 45160, avg_grad_norm = 526246
I0315 13:10:00.343598 29479 solver.cpp:214] Iteration 45180, loss = 6054.6
I0315 13:10:00.343762 29479 solver.cpp:229]     Train net output #0: loss = 6043.66 (* 1 = 6043.66 loss)
I0315 13:10:00.458300 29479 solver.cpp:610] Iteration 45180, lr = 7.94177e-09
I0315 13:10:00.458313 29479 solver.cpp:613] Iteration 45180, avg_grad_norm = 499423
I0315 13:10:26.055562 29479 solver.cpp:214] Iteration 45200, loss = 6314.89
I0315 13:10:26.055615 29479 solver.cpp:229]     Train net output #0: loss = 6793.35 (* 1 = 6793.35 loss)
I0315 13:10:26.170207 29479 solver.cpp:610] Iteration 45200, lr = 7.94085e-09
I0315 13:10:26.170222 29479 solver.cpp:613] Iteration 45200, avg_grad_norm = 548774
I0315 13:11:03.609663 29479 solver.cpp:214] Iteration 45220, loss = 6166.6
I0315 13:11:03.609830 29479 solver.cpp:229]     Train net output #0: loss = 11010.3 (* 1 = 11010.3 loss)
I0315 13:11:03.714817 29479 solver.cpp:610] Iteration 45220, lr = 7.93992e-09
I0315 13:11:03.714830 29479 solver.cpp:613] Iteration 45220, avg_grad_norm = 540040
I0315 13:11:27.720715 29479 solver.cpp:214] Iteration 45240, loss = 6187.31
I0315 13:11:27.720793 29479 solver.cpp:229]     Train net output #0: loss = 6507.85 (* 1 = 6507.85 loss)
I0315 13:11:27.835268 29479 solver.cpp:610] Iteration 45240, lr = 7.939e-09
I0315 13:11:27.835283 29479 solver.cpp:613] Iteration 45240, avg_grad_norm = 554751
I0315 13:11:53.397724 29479 solver.cpp:214] Iteration 45260, loss = 6185.08
I0315 13:11:53.397850 29479 solver.cpp:229]     Train net output #0: loss = 6193.74 (* 1 = 6193.74 loss)
I0315 13:11:53.512481 29479 solver.cpp:610] Iteration 45260, lr = 7.93808e-09
I0315 13:11:53.512497 29479 solver.cpp:613] Iteration 45260, avg_grad_norm = 536772
I0315 13:12:19.094117 29479 solver.cpp:214] Iteration 45280, loss = 6140.46
I0315 13:12:19.094197 29479 solver.cpp:229]     Train net output #0: loss = 4913.68 (* 1 = 4913.68 loss)
I0315 13:12:19.208798 29479 solver.cpp:610] Iteration 45280, lr = 7.93715e-09
I0315 13:12:19.208813 29479 solver.cpp:613] Iteration 45280, avg_grad_norm = 534774
I0315 13:12:44.815865 29479 solver.cpp:214] Iteration 45300, loss = 5956.77
I0315 13:12:44.815999 29479 solver.cpp:229]     Train net output #0: loss = 4950.49 (* 1 = 4950.49 loss)
I0315 13:12:44.930493 29479 solver.cpp:610] Iteration 45300, lr = 7.93623e-09
I0315 13:12:44.930507 29479 solver.cpp:613] Iteration 45300, avg_grad_norm = 535375
I0315 13:13:10.540132 29479 solver.cpp:214] Iteration 45320, loss = 6201.8
I0315 13:13:10.540194 29479 solver.cpp:229]     Train net output #0: loss = 8307.75 (* 1 = 8307.75 loss)
I0315 13:13:10.654695 29479 solver.cpp:610] Iteration 45320, lr = 7.93531e-09
I0315 13:13:10.654707 29479 solver.cpp:613] Iteration 45320, avg_grad_norm = 542881
I0315 13:14:06.601380 29479 solver.cpp:214] Iteration 45340, loss = 5985.36
I0315 13:14:06.601555 29479 solver.cpp:229]     Train net output #0: loss = 4882.91 (* 1 = 4882.91 loss)
I0315 13:14:06.706784 29479 solver.cpp:610] Iteration 45340, lr = 7.93438e-09
I0315 13:14:06.706797 29479 solver.cpp:613] Iteration 45340, avg_grad_norm = 508222
I0315 13:14:30.172030 29479 solver.cpp:214] Iteration 45360, loss = 5891.05
I0315 13:14:30.172093 29479 solver.cpp:229]     Train net output #0: loss = 9245.31 (* 1 = 9245.31 loss)
I0315 13:14:30.275956 29479 solver.cpp:610] Iteration 45360, lr = 7.93346e-09
I0315 13:14:30.275969 29479 solver.cpp:613] Iteration 45360, avg_grad_norm = 539239
I0315 13:14:53.794828 29479 solver.cpp:214] Iteration 45380, loss = 6050.21
I0315 13:14:53.795022 29479 solver.cpp:229]     Train net output #0: loss = 4862.66 (* 1 = 4862.66 loss)
I0315 13:14:53.900084 29479 solver.cpp:610] Iteration 45380, lr = 7.93254e-09
I0315 13:14:53.900097 29479 solver.cpp:613] Iteration 45380, avg_grad_norm = 697884
I0315 13:15:18.631703 29479 solver.cpp:214] Iteration 45400, loss = 6103.17
I0315 13:15:18.631757 29479 solver.cpp:229]     Train net output #0: loss = 6996.52 (* 1 = 6996.52 loss)
I0315 13:15:18.744683 29479 solver.cpp:610] Iteration 45400, lr = 7.93161e-09
I0315 13:15:18.744696 29479 solver.cpp:613] Iteration 45400, avg_grad_norm = 634267
I0315 13:15:44.331619 29479 solver.cpp:214] Iteration 45420, loss = 6056.65
I0315 13:15:44.331737 29479 solver.cpp:229]     Train net output #0: loss = 6495.64 (* 1 = 6495.64 loss)
I0315 13:15:44.446352 29479 solver.cpp:610] Iteration 45420, lr = 7.93069e-09
I0315 13:15:44.446367 29479 solver.cpp:613] Iteration 45420, avg_grad_norm = 488775
I0315 13:16:10.025590 29479 solver.cpp:214] Iteration 45440, loss = 6565.59
I0315 13:16:10.025657 29479 solver.cpp:229]     Train net output #0: loss = 4568.04 (* 1 = 4568.04 loss)
I0315 13:16:10.140142 29479 solver.cpp:610] Iteration 45440, lr = 7.92977e-09
I0315 13:16:10.140156 29479 solver.cpp:613] Iteration 45440, avg_grad_norm = 559948
I0315 13:16:35.384940 29479 solver.cpp:214] Iteration 45460, loss = 5916.59
I0315 13:16:35.385118 29479 solver.cpp:229]     Train net output #0: loss = 4234.53 (* 1 = 4234.53 loss)
I0315 13:16:35.497867 29479 solver.cpp:610] Iteration 45460, lr = 7.92884e-09
I0315 13:16:35.497880 29479 solver.cpp:613] Iteration 45460, avg_grad_norm = 510309
I0315 13:17:39.609258 29479 solver.cpp:214] Iteration 45480, loss = 6143.6
I0315 13:17:39.609400 29479 solver.cpp:229]     Train net output #0: loss = 3330.11 (* 1 = 3330.11 loss)
I0315 13:17:39.713248 29479 solver.cpp:610] Iteration 45480, lr = 7.92792e-09
I0315 13:17:39.713261 29479 solver.cpp:613] Iteration 45480, avg_grad_norm = 548742
I0315 13:18:03.125408 29479 solver.cpp:214] Iteration 45500, loss = 6247.92
I0315 13:18:03.125501 29479 solver.cpp:229]     Train net output #0: loss = 9616.19 (* 1 = 9616.19 loss)
I0315 13:18:03.230633 29479 solver.cpp:610] Iteration 45500, lr = 7.927e-09
I0315 13:18:03.230645 29479 solver.cpp:613] Iteration 45500, avg_grad_norm = 519416
I0315 13:18:26.674530 29479 solver.cpp:214] Iteration 45520, loss = 6075.18
I0315 13:18:26.674651 29479 solver.cpp:229]     Train net output #0: loss = 4273.37 (* 1 = 4273.37 loss)
I0315 13:18:26.779664 29479 solver.cpp:610] Iteration 45520, lr = 7.92607e-09
I0315 13:18:26.779676 29479 solver.cpp:613] Iteration 45520, avg_grad_norm = 504283
I0315 13:18:51.732321 29479 solver.cpp:214] Iteration 45540, loss = 6050.3
I0315 13:18:51.732394 29479 solver.cpp:229]     Train net output #0: loss = 4217.48 (* 1 = 4217.48 loss)
I0315 13:18:51.846943 29479 solver.cpp:610] Iteration 45540, lr = 7.92515e-09
I0315 13:18:51.846982 29479 solver.cpp:613] Iteration 45540, avg_grad_norm = 546410
I0315 13:19:17.468886 29479 solver.cpp:214] Iteration 45560, loss = 6083.28
I0315 13:19:17.469084 29479 solver.cpp:229]     Train net output #0: loss = 4021.84 (* 1 = 4021.84 loss)
I0315 13:19:17.581845 29479 solver.cpp:610] Iteration 45560, lr = 7.92422e-09
I0315 13:19:17.581858 29479 solver.cpp:613] Iteration 45560, avg_grad_norm = 510044
I0315 13:19:42.802141 29479 solver.cpp:214] Iteration 45580, loss = 6149.15
I0315 13:19:42.802207 29479 solver.cpp:229]     Train net output #0: loss = 4319.29 (* 1 = 4319.29 loss)
I0315 13:19:42.915017 29479 solver.cpp:610] Iteration 45580, lr = 7.9233e-09
I0315 13:19:42.915030 29479 solver.cpp:613] Iteration 45580, avg_grad_norm = 509064
I0315 13:20:20.252988 29479 solver.cpp:214] Iteration 45600, loss = 5857.5
I0315 13:20:20.253212 29479 solver.cpp:229]     Train net output #0: loss = 8334.62 (* 1 = 8334.62 loss)
I0315 13:20:20.358111 29479 solver.cpp:610] Iteration 45600, lr = 7.92238e-09
I0315 13:20:20.358125 29479 solver.cpp:613] Iteration 45600, avg_grad_norm = 514947
I0315 13:20:44.219305 29479 solver.cpp:214] Iteration 45620, loss = 6074.4
I0315 13:20:44.219362 29479 solver.cpp:229]     Train net output #0: loss = 4569.35 (* 1 = 4569.35 loss)
I0315 13:20:44.330986 29479 solver.cpp:610] Iteration 45620, lr = 7.92145e-09
I0315 13:20:44.330998 29479 solver.cpp:613] Iteration 45620, avg_grad_norm = 528780
I0315 13:21:09.895232 29479 solver.cpp:214] Iteration 45640, loss = 6407.45
I0315 13:21:09.895386 29479 solver.cpp:229]     Train net output #0: loss = 11034.6 (* 1 = 11034.6 loss)
I0315 13:21:10.009819 29479 solver.cpp:610] Iteration 45640, lr = 7.92053e-09
I0315 13:21:10.009834 29479 solver.cpp:613] Iteration 45640, avg_grad_norm = 508014
I0315 13:21:35.637768 29479 solver.cpp:214] Iteration 45660, loss = 6014.5
I0315 13:21:35.637817 29479 solver.cpp:229]     Train net output #0: loss = 5608.28 (* 1 = 5608.28 loss)
I0315 13:21:35.752297 29479 solver.cpp:610] Iteration 45660, lr = 7.91961e-09
I0315 13:21:35.752311 29479 solver.cpp:613] Iteration 45660, avg_grad_norm = 698900
I0315 13:22:01.391365 29479 solver.cpp:214] Iteration 45680, loss = 6190.58
I0315 13:22:01.391505 29479 solver.cpp:229]     Train net output #0: loss = 3818.69 (* 1 = 3818.69 loss)
I0315 13:22:01.506006 29479 solver.cpp:610] Iteration 45680, lr = 7.91868e-09
I0315 13:22:01.506018 29479 solver.cpp:613] Iteration 45680, avg_grad_norm = 596246
I0315 13:22:27.145758 29479 solver.cpp:214] Iteration 45700, loss = 6066.92
I0315 13:22:27.145817 29479 solver.cpp:229]     Train net output #0: loss = 3067.08 (* 1 = 3067.08 loss)
I0315 13:22:27.260393 29479 solver.cpp:610] Iteration 45700, lr = 7.91776e-09
I0315 13:22:27.260407 29479 solver.cpp:613] Iteration 45700, avg_grad_norm = 607272
I0315 13:23:05.222232 29479 solver.cpp:214] Iteration 45720, loss = 6124.45
I0315 13:23:05.222419 29479 solver.cpp:229]     Train net output #0: loss = 4863.05 (* 1 = 4863.05 loss)
I0315 13:23:05.327483 29479 solver.cpp:610] Iteration 45720, lr = 7.91684e-09
I0315 13:23:05.327497 29479 solver.cpp:613] Iteration 45720, avg_grad_norm = 562753
I0315 13:23:28.838449 29479 solver.cpp:214] Iteration 45740, loss = 5957.9
I0315 13:23:28.838500 29479 solver.cpp:229]     Train net output #0: loss = 3469.59 (* 1 = 3469.59 loss)
I0315 13:23:28.943603 29479 solver.cpp:610] Iteration 45740, lr = 7.91591e-09
I0315 13:23:28.943614 29479 solver.cpp:613] Iteration 45740, avg_grad_norm = 522702
I0315 13:23:54.342021 29479 solver.cpp:214] Iteration 45760, loss = 6315.4
I0315 13:23:54.342162 29479 solver.cpp:229]     Train net output #0: loss = 5658.99 (* 1 = 5658.99 loss)
I0315 13:23:54.456619 29479 solver.cpp:610] Iteration 45760, lr = 7.91499e-09
I0315 13:23:54.456656 29479 solver.cpp:613] Iteration 45760, avg_grad_norm = 538239
I0315 13:24:20.050552 29479 solver.cpp:214] Iteration 45780, loss = 6345.71
I0315 13:24:20.050595 29479 solver.cpp:229]     Train net output #0: loss = 10388.6 (* 1 = 10388.6 loss)
I0315 13:24:20.165207 29479 solver.cpp:610] Iteration 45780, lr = 7.91406e-09
I0315 13:24:20.165220 29479 solver.cpp:613] Iteration 45780, avg_grad_norm = 553308
I0315 13:24:45.753278 29479 solver.cpp:214] Iteration 45800, loss = 6530.85
I0315 13:24:45.753486 29479 solver.cpp:229]     Train net output #0: loss = 11843.8 (* 1 = 11843.8 loss)
I0315 13:24:45.867940 29479 solver.cpp:610] Iteration 45800, lr = 7.91314e-09
I0315 13:24:45.867954 29479 solver.cpp:613] Iteration 45800, avg_grad_norm = 550865
I0315 13:25:11.437934 29479 solver.cpp:214] Iteration 45820, loss = 6156.56
I0315 13:25:11.437999 29479 solver.cpp:229]     Train net output #0: loss = 4258.69 (* 1 = 4258.69 loss)
I0315 13:25:11.552477 29479 solver.cpp:610] Iteration 45820, lr = 7.91222e-09
I0315 13:25:11.552492 29479 solver.cpp:613] Iteration 45820, avg_grad_norm = 521678
I0315 13:25:37.130514 29479 solver.cpp:214] Iteration 45840, loss = 6231.9
I0315 13:25:37.130666 29479 solver.cpp:229]     Train net output #0: loss = 4251.27 (* 1 = 4251.27 loss)
I0315 13:25:37.245188 29479 solver.cpp:610] Iteration 45840, lr = 7.91129e-09
I0315 13:25:37.245213 29479 solver.cpp:613] Iteration 45840, avg_grad_norm = 566542
I0315 13:26:15.491190 29479 solver.cpp:214] Iteration 45860, loss = 6215.74
I0315 13:26:15.491319 29479 solver.cpp:229]     Train net output #0: loss = 3865.56 (* 1 = 3865.56 loss)
I0315 13:26:15.596397 29479 solver.cpp:610] Iteration 45860, lr = 7.91037e-09
I0315 13:26:15.596410 29479 solver.cpp:613] Iteration 45860, avg_grad_norm = 543242
I0315 13:26:39.903151 29479 solver.cpp:214] Iteration 45880, loss = 6298.68
I0315 13:26:39.903247 29479 solver.cpp:229]     Train net output #0: loss = 10177.9 (* 1 = 10177.9 loss)
I0315 13:26:40.017616 29479 solver.cpp:610] Iteration 45880, lr = 7.90945e-09
I0315 13:26:40.017630 29479 solver.cpp:613] Iteration 45880, avg_grad_norm = 565936
I0315 13:27:05.846726 29479 solver.cpp:214] Iteration 45900, loss = 6046.36
I0315 13:27:05.846915 29479 solver.cpp:229]     Train net output #0: loss = 3684.69 (* 1 = 3684.69 loss)
I0315 13:27:05.961836 29479 solver.cpp:610] Iteration 45900, lr = 7.90852e-09
I0315 13:27:05.961849 29479 solver.cpp:613] Iteration 45900, avg_grad_norm = 550758
I0315 13:27:31.505417 29479 solver.cpp:214] Iteration 45920, loss = 6099.37
I0315 13:27:31.505481 29479 solver.cpp:229]     Train net output #0: loss = 5874.28 (* 1 = 5874.28 loss)
I0315 13:27:31.619952 29479 solver.cpp:610] Iteration 45920, lr = 7.9076e-09
I0315 13:27:31.619964 29479 solver.cpp:613] Iteration 45920, avg_grad_norm = 564653
I0315 13:27:57.158658 29479 solver.cpp:214] Iteration 45940, loss = 6380.15
I0315 13:27:57.158798 29479 solver.cpp:229]     Train net output #0: loss = 4628.63 (* 1 = 4628.63 loss)
I0315 13:27:57.273201 29479 solver.cpp:610] Iteration 45940, lr = 7.90668e-09
I0315 13:27:57.273214 29479 solver.cpp:613] Iteration 45940, avg_grad_norm = 575440
I0315 13:28:22.819463 29479 solver.cpp:214] Iteration 45960, loss = 6036.28
I0315 13:28:22.819530 29479 solver.cpp:229]     Train net output #0: loss = 9017.86 (* 1 = 9017.86 loss)
I0315 13:28:22.934077 29479 solver.cpp:610] Iteration 45960, lr = 7.90575e-09
I0315 13:28:22.934090 29479 solver.cpp:613] Iteration 45960, avg_grad_norm = 566619
I0315 13:29:09.733949 29479 solver.cpp:214] Iteration 45980, loss = 6133.39
I0315 13:29:09.734072 29479 solver.cpp:229]     Train net output #0: loss = 6242.85 (* 1 = 6242.85 loss)
I0315 13:29:09.839529 29479 solver.cpp:610] Iteration 45980, lr = 7.90483e-09
I0315 13:29:09.839543 29479 solver.cpp:613] Iteration 45980, avg_grad_norm = 530101
I0315 13:29:33.339015 29479 solver.cpp:214] Iteration 46000, loss = 5976.49
I0315 13:29:33.339082 29479 solver.cpp:229]     Train net output #0: loss = 5109.21 (* 1 = 5109.21 loss)
I0315 13:29:33.444331 29479 solver.cpp:610] Iteration 46000, lr = 7.9039e-09
I0315 13:29:33.444344 29479 solver.cpp:613] Iteration 46000, avg_grad_norm = 512084
I0315 13:29:58.140918 29479 solver.cpp:214] Iteration 46020, loss = 5943.64
I0315 13:29:58.141063 29479 solver.cpp:229]     Train net output #0: loss = 6104.75 (* 1 = 6104.75 loss)
I0315 13:29:58.255657 29479 solver.cpp:610] Iteration 46020, lr = 7.90298e-09
I0315 13:29:58.255671 29479 solver.cpp:613] Iteration 46020, avg_grad_norm = 533128
I0315 13:30:23.902863 29479 solver.cpp:214] Iteration 46040, loss = 6207.19
I0315 13:30:23.902930 29479 solver.cpp:229]     Train net output #0: loss = 6779.58 (* 1 = 6779.58 loss)
I0315 13:30:24.017410 29479 solver.cpp:610] Iteration 46040, lr = 7.90206e-09
I0315 13:30:24.017423 29479 solver.cpp:613] Iteration 46040, avg_grad_norm = 570130
I0315 13:30:49.403033 29479 solver.cpp:214] Iteration 46060, loss = 6254
I0315 13:30:49.403152 29479 solver.cpp:229]     Train net output #0: loss = 9592.67 (* 1 = 9592.67 loss)
I0315 13:30:49.515928 29479 solver.cpp:610] Iteration 46060, lr = 7.90113e-09
I0315 13:30:49.515940 29479 solver.cpp:613] Iteration 46060, avg_grad_norm = 503217
I0315 13:31:14.818851 29479 solver.cpp:214] Iteration 46080, loss = 6327.58
I0315 13:31:14.818922 29479 solver.cpp:229]     Train net output #0: loss = 4769.15 (* 1 = 4769.15 loss)
I0315 13:31:14.933614 29479 solver.cpp:610] Iteration 46080, lr = 7.90021e-09
I0315 13:31:14.933629 29479 solver.cpp:613] Iteration 46080, avg_grad_norm = 524558
I0315 13:31:54.786216 29479 solver.cpp:214] Iteration 46100, loss = 6199.17
I0315 13:31:54.786324 29479 solver.cpp:229]     Train net output #0: loss = 5206.9 (* 1 = 5206.9 loss)
I0315 13:31:54.889878 29479 solver.cpp:610] Iteration 46100, lr = 7.89928e-09
I0315 13:31:54.889891 29479 solver.cpp:613] Iteration 46100, avg_grad_norm = 575447
I0315 13:32:18.323439 29479 solver.cpp:214] Iteration 46120, loss = 6333.74
I0315 13:32:18.323500 29479 solver.cpp:229]     Train net output #0: loss = 9889.61 (* 1 = 9889.61 loss)
I0315 13:32:18.428514 29479 solver.cpp:610] Iteration 46120, lr = 7.89836e-09
I0315 13:32:18.428526 29479 solver.cpp:613] Iteration 46120, avg_grad_norm = 635617
I0315 13:32:43.353054 29479 solver.cpp:214] Iteration 46140, loss = 6017.21
I0315 13:32:43.353158 29479 solver.cpp:229]     Train net output #0: loss = 6339.1 (* 1 = 6339.1 loss)
I0315 13:32:43.467593 29479 solver.cpp:610] Iteration 46140, lr = 7.89744e-09
I0315 13:32:43.467607 29479 solver.cpp:613] Iteration 46140, avg_grad_norm = 516492
I0315 13:33:09.009014 29479 solver.cpp:214] Iteration 46160, loss = 6325.23
I0315 13:33:09.009081 29479 solver.cpp:229]     Train net output #0: loss = 4842.48 (* 1 = 4842.48 loss)
I0315 13:33:09.123616 29479 solver.cpp:610] Iteration 46160, lr = 7.89651e-09
I0315 13:33:09.123630 29479 solver.cpp:613] Iteration 46160, avg_grad_norm = 524829
I0315 13:33:34.660960 29479 solver.cpp:214] Iteration 46180, loss = 6000.42
I0315 13:33:34.661211 29479 solver.cpp:229]     Train net output #0: loss = 4168.57 (* 1 = 4168.57 loss)
I0315 13:33:34.775415 29479 solver.cpp:610] Iteration 46180, lr = 7.89559e-09
I0315 13:33:34.775449 29479 solver.cpp:613] Iteration 46180, avg_grad_norm = 564537
I0315 13:34:00.368908 29479 solver.cpp:214] Iteration 46200, loss = 6186.44
I0315 13:34:00.368974 29479 solver.cpp:229]     Train net output #0: loss = 5199.35 (* 1 = 5199.35 loss)
I0315 13:34:00.483579 29479 solver.cpp:610] Iteration 46200, lr = 7.89467e-09
I0315 13:34:00.483593 29479 solver.cpp:613] Iteration 46200, avg_grad_norm = 614880
I0315 13:34:26.094852 29479 solver.cpp:214] Iteration 46220, loss = 6076.7
I0315 13:34:26.095002 29479 solver.cpp:229]     Train net output #0: loss = 4803.2 (* 1 = 4803.2 loss)
I0315 13:34:26.209373 29479 solver.cpp:610] Iteration 46220, lr = 7.89374e-09
I0315 13:34:26.209388 29479 solver.cpp:613] Iteration 46220, avg_grad_norm = 523720
I0315 13:35:03.486943 29479 solver.cpp:214] Iteration 46240, loss = 6546.84
I0315 13:35:03.487129 29479 solver.cpp:229]     Train net output #0: loss = 4516.52 (* 1 = 4516.52 loss)
I0315 13:35:03.592041 29479 solver.cpp:610] Iteration 46240, lr = 7.89282e-09
I0315 13:35:03.592056 29479 solver.cpp:613] Iteration 46240, avg_grad_norm = 626398
I0315 13:35:27.903940 29479 solver.cpp:214] Iteration 46260, loss = 6105.66
I0315 13:35:27.904006 29479 solver.cpp:229]     Train net output #0: loss = 6092.92 (* 1 = 6092.92 loss)
I0315 13:35:28.018573 29479 solver.cpp:610] Iteration 46260, lr = 7.89189e-09
I0315 13:35:28.018586 29479 solver.cpp:613] Iteration 46260, avg_grad_norm = 643576
I0315 13:35:53.579071 29479 solver.cpp:214] Iteration 46280, loss = 5864.44
I0315 13:35:53.579190 29479 solver.cpp:229]     Train net output #0: loss = 8093.13 (* 1 = 8093.13 loss)
I0315 13:35:53.693681 29479 solver.cpp:610] Iteration 46280, lr = 7.89097e-09
I0315 13:35:53.693694 29479 solver.cpp:613] Iteration 46280, avg_grad_norm = 573191
I0315 13:36:19.243362 29479 solver.cpp:214] Iteration 46300, loss = 6149.72
I0315 13:36:19.243427 29479 solver.cpp:229]     Train net output #0: loss = 4826.23 (* 1 = 4826.23 loss)
I0315 13:36:19.357997 29479 solver.cpp:610] Iteration 46300, lr = 7.89005e-09
I0315 13:36:19.358011 29479 solver.cpp:613] Iteration 46300, avg_grad_norm = 552673
I0315 13:36:44.919780 29479 solver.cpp:214] Iteration 46320, loss = 6013.5
I0315 13:36:44.919929 29479 solver.cpp:229]     Train net output #0: loss = 4773.59 (* 1 = 4773.59 loss)
I0315 13:36:45.034441 29479 solver.cpp:610] Iteration 46320, lr = 7.88912e-09
I0315 13:36:45.034456 29479 solver.cpp:613] Iteration 46320, avg_grad_norm = 501314
I0315 13:37:10.686084 29479 solver.cpp:214] Iteration 46340, loss = 6062.73
I0315 13:37:10.686133 29479 solver.cpp:229]     Train net output #0: loss = 3907.35 (* 1 = 3907.35 loss)
I0315 13:37:10.800617 29479 solver.cpp:610] Iteration 46340, lr = 7.8882e-09
I0315 13:37:10.800632 29479 solver.cpp:613] Iteration 46340, avg_grad_norm = 486555
I0315 13:37:50.400115 29479 solver.cpp:214] Iteration 46360, loss = 6085.06
I0315 13:37:50.400245 29479 solver.cpp:229]     Train net output #0: loss = 3926.57 (* 1 = 3926.57 loss)
I0315 13:37:50.505370 29479 solver.cpp:610] Iteration 46360, lr = 7.88727e-09
I0315 13:37:50.505384 29479 solver.cpp:613] Iteration 46360, avg_grad_norm = 572946
I0315 13:38:13.956861 29479 solver.cpp:214] Iteration 46380, loss = 6297.51
I0315 13:38:13.956895 29479 solver.cpp:229]     Train net output #0: loss = 5478.05 (* 1 = 5478.05 loss)
I0315 13:38:14.065953 29479 solver.cpp:610] Iteration 46380, lr = 7.88635e-09
I0315 13:38:14.065966 29479 solver.cpp:613] Iteration 46380, avg_grad_norm = 620655
I0315 13:38:39.369168 29479 solver.cpp:214] Iteration 46400, loss = 6296.7
I0315 13:38:39.369277 29479 solver.cpp:229]     Train net output #0: loss = 3198.47 (* 1 = 3198.47 loss)
I0315 13:38:39.483642 29479 solver.cpp:610] Iteration 46400, lr = 7.88542e-09
I0315 13:38:39.483655 29479 solver.cpp:613] Iteration 46400, avg_grad_norm = 518619
I0315 13:39:05.071224 29479 solver.cpp:214] Iteration 46420, loss = 6416.7
I0315 13:39:05.071290 29479 solver.cpp:229]     Train net output #0: loss = 13390.1 (* 1 = 13390.1 loss)
I0315 13:39:05.185967 29479 solver.cpp:610] Iteration 46420, lr = 7.8845e-09
I0315 13:39:05.185981 29479 solver.cpp:613] Iteration 46420, avg_grad_norm = 578515
I0315 13:39:30.767606 29479 solver.cpp:214] Iteration 46440, loss = 6094.98
I0315 13:39:30.767776 29479 solver.cpp:229]     Train net output #0: loss = 5445.21 (* 1 = 5445.21 loss)
I0315 13:39:30.882375 29479 solver.cpp:610] Iteration 46440, lr = 7.88358e-09
I0315 13:39:30.882390 29479 solver.cpp:613] Iteration 46440, avg_grad_norm = 611160
I0315 13:39:56.475487 29479 solver.cpp:214] Iteration 46460, loss = 6256.73
I0315 13:39:56.475544 29479 solver.cpp:229]     Train net output #0: loss = 7323.28 (* 1 = 7323.28 loss)
I0315 13:39:56.590100 29479 solver.cpp:610] Iteration 46460, lr = 7.88265e-09
I0315 13:39:56.590112 29479 solver.cpp:613] Iteration 46460, avg_grad_norm = 576909
I0315 13:40:34.930565 29479 solver.cpp:214] Iteration 46480, loss = 6126.08
I0315 13:40:34.930688 29479 solver.cpp:229]     Train net output #0: loss = 9904.38 (* 1 = 9904.38 loss)
I0315 13:40:35.035689 29479 solver.cpp:610] Iteration 46480, lr = 7.88173e-09
I0315 13:40:35.035702 29479 solver.cpp:613] Iteration 46480, avg_grad_norm = 654590
I0315 13:40:58.541841 29479 solver.cpp:214] Iteration 46500, loss = 6008.57
I0315 13:40:58.541893 29479 solver.cpp:229]     Train net output #0: loss = 4510.41 (* 1 = 4510.41 loss)
I0315 13:40:58.647016 29479 solver.cpp:610] Iteration 46500, lr = 7.8808e-09
I0315 13:40:58.647028 29479 solver.cpp:613] Iteration 46500, avg_grad_norm = 505751
I0315 13:41:23.865689 29479 solver.cpp:214] Iteration 46520, loss = 5993.03
I0315 13:41:23.865813 29479 solver.cpp:229]     Train net output #0: loss = 4499.1 (* 1 = 4499.1 loss)
I0315 13:41:23.980239 29479 solver.cpp:610] Iteration 46520, lr = 7.87988e-09
I0315 13:41:23.980252 29479 solver.cpp:613] Iteration 46520, avg_grad_norm = 545841
I0315 13:41:49.567484 29479 solver.cpp:214] Iteration 46540, loss = 5976.1
I0315 13:41:49.567553 29479 solver.cpp:229]     Train net output #0: loss = 8462.46 (* 1 = 8462.46 loss)
I0315 13:41:49.681963 29479 solver.cpp:610] Iteration 46540, lr = 7.87896e-09
I0315 13:41:49.681977 29479 solver.cpp:613] Iteration 46540, avg_grad_norm = 538005
I0315 13:42:15.279814 29479 solver.cpp:214] Iteration 46560, loss = 5707.76
I0315 13:42:15.279956 29479 solver.cpp:229]     Train net output #0: loss = 3764.83 (* 1 = 3764.83 loss)
I0315 13:42:15.394435 29479 solver.cpp:610] Iteration 46560, lr = 7.87803e-09
I0315 13:42:15.394450 29479 solver.cpp:613] Iteration 46560, avg_grad_norm = 517922
I0315 13:42:41.011696 29479 solver.cpp:214] Iteration 46580, loss = 6070.14
I0315 13:42:41.011744 29479 solver.cpp:229]     Train net output #0: loss = 3191.47 (* 1 = 3191.47 loss)
I0315 13:42:41.126317 29479 solver.cpp:610] Iteration 46580, lr = 7.87711e-09
I0315 13:42:41.126332 29479 solver.cpp:613] Iteration 46580, avg_grad_norm = 496361
I0315 13:43:06.728060 29479 solver.cpp:214] Iteration 46600, loss = 6153.47
I0315 13:43:06.728224 29479 solver.cpp:229]     Train net output #0: loss = 3837.09 (* 1 = 3837.09 loss)
I0315 13:43:06.842555 29479 solver.cpp:610] Iteration 46600, lr = 7.87618e-09
I0315 13:43:06.842568 29479 solver.cpp:613] Iteration 46600, avg_grad_norm = 549227
I0315 13:43:44.232081 29479 solver.cpp:214] Iteration 46620, loss = 6162.18
I0315 13:43:44.232216 29479 solver.cpp:229]     Train net output #0: loss = 4902.14 (* 1 = 4902.14 loss)
I0315 13:43:44.337410 29479 solver.cpp:610] Iteration 46620, lr = 7.87526e-09
I0315 13:43:44.337447 29479 solver.cpp:613] Iteration 46620, avg_grad_norm = 566630
I0315 13:44:08.678836 29479 solver.cpp:214] Iteration 46640, loss = 6291.21
I0315 13:44:08.678892 29479 solver.cpp:229]     Train net output #0: loss = 4699.12 (* 1 = 4699.12 loss)
I0315 13:44:08.794872 29479 solver.cpp:610] Iteration 46640, lr = 7.87433e-09
I0315 13:44:08.794885 29479 solver.cpp:613] Iteration 46640, avg_grad_norm = 609753
I0315 13:44:34.546490 29479 solver.cpp:214] Iteration 46660, loss = 6147.81
I0315 13:44:34.546670 29479 solver.cpp:229]     Train net output #0: loss = 7254.15 (* 1 = 7254.15 loss)
I0315 13:44:34.659373 29479 solver.cpp:610] Iteration 46660, lr = 7.87341e-09
I0315 13:44:34.659387 29479 solver.cpp:613] Iteration 46660, avg_grad_norm = 566973
I0315 13:44:59.850062 29479 solver.cpp:214] Iteration 46680, loss = 6143.96
I0315 13:44:59.850128 29479 solver.cpp:229]     Train net output #0: loss = 4845.84 (* 1 = 4845.84 loss)
I0315 13:44:59.963009 29479 solver.cpp:610] Iteration 46680, lr = 7.87249e-09
I0315 13:44:59.963022 29479 solver.cpp:613] Iteration 46680, avg_grad_norm = 564580
I0315 13:45:25.439743 29479 solver.cpp:214] Iteration 46700, loss = 6157
I0315 13:45:25.439888 29479 solver.cpp:229]     Train net output #0: loss = 4814.82 (* 1 = 4814.82 loss)
I0315 13:45:25.554455 29479 solver.cpp:610] Iteration 46700, lr = 7.87156e-09
I0315 13:45:25.554467 29479 solver.cpp:613] Iteration 46700, avg_grad_norm = 581418
I0315 13:45:51.145987 29479 solver.cpp:214] Iteration 46720, loss = 6241.85
I0315 13:45:51.146054 29479 solver.cpp:229]     Train net output #0: loss = 3704.51 (* 1 = 3704.51 loss)
I0315 13:45:51.260535 29479 solver.cpp:610] Iteration 46720, lr = 7.87064e-09
I0315 13:45:51.260547 29479 solver.cpp:613] Iteration 46720, avg_grad_norm = 566443
I0315 13:46:39.211784 29479 solver.cpp:214] Iteration 46740, loss = 6028.59
I0315 13:46:39.211935 29479 solver.cpp:229]     Train net output #0: loss = 6793.61 (* 1 = 6793.61 loss)
I0315 13:46:39.317162 29479 solver.cpp:610] Iteration 46740, lr = 7.86971e-09
I0315 13:46:39.317175 29479 solver.cpp:613] Iteration 46740, avg_grad_norm = 497953
I0315 13:47:02.742753 29479 solver.cpp:214] Iteration 46760, loss = 5985.98
I0315 13:47:02.742832 29479 solver.cpp:229]     Train net output #0: loss = 9191.39 (* 1 = 9191.39 loss)
I0315 13:47:02.847913 29479 solver.cpp:610] Iteration 46760, lr = 7.86879e-09
I0315 13:47:02.847925 29479 solver.cpp:613] Iteration 46760, avg_grad_norm = 598430
I0315 13:47:27.036870 29479 solver.cpp:214] Iteration 46780, loss = 6264.44
I0315 13:47:27.037019 29479 solver.cpp:229]     Train net output #0: loss = 4888.46 (* 1 = 4888.46 loss)
I0315 13:47:27.149786 29479 solver.cpp:610] Iteration 46780, lr = 7.86787e-09
I0315 13:47:27.149827 29479 solver.cpp:613] Iteration 46780, avg_grad_norm = 577253
I0315 13:47:52.570572 29479 solver.cpp:214] Iteration 46800, loss = 6281.43
I0315 13:47:52.570639 29479 solver.cpp:229]     Train net output #0: loss = 10502.6 (* 1 = 10502.6 loss)
I0315 13:47:52.685179 29479 solver.cpp:610] Iteration 46800, lr = 7.86694e-09
I0315 13:47:52.685194 29479 solver.cpp:613] Iteration 46800, avg_grad_norm = 517930
I0315 13:48:18.253283 29479 solver.cpp:214] Iteration 46820, loss = 6136.68
I0315 13:48:18.253422 29479 solver.cpp:229]     Train net output #0: loss = 6962.23 (* 1 = 6962.23 loss)
I0315 13:48:18.367765 29479 solver.cpp:610] Iteration 46820, lr = 7.86602e-09
I0315 13:48:18.367779 29479 solver.cpp:613] Iteration 46820, avg_grad_norm = 567641
I0315 13:48:43.916110 29479 solver.cpp:214] Iteration 46840, loss = 5849.23
I0315 13:48:43.916182 29479 solver.cpp:229]     Train net output #0: loss = 9850.28 (* 1 = 9850.28 loss)
I0315 13:48:44.030719 29479 solver.cpp:610] Iteration 46840, lr = 7.86509e-09
I0315 13:48:44.030771 29479 solver.cpp:613] Iteration 46840, avg_grad_norm = 543885
I0315 13:49:28.738453 29479 solver.cpp:214] Iteration 46860, loss = 5777.44
I0315 13:49:28.738592 29479 solver.cpp:229]     Train net output #0: loss = 6991.43 (* 1 = 6991.43 loss)
I0315 13:49:28.848644 29479 solver.cpp:610] Iteration 46860, lr = 7.86417e-09
I0315 13:49:28.848659 29479 solver.cpp:613] Iteration 46860, avg_grad_norm = 605613
I0315 13:49:52.309727 29479 solver.cpp:214] Iteration 46880, loss = 5955.8
I0315 13:49:52.309773 29479 solver.cpp:229]     Train net output #0: loss = 4165.04 (* 1 = 4165.04 loss)
I0315 13:49:52.414944 29479 solver.cpp:610] Iteration 46880, lr = 7.86324e-09
I0315 13:49:52.414958 29479 solver.cpp:613] Iteration 46880, avg_grad_norm = 506442
I0315 13:50:16.439016 29479 solver.cpp:214] Iteration 46900, loss = 6017.43
I0315 13:50:16.439215 29479 solver.cpp:229]     Train net output #0: loss = 7005.71 (* 1 = 7005.71 loss)
I0315 13:50:16.553822 29479 solver.cpp:610] Iteration 46900, lr = 7.86232e-09
I0315 13:50:16.553836 29479 solver.cpp:613] Iteration 46900, avg_grad_norm = 548421
I0315 13:50:42.142937 29479 solver.cpp:214] Iteration 46920, loss = 5914.02
I0315 13:50:42.142987 29479 solver.cpp:229]     Train net output #0: loss = 4016.32 (* 1 = 4016.32 loss)
I0315 13:50:42.257576 29479 solver.cpp:610] Iteration 46920, lr = 7.8614e-09
I0315 13:50:42.257589 29479 solver.cpp:613] Iteration 46920, avg_grad_norm = 515822
I0315 13:51:07.810632 29479 solver.cpp:214] Iteration 46940, loss = 5964.39
I0315 13:51:07.810768 29479 solver.cpp:229]     Train net output #0: loss = 8222.15 (* 1 = 8222.15 loss)
I0315 13:51:07.923645 29479 solver.cpp:610] Iteration 46940, lr = 7.86047e-09
I0315 13:51:07.923660 29479 solver.cpp:613] Iteration 46940, avg_grad_norm = 551931
I0315 13:51:33.213807 29479 solver.cpp:214] Iteration 46960, loss = 5965.42
I0315 13:51:33.213870 29479 solver.cpp:229]     Train net output #0: loss = 4914.56 (* 1 = 4914.56 loss)
I0315 13:51:33.326863 29479 solver.cpp:610] Iteration 46960, lr = 7.85955e-09
I0315 13:51:33.326876 29479 solver.cpp:613] Iteration 46960, avg_grad_norm = 527458
I0315 13:51:58.892369 29479 solver.cpp:214] Iteration 46980, loss = 5889.14
I0315 13:51:58.892514 29479 solver.cpp:229]     Train net output #0: loss = 3981.97 (* 1 = 3981.97 loss)
I0315 13:51:59.006947 29479 solver.cpp:610] Iteration 46980, lr = 7.85862e-09
I0315 13:51:59.006994 29479 solver.cpp:613] Iteration 46980, avg_grad_norm = 501110
I0315 13:52:46.020613 29479 solver.cpp:214] Iteration 47000, loss = 6137.66
I0315 13:52:46.020774 29479 solver.cpp:229]     Train net output #0: loss = 4350.56 (* 1 = 4350.56 loss)
I0315 13:52:46.125108 29479 solver.cpp:610] Iteration 47000, lr = 7.8577e-09
I0315 13:52:46.125121 29479 solver.cpp:613] Iteration 47000, avg_grad_norm = 557526
I0315 13:53:09.566295 29479 solver.cpp:214] Iteration 47020, loss = 6014.27
I0315 13:53:09.566350 29479 solver.cpp:229]     Train net output #0: loss = 4901.77 (* 1 = 4901.77 loss)
I0315 13:53:09.671432 29479 solver.cpp:610] Iteration 47020, lr = 7.85677e-09
I0315 13:53:09.671444 29479 solver.cpp:613] Iteration 47020, avg_grad_norm = 669623
I0315 13:53:34.666558 29479 solver.cpp:214] Iteration 47040, loss = 5923.05
I0315 13:53:34.666702 29479 solver.cpp:229]     Train net output #0: loss = 5010.89 (* 1 = 5010.89 loss)
I0315 13:53:34.781188 29479 solver.cpp:610] Iteration 47040, lr = 7.85585e-09
I0315 13:53:34.781201 29479 solver.cpp:613] Iteration 47040, avg_grad_norm = 572330
I0315 13:54:00.333458 29479 solver.cpp:214] Iteration 47060, loss = 6238.91
I0315 13:54:00.333524 29479 solver.cpp:229]     Train net output #0: loss = 5552.18 (* 1 = 5552.18 loss)
I0315 13:54:00.446535 29479 solver.cpp:610] Iteration 47060, lr = 7.85492e-09
I0315 13:54:00.446548 29479 solver.cpp:613] Iteration 47060, avg_grad_norm = 566131
I0315 13:54:25.737885 29479 solver.cpp:214] Iteration 47080, loss = 5731.73
I0315 13:54:25.738018 29479 solver.cpp:229]     Train net output #0: loss = 6059.06 (* 1 = 6059.06 loss)
I0315 13:54:25.850972 29479 solver.cpp:610] Iteration 47080, lr = 7.854e-09
I0315 13:54:25.850986 29479 solver.cpp:613] Iteration 47080, avg_grad_norm = 520580
I0315 13:54:51.601281 29479 solver.cpp:214] Iteration 47100, loss = 6006.42
I0315 13:54:51.601330 29479 solver.cpp:229]     Train net output #0: loss = 3980.18 (* 1 = 3980.18 loss)
I0315 13:54:51.715770 29479 solver.cpp:610] Iteration 47100, lr = 7.85308e-09
I0315 13:54:51.715783 29479 solver.cpp:613] Iteration 47100, avg_grad_norm = 557824
I0315 13:55:29.636142 29479 solver.cpp:214] Iteration 47120, loss = 5919.85
I0315 13:55:29.636253 29479 solver.cpp:229]     Train net output #0: loss = 5949.24 (* 1 = 5949.24 loss)
I0315 13:55:29.741312 29479 solver.cpp:610] Iteration 47120, lr = 7.85215e-09
I0315 13:55:29.741325 29479 solver.cpp:613] Iteration 47120, avg_grad_norm = 549048
I0315 13:55:53.198508 29479 solver.cpp:214] Iteration 47140, loss = 5975.49
I0315 13:55:53.198571 29479 solver.cpp:229]     Train net output #0: loss = 3953.2 (* 1 = 3953.2 loss)
I0315 13:55:53.304188 29479 solver.cpp:610] Iteration 47140, lr = 7.85123e-09
I0315 13:55:53.304201 29479 solver.cpp:613] Iteration 47140, avg_grad_norm = 536210
I0315 13:56:19.026533 29479 solver.cpp:214] Iteration 47160, loss = 6301.73
I0315 13:56:19.026700 29479 solver.cpp:229]     Train net output #0: loss = 6191.95 (* 1 = 6191.95 loss)
I0315 13:56:19.141281 29479 solver.cpp:610] Iteration 47160, lr = 7.8503e-09
I0315 13:56:19.141294 29479 solver.cpp:613] Iteration 47160, avg_grad_norm = 589672
I0315 13:56:44.505650 29479 solver.cpp:214] Iteration 47180, loss = 5976.09
I0315 13:56:44.505717 29479 solver.cpp:229]     Train net output #0: loss = 5712.03 (* 1 = 5712.03 loss)
I0315 13:56:44.618824 29479 solver.cpp:610] Iteration 47180, lr = 7.84938e-09
I0315 13:56:44.618837 29479 solver.cpp:613] Iteration 47180, avg_grad_norm = 588347
I0315 13:57:10.060331 29479 solver.cpp:214] Iteration 47200, loss = 5924.76
I0315 13:57:10.060477 29479 solver.cpp:229]     Train net output #0: loss = 4241.82 (* 1 = 4241.82 loss)
I0315 13:57:10.174672 29479 solver.cpp:610] Iteration 47200, lr = 7.84845e-09
I0315 13:57:10.174685 29479 solver.cpp:613] Iteration 47200, avg_grad_norm = 551314
I0315 13:57:35.780164 29479 solver.cpp:214] Iteration 47220, loss = 6406.63
I0315 13:57:35.780225 29479 solver.cpp:229]     Train net output #0: loss = 5644.02 (* 1 = 5644.02 loss)
I0315 13:57:35.894731 29479 solver.cpp:610] Iteration 47220, lr = 7.84753e-09
I0315 13:57:35.894749 29479 solver.cpp:613] Iteration 47220, avg_grad_norm = 579135
I0315 13:58:01.504374 29479 solver.cpp:214] Iteration 47240, loss = 6127.54
I0315 13:58:01.504523 29479 solver.cpp:229]     Train net output #0: loss = 5517.24 (* 1 = 5517.24 loss)
I0315 13:58:01.618825 29479 solver.cpp:610] Iteration 47240, lr = 7.8466e-09
I0315 13:58:01.618839 29479 solver.cpp:613] Iteration 47240, avg_grad_norm = 644679
I0315 13:58:38.407357 29479 solver.cpp:214] Iteration 47260, loss = 6157.23
I0315 13:58:38.407516 29479 solver.cpp:229]     Train net output #0: loss = 14201.7 (* 1 = 14201.7 loss)
I0315 13:58:38.512500 29479 solver.cpp:610] Iteration 47260, lr = 7.84568e-09
I0315 13:58:38.512513 29479 solver.cpp:613] Iteration 47260, avg_grad_norm = 735374
I0315 13:59:03.317343 29479 solver.cpp:214] Iteration 47280, loss = 5998.98
I0315 13:59:03.317400 29479 solver.cpp:229]     Train net output #0: loss = 5217.5 (* 1 = 5217.5 loss)
I0315 13:59:03.432096 29479 solver.cpp:610] Iteration 47280, lr = 7.84475e-09
I0315 13:59:03.432109 29479 solver.cpp:613] Iteration 47280, avg_grad_norm = 568075
I0315 13:59:29.044394 29479 solver.cpp:214] Iteration 47300, loss = 6007.21
I0315 13:59:29.044540 29479 solver.cpp:229]     Train net output #0: loss = 4411.66 (* 1 = 4411.66 loss)
I0315 13:59:29.158830 29479 solver.cpp:610] Iteration 47300, lr = 7.84383e-09
I0315 13:59:29.158844 29479 solver.cpp:613] Iteration 47300, avg_grad_norm = 581078
I0315 13:59:54.716770 29479 solver.cpp:214] Iteration 47320, loss = 6239.51
I0315 13:59:54.716846 29479 solver.cpp:229]     Train net output #0: loss = 4973.13 (* 1 = 4973.13 loss)
I0315 13:59:54.831138 29479 solver.cpp:610] Iteration 47320, lr = 7.8429e-09
I0315 13:59:54.831151 29479 solver.cpp:613] Iteration 47320, avg_grad_norm = 523613
I0315 14:00:20.369838 29479 solver.cpp:214] Iteration 47340, loss = 5927.23
I0315 14:00:20.370034 29479 solver.cpp:229]     Train net output #0: loss = 7477.68 (* 1 = 7477.68 loss)
I0315 14:00:20.484345 29479 solver.cpp:610] Iteration 47340, lr = 7.84198e-09
I0315 14:00:20.484359 29479 solver.cpp:613] Iteration 47340, avg_grad_norm = 511503
I0315 14:00:46.031054 29479 solver.cpp:214] Iteration 47360, loss = 6031.65
I0315 14:00:46.031126 29479 solver.cpp:229]     Train net output #0: loss = 4990.56 (* 1 = 4990.56 loss)
I0315 14:00:46.145620 29479 solver.cpp:610] Iteration 47360, lr = 7.84105e-09
I0315 14:00:46.145633 29479 solver.cpp:613] Iteration 47360, avg_grad_norm = 505968
I0315 14:01:38.868842 29479 solver.cpp:214] Iteration 47380, loss = 6185.99
I0315 14:01:38.868985 29479 solver.cpp:229]     Train net output #0: loss = 4062.6 (* 1 = 4062.6 loss)
I0315 14:01:38.974200 29479 solver.cpp:610] Iteration 47380, lr = 7.84013e-09
I0315 14:01:38.974215 29479 solver.cpp:613] Iteration 47380, avg_grad_norm = 539941
I0315 14:02:02.457115 29479 solver.cpp:214] Iteration 47400, loss = 6000.34
I0315 14:02:02.457186 29479 solver.cpp:229]     Train net output #0: loss = 4712.47 (* 1 = 4712.47 loss)
I0315 14:02:02.562455 29479 solver.cpp:610] Iteration 47400, lr = 7.83921e-09
I0315 14:02:02.562469 29479 solver.cpp:613] Iteration 47400, avg_grad_norm = 520556
I0315 14:02:26.705632 29479 solver.cpp:214] Iteration 47420, loss = 6273.84
I0315 14:02:26.705771 29479 solver.cpp:229]     Train net output #0: loss = 7532.23 (* 1 = 7532.23 loss)
I0315 14:02:26.821751 29479 solver.cpp:610] Iteration 47420, lr = 7.83828e-09
I0315 14:02:26.821765 29479 solver.cpp:613] Iteration 47420, avg_grad_norm = 499230
I0315 14:02:52.376569 29479 solver.cpp:214] Iteration 47440, loss = 6416.34
I0315 14:02:52.376641 29479 solver.cpp:229]     Train net output #0: loss = 6818.07 (* 1 = 6818.07 loss)
I0315 14:02:52.489589 29479 solver.cpp:610] Iteration 47440, lr = 7.83736e-09
I0315 14:02:52.489605 29479 solver.cpp:613] Iteration 47440, avg_grad_norm = 542847
I0315 14:03:17.760485 29479 solver.cpp:214] Iteration 47460, loss = 6110.25
I0315 14:03:17.760620 29479 solver.cpp:229]     Train net output #0: loss = 2277.61 (* 1 = 2277.61 loss)
I0315 14:03:17.873513 29479 solver.cpp:610] Iteration 47460, lr = 7.83643e-09
I0315 14:03:17.873527 29479 solver.cpp:613] Iteration 47460, avg_grad_norm = 688692
I0315 14:03:43.218426 29479 solver.cpp:214] Iteration 47480, loss = 6111.21
I0315 14:03:43.218499 29479 solver.cpp:229]     Train net output #0: loss = 11001 (* 1 = 11001 loss)
I0315 14:03:43.333077 29479 solver.cpp:610] Iteration 47480, lr = 7.83551e-09
I0315 14:03:43.333091 29479 solver.cpp:613] Iteration 47480, avg_grad_norm = 599047
I0315 14:04:31.894045 29479 solver.cpp:214] Iteration 47500, loss = 6446.52
I0315 14:04:31.894181 29479 solver.cpp:229]     Train net output #0: loss = 6364.65 (* 1 = 6364.65 loss)
I0315 14:04:31.999248 29479 solver.cpp:610] Iteration 47500, lr = 7.83458e-09
I0315 14:04:31.999261 29479 solver.cpp:613] Iteration 47500, avg_grad_norm = 588524
I0315 14:04:55.465894 29479 solver.cpp:214] Iteration 47520, loss = 5784.38
I0315 14:04:55.465961 29479 solver.cpp:229]     Train net output #0: loss = 5753.21 (* 1 = 5753.21 loss)
I0315 14:04:55.570325 29479 solver.cpp:610] Iteration 47520, lr = 7.83366e-09
I0315 14:04:55.570343 29479 solver.cpp:613] Iteration 47520, avg_grad_norm = 555769
I0315 14:05:19.664839 29479 solver.cpp:214] Iteration 47540, loss = 5975.29
I0315 14:05:19.665087 29479 solver.cpp:229]     Train net output #0: loss = 6277.91 (* 1 = 6277.91 loss)
I0315 14:05:19.779392 29479 solver.cpp:610] Iteration 47540, lr = 7.83273e-09
I0315 14:05:19.779407 29479 solver.cpp:613] Iteration 47540, avg_grad_norm = 618216
I0315 14:05:45.319816 29479 solver.cpp:214] Iteration 47560, loss = 6130.49
I0315 14:05:45.319886 29479 solver.cpp:229]     Train net output #0: loss = 4773.37 (* 1 = 4773.37 loss)
I0315 14:05:45.434381 29479 solver.cpp:610] Iteration 47560, lr = 7.83181e-09
I0315 14:05:45.434394 29479 solver.cpp:613] Iteration 47560, avg_grad_norm = 545481
I0315 14:06:11.032418 29479 solver.cpp:214] Iteration 47580, loss = 6402.89
I0315 14:06:11.032551 29479 solver.cpp:229]     Train net output #0: loss = 5662.6 (* 1 = 5662.6 loss)
I0315 14:06:11.147171 29479 solver.cpp:610] Iteration 47580, lr = 7.83088e-09
I0315 14:06:11.147184 29479 solver.cpp:613] Iteration 47580, avg_grad_norm = 538752
I0315 14:06:36.504416 29479 solver.cpp:214] Iteration 47600, loss = 6276.91
I0315 14:06:36.504489 29479 solver.cpp:229]     Train net output #0: loss = 5266.06 (* 1 = 5266.06 loss)
I0315 14:06:36.617410 29479 solver.cpp:610] Iteration 47600, lr = 7.82996e-09
I0315 14:06:36.617424 29479 solver.cpp:613] Iteration 47600, avg_grad_norm = 511673
I0315 14:07:02.084676 29479 solver.cpp:214] Iteration 47620, loss = 5839.15
I0315 14:07:02.084890 29479 solver.cpp:229]     Train net output #0: loss = 5167.5 (* 1 = 5167.5 loss)
I0315 14:07:02.199187 29479 solver.cpp:610] Iteration 47620, lr = 7.82903e-09
I0315 14:07:02.199200 29479 solver.cpp:613] Iteration 47620, avg_grad_norm = 522185
I0315 14:07:38.756127 29479 solver.cpp:214] Iteration 47640, loss = 5852.96
I0315 14:07:38.756337 29479 solver.cpp:229]     Train net output #0: loss = 4907.34 (* 1 = 4907.34 loss)
I0315 14:07:38.861263 29479 solver.cpp:610] Iteration 47640, lr = 7.82811e-09
I0315 14:07:38.861275 29479 solver.cpp:613] Iteration 47640, avg_grad_norm = 532571
I0315 14:08:03.507913 29479 solver.cpp:214] Iteration 47660, loss = 5986.21
I0315 14:08:03.507979 29479 solver.cpp:229]     Train net output #0: loss = 6738.38 (* 1 = 6738.38 loss)
I0315 14:08:03.622486 29479 solver.cpp:610] Iteration 47660, lr = 7.82718e-09
I0315 14:08:03.622499 29479 solver.cpp:613] Iteration 47660, avg_grad_norm = 507383
I0315 14:08:29.175779 29479 solver.cpp:214] Iteration 47680, loss = 5873.68
I0315 14:08:29.175896 29479 solver.cpp:229]     Train net output #0: loss = 8196.76 (* 1 = 8196.76 loss)
I0315 14:08:29.290251 29479 solver.cpp:610] Iteration 47680, lr = 7.82626e-09
I0315 14:08:29.290273 29479 solver.cpp:613] Iteration 47680, avg_grad_norm = 540621
I0315 14:08:54.894155 29479 solver.cpp:214] Iteration 47700, loss = 6313.93
I0315 14:08:54.894223 29479 solver.cpp:229]     Train net output #0: loss = 3245.52 (* 1 = 3245.52 loss)
I0315 14:08:55.008630 29479 solver.cpp:610] Iteration 47700, lr = 7.82534e-09
I0315 14:08:55.008643 29479 solver.cpp:613] Iteration 47700, avg_grad_norm = 562999
I0315 14:09:20.563793 29479 solver.cpp:214] Iteration 47720, loss = 6042.76
I0315 14:09:20.563901 29479 solver.cpp:229]     Train net output #0: loss = 8851.34 (* 1 = 8851.34 loss)
I0315 14:09:20.678405 29479 solver.cpp:610] Iteration 47720, lr = 7.82441e-09
I0315 14:09:20.678417 29479 solver.cpp:613] Iteration 47720, avg_grad_norm = 517005
I0315 14:09:46.240900 29479 solver.cpp:214] Iteration 47740, loss = 6158.67
I0315 14:09:46.240947 29479 solver.cpp:229]     Train net output #0: loss = 5315.88 (* 1 = 5315.88 loss)
I0315 14:09:46.355446 29479 solver.cpp:610] Iteration 47740, lr = 7.82348e-09
I0315 14:09:46.355459 29479 solver.cpp:613] Iteration 47740, avg_grad_norm = 531183
I0315 14:10:23.962769 29479 solver.cpp:214] Iteration 47760, loss = 6218.09
I0315 14:10:23.962919 29479 solver.cpp:229]     Train net output #0: loss = 5730.8 (* 1 = 5730.8 loss)
I0315 14:10:24.067915 29479 solver.cpp:610] Iteration 47760, lr = 7.82256e-09
I0315 14:10:24.067929 29479 solver.cpp:613] Iteration 47760, avg_grad_norm = 537494
I0315 14:10:48.105018 29479 solver.cpp:214] Iteration 47780, loss = 5797.47
I0315 14:10:48.105077 29479 solver.cpp:229]     Train net output #0: loss = 8804.95 (* 1 = 8804.95 loss)
I0315 14:10:48.219682 29479 solver.cpp:610] Iteration 47780, lr = 7.82163e-09
I0315 14:10:48.219694 29479 solver.cpp:613] Iteration 47780, avg_grad_norm = 517775
I0315 14:11:13.776270 29479 solver.cpp:214] Iteration 47800, loss = 6136.52
I0315 14:11:13.776394 29479 solver.cpp:229]     Train net output #0: loss = 4810.93 (* 1 = 4810.93 loss)
I0315 14:11:13.890962 29479 solver.cpp:610] Iteration 47800, lr = 7.82071e-09
I0315 14:11:13.890977 29479 solver.cpp:613] Iteration 47800, avg_grad_norm = 500892
I0315 14:11:39.491864 29479 solver.cpp:214] Iteration 47820, loss = 6190.12
I0315 14:11:39.491921 29479 solver.cpp:229]     Train net output #0: loss = 5339.75 (* 1 = 5339.75 loss)
I0315 14:11:39.606436 29479 solver.cpp:610] Iteration 47820, lr = 7.81979e-09
I0315 14:11:39.606449 29479 solver.cpp:613] Iteration 47820, avg_grad_norm = 536779
I0315 14:12:05.199090 29479 solver.cpp:214] Iteration 47840, loss = 6189.97
I0315 14:12:05.199331 29479 solver.cpp:229]     Train net output #0: loss = 7710.24 (* 1 = 7710.24 loss)
I0315 14:12:05.313755 29479 solver.cpp:610] Iteration 47840, lr = 7.81886e-09
I0315 14:12:05.313767 29479 solver.cpp:613] Iteration 47840, avg_grad_norm = 532394
I0315 14:12:30.918270 29479 solver.cpp:214] Iteration 47860, loss = 5976.6
I0315 14:12:30.918320 29479 solver.cpp:229]     Train net output #0: loss = 8898.68 (* 1 = 8898.68 loss)
I0315 14:12:31.033007 29479 solver.cpp:610] Iteration 47860, lr = 7.81794e-09
I0315 14:12:31.033020 29479 solver.cpp:613] Iteration 47860, avg_grad_norm = 555727
I0315 14:13:21.090698 29479 solver.cpp:214] Iteration 47880, loss = 5949.27
I0315 14:13:21.090811 29479 solver.cpp:229]     Train net output #0: loss = 9210.49 (* 1 = 9210.49 loss)
I0315 14:13:21.196053 29479 solver.cpp:610] Iteration 47880, lr = 7.81701e-09
I0315 14:13:21.196079 29479 solver.cpp:613] Iteration 47880, avg_grad_norm = 520359
I0315 14:13:44.672716 29479 solver.cpp:214] Iteration 47900, loss = 6118
I0315 14:13:44.672780 29479 solver.cpp:229]     Train net output #0: loss = 8388.9 (* 1 = 8388.9 loss)
I0315 14:13:44.778018 29479 solver.cpp:610] Iteration 47900, lr = 7.81609e-09
I0315 14:13:44.778043 29479 solver.cpp:613] Iteration 47900, avg_grad_norm = 577616
I0315 14:14:08.633868 29479 solver.cpp:214] Iteration 47920, loss = 5741.54
I0315 14:14:08.633991 29479 solver.cpp:229]     Train net output #0: loss = 4753.38 (* 1 = 4753.38 loss)
I0315 14:14:08.745570 29479 solver.cpp:610] Iteration 47920, lr = 7.81516e-09
I0315 14:14:08.745584 29479 solver.cpp:613] Iteration 47920, avg_grad_norm = 531935
I0315 14:14:34.216532 29479 solver.cpp:214] Iteration 47940, loss = 6172.03
I0315 14:14:34.216591 29479 solver.cpp:229]     Train net output #0: loss = 4359 (* 1 = 4359 loss)
I0315 14:14:34.331526 29479 solver.cpp:610] Iteration 47940, lr = 7.81424e-09
I0315 14:14:34.331538 29479 solver.cpp:613] Iteration 47940, avg_grad_norm = 538877
I0315 14:14:59.935766 29479 solver.cpp:214] Iteration 47960, loss = 6219.93
I0315 14:14:59.935904 29479 solver.cpp:229]     Train net output #0: loss = 5130.8 (* 1 = 5130.8 loss)
I0315 14:15:00.050338 29479 solver.cpp:610] Iteration 47960, lr = 7.81331e-09
I0315 14:15:00.050353 29479 solver.cpp:613] Iteration 47960, avg_grad_norm = 515996
I0315 14:15:25.506399 29479 solver.cpp:214] Iteration 47980, loss = 5791.25
I0315 14:15:25.506450 29479 solver.cpp:229]     Train net output #0: loss = 5314.54 (* 1 = 5314.54 loss)
I0315 14:15:25.619519 29479 solver.cpp:610] Iteration 47980, lr = 7.81239e-09
I0315 14:15:25.619532 29479 solver.cpp:613] Iteration 47980, avg_grad_norm = 527855
I0315 14:15:50.977768 29479 solver.cpp:214] Iteration 48000, loss = 6148.9
I0315 14:15:50.977960 29479 solver.cpp:229]     Train net output #0: loss = 5972.1 (* 1 = 5972.1 loss)
I0315 14:15:51.092494 29479 solver.cpp:610] Iteration 48000, lr = 7.81146e-09
I0315 14:15:51.092506 29479 solver.cpp:613] Iteration 48000, avg_grad_norm = 495560
I0315 14:16:45.595121 29479 solver.cpp:214] Iteration 48020, loss = 6466.43
I0315 14:16:45.595257 29479 solver.cpp:229]     Train net output #0: loss = 10476 (* 1 = 10476 loss)
I0315 14:16:45.698983 29479 solver.cpp:610] Iteration 48020, lr = 7.81054e-09
I0315 14:16:45.698997 29479 solver.cpp:613] Iteration 48020, avg_grad_norm = 494580
I0315 14:17:09.192515 29479 solver.cpp:214] Iteration 48040, loss = 6118.54
I0315 14:17:09.192586 29479 solver.cpp:229]     Train net output #0: loss = 9334.14 (* 1 = 9334.14 loss)
I0315 14:17:09.297921 29479 solver.cpp:610] Iteration 48040, lr = 7.80961e-09
I0315 14:17:09.297935 29479 solver.cpp:613] Iteration 48040, avg_grad_norm = 527504
I0315 14:17:33.484953 29479 solver.cpp:214] Iteration 48060, loss = 6334.94
I0315 14:17:33.485154 29479 solver.cpp:229]     Train net output #0: loss = 4614.66 (* 1 = 4614.66 loss)
I0315 14:17:33.599683 29479 solver.cpp:610] Iteration 48060, lr = 7.80869e-09
I0315 14:17:33.599700 29479 solver.cpp:613] Iteration 48060, avg_grad_norm = 631853
I0315 14:17:59.164587 29479 solver.cpp:214] Iteration 48080, loss = 6247.98
I0315 14:17:59.164659 29479 solver.cpp:229]     Train net output #0: loss = 3847.18 (* 1 = 3847.18 loss)
I0315 14:17:59.279239 29479 solver.cpp:610] Iteration 48080, lr = 7.80776e-09
I0315 14:17:59.279253 29479 solver.cpp:613] Iteration 48080, avg_grad_norm = 584583
I0315 14:18:24.842188 29479 solver.cpp:214] Iteration 48100, loss = 5829.78
I0315 14:18:24.842437 29479 solver.cpp:229]     Train net output #0: loss = 5949.97 (* 1 = 5949.97 loss)
I0315 14:18:24.955196 29479 solver.cpp:610] Iteration 48100, lr = 7.80684e-09
I0315 14:18:24.955209 29479 solver.cpp:613] Iteration 48100, avg_grad_norm = 557846
I0315 14:18:50.270933 29479 solver.cpp:214] Iteration 48120, loss = 6247.79
I0315 14:18:50.271001 29479 solver.cpp:229]     Train net output #0: loss = 3050.37 (* 1 = 3050.37 loss)
I0315 14:18:50.383970 29479 solver.cpp:610] Iteration 48120, lr = 7.80591e-09
I0315 14:18:50.384034 29479 solver.cpp:613] Iteration 48120, avg_grad_norm = 522653
I0315 14:19:36.758059 29479 solver.cpp:214] Iteration 48140, loss = 6012.57
I0315 14:19:36.758200 29479 solver.cpp:229]     Train net output #0: loss = 4283.06 (* 1 = 4283.06 loss)
I0315 14:19:36.863443 29479 solver.cpp:610] Iteration 48140, lr = 7.80499e-09
I0315 14:19:36.863461 29479 solver.cpp:613] Iteration 48140, avg_grad_norm = 556687
I0315 14:20:00.374064 29479 solver.cpp:214] Iteration 48160, loss = 6036.8
I0315 14:20:00.374125 29479 solver.cpp:229]     Train net output #0: loss = 4132.49 (* 1 = 4132.49 loss)
I0315 14:20:00.479295 29479 solver.cpp:610] Iteration 48160, lr = 7.80406e-09
I0315 14:20:00.479307 29479 solver.cpp:613] Iteration 48160, avg_grad_norm = 616031
I0315 14:20:25.149745 29479 solver.cpp:214] Iteration 48180, loss = 6288.29
I0315 14:20:25.149883 29479 solver.cpp:229]     Train net output #0: loss = 3998.36 (* 1 = 3998.36 loss)
I0315 14:20:25.264508 29479 solver.cpp:610] Iteration 48180, lr = 7.80314e-09
I0315 14:20:25.264523 29479 solver.cpp:613] Iteration 48180, avg_grad_norm = 513335
I0315 14:20:50.863878 29479 solver.cpp:214] Iteration 48200, loss = 6108.83
I0315 14:20:50.863940 29479 solver.cpp:229]     Train net output #0: loss = 4952.71 (* 1 = 4952.71 loss)
I0315 14:20:50.978518 29479 solver.cpp:610] Iteration 48200, lr = 7.80221e-09
I0315 14:20:50.978530 29479 solver.cpp:613] Iteration 48200, avg_grad_norm = 536353
I0315 14:21:16.574674 29479 solver.cpp:214] Iteration 48220, loss = 5997.23
I0315 14:21:16.574796 29479 solver.cpp:229]     Train net output #0: loss = 4363.21 (* 1 = 4363.21 loss)
I0315 14:21:16.689229 29479 solver.cpp:610] Iteration 48220, lr = 7.80128e-09
I0315 14:21:16.689244 29479 solver.cpp:613] Iteration 48220, avg_grad_norm = 523368
I0315 14:21:42.314004 29479 solver.cpp:214] Iteration 48240, loss = 5824.72
I0315 14:21:42.314064 29479 solver.cpp:229]     Train net output #0: loss = 6001.06 (* 1 = 6001.06 loss)
I0315 14:21:42.428689 29479 solver.cpp:610] Iteration 48240, lr = 7.80036e-09
I0315 14:21:42.428704 29479 solver.cpp:613] Iteration 48240, avg_grad_norm = 549792
I0315 14:22:20.797191 29479 solver.cpp:214] Iteration 48260, loss = 5989.18
I0315 14:22:20.797405 29479 solver.cpp:229]     Train net output #0: loss = 5176.51 (* 1 = 5176.51 loss)
I0315 14:22:20.902171 29479 solver.cpp:610] Iteration 48260, lr = 7.79943e-09
I0315 14:22:20.902186 29479 solver.cpp:613] Iteration 48260, avg_grad_norm = 555552
I0315 14:22:44.343320 29479 solver.cpp:214] Iteration 48280, loss = 5925.01
I0315 14:22:44.343390 29479 solver.cpp:229]     Train net output #0: loss = 4045.64 (* 1 = 4045.64 loss)
I0315 14:22:44.448447 29479 solver.cpp:610] Iteration 48280, lr = 7.79851e-09
I0315 14:22:44.448460 29479 solver.cpp:613] Iteration 48280, avg_grad_norm = 603328
I0315 14:23:09.761633 29479 solver.cpp:214] Iteration 48300, loss = 5909.2
I0315 14:23:09.761762 29479 solver.cpp:229]     Train net output #0: loss = 5119.89 (* 1 = 5119.89 loss)
I0315 14:23:09.876107 29479 solver.cpp:610] Iteration 48300, lr = 7.79758e-09
I0315 14:23:09.876121 29479 solver.cpp:613] Iteration 48300, avg_grad_norm = 561877
I0315 14:23:35.449013 29479 solver.cpp:214] Iteration 48320, loss = 6009.11
I0315 14:23:35.449085 29479 solver.cpp:229]     Train net output #0: loss = 5912.85 (* 1 = 5912.85 loss)
I0315 14:23:35.563521 29479 solver.cpp:610] Iteration 48320, lr = 7.79666e-09
I0315 14:23:35.563534 29479 solver.cpp:613] Iteration 48320, avg_grad_norm = 506582
I0315 14:24:01.169752 29479 solver.cpp:214] Iteration 48340, loss = 5936.37
I0315 14:24:01.169931 29479 solver.cpp:229]     Train net output #0: loss = 4741.42 (* 1 = 4741.42 loss)
I0315 14:24:01.284389 29479 solver.cpp:610] Iteration 48340, lr = 7.79573e-09
I0315 14:24:01.284402 29479 solver.cpp:613] Iteration 48340, avg_grad_norm = 523257
I0315 14:24:26.880889 29479 solver.cpp:214] Iteration 48360, loss = 5918.91
I0315 14:24:26.880955 29479 solver.cpp:229]     Train net output #0: loss = 3534.98 (* 1 = 3534.98 loss)
I0315 14:24:26.995424 29479 solver.cpp:610] Iteration 48360, lr = 7.79481e-09
I0315 14:24:26.995436 29479 solver.cpp:613] Iteration 48360, avg_grad_norm = 541913
I0315 14:24:52.603360 29479 solver.cpp:214] Iteration 48380, loss = 5930.58
I0315 14:24:52.603591 29479 solver.cpp:229]     Train net output #0: loss = 4848.46 (* 1 = 4848.46 loss)
I0315 14:24:52.717845 29479 solver.cpp:610] Iteration 48380, lr = 7.79388e-09
I0315 14:24:52.717859 29479 solver.cpp:613] Iteration 48380, avg_grad_norm = 544731
I0315 14:25:29.502607 29479 solver.cpp:214] Iteration 48400, loss = 5942.31
I0315 14:25:29.502744 29479 solver.cpp:229]     Train net output #0: loss = 7141.1 (* 1 = 7141.1 loss)
I0315 14:25:29.607785 29479 solver.cpp:610] Iteration 48400, lr = 7.79296e-09
I0315 14:25:29.607799 29479 solver.cpp:613] Iteration 48400, avg_grad_norm = 537526
I0315 14:25:54.114845 29479 solver.cpp:214] Iteration 48420, loss = 5943.11
I0315 14:25:54.114930 29479 solver.cpp:229]     Train net output #0: loss = 5817.71 (* 1 = 5817.71 loss)
I0315 14:25:54.229321 29479 solver.cpp:610] Iteration 48420, lr = 7.79203e-09
I0315 14:25:54.229334 29479 solver.cpp:613] Iteration 48420, avg_grad_norm = 520340
I0315 14:26:19.767081 29479 solver.cpp:214] Iteration 48440, loss = 5927.95
I0315 14:26:19.767299 29479 solver.cpp:229]     Train net output #0: loss = 7803.86 (* 1 = 7803.86 loss)
I0315 14:26:19.881597 29479 solver.cpp:610] Iteration 48440, lr = 7.79111e-09
I0315 14:26:19.881609 29479 solver.cpp:613] Iteration 48440, avg_grad_norm = 580110
I0315 14:26:45.441376 29479 solver.cpp:214] Iteration 48460, loss = 5918.51
I0315 14:26:45.441447 29479 solver.cpp:229]     Train net output #0: loss = 4309.65 (* 1 = 4309.65 loss)
I0315 14:26:45.556179 29479 solver.cpp:610] Iteration 48460, lr = 7.79018e-09
I0315 14:26:45.556193 29479 solver.cpp:613] Iteration 48460, avg_grad_norm = 560923
I0315 14:27:11.101275 29479 solver.cpp:214] Iteration 48480, loss = 6110.53
I0315 14:27:11.101408 29479 solver.cpp:229]     Train net output #0: loss = 3934.85 (* 1 = 3934.85 loss)
I0315 14:27:11.215822 29479 solver.cpp:610] Iteration 48480, lr = 7.78926e-09
I0315 14:27:11.215857 29479 solver.cpp:613] Iteration 48480, avg_grad_norm = 549813
I0315 14:27:36.765323 29479 solver.cpp:214] Iteration 48500, loss = 6288.74
I0315 14:27:36.765385 29479 solver.cpp:229]     Train net output #0: loss = 4354.29 (* 1 = 4354.29 loss)
I0315 14:27:36.879906 29479 solver.cpp:610] Iteration 48500, lr = 7.78833e-09
I0315 14:27:36.879920 29479 solver.cpp:613] Iteration 48500, avg_grad_norm = 543859
I0315 14:28:15.300199 29479 solver.cpp:214] Iteration 48520, loss = 6072.35
I0315 14:28:15.300318 29479 solver.cpp:229]     Train net output #0: loss = 7769.68 (* 1 = 7769.68 loss)
I0315 14:28:15.405608 29479 solver.cpp:610] Iteration 48520, lr = 7.78741e-09
I0315 14:28:15.405622 29479 solver.cpp:613] Iteration 48520, avg_grad_norm = 574744
I0315 14:28:39.128257 29479 solver.cpp:214] Iteration 48540, loss = 5678.71
I0315 14:28:39.128360 29479 solver.cpp:229]     Train net output #0: loss = 5363.23 (* 1 = 5363.23 loss)
I0315 14:28:39.239866 29479 solver.cpp:610] Iteration 48540, lr = 7.78648e-09
I0315 14:28:39.239918 29479 solver.cpp:613] Iteration 48540, avg_grad_norm = 557885
I0315 14:29:04.710002 29479 solver.cpp:214] Iteration 48560, loss = 6537.71
I0315 14:29:04.710201 29479 solver.cpp:229]     Train net output #0: loss = 5335.76 (* 1 = 5335.76 loss)
I0315 14:29:04.824617 29479 solver.cpp:610] Iteration 48560, lr = 7.78555e-09
I0315 14:29:04.824632 29479 solver.cpp:613] Iteration 48560, avg_grad_norm = 523016
I0315 14:29:30.411350 29479 solver.cpp:214] Iteration 48580, loss = 6215.48
I0315 14:29:30.411414 29479 solver.cpp:229]     Train net output #0: loss = 7287.38 (* 1 = 7287.38 loss)
I0315 14:29:30.525940 29479 solver.cpp:610] Iteration 48580, lr = 7.78463e-09
I0315 14:29:30.525954 29479 solver.cpp:613] Iteration 48580, avg_grad_norm = 531556
I0315 14:29:56.119760 29479 solver.cpp:214] Iteration 48600, loss = 5638.38
I0315 14:29:56.119951 29479 solver.cpp:229]     Train net output #0: loss = 4426.67 (* 1 = 4426.67 loss)
I0315 14:29:56.234112 29479 solver.cpp:610] Iteration 48600, lr = 7.7837e-09
I0315 14:29:56.234127 29479 solver.cpp:613] Iteration 48600, avg_grad_norm = 565864
I0315 14:30:21.831311 29479 solver.cpp:214] Iteration 48620, loss = 6143.38
I0315 14:30:21.831379 29479 solver.cpp:229]     Train net output #0: loss = 4857.27 (* 1 = 4857.27 loss)
I0315 14:30:21.945942 29479 solver.cpp:610] Iteration 48620, lr = 7.78278e-09
I0315 14:30:21.945956 29479 solver.cpp:613] Iteration 48620, avg_grad_norm = 580891
I0315 14:31:09.446624 29479 solver.cpp:214] Iteration 48640, loss = 5918.02
I0315 14:31:09.446737 29479 solver.cpp:229]     Train net output #0: loss = 6265.83 (* 1 = 6265.83 loss)
I0315 14:31:09.551939 29479 solver.cpp:610] Iteration 48640, lr = 7.78185e-09
I0315 14:31:09.551951 29479 solver.cpp:613] Iteration 48640, avg_grad_norm = 583837
I0315 14:31:33.012840 29479 solver.cpp:214] Iteration 48660, loss = 6236.31
I0315 14:31:33.012892 29479 solver.cpp:229]     Train net output #0: loss = 5171.59 (* 1 = 5171.59 loss)
I0315 14:31:33.117676 29479 solver.cpp:610] Iteration 48660, lr = 7.78093e-09
I0315 14:31:33.117688 29479 solver.cpp:613] Iteration 48660, avg_grad_norm = 528795
I0315 14:31:57.084558 29479 solver.cpp:214] Iteration 48680, loss = 5854.42
I0315 14:31:57.084689 29479 solver.cpp:229]     Train net output #0: loss = 4778.35 (* 1 = 4778.35 loss)
I0315 14:31:57.199172 29479 solver.cpp:610] Iteration 48680, lr = 7.78e-09
I0315 14:31:57.199185 29479 solver.cpp:613] Iteration 48680, avg_grad_norm = 569118
I0315 14:32:22.771729 29479 solver.cpp:214] Iteration 48700, loss = 5789.14
I0315 14:32:22.771800 29479 solver.cpp:229]     Train net output #0: loss = 4261.16 (* 1 = 4261.16 loss)
I0315 14:32:22.886199 29479 solver.cpp:610] Iteration 48700, lr = 7.77908e-09
I0315 14:32:22.886211 29479 solver.cpp:613] Iteration 48700, avg_grad_norm = 535308
I0315 14:32:48.412412 29479 solver.cpp:214] Iteration 48720, loss = 5827.32
I0315 14:32:48.412564 29479 solver.cpp:229]     Train net output #0: loss = 4207.14 (* 1 = 4207.14 loss)
I0315 14:32:48.526969 29479 solver.cpp:610] Iteration 48720, lr = 7.77815e-09
I0315 14:32:48.526983 29479 solver.cpp:613] Iteration 48720, avg_grad_norm = 539383
I0315 14:33:13.755815 29479 solver.cpp:214] Iteration 48740, loss = 5959.89
I0315 14:33:13.755910 29479 solver.cpp:229]     Train net output #0: loss = 3543.12 (* 1 = 3543.12 loss)
I0315 14:33:13.868700 29479 solver.cpp:610] Iteration 48740, lr = 7.77723e-09
I0315 14:33:13.868715 29479 solver.cpp:613] Iteration 48740, avg_grad_norm = 485842
I0315 14:33:39.409664 29479 solver.cpp:214] Iteration 48760, loss = 5867.47
I0315 14:33:39.409811 29479 solver.cpp:229]     Train net output #0: loss = 2825.32 (* 1 = 2825.32 loss)
I0315 14:33:39.524325 29479 solver.cpp:610] Iteration 48760, lr = 7.7763e-09
I0315 14:33:39.524375 29479 solver.cpp:613] Iteration 48760, avg_grad_norm = 598836
I0315 14:34:34.356745 29479 solver.cpp:214] Iteration 48780, loss = 5984.55
I0315 14:34:34.356884 29479 solver.cpp:229]     Train net output #0: loss = 3445.36 (* 1 = 3445.36 loss)
I0315 14:34:34.462029 29479 solver.cpp:610] Iteration 48780, lr = 7.77537e-09
I0315 14:34:34.462043 29479 solver.cpp:613] Iteration 48780, avg_grad_norm = 538762
I0315 14:34:57.884150 29479 solver.cpp:214] Iteration 48800, loss = 5970.3
I0315 14:34:57.884197 29479 solver.cpp:229]     Train net output #0: loss = 4465.62 (* 1 = 4465.62 loss)
I0315 14:34:57.989358 29479 solver.cpp:610] Iteration 48800, lr = 7.77445e-09
I0315 14:34:57.989372 29479 solver.cpp:613] Iteration 48800, avg_grad_norm = 484706
I0315 14:35:21.969635 29479 solver.cpp:214] Iteration 48820, loss = 5827.63
I0315 14:35:21.969776 29479 solver.cpp:229]     Train net output #0: loss = 8676.77 (* 1 = 8676.77 loss)
I0315 14:35:22.082698 29479 solver.cpp:610] Iteration 48820, lr = 7.77352e-09
I0315 14:35:22.082711 29479 solver.cpp:613] Iteration 48820, avg_grad_norm = 630706
I0315 14:35:47.341148 29479 solver.cpp:214] Iteration 48840, loss = 6188.98
I0315 14:35:47.341214 29479 solver.cpp:229]     Train net output #0: loss = 6110.25 (* 1 = 6110.25 loss)
I0315 14:35:47.455782 29479 solver.cpp:610] Iteration 48840, lr = 7.7726e-09
I0315 14:35:47.455797 29479 solver.cpp:613] Iteration 48840, avg_grad_norm = 543069
I0315 14:36:13.037204 29479 solver.cpp:214] Iteration 48860, loss = 6001.47
I0315 14:36:13.037329 29479 solver.cpp:229]     Train net output #0: loss = 5367.62 (* 1 = 5367.62 loss)
I0315 14:36:13.151706 29479 solver.cpp:610] Iteration 48860, lr = 7.77167e-09
I0315 14:36:13.151721 29479 solver.cpp:613] Iteration 48860, avg_grad_norm = 564625
I0315 14:36:38.697558 29479 solver.cpp:214] Iteration 48880, loss = 6250.83
I0315 14:36:38.697609 29479 solver.cpp:229]     Train net output #0: loss = 5369.22 (* 1 = 5369.22 loss)
I0315 14:36:38.812165 29479 solver.cpp:610] Iteration 48880, lr = 7.77075e-09
I0315 14:36:38.812177 29479 solver.cpp:613] Iteration 48880, avg_grad_norm = 531956
I0315 14:37:16.647491 29479 solver.cpp:214] Iteration 48900, loss = 5852.25
I0315 14:37:16.647594 29479 solver.cpp:229]     Train net output #0: loss = 9535.41 (* 1 = 9535.41 loss)
I0315 14:37:16.752703 29479 solver.cpp:610] Iteration 48900, lr = 7.76982e-09
I0315 14:37:16.752717 29479 solver.cpp:613] Iteration 48900, avg_grad_norm = 508427
I0315 14:37:40.383476 29479 solver.cpp:214] Iteration 48920, loss = 6202.66
I0315 14:37:40.383523 29479 solver.cpp:229]     Train net output #0: loss = 6236.26 (* 1 = 6236.26 loss)
I0315 14:37:40.495053 29479 solver.cpp:610] Iteration 48920, lr = 7.7689e-09
I0315 14:37:40.495066 29479 solver.cpp:613] Iteration 48920, avg_grad_norm = 500737
I0315 14:38:05.974136 29479 solver.cpp:214] Iteration 48940, loss = 5999.44
I0315 14:38:05.974263 29479 solver.cpp:229]     Train net output #0: loss = 8714.08 (* 1 = 8714.08 loss)
I0315 14:38:06.088858 29479 solver.cpp:610] Iteration 48940, lr = 7.76797e-09
I0315 14:38:06.088873 29479 solver.cpp:613] Iteration 48940, avg_grad_norm = 553336
I0315 14:38:31.633813 29479 solver.cpp:214] Iteration 48960, loss = 5915.55
I0315 14:38:31.633867 29479 solver.cpp:229]     Train net output #0: loss = 5006.68 (* 1 = 5006.68 loss)
I0315 14:38:31.748424 29479 solver.cpp:610] Iteration 48960, lr = 7.76704e-09
I0315 14:38:31.748437 29479 solver.cpp:613] Iteration 48960, avg_grad_norm = 516961
I0315 14:38:57.328477 29479 solver.cpp:214] Iteration 48980, loss = 6315.86
I0315 14:38:57.328673 29479 solver.cpp:229]     Train net output #0: loss = 7595.85 (* 1 = 7595.85 loss)
I0315 14:38:57.443066 29479 solver.cpp:610] Iteration 48980, lr = 7.76612e-09
I0315 14:38:57.443080 29479 solver.cpp:613] Iteration 48980, avg_grad_norm = 523060
I0315 14:39:23.049860 29479 solver.cpp:214] Iteration 49000, loss = 6121.36
I0315 14:39:23.049911 29479 solver.cpp:229]     Train net output #0: loss = 5698.7 (* 1 = 5698.7 loss)
I0315 14:39:23.164403 29479 solver.cpp:610] Iteration 49000, lr = 7.76519e-09
I0315 14:39:23.164417 29479 solver.cpp:613] Iteration 49000, avg_grad_norm = 486638
I0315 14:40:01.721396 29479 solver.cpp:214] Iteration 49020, loss = 5936.51
I0315 14:40:01.721529 29479 solver.cpp:229]     Train net output #0: loss = 6707.22 (* 1 = 6707.22 loss)
I0315 14:40:01.825723 29479 solver.cpp:610] Iteration 49020, lr = 7.76427e-09
I0315 14:40:01.825748 29479 solver.cpp:613] Iteration 49020, avg_grad_norm = 544938
I0315 14:40:25.259280 29479 solver.cpp:214] Iteration 49040, loss = 6384.31
I0315 14:40:25.259351 29479 solver.cpp:229]     Train net output #0: loss = 4374.01 (* 1 = 4374.01 loss)
I0315 14:40:25.364424 29479 solver.cpp:610] Iteration 49040, lr = 7.76334e-09
I0315 14:40:25.364437 29479 solver.cpp:613] Iteration 49040, avg_grad_norm = 585720
I0315 14:40:50.399960 29479 solver.cpp:214] Iteration 49060, loss = 5880.6
I0315 14:40:50.400188 29479 solver.cpp:229]     Train net output #0: loss = 5866.37 (* 1 = 5866.37 loss)
I0315 14:40:50.514516 29479 solver.cpp:610] Iteration 49060, lr = 7.76242e-09
I0315 14:40:50.514529 29479 solver.cpp:613] Iteration 49060, avg_grad_norm = 559813
I0315 14:41:16.051717 29479 solver.cpp:214] Iteration 49080, loss = 6001.22
I0315 14:41:16.051784 29479 solver.cpp:229]     Train net output #0: loss = 9129.22 (* 1 = 9129.22 loss)
I0315 14:41:16.166304 29479 solver.cpp:610] Iteration 49080, lr = 7.76149e-09
I0315 14:41:16.166318 29479 solver.cpp:613] Iteration 49080, avg_grad_norm = 521393
I0315 14:41:41.701736 29479 solver.cpp:214] Iteration 49100, loss = 6193.65
I0315 14:41:41.701859 29479 solver.cpp:229]     Train net output #0: loss = 3367.75 (* 1 = 3367.75 loss)
I0315 14:41:41.816103 29479 solver.cpp:610] Iteration 49100, lr = 7.76056e-09
I0315 14:41:41.816115 29479 solver.cpp:613] Iteration 49100, avg_grad_norm = 543988
I0315 14:42:07.363538 29479 solver.cpp:214] Iteration 49120, loss = 6040.85
I0315 14:42:07.363620 29479 solver.cpp:229]     Train net output #0: loss = 3942.88 (* 1 = 3942.88 loss)
I0315 14:42:07.478135 29479 solver.cpp:610] Iteration 49120, lr = 7.75964e-09
I0315 14:42:07.478148 29479 solver.cpp:613] Iteration 49120, avg_grad_norm = 508266
I0315 14:42:33.054929 29479 solver.cpp:214] Iteration 49140, loss = 6076.23
I0315 14:42:33.055063 29479 solver.cpp:229]     Train net output #0: loss = 7691.81 (* 1 = 7691.81 loss)
I0315 14:42:33.169656 29479 solver.cpp:610] Iteration 49140, lr = 7.75871e-09
I0315 14:42:33.169669 29479 solver.cpp:613] Iteration 49140, avg_grad_norm = 569775
I0315 14:43:10.546057 29479 solver.cpp:214] Iteration 49160, loss = 5905.01
I0315 14:43:10.546187 29479 solver.cpp:229]     Train net output #0: loss = 5826.28 (* 1 = 5826.28 loss)
I0315 14:43:10.651083 29479 solver.cpp:610] Iteration 49160, lr = 7.75779e-09
I0315 14:43:10.651096 29479 solver.cpp:613] Iteration 49160, avg_grad_norm = 567899
I0315 14:43:35.057252 29479 solver.cpp:214] Iteration 49180, loss = 5602.3
I0315 14:43:35.057317 29479 solver.cpp:229]     Train net output #0: loss = 4145.18 (* 1 = 4145.18 loss)
I0315 14:43:35.171735 29479 solver.cpp:610] Iteration 49180, lr = 7.75686e-09
I0315 14:43:35.171749 29479 solver.cpp:613] Iteration 49180, avg_grad_norm = 511598
I0315 14:44:00.711206 29479 solver.cpp:214] Iteration 49200, loss = 5947.91
I0315 14:44:00.711357 29479 solver.cpp:229]     Train net output #0: loss = 4173.8 (* 1 = 4173.8 loss)
I0315 14:44:00.825772 29479 solver.cpp:610] Iteration 49200, lr = 7.75594e-09
I0315 14:44:00.825785 29479 solver.cpp:613] Iteration 49200, avg_grad_norm = 508754
I0315 14:44:26.379134 29479 solver.cpp:214] Iteration 49220, loss = 6099.55
I0315 14:44:26.379180 29479 solver.cpp:229]     Train net output #0: loss = 3775.51 (* 1 = 3775.51 loss)
I0315 14:44:26.493712 29479 solver.cpp:610] Iteration 49220, lr = 7.75501e-09
I0315 14:44:26.493724 29479 solver.cpp:613] Iteration 49220, avg_grad_norm = 584477
I0315 14:44:52.035269 29479 solver.cpp:214] Iteration 49240, loss = 6066.28
I0315 14:44:52.035392 29479 solver.cpp:229]     Train net output #0: loss = 2782.43 (* 1 = 2782.43 loss)
I0315 14:44:52.150084 29479 solver.cpp:610] Iteration 49240, lr = 7.75408e-09
I0315 14:44:52.150097 29479 solver.cpp:613] Iteration 49240, avg_grad_norm = 560400
I0315 14:45:17.694816 29479 solver.cpp:214] Iteration 49260, loss = 6027.77
I0315 14:45:17.694860 29479 solver.cpp:229]     Train net output #0: loss = 6452.35 (* 1 = 6452.35 loss)
I0315 14:45:17.809399 29479 solver.cpp:610] Iteration 49260, lr = 7.75316e-09
I0315 14:45:17.809412 29479 solver.cpp:613] Iteration 49260, avg_grad_norm = 460027
I0315 14:46:04.196835 29479 solver.cpp:214] Iteration 49280, loss = 6180.33
I0315 14:46:04.197012 29479 solver.cpp:229]     Train net output #0: loss = 5825.53 (* 1 = 5825.53 loss)
I0315 14:46:04.301116 29479 solver.cpp:610] Iteration 49280, lr = 7.75223e-09
I0315 14:46:04.301131 29479 solver.cpp:613] Iteration 49280, avg_grad_norm = 493984
I0315 14:46:27.807463 29479 solver.cpp:214] Iteration 49300, loss = 6110.93
I0315 14:46:27.807514 29479 solver.cpp:229]     Train net output #0: loss = 7217.68 (* 1 = 7217.68 loss)
I0315 14:46:27.912138 29479 solver.cpp:610] Iteration 49300, lr = 7.75131e-09
I0315 14:46:27.912153 29479 solver.cpp:613] Iteration 49300, avg_grad_norm = 562739
I0315 14:46:52.370240 29479 solver.cpp:214] Iteration 49320, loss = 6109.62
I0315 14:46:52.370379 29479 solver.cpp:229]     Train net output #0: loss = 4748.93 (* 1 = 4748.93 loss)
I0315 14:46:52.484746 29479 solver.cpp:610] Iteration 49320, lr = 7.75038e-09
I0315 14:46:52.484763 29479 solver.cpp:613] Iteration 49320, avg_grad_norm = 569101
I0315 14:47:18.067334 29479 solver.cpp:214] Iteration 49340, loss = 5827.93
I0315 14:47:18.067389 29479 solver.cpp:229]     Train net output #0: loss = 2569.68 (* 1 = 2569.68 loss)
I0315 14:47:18.182031 29479 solver.cpp:610] Iteration 49340, lr = 7.74946e-09
I0315 14:47:18.182045 29479 solver.cpp:613] Iteration 49340, avg_grad_norm = 565482
I0315 14:47:43.725775 29479 solver.cpp:214] Iteration 49360, loss = 6125.81
I0315 14:47:43.725900 29479 solver.cpp:229]     Train net output #0: loss = 5216.38 (* 1 = 5216.38 loss)
I0315 14:47:43.840644 29479 solver.cpp:610] Iteration 49360, lr = 7.74853e-09
I0315 14:47:43.840658 29479 solver.cpp:613] Iteration 49360, avg_grad_norm = 623839
I0315 14:48:09.403800 29479 solver.cpp:214] Iteration 49380, loss = 6026
I0315 14:48:09.403867 29479 solver.cpp:229]     Train net output #0: loss = 3277.31 (* 1 = 3277.31 loss)
I0315 14:48:09.518385 29479 solver.cpp:610] Iteration 49380, lr = 7.7476e-09
I0315 14:48:09.518399 29479 solver.cpp:613] Iteration 49380, avg_grad_norm = 659683
I0315 14:48:55.558467 29479 solver.cpp:214] Iteration 49400, loss = 6170.17
I0315 14:48:55.558593 29479 solver.cpp:229]     Train net output #0: loss = 4342.38 (* 1 = 4342.38 loss)
I0315 14:48:55.664161 29479 solver.cpp:610] Iteration 49400, lr = 7.74668e-09
I0315 14:48:55.664175 29479 solver.cpp:613] Iteration 49400, avg_grad_norm = 570265
I0315 14:49:19.125567 29479 solver.cpp:214] Iteration 49420, loss = 5861.09
I0315 14:49:19.125622 29479 solver.cpp:229]     Train net output #0: loss = 4660.05 (* 1 = 4660.05 loss)
I0315 14:49:19.230945 29479 solver.cpp:610] Iteration 49420, lr = 7.74575e-09
I0315 14:49:19.230958 29479 solver.cpp:613] Iteration 49420, avg_grad_norm = 532695
I0315 14:49:43.102215 29479 solver.cpp:214] Iteration 49440, loss = 5928.2
I0315 14:49:43.102365 29479 solver.cpp:229]     Train net output #0: loss = 3152.27 (* 1 = 3152.27 loss)
I0315 14:49:43.215157 29479 solver.cpp:610] Iteration 49440, lr = 7.74483e-09
I0315 14:49:43.215170 29479 solver.cpp:613] Iteration 49440, avg_grad_norm = 497294
I0315 14:50:08.603384 29479 solver.cpp:214] Iteration 49460, loss = 5942.43
I0315 14:50:08.603440 29479 solver.cpp:229]     Train net output #0: loss = 6324.34 (* 1 = 6324.34 loss)
I0315 14:50:08.717996 29479 solver.cpp:610] Iteration 49460, lr = 7.7439e-09
I0315 14:50:08.718009 29479 solver.cpp:613] Iteration 49460, avg_grad_norm = 546585
I0315 14:50:34.314934 29479 solver.cpp:214] Iteration 49480, loss = 6414.47
I0315 14:50:34.315052 29479 solver.cpp:229]     Train net output #0: loss = 7410.46 (* 1 = 7410.46 loss)
I0315 14:50:34.429409 29479 solver.cpp:610] Iteration 49480, lr = 7.74297e-09
I0315 14:50:34.429422 29479 solver.cpp:613] Iteration 49480, avg_grad_norm = 535673
I0315 14:51:00.017989 29479 solver.cpp:214] Iteration 49500, loss = 5780.93
I0315 14:51:00.018046 29479 solver.cpp:229]     Train net output #0: loss = 3670.18 (* 1 = 3670.18 loss)
I0315 14:51:00.132570 29479 solver.cpp:610] Iteration 49500, lr = 7.74205e-09
I0315 14:51:00.132585 29479 solver.cpp:613] Iteration 49500, avg_grad_norm = 583164
I0315 14:51:25.739629 29479 solver.cpp:214] Iteration 49520, loss = 6202.41
I0315 14:51:25.739850 29479 solver.cpp:229]     Train net output #0: loss = 4243.07 (* 1 = 4243.07 loss)
I0315 14:51:25.854300 29479 solver.cpp:610] Iteration 49520, lr = 7.74112e-09
I0315 14:51:25.854315 29479 solver.cpp:613] Iteration 49520, avg_grad_norm = 550279
I0315 14:52:03.293648 29479 solver.cpp:214] Iteration 49540, loss = 6024.56
I0315 14:52:03.293802 29479 solver.cpp:229]     Train net output #0: loss = 8187.82 (* 1 = 8187.82 loss)
I0315 14:52:03.398788 29479 solver.cpp:610] Iteration 49540, lr = 7.7402e-09
I0315 14:52:03.398803 29479 solver.cpp:613] Iteration 49540, avg_grad_norm = 549309
I0315 14:52:27.494529 29479 solver.cpp:214] Iteration 49560, loss = 5857.1
I0315 14:52:27.494624 29479 solver.cpp:229]     Train net output #0: loss = 5012.85 (* 1 = 5012.85 loss)
I0315 14:52:27.609148 29479 solver.cpp:610] Iteration 49560, lr = 7.73927e-09
I0315 14:52:27.609160 29479 solver.cpp:613] Iteration 49560, avg_grad_norm = 523472
I0315 14:52:53.154551 29479 solver.cpp:214] Iteration 49580, loss = 6054.43
I0315 14:52:53.154657 29479 solver.cpp:229]     Train net output #0: loss = 11286.8 (* 1 = 11286.8 loss)
I0315 14:52:53.269240 29479 solver.cpp:610] Iteration 49580, lr = 7.73834e-09
I0315 14:52:53.269253 29479 solver.cpp:613] Iteration 49580, avg_grad_norm = 567826
I0315 14:53:18.856264 29479 solver.cpp:214] Iteration 49600, loss = 6103.42
I0315 14:53:18.856338 29479 solver.cpp:229]     Train net output #0: loss = 5650.6 (* 1 = 5650.6 loss)
I0315 14:53:18.970901 29479 solver.cpp:610] Iteration 49600, lr = 7.73742e-09
I0315 14:53:18.971022 29479 solver.cpp:613] Iteration 49600, avg_grad_norm = 534306
I0315 14:53:44.529060 29479 solver.cpp:214] Iteration 49620, loss = 5860.09
I0315 14:53:44.529217 29479 solver.cpp:229]     Train net output #0: loss = 6825.09 (* 1 = 6825.09 loss)
I0315 14:53:44.643615 29479 solver.cpp:610] Iteration 49620, lr = 7.73649e-09
I0315 14:53:44.643627 29479 solver.cpp:613] Iteration 49620, avg_grad_norm = 522013
I0315 14:54:10.219363 29479 solver.cpp:214] Iteration 49640, loss = 6197.03
I0315 14:54:10.219435 29479 solver.cpp:229]     Train net output #0: loss = 2939.69 (* 1 = 2939.69 loss)
I0315 14:54:10.333968 29479 solver.cpp:610] Iteration 49640, lr = 7.73557e-09
I0315 14:54:10.333981 29479 solver.cpp:613] Iteration 49640, avg_grad_norm = 536577
I0315 14:54:48.481843 29479 solver.cpp:214] Iteration 49660, loss = 6073.83
I0315 14:54:48.481957 29479 solver.cpp:229]     Train net output #0: loss = 4375.5 (* 1 = 4375.5 loss)
I0315 14:54:48.586498 29479 solver.cpp:610] Iteration 49660, lr = 7.73464e-09
I0315 14:54:48.586510 29479 solver.cpp:613] Iteration 49660, avg_grad_norm = 546177
I0315 14:55:12.156929 29479 solver.cpp:214] Iteration 49680, loss = 5945.94
I0315 14:55:12.156990 29479 solver.cpp:229]     Train net output #0: loss = 12026.7 (* 1 = 12026.7 loss)
I0315 14:55:12.268666 29479 solver.cpp:610] Iteration 49680, lr = 7.73371e-09
I0315 14:55:12.268681 29479 solver.cpp:613] Iteration 49680, avg_grad_norm = 593982
I0315 14:55:37.823693 29479 solver.cpp:214] Iteration 49700, loss = 6124.49
I0315 14:55:37.823827 29479 solver.cpp:229]     Train net output #0: loss = 5308.15 (* 1 = 5308.15 loss)
I0315 14:55:37.938318 29479 solver.cpp:610] Iteration 49700, lr = 7.73279e-09
I0315 14:55:37.938330 29479 solver.cpp:613] Iteration 49700, avg_grad_norm = 543045
I0315 14:56:03.538643 29479 solver.cpp:214] Iteration 49720, loss = 6133.22
I0315 14:56:03.538718 29479 solver.cpp:229]     Train net output #0: loss = 4073.56 (* 1 = 4073.56 loss)
I0315 14:56:03.653081 29479 solver.cpp:610] Iteration 49720, lr = 7.73186e-09
I0315 14:56:03.653095 29479 solver.cpp:613] Iteration 49720, avg_grad_norm = 587932
I0315 14:56:29.251346 29479 solver.cpp:214] Iteration 49740, loss = 5954.72
I0315 14:56:29.251490 29479 solver.cpp:229]     Train net output #0: loss = 6955.11 (* 1 = 6955.11 loss)
I0315 14:56:29.365955 29479 solver.cpp:610] Iteration 49740, lr = 7.73094e-09
I0315 14:56:29.365968 29479 solver.cpp:613] Iteration 49740, avg_grad_norm = 543550
I0315 14:56:54.973752 29479 solver.cpp:214] Iteration 49760, loss = 6035.3
I0315 14:56:54.973798 29479 solver.cpp:229]     Train net output #0: loss = 4472.92 (* 1 = 4472.92 loss)
I0315 14:56:55.088204 29479 solver.cpp:610] Iteration 49760, lr = 7.73001e-09
I0315 14:56:55.088217 29479 solver.cpp:613] Iteration 49760, avg_grad_norm = 529207
I0315 14:57:20.706032 29479 solver.cpp:214] Iteration 49780, loss = 6246.17
I0315 14:57:20.706213 29479 solver.cpp:229]     Train net output #0: loss = 4018.23 (* 1 = 4018.23 loss)
I0315 14:57:20.820798 29479 solver.cpp:610] Iteration 49780, lr = 7.72908e-09
I0315 14:57:20.820812 29479 solver.cpp:613] Iteration 49780, avg_grad_norm = 546437
I0315 14:57:58.246107 29479 solver.cpp:214] Iteration 49800, loss = 5795.36
I0315 14:57:58.246237 29479 solver.cpp:229]     Train net output #0: loss = 3483.88 (* 1 = 3483.88 loss)
I0315 14:57:58.351271 29479 solver.cpp:610] Iteration 49800, lr = 7.72816e-09
I0315 14:57:58.351284 29479 solver.cpp:613] Iteration 49800, avg_grad_norm = 604122
I0315 14:58:23.259438 29479 solver.cpp:214] Iteration 49820, loss = 6240.66
I0315 14:58:23.259501 29479 solver.cpp:229]     Train net output #0: loss = 8240.59 (* 1 = 8240.59 loss)
I0315 14:58:23.373987 29479 solver.cpp:610] Iteration 49820, lr = 7.72723e-09
I0315 14:58:23.374001 29479 solver.cpp:613] Iteration 49820, avg_grad_norm = 543388
I0315 14:58:48.967610 29479 solver.cpp:214] Iteration 49840, loss = 5851.91
I0315 14:58:48.967735 29479 solver.cpp:229]     Train net output #0: loss = 7679.99 (* 1 = 7679.99 loss)
I0315 14:58:49.082561 29479 solver.cpp:610] Iteration 49840, lr = 7.7263e-09
I0315 14:58:49.082576 29479 solver.cpp:613] Iteration 49840, avg_grad_norm = 480652
I0315 14:59:14.679679 29479 solver.cpp:214] Iteration 49860, loss = 5982.58
I0315 14:59:14.679730 29479 solver.cpp:229]     Train net output #0: loss = 7664.77 (* 1 = 7664.77 loss)
I0315 14:59:14.794183 29479 solver.cpp:610] Iteration 49860, lr = 7.72538e-09
I0315 14:59:14.794196 29479 solver.cpp:613] Iteration 49860, avg_grad_norm = 549226
I0315 14:59:40.395120 29479 solver.cpp:214] Iteration 49880, loss = 6011.61
I0315 14:59:40.395265 29479 solver.cpp:229]     Train net output #0: loss = 4451.11 (* 1 = 4451.11 loss)
I0315 14:59:40.509501 29479 solver.cpp:610] Iteration 49880, lr = 7.72445e-09
I0315 14:59:40.509516 29479 solver.cpp:613] Iteration 49880, avg_grad_norm = 555542
I0315 15:00:06.111740 29479 solver.cpp:214] Iteration 49900, loss = 5932.92
I0315 15:00:06.111805 29479 solver.cpp:229]     Train net output #0: loss = 4510.57 (* 1 = 4510.57 loss)
I0315 15:00:06.226261 29479 solver.cpp:610] Iteration 49900, lr = 7.72353e-09
I0315 15:00:06.226274 29479 solver.cpp:613] Iteration 49900, avg_grad_norm = 564763
I0315 15:01:05.988153 29479 solver.cpp:214] Iteration 49920, loss = 5897.65
I0315 15:01:05.988294 29479 solver.cpp:229]     Train net output #0: loss = 5906.41 (* 1 = 5906.41 loss)
I0315 15:01:06.092126 29479 solver.cpp:610] Iteration 49920, lr = 7.7226e-09
I0315 15:01:06.092139 29479 solver.cpp:613] Iteration 49920, avg_grad_norm = 518851
I0315 15:01:29.541678 29479 solver.cpp:214] Iteration 49940, loss = 6063.19
I0315 15:01:29.541725 29479 solver.cpp:229]     Train net output #0: loss = 7124.33 (* 1 = 7124.33 loss)
I0315 15:01:29.646931 29479 solver.cpp:610] Iteration 49940, lr = 7.72167e-09
I0315 15:01:29.646944 29479 solver.cpp:613] Iteration 49940, avg_grad_norm = 539719
I0315 15:01:53.154824 29479 solver.cpp:214] Iteration 49960, loss = 6374.03
I0315 15:01:53.154968 29479 solver.cpp:229]     Train net output #0: loss = 11926.3 (* 1 = 11926.3 loss)
I0315 15:01:53.259562 29479 solver.cpp:610] Iteration 49960, lr = 7.72075e-09
I0315 15:01:53.259575 29479 solver.cpp:613] Iteration 49960, avg_grad_norm = 538103
I0315 15:02:18.353821 29479 solver.cpp:214] Iteration 49980, loss = 5875.66
I0315 15:02:18.353891 29479 solver.cpp:229]     Train net output #0: loss = 7967.46 (* 1 = 7967.46 loss)
I0315 15:02:18.468595 29479 solver.cpp:610] Iteration 49980, lr = 7.71982e-09
I0315 15:02:18.468610 29479 solver.cpp:613] Iteration 49980, avg_grad_norm = 536855
I0315 15:02:42.933668 29479 solver.cpp:458] Snapshotting to models/pnet/VGG_VOC2012ext_iter_50000.caffemodel
I0315 15:02:51.735851 29479 solver.cpp:466] Snapshotting solver state to models/pnet/VGG_VOC2012ext_iter_50000.solverstate
I0315 15:02:58.041656 29479 solver.cpp:214] Iteration 50000, loss = 6269.6
I0315 15:02:58.041728 29479 solver.cpp:229]     Train net output #0: loss = 9384.43 (* 1 = 9384.43 loss)
I0315 15:02:58.145537 29479 solver.cpp:610] Iteration 50000, lr = 7.71889e-09
I0315 15:02:58.145560 29479 solver.cpp:613] Iteration 50000, avg_grad_norm = 529664
I0315 15:03:21.628028 29479 solver.cpp:214] Iteration 50020, loss = 5825.79
I0315 15:03:21.628190 29479 solver.cpp:229]     Train net output #0: loss = 5388.42 (* 1 = 5388.42 loss)
I0315 15:03:21.733271 29479 solver.cpp:610] Iteration 50020, lr = 7.71797e-09
I0315 15:03:21.733285 29479 solver.cpp:613] Iteration 50020, avg_grad_norm = 468111
I0315 15:04:05.975139 29479 solver.cpp:214] Iteration 50040, loss = 6142.85
I0315 15:04:05.975293 29479 solver.cpp:229]     Train net output #0: loss = 4706.76 (* 1 = 4706.76 loss)
I0315 15:04:06.079766 29479 solver.cpp:610] Iteration 50040, lr = 7.71704e-09
I0315 15:04:06.079778 29479 solver.cpp:613] Iteration 50040, avg_grad_norm = 523110
I0315 15:04:29.501178 29479 solver.cpp:214] Iteration 50060, loss = 5949.98
I0315 15:04:29.501242 29479 solver.cpp:229]     Train net output #0: loss = 5830.92 (* 1 = 5830.92 loss)
I0315 15:04:29.606245 29479 solver.cpp:610] Iteration 50060, lr = 7.71612e-09
I0315 15:04:29.606257 29479 solver.cpp:613] Iteration 50060, avg_grad_norm = 499432
I0315 15:04:53.889791 29479 solver.cpp:214] Iteration 50080, loss = 6460.9
I0315 15:04:53.889920 29479 solver.cpp:229]     Train net output #0: loss = 5163.48 (* 1 = 5163.48 loss)
I0315 15:04:54.004411 29479 solver.cpp:610] Iteration 50080, lr = 7.71519e-09
I0315 15:04:54.004425 29479 solver.cpp:613] Iteration 50080, avg_grad_norm = 524134
I0315 15:05:19.538404 29479 solver.cpp:214] Iteration 50100, loss = 6065.01
I0315 15:05:19.538455 29479 solver.cpp:229]     Train net output #0: loss = 5622.26 (* 1 = 5622.26 loss)
I0315 15:05:19.652986 29479 solver.cpp:610] Iteration 50100, lr = 7.71426e-09
I0315 15:05:19.652998 29479 solver.cpp:613] Iteration 50100, avg_grad_norm = 523326
I0315 15:05:45.032286 29479 solver.cpp:214] Iteration 50120, loss = 6278.99
I0315 15:05:45.032414 29479 solver.cpp:229]     Train net output #0: loss = 3698.87 (* 1 = 3698.87 loss)
I0315 15:05:45.145195 29479 solver.cpp:610] Iteration 50120, lr = 7.71334e-09
I0315 15:05:45.145210 29479 solver.cpp:613] Iteration 50120, avg_grad_norm = 517500
I0315 15:06:10.419219 29479 solver.cpp:214] Iteration 50140, loss = 6467.95
I0315 15:06:10.419272 29479 solver.cpp:229]     Train net output #0: loss = 3677.43 (* 1 = 3677.43 loss)
I0315 15:06:10.533812 29479 solver.cpp:610] Iteration 50140, lr = 7.71241e-09
I0315 15:06:10.533826 29479 solver.cpp:613] Iteration 50140, avg_grad_norm = 547490
I0315 15:06:36.101449 29479 solver.cpp:214] Iteration 50160, loss = 5864.97
I0315 15:06:36.101655 29479 solver.cpp:229]     Train net output #0: loss = 5154.02 (* 1 = 5154.02 loss)
I0315 15:06:36.216120 29479 solver.cpp:610] Iteration 50160, lr = 7.71148e-09
I0315 15:06:36.216133 29479 solver.cpp:613] Iteration 50160, avg_grad_norm = 492459
I0315 15:07:30.456641 29479 solver.cpp:214] Iteration 50180, loss = 6147.28
I0315 15:07:30.456774 29479 solver.cpp:229]     Train net output #0: loss = 3651.83 (* 1 = 3651.83 loss)
I0315 15:07:30.562022 29479 solver.cpp:610] Iteration 50180, lr = 7.71056e-09
I0315 15:07:30.562036 29479 solver.cpp:613] Iteration 50180, avg_grad_norm = 525115
I0315 15:07:54.000087 29479 solver.cpp:214] Iteration 50200, loss = 5963.42
I0315 15:07:54.000152 29479 solver.cpp:229]     Train net output #0: loss = 5399.97 (* 1 = 5399.97 loss)
I0315 15:07:54.105459 29479 solver.cpp:610] Iteration 50200, lr = 7.70963e-09
I0315 15:07:54.105473 29479 solver.cpp:613] Iteration 50200, avg_grad_norm = 530073
I0315 15:08:18.455463 29479 solver.cpp:214] Iteration 50220, loss = 5750.06
I0315 15:08:18.455639 29479 solver.cpp:229]     Train net output #0: loss = 8245.21 (* 1 = 8245.21 loss)
I0315 15:08:18.568516 29479 solver.cpp:610] Iteration 50220, lr = 7.70871e-09
I0315 15:08:18.568569 29479 solver.cpp:613] Iteration 50220, avg_grad_norm = 581476
I0315 15:08:43.915012 29479 solver.cpp:214] Iteration 50240, loss = 5866.3
I0315 15:08:43.915069 29479 solver.cpp:229]     Train net output #0: loss = 5073.37 (* 1 = 5073.37 loss)
I0315 15:08:44.029804 29479 solver.cpp:610] Iteration 50240, lr = 7.70778e-09
I0315 15:08:44.029819 29479 solver.cpp:613] Iteration 50240, avg_grad_norm = 521421
I0315 15:09:09.583811 29479 solver.cpp:214] Iteration 50260, loss = 5924.72
I0315 15:09:09.584015 29479 solver.cpp:229]     Train net output #0: loss = 7549.25 (* 1 = 7549.25 loss)
I0315 15:09:09.698379 29479 solver.cpp:610] Iteration 50260, lr = 7.70685e-09
I0315 15:09:09.698392 29479 solver.cpp:613] Iteration 50260, avg_grad_norm = 492906
I0315 15:09:35.264209 29479 solver.cpp:214] Iteration 50280, loss = 5812.83
I0315 15:09:35.264261 29479 solver.cpp:229]     Train net output #0: loss = 11666.4 (* 1 = 11666.4 loss)
I0315 15:09:35.378769 29479 solver.cpp:610] Iteration 50280, lr = 7.70593e-09
I0315 15:09:35.378783 29479 solver.cpp:613] Iteration 50280, avg_grad_norm = 512431
I0315 15:10:15.472296 29479 solver.cpp:214] Iteration 50300, loss = 6054.17
I0315 15:10:15.472414 29479 solver.cpp:229]     Train net output #0: loss = 3290.4 (* 1 = 3290.4 loss)
I0315 15:10:15.577389 29479 solver.cpp:610] Iteration 50300, lr = 7.705e-09
I0315 15:10:15.577402 29479 solver.cpp:613] Iteration 50300, avg_grad_norm = 498404
I0315 15:10:39.225611 29479 solver.cpp:214] Iteration 50320, loss = 5933.21
I0315 15:10:39.225683 29479 solver.cpp:229]     Train net output #0: loss = 6674.39 (* 1 = 6674.39 loss)
I0315 15:10:39.340227 29479 solver.cpp:610] Iteration 50320, lr = 7.70407e-09
I0315 15:10:39.340240 29479 solver.cpp:613] Iteration 50320, avg_grad_norm = 556325
I0315 15:11:04.911308 29479 solver.cpp:214] Iteration 50340, loss = 6008.49
I0315 15:11:04.911458 29479 solver.cpp:229]     Train net output #0: loss = 2969.81 (* 1 = 2969.81 loss)
I0315 15:11:05.025853 29479 solver.cpp:610] Iteration 50340, lr = 7.70315e-09
I0315 15:11:05.025868 29479 solver.cpp:613] Iteration 50340, avg_grad_norm = 528498
I0315 15:11:30.576216 29479 solver.cpp:214] Iteration 50360, loss = 5998.58
I0315 15:11:30.576305 29479 solver.cpp:229]     Train net output #0: loss = 12529.5 (* 1 = 12529.5 loss)
I0315 15:11:30.690866 29479 solver.cpp:610] Iteration 50360, lr = 7.70222e-09
I0315 15:11:30.690879 29479 solver.cpp:613] Iteration 50360, avg_grad_norm = 504312
I0315 15:11:56.270086 29479 solver.cpp:214] Iteration 50380, loss = 6167.9
I0315 15:11:56.270298 29479 solver.cpp:229]     Train net output #0: loss = 4160.02 (* 1 = 4160.02 loss)
I0315 15:11:56.384989 29479 solver.cpp:610] Iteration 50380, lr = 7.70129e-09
I0315 15:11:56.385004 29479 solver.cpp:613] Iteration 50380, avg_grad_norm = 532710
I0315 15:12:21.724691 29479 solver.cpp:214] Iteration 50400, loss = 6205.05
I0315 15:12:21.724761 29479 solver.cpp:229]     Train net output #0: loss = 6409.38 (* 1 = 6409.38 loss)
I0315 15:12:21.837774 29479 solver.cpp:610] Iteration 50400, lr = 7.70037e-09
I0315 15:12:21.837790 29479 solver.cpp:613] Iteration 50400, avg_grad_norm = 525140
I0315 15:13:00.137717 29479 solver.cpp:214] Iteration 50420, loss = 6184.72
I0315 15:13:00.137866 29479 solver.cpp:229]     Train net output #0: loss = 2959.9 (* 1 = 2959.9 loss)
I0315 15:13:00.241693 29479 solver.cpp:610] Iteration 50420, lr = 7.69944e-09
I0315 15:13:00.241747 29479 solver.cpp:613] Iteration 50420, avg_grad_norm = 570249
I0315 15:13:23.730623 29479 solver.cpp:214] Iteration 50440, loss = 5804.77
I0315 15:13:23.730695 29479 solver.cpp:229]     Train net output #0: loss = 7144.43 (* 1 = 7144.43 loss)
I0315 15:13:23.835616 29479 solver.cpp:610] Iteration 50440, lr = 7.69851e-09
I0315 15:13:23.835631 29479 solver.cpp:613] Iteration 50440, avg_grad_norm = 591919
I0315 15:13:49.540328 29479 solver.cpp:214] Iteration 50460, loss = 6061.52
I0315 15:13:49.540518 29479 solver.cpp:229]     Train net output #0: loss = 5247.42 (* 1 = 5247.42 loss)
I0315 15:13:49.654996 29479 solver.cpp:610] Iteration 50460, lr = 7.69759e-09
I0315 15:13:49.655011 29479 solver.cpp:613] Iteration 50460, avg_grad_norm = 637328
I0315 15:14:14.977962 29479 solver.cpp:214] Iteration 50480, loss = 5993.31
I0315 15:14:14.978031 29479 solver.cpp:229]     Train net output #0: loss = 5146.58 (* 1 = 5146.58 loss)
I0315 15:14:15.091017 29479 solver.cpp:610] Iteration 50480, lr = 7.69666e-09
I0315 15:14:15.091030 29479 solver.cpp:613] Iteration 50480, avg_grad_norm = 623605
I0315 15:14:40.453491 29479 solver.cpp:214] Iteration 50500, loss = 6193.92
I0315 15:14:40.453686 29479 solver.cpp:229]     Train net output #0: loss = 5902.35 (* 1 = 5902.35 loss)
I0315 15:14:40.567955 29479 solver.cpp:610] Iteration 50500, lr = 7.69573e-09
I0315 15:14:40.567967 29479 solver.cpp:613] Iteration 50500, avg_grad_norm = 610221
I0315 15:15:06.115944 29479 solver.cpp:214] Iteration 50520, loss = 6111.88
I0315 15:15:06.115998 29479 solver.cpp:229]     Train net output #0: loss = 6065.8 (* 1 = 6065.8 loss)
I0315 15:15:06.230505 29479 solver.cpp:610] Iteration 50520, lr = 7.69481e-09
I0315 15:15:06.230520 29479 solver.cpp:613] Iteration 50520, avg_grad_norm = 620433
I0315 15:15:31.805529 29479 solver.cpp:214] Iteration 50540, loss = 6202.6
I0315 15:15:31.805672 29479 solver.cpp:229]     Train net output #0: loss = 9248.42 (* 1 = 9248.42 loss)
I0315 15:15:31.920045 29479 solver.cpp:610] Iteration 50540, lr = 7.69388e-09
I0315 15:15:31.920060 29479 solver.cpp:613] Iteration 50540, avg_grad_norm = 560896
I0315 15:16:14.930594 29479 solver.cpp:214] Iteration 50560, loss = 6053.98
I0315 15:16:14.930744 29479 solver.cpp:229]     Train net output #0: loss = 3530.09 (* 1 = 3530.09 loss)
I0315 15:16:15.035856 29479 solver.cpp:610] Iteration 50560, lr = 7.69295e-09
I0315 15:16:15.035868 29479 solver.cpp:613] Iteration 50560, avg_grad_norm = 505466
I0315 15:16:38.844578 29479 solver.cpp:214] Iteration 50580, loss = 6339.67
I0315 15:16:38.844627 29479 solver.cpp:229]     Train net output #0: loss = 5933.91 (* 1 = 5933.91 loss)
I0315 15:16:38.956447 29479 solver.cpp:610] Iteration 50580, lr = 7.69203e-09
I0315 15:16:38.956460 29479 solver.cpp:613] Iteration 50580, avg_grad_norm = 531027
I0315 15:17:04.600143 29479 solver.cpp:214] Iteration 50600, loss = 6210.14
I0315 15:17:04.600335 29479 solver.cpp:229]     Train net output #0: loss = 7336.48 (* 1 = 7336.48 loss)
I0315 15:17:04.716203 29479 solver.cpp:610] Iteration 50600, lr = 7.6911e-09
I0315 15:17:04.716217 29479 solver.cpp:613] Iteration 50600, avg_grad_norm = 615504
I0315 15:17:30.119554 29479 solver.cpp:214] Iteration 50620, loss = 6350.56
I0315 15:17:30.119616 29479 solver.cpp:229]     Train net output #0: loss = 3419.58 (* 1 = 3419.58 loss)
I0315 15:17:30.232628 29479 solver.cpp:610] Iteration 50620, lr = 7.69017e-09
I0315 15:17:30.232641 29479 solver.cpp:613] Iteration 50620, avg_grad_norm = 582467
I0315 15:17:55.656610 29479 solver.cpp:214] Iteration 50640, loss = 5795.57
I0315 15:17:55.656757 29479 solver.cpp:229]     Train net output #0: loss = 2748.9 (* 1 = 2748.9 loss)
I0315 15:17:55.772770 29479 solver.cpp:610] Iteration 50640, lr = 7.68925e-09
I0315 15:17:55.772784 29479 solver.cpp:613] Iteration 50640, avg_grad_norm = 502854
I0315 15:18:21.595577 29479 solver.cpp:214] Iteration 50660, loss = 6099.43
I0315 15:18:21.595645 29479 solver.cpp:229]     Train net output #0: loss = 4101.79 (* 1 = 4101.79 loss)
I0315 15:18:21.710242 29479 solver.cpp:610] Iteration 50660, lr = 7.68832e-09
I0315 15:18:21.710259 29479 solver.cpp:613] Iteration 50660, avg_grad_norm = 510088
I0315 15:19:05.974268 29479 solver.cpp:214] Iteration 50680, loss = 5827.39
I0315 15:19:05.974392 29479 solver.cpp:229]     Train net output #0: loss = 4754.57 (* 1 = 4754.57 loss)
I0315 15:19:06.079448 29479 solver.cpp:610] Iteration 50680, lr = 7.68739e-09
I0315 15:19:06.079463 29479 solver.cpp:613] Iteration 50680, avg_grad_norm = 623424
I0315 15:19:29.511801 29479 solver.cpp:214] Iteration 50700, loss = 5929.57
I0315 15:19:29.511868 29479 solver.cpp:229]     Train net output #0: loss = 9457.99 (* 1 = 9457.99 loss)
I0315 15:19:29.616921 29479 solver.cpp:610] Iteration 50700, lr = 7.68647e-09
I0315 15:19:29.616935 29479 solver.cpp:613] Iteration 50700, avg_grad_norm = 596516
I0315 15:19:54.574946 29479 solver.cpp:214] Iteration 50720, loss = 6154.26
I0315 15:19:54.575134 29479 solver.cpp:229]     Train net output #0: loss = 7794.81 (* 1 = 7794.81 loss)
I0315 15:19:54.689463 29479 solver.cpp:610] Iteration 50720, lr = 7.68554e-09
I0315 15:19:54.689476 29479 solver.cpp:613] Iteration 50720, avg_grad_norm = 602063
I0315 15:20:20.245818 29479 solver.cpp:214] Iteration 50740, loss = 5701.63
I0315 15:20:20.245884 29479 solver.cpp:229]     Train net output #0: loss = 8716.05 (* 1 = 8716.05 loss)
I0315 15:20:20.360321 29479 solver.cpp:610] Iteration 50740, lr = 7.68461e-09
I0315 15:20:20.360333 29479 solver.cpp:613] Iteration 50740, avg_grad_norm = 552071
I0315 15:20:45.916954 29479 solver.cpp:214] Iteration 50760, loss = 6176.28
I0315 15:20:45.917137 29479 solver.cpp:229]     Train net output #0: loss = 4453.87 (* 1 = 4453.87 loss)
I0315 15:20:46.031666 29479 solver.cpp:610] Iteration 50760, lr = 7.68369e-09
I0315 15:20:46.031677 29479 solver.cpp:613] Iteration 50760, avg_grad_norm = 548483
I0315 15:21:11.393954 29479 solver.cpp:214] Iteration 50780, loss = 6227.81
I0315 15:21:11.394014 29479 solver.cpp:229]     Train net output #0: loss = 2249.72 (* 1 = 2249.72 loss)
I0315 15:21:11.506880 29479 solver.cpp:610] Iteration 50780, lr = 7.68276e-09
I0315 15:21:11.506893 29479 solver.cpp:613] Iteration 50780, avg_grad_norm = 531608
I0315 15:21:49.404418 29479 solver.cpp:214] Iteration 50800, loss = 6328.57
I0315 15:21:49.404573 29479 solver.cpp:229]     Train net output #0: loss = 7112.65 (* 1 = 7112.65 loss)
I0315 15:21:49.508859 29479 solver.cpp:610] Iteration 50800, lr = 7.68183e-09
I0315 15:21:49.508873 29479 solver.cpp:613] Iteration 50800, avg_grad_norm = 567476
I0315 15:22:12.966806 29479 solver.cpp:214] Iteration 50820, loss = 5831.59
I0315 15:22:12.966871 29479 solver.cpp:229]     Train net output #0: loss = 6328.97 (* 1 = 6328.97 loss)
I0315 15:22:13.071844 29479 solver.cpp:610] Iteration 50820, lr = 7.68091e-09
I0315 15:22:13.071858 29479 solver.cpp:613] Iteration 50820, avg_grad_norm = 579672
I0315 15:22:38.387840 29479 solver.cpp:214] Iteration 50840, loss = 6025.4
I0315 15:22:38.387970 29479 solver.cpp:229]     Train net output #0: loss = 4339.53 (* 1 = 4339.53 loss)
I0315 15:22:38.502454 29479 solver.cpp:610] Iteration 50840, lr = 7.67998e-09
I0315 15:22:38.502467 29479 solver.cpp:613] Iteration 50840, avg_grad_norm = 521935
I0315 15:23:04.079020 29479 solver.cpp:214] Iteration 50860, loss = 5718.55
I0315 15:23:04.079092 29479 solver.cpp:229]     Train net output #0: loss = 5001.51 (* 1 = 5001.51 loss)
I0315 15:23:04.193639 29479 solver.cpp:610] Iteration 50860, lr = 7.67905e-09
I0315 15:23:04.193692 29479 solver.cpp:613] Iteration 50860, avg_grad_norm = 476283
I0315 15:23:29.843178 29479 solver.cpp:214] Iteration 50880, loss = 5858.35
I0315 15:23:29.843315 29479 solver.cpp:229]     Train net output #0: loss = 4388.43 (* 1 = 4388.43 loss)
I0315 15:23:29.957813 29479 solver.cpp:610] Iteration 50880, lr = 7.67813e-09
I0315 15:23:29.957826 29479 solver.cpp:613] Iteration 50880, avg_grad_norm = 510376
I0315 15:23:55.527601 29479 solver.cpp:214] Iteration 50900, loss = 5744.41
I0315 15:23:55.527673 29479 solver.cpp:229]     Train net output #0: loss = 6197.44 (* 1 = 6197.44 loss)
I0315 15:23:55.642223 29479 solver.cpp:610] Iteration 50900, lr = 7.6772e-09
I0315 15:23:55.642236 29479 solver.cpp:613] Iteration 50900, avg_grad_norm = 540044
I0315 15:24:21.221774 29479 solver.cpp:214] Iteration 50920, loss = 6038.15
I0315 15:24:21.221880 29479 solver.cpp:229]     Train net output #0: loss = 3364.54 (* 1 = 3364.54 loss)
I0315 15:24:21.336180 29479 solver.cpp:610] Iteration 50920, lr = 7.67627e-09
I0315 15:24:21.336192 29479 solver.cpp:613] Iteration 50920, avg_grad_norm = 590866
I0315 15:24:58.078081 29479 solver.cpp:214] Iteration 50940, loss = 5931.07
I0315 15:24:58.078307 29479 solver.cpp:229]     Train net output #0: loss = 5324.14 (* 1 = 5324.14 loss)
I0315 15:24:58.183300 29479 solver.cpp:610] Iteration 50940, lr = 7.67535e-09
I0315 15:24:58.183312 29479 solver.cpp:613] Iteration 50940, avg_grad_norm = 578066
I0315 15:25:22.687530 29479 solver.cpp:214] Iteration 50960, loss = 5945.68
I0315 15:25:22.687580 29479 solver.cpp:229]     Train net output #0: loss = 8195.93 (* 1 = 8195.93 loss)
I0315 15:25:22.802229 29479 solver.cpp:610] Iteration 50960, lr = 7.67442e-09
I0315 15:25:22.802242 29479 solver.cpp:613] Iteration 50960, avg_grad_norm = 695569
I0315 15:25:48.342162 29479 solver.cpp:214] Iteration 50980, loss = 5961.16
I0315 15:25:48.342291 29479 solver.cpp:229]     Train net output #0: loss = 10035.1 (* 1 = 10035.1 loss)
I0315 15:25:48.456676 29479 solver.cpp:610] Iteration 50980, lr = 7.67349e-09
I0315 15:25:48.456688 29479 solver.cpp:613] Iteration 50980, avg_grad_norm = 597267
I0315 15:26:13.998551 29479 solver.cpp:214] Iteration 51000, loss = 6022.53
I0315 15:26:13.998608 29479 solver.cpp:229]     Train net output #0: loss = 5837.55 (* 1 = 5837.55 loss)
I0315 15:26:14.113148 29479 solver.cpp:610] Iteration 51000, lr = 7.67257e-09
I0315 15:26:14.113160 29479 solver.cpp:613] Iteration 51000, avg_grad_norm = 496156
I0315 15:26:39.650846 29479 solver.cpp:214] Iteration 51020, loss = 5663.97
I0315 15:26:39.650995 29479 solver.cpp:229]     Train net output #0: loss = 6768.45 (* 1 = 6768.45 loss)
I0315 15:26:39.765643 29479 solver.cpp:610] Iteration 51020, lr = 7.67164e-09
I0315 15:26:39.765656 29479 solver.cpp:613] Iteration 51020, avg_grad_norm = 527658
I0315 15:27:05.364251 29479 solver.cpp:214] Iteration 51040, loss = 6060.94
I0315 15:27:05.364317 29479 solver.cpp:229]     Train net output #0: loss = 9572.7 (* 1 = 9572.7 loss)
I0315 15:27:05.478910 29479 solver.cpp:610] Iteration 51040, lr = 7.67071e-09
I0315 15:27:05.478924 29479 solver.cpp:613] Iteration 51040, avg_grad_norm = 521849
I0315 15:27:43.507787 29479 solver.cpp:214] Iteration 51060, loss = 6046.63
I0315 15:27:43.507937 29479 solver.cpp:229]     Train net output #0: loss = 3019.29 (* 1 = 3019.29 loss)
I0315 15:27:43.613060 29479 solver.cpp:610] Iteration 51060, lr = 7.66979e-09
I0315 15:27:43.613073 29479 solver.cpp:613] Iteration 51060, avg_grad_norm = 553735
I0315 15:28:07.342432 29479 solver.cpp:214] Iteration 51080, loss = 6112
I0315 15:28:07.342488 29479 solver.cpp:229]     Train net output #0: loss = 5329.72 (* 1 = 5329.72 loss)
I0315 15:28:07.454234 29479 solver.cpp:610] Iteration 51080, lr = 7.66886e-09
I0315 15:28:07.454247 29479 solver.cpp:613] Iteration 51080, avg_grad_norm = 542823
I0315 15:28:32.988270 29479 solver.cpp:214] Iteration 51100, loss = 5932.59
I0315 15:28:32.988409 29479 solver.cpp:229]     Train net output #0: loss = 6120.95 (* 1 = 6120.95 loss)
I0315 15:28:33.102782 29479 solver.cpp:610] Iteration 51100, lr = 7.66793e-09
I0315 15:28:33.102795 29479 solver.cpp:613] Iteration 51100, avg_grad_norm = 520532
I0315 15:28:58.702013 29479 solver.cpp:214] Iteration 51120, loss = 6015.53
I0315 15:28:58.702059 29479 solver.cpp:229]     Train net output #0: loss = 7361.29 (* 1 = 7361.29 loss)
I0315 15:28:58.816583 29479 solver.cpp:610] Iteration 51120, lr = 7.667e-09
I0315 15:28:58.816596 29479 solver.cpp:613] Iteration 51120, avg_grad_norm = 567717
I0315 15:29:24.416638 29479 solver.cpp:214] Iteration 51140, loss = 6092.04
I0315 15:29:24.416769 29479 solver.cpp:229]     Train net output #0: loss = 3770.29 (* 1 = 3770.29 loss)
I0315 15:29:24.531283 29479 solver.cpp:610] Iteration 51140, lr = 7.66608e-09
I0315 15:29:24.531296 29479 solver.cpp:613] Iteration 51140, avg_grad_norm = 574375
I0315 15:29:50.137142 29479 solver.cpp:214] Iteration 51160, loss = 6426.45
I0315 15:29:50.137234 29479 solver.cpp:229]     Train net output #0: loss = 7353.07 (* 1 = 7353.07 loss)
I0315 15:29:50.251792 29479 solver.cpp:610] Iteration 51160, lr = 7.66515e-09
I0315 15:29:50.251808 29479 solver.cpp:613] Iteration 51160, avg_grad_norm = 537710
I0315 15:30:36.331632 29479 solver.cpp:214] Iteration 51180, loss = 6136.62
I0315 15:30:36.331784 29479 solver.cpp:229]     Train net output #0: loss = 5545 (* 1 = 5545 loss)
I0315 15:30:36.436898 29479 solver.cpp:610] Iteration 51180, lr = 7.66422e-09
I0315 15:30:36.436913 29479 solver.cpp:613] Iteration 51180, avg_grad_norm = 516312
I0315 15:30:59.851809 29479 solver.cpp:214] Iteration 51200, loss = 5824.97
I0315 15:30:59.851865 29479 solver.cpp:229]     Train net output #0: loss = 11958.6 (* 1 = 11958.6 loss)
I0315 15:30:59.956120 29479 solver.cpp:610] Iteration 51200, lr = 7.6633e-09
I0315 15:30:59.956135 29479 solver.cpp:613] Iteration 51200, avg_grad_norm = 554442
I0315 15:31:24.120113 29479 solver.cpp:214] Iteration 51220, loss = 6042.78
I0315 15:31:24.120260 29479 solver.cpp:229]     Train net output #0: loss = 6706.25 (* 1 = 6706.25 loss)
I0315 15:31:24.235008 29479 solver.cpp:610] Iteration 51220, lr = 7.66237e-09
I0315 15:31:24.235020 29479 solver.cpp:613] Iteration 51220, avg_grad_norm = 625917
I0315 15:31:49.884506 29479 solver.cpp:214] Iteration 51240, loss = 6065.15
I0315 15:31:49.884557 29479 solver.cpp:229]     Train net output #0: loss = 7532.44 (* 1 = 7532.44 loss)
I0315 15:31:49.999125 29479 solver.cpp:610] Iteration 51240, lr = 7.66144e-09
I0315 15:31:49.999138 29479 solver.cpp:613] Iteration 51240, avg_grad_norm = 652667
I0315 15:32:15.472208 29479 solver.cpp:214] Iteration 51260, loss = 5841.56
I0315 15:32:15.472355 29479 solver.cpp:229]     Train net output #0: loss = 6942.78 (* 1 = 6942.78 loss)
I0315 15:32:15.585269 29479 solver.cpp:610] Iteration 51260, lr = 7.66052e-09
I0315 15:32:15.585284 29479 solver.cpp:613] Iteration 51260, avg_grad_norm = 583091
I0315 15:32:40.853513 29479 solver.cpp:214] Iteration 51280, loss = 5905.49
I0315 15:32:40.853569 29479 solver.cpp:229]     Train net output #0: loss = 4922.87 (* 1 = 4922.87 loss)
I0315 15:32:40.968014 29479 solver.cpp:610] Iteration 51280, lr = 7.65959e-09
I0315 15:32:40.968027 29479 solver.cpp:613] Iteration 51280, avg_grad_norm = 601430
I0315 15:33:06.591003 29479 solver.cpp:214] Iteration 51300, loss = 5982.41
I0315 15:33:06.591128 29479 solver.cpp:229]     Train net output #0: loss = 5758.66 (* 1 = 5758.66 loss)
I0315 15:33:06.705706 29479 solver.cpp:610] Iteration 51300, lr = 7.65866e-09
I0315 15:33:06.705727 29479 solver.cpp:613] Iteration 51300, avg_grad_norm = 563999
I0315 15:33:52.455607 29479 solver.cpp:214] Iteration 51320, loss = 6021.2
I0315 15:33:52.455744 29479 solver.cpp:229]     Train net output #0: loss = 7443.73 (* 1 = 7443.73 loss)
I0315 15:33:52.560114 29479 solver.cpp:610] Iteration 51320, lr = 7.65773e-09
I0315 15:33:52.560128 29479 solver.cpp:613] Iteration 51320, avg_grad_norm = 583443
I0315 15:34:16.089488 29479 solver.cpp:214] Iteration 51340, loss = 5931.35
I0315 15:34:16.089545 29479 solver.cpp:229]     Train net output #0: loss = 5566.48 (* 1 = 5566.48 loss)
I0315 15:34:16.194810 29479 solver.cpp:610] Iteration 51340, lr = 7.65681e-09
I0315 15:34:16.194823 29479 solver.cpp:613] Iteration 51340, avg_grad_norm = 518015
I0315 15:34:41.386592 29479 solver.cpp:214] Iteration 51360, loss = 5720.49
I0315 15:34:41.386693 29479 solver.cpp:229]     Train net output #0: loss = 4907.2 (* 1 = 4907.2 loss)
I0315 15:34:41.501307 29479 solver.cpp:610] Iteration 51360, lr = 7.65588e-09
I0315 15:34:41.501320 29479 solver.cpp:613] Iteration 51360, avg_grad_norm = 500795
I0315 15:35:07.127475 29479 solver.cpp:214] Iteration 51380, loss = 5743.94
I0315 15:35:07.127527 29479 solver.cpp:229]     Train net output #0: loss = 7490.28 (* 1 = 7490.28 loss)
I0315 15:35:07.242100 29479 solver.cpp:610] Iteration 51380, lr = 7.65495e-09
I0315 15:35:07.242113 29479 solver.cpp:613] Iteration 51380, avg_grad_norm = 509732
I0315 15:35:32.728374 29479 solver.cpp:214] Iteration 51400, loss = 5978.01
I0315 15:35:32.728502 29479 solver.cpp:229]     Train net output #0: loss = 10040 (* 1 = 10040 loss)
I0315 15:35:32.841330 29479 solver.cpp:610] Iteration 51400, lr = 7.65403e-09
I0315 15:35:32.841343 29479 solver.cpp:613] Iteration 51400, avg_grad_norm = 531759
I0315 15:35:58.122242 29479 solver.cpp:214] Iteration 51420, loss = 6140.85
I0315 15:35:58.122315 29479 solver.cpp:229]     Train net output #0: loss = 8763.35 (* 1 = 8763.35 loss)
I0315 15:35:58.238236 29479 solver.cpp:610] Iteration 51420, lr = 7.6531e-09
I0315 15:35:58.238250 29479 solver.cpp:613] Iteration 51420, avg_grad_norm = 502125
I0315 15:36:36.515660 29479 solver.cpp:214] Iteration 51440, loss = 5864.57
I0315 15:36:36.515846 29479 solver.cpp:229]     Train net output #0: loss = 4249.59 (* 1 = 4249.59 loss)
I0315 15:36:36.620867 29479 solver.cpp:610] Iteration 51440, lr = 7.65217e-09
I0315 15:36:36.620880 29479 solver.cpp:613] Iteration 51440, avg_grad_norm = 492151
I0315 15:37:00.287936 29479 solver.cpp:214] Iteration 51460, loss = 6118.1
I0315 15:37:00.287989 29479 solver.cpp:229]     Train net output #0: loss = 3305.39 (* 1 = 3305.39 loss)
I0315 15:37:00.402647 29479 solver.cpp:610] Iteration 51460, lr = 7.65124e-09
I0315 15:37:00.402658 29479 solver.cpp:613] Iteration 51460, avg_grad_norm = 511141
I0315 15:37:26.002261 29479 solver.cpp:214] Iteration 51480, loss = 6091.08
I0315 15:37:26.002473 29479 solver.cpp:229]     Train net output #0: loss = 7750.67 (* 1 = 7750.67 loss)
I0315 15:37:26.116837 29479 solver.cpp:610] Iteration 51480, lr = 7.65032e-09
I0315 15:37:26.116849 29479 solver.cpp:613] Iteration 51480, avg_grad_norm = 544751
I0315 15:37:51.688263 29479 solver.cpp:214] Iteration 51500, loss = 5690.61
I0315 15:37:51.688344 29479 solver.cpp:229]     Train net output #0: loss = 3080.82 (* 1 = 3080.82 loss)
I0315 15:37:51.802906 29479 solver.cpp:610] Iteration 51500, lr = 7.64939e-09
I0315 15:37:51.802928 29479 solver.cpp:613] Iteration 51500, avg_grad_norm = 475233
I0315 15:38:17.404443 29479 solver.cpp:214] Iteration 51520, loss = 6185.04
I0315 15:38:17.404644 29479 solver.cpp:229]     Train net output #0: loss = 9420.17 (* 1 = 9420.17 loss)
I0315 15:38:17.518957 29479 solver.cpp:610] Iteration 51520, lr = 7.64846e-09
I0315 15:38:17.518971 29479 solver.cpp:613] Iteration 51520, avg_grad_norm = 581180
I0315 15:38:43.073053 29479 solver.cpp:214] Iteration 51540, loss = 5838.61
I0315 15:38:43.073122 29479 solver.cpp:229]     Train net output #0: loss = 3699.24 (* 1 = 3699.24 loss)
I0315 15:38:43.187659 29479 solver.cpp:610] Iteration 51540, lr = 7.64754e-09
I0315 15:38:43.187672 29479 solver.cpp:613] Iteration 51540, avg_grad_norm = 577966
I0315 15:39:21.803694 29479 solver.cpp:214] Iteration 51560, loss = 6023.91
I0315 15:39:21.803830 29479 solver.cpp:229]     Train net output #0: loss = 7136.22 (* 1 = 7136.22 loss)
I0315 15:39:21.909019 29479 solver.cpp:610] Iteration 51560, lr = 7.64661e-09
I0315 15:39:21.909044 29479 solver.cpp:613] Iteration 51560, avg_grad_norm = 536586
I0315 15:39:45.337119 29479 solver.cpp:214] Iteration 51580, loss = 5812.69
I0315 15:39:45.337182 29479 solver.cpp:229]     Train net output #0: loss = 4627.12 (* 1 = 4627.12 loss)
I0315 15:39:45.442371 29479 solver.cpp:610] Iteration 51580, lr = 7.64568e-09
I0315 15:39:45.442384 29479 solver.cpp:613] Iteration 51580, avg_grad_norm = 599991
I0315 15:40:10.462453 29479 solver.cpp:214] Iteration 51600, loss = 5952.3
I0315 15:40:10.462592 29479 solver.cpp:229]     Train net output #0: loss = 5402.87 (* 1 = 5402.87 loss)
I0315 15:40:10.577143 29479 solver.cpp:610] Iteration 51600, lr = 7.64475e-09
I0315 15:40:10.577157 29479 solver.cpp:613] Iteration 51600, avg_grad_norm = 514310
I0315 15:40:36.122156 29479 solver.cpp:214] Iteration 51620, loss = 6196.45
I0315 15:40:36.122225 29479 solver.cpp:229]     Train net output #0: loss = 9012.04 (* 1 = 9012.04 loss)
I0315 15:40:36.236711 29479 solver.cpp:610] Iteration 51620, lr = 7.64383e-09
I0315 15:40:36.236743 29479 solver.cpp:613] Iteration 51620, avg_grad_norm = 517672
I0315 15:41:01.800055 29479 solver.cpp:214] Iteration 51640, loss = 6085.56
I0315 15:41:01.800190 29479 solver.cpp:229]     Train net output #0: loss = 4770.97 (* 1 = 4770.97 loss)
I0315 15:41:01.914611 29479 solver.cpp:610] Iteration 51640, lr = 7.6429e-09
I0315 15:41:01.914625 29479 solver.cpp:613] Iteration 51640, avg_grad_norm = 553559
I0315 15:41:27.463731 29479 solver.cpp:214] Iteration 51660, loss = 6075.75
I0315 15:41:27.463798 29479 solver.cpp:229]     Train net output #0: loss = 8178.81 (* 1 = 8178.81 loss)
I0315 15:41:27.578325 29479 solver.cpp:610] Iteration 51660, lr = 7.64197e-09
I0315 15:41:27.578338 29479 solver.cpp:613] Iteration 51660, avg_grad_norm = 457384
I0315 15:41:53.144284 29479 solver.cpp:214] Iteration 51680, loss = 6152.43
I0315 15:41:53.144461 29479 solver.cpp:229]     Train net output #0: loss = 5149.11 (* 1 = 5149.11 loss)
I0315 15:41:53.259035 29479 solver.cpp:610] Iteration 51680, lr = 7.64105e-09
I0315 15:41:53.259049 29479 solver.cpp:613] Iteration 51680, avg_grad_norm = 506590
I0315 15:42:30.735682 29479 solver.cpp:214] Iteration 51700, loss = 6207.57
I0315 15:42:30.735800 29479 solver.cpp:229]     Train net output #0: loss = 3404.33 (* 1 = 3404.33 loss)
I0315 15:42:30.841079 29479 solver.cpp:610] Iteration 51700, lr = 7.64012e-09
I0315 15:42:30.841092 29479 solver.cpp:613] Iteration 51700, avg_grad_norm = 502815
I0315 15:42:55.186075 29479 solver.cpp:214] Iteration 51720, loss = 6003.78
I0315 15:42:55.186132 29479 solver.cpp:229]     Train net output #0: loss = 5862.15 (* 1 = 5862.15 loss)
I0315 15:42:55.300612 29479 solver.cpp:610] Iteration 51720, lr = 7.63919e-09
I0315 15:42:55.300655 29479 solver.cpp:613] Iteration 51720, avg_grad_norm = 518709
I0315 15:43:20.887538 29479 solver.cpp:214] Iteration 51740, loss = 5971.78
I0315 15:43:20.887670 29479 solver.cpp:229]     Train net output #0: loss = 5292.48 (* 1 = 5292.48 loss)
I0315 15:43:21.002010 29479 solver.cpp:610] Iteration 51740, lr = 7.63826e-09
I0315 15:43:21.002024 29479 solver.cpp:613] Iteration 51740, avg_grad_norm = 509723
I0315 15:43:46.561456 29479 solver.cpp:214] Iteration 51760, loss = 5827.47
I0315 15:43:46.561503 29479 solver.cpp:229]     Train net output #0: loss = 7148.09 (* 1 = 7148.09 loss)
I0315 15:43:46.676064 29479 solver.cpp:610] Iteration 51760, lr = 7.63734e-09
I0315 15:43:46.676077 29479 solver.cpp:613] Iteration 51760, avg_grad_norm = 500599
I0315 15:44:12.219491 29479 solver.cpp:214] Iteration 51780, loss = 6296.58
I0315 15:44:12.219630 29479 solver.cpp:229]     Train net output #0: loss = 4060.74 (* 1 = 4060.74 loss)
I0315 15:44:12.333961 29479 solver.cpp:610] Iteration 51780, lr = 7.63641e-09
I0315 15:44:12.333973 29479 solver.cpp:613] Iteration 51780, avg_grad_norm = 540386
I0315 15:44:37.887769 29479 solver.cpp:214] Iteration 51800, loss = 6194.44
I0315 15:44:37.887817 29479 solver.cpp:229]     Train net output #0: loss = 6054.71 (* 1 = 6054.71 loss)
I0315 15:44:38.002538 29479 solver.cpp:610] Iteration 51800, lr = 7.63548e-09
I0315 15:44:38.002550 29479 solver.cpp:613] Iteration 51800, avg_grad_norm = 557386
I0315 15:45:16.011793 29479 solver.cpp:214] Iteration 51820, loss = 6160.11
I0315 15:45:16.011914 29479 solver.cpp:229]     Train net output #0: loss = 8844.28 (* 1 = 8844.28 loss)
I0315 15:45:16.117197 29479 solver.cpp:610] Iteration 51820, lr = 7.63455e-09
I0315 15:45:16.117208 29479 solver.cpp:613] Iteration 51820, avg_grad_norm = 518815
I0315 15:45:39.746515 29479 solver.cpp:214] Iteration 51840, loss = 6000.62
I0315 15:45:39.746570 29479 solver.cpp:229]     Train net output #0: loss = 4807.05 (* 1 = 4807.05 loss)
I0315 15:45:39.859405 29479 solver.cpp:610] Iteration 51840, lr = 7.63363e-09
I0315 15:45:39.859416 29479 solver.cpp:613] Iteration 51840, avg_grad_norm = 566087
I0315 15:46:05.398926 29479 solver.cpp:214] Iteration 51860, loss = 5925.43
I0315 15:46:05.399049 29479 solver.cpp:229]     Train net output #0: loss = 5327.11 (* 1 = 5327.11 loss)
I0315 15:46:05.513653 29479 solver.cpp:610] Iteration 51860, lr = 7.6327e-09
I0315 15:46:05.513664 29479 solver.cpp:613] Iteration 51860, avg_grad_norm = 576498
I0315 15:46:31.058228 29479 solver.cpp:214] Iteration 51880, loss = 6292.6
I0315 15:46:31.058281 29479 solver.cpp:229]     Train net output #0: loss = 6617.1 (* 1 = 6617.1 loss)
I0315 15:46:31.173068 29479 solver.cpp:610] Iteration 51880, lr = 7.63177e-09
I0315 15:46:31.173080 29479 solver.cpp:613] Iteration 51880, avg_grad_norm = 555559
I0315 15:46:56.712752 29479 solver.cpp:214] Iteration 51900, loss = 5673.45
I0315 15:46:56.712885 29479 solver.cpp:229]     Train net output #0: loss = 4515.21 (* 1 = 4515.21 loss)
I0315 15:46:56.827385 29479 solver.cpp:610] Iteration 51900, lr = 7.63084e-09
I0315 15:46:56.827399 29479 solver.cpp:613] Iteration 51900, avg_grad_norm = 537489
I0315 15:47:22.372561 29479 solver.cpp:214] Iteration 51920, loss = 6029.61
I0315 15:47:22.372627 29479 solver.cpp:229]     Train net output #0: loss = 4161.14 (* 1 = 4161.14 loss)
I0315 15:47:22.487290 29479 solver.cpp:610] Iteration 51920, lr = 7.62992e-09
I0315 15:47:22.487303 29479 solver.cpp:613] Iteration 51920, avg_grad_norm = 577433
I0315 15:48:29.737550 29479 solver.cpp:214] Iteration 51940, loss = 6074.72
I0315 15:48:29.737675 29479 solver.cpp:229]     Train net output #0: loss = 4974.24 (* 1 = 4974.24 loss)
I0315 15:48:29.841393 29479 solver.cpp:610] Iteration 51940, lr = 7.62899e-09
I0315 15:48:29.841406 29479 solver.cpp:613] Iteration 51940, avg_grad_norm = 525409
I0315 15:48:53.219821 29479 solver.cpp:214] Iteration 51960, loss = 5667.24
I0315 15:48:53.219884 29479 solver.cpp:229]     Train net output #0: loss = 3195.67 (* 1 = 3195.67 loss)
I0315 15:48:53.324368 29479 solver.cpp:610] Iteration 51960, lr = 7.62806e-09
I0315 15:48:53.324380 29479 solver.cpp:613] Iteration 51960, avg_grad_norm = 515587
I0315 15:49:16.745113 29479 solver.cpp:214] Iteration 51980, loss = 5813.1
I0315 15:49:16.745260 29479 solver.cpp:229]     Train net output #0: loss = 5766.24 (* 1 = 5766.24 loss)
I0315 15:49:16.850373 29479 solver.cpp:610] Iteration 51980, lr = 7.62713e-09
I0315 15:49:16.850388 29479 solver.cpp:613] Iteration 51980, avg_grad_norm = 505002
I0315 15:49:40.370643 29479 solver.cpp:214] Iteration 52000, loss = 5980.52
I0315 15:49:40.370705 29479 solver.cpp:229]     Train net output #0: loss = 9448.75 (* 1 = 9448.75 loss)
I0315 15:49:40.476027 29479 solver.cpp:610] Iteration 52000, lr = 7.62621e-09
I0315 15:49:40.476040 29479 solver.cpp:613] Iteration 52000, avg_grad_norm = 529286
I0315 15:50:05.650472 29479 solver.cpp:214] Iteration 52020, loss = 6165.92
I0315 15:50:05.650590 29479 solver.cpp:229]     Train net output #0: loss = 6042.38 (* 1 = 6042.38 loss)
I0315 15:50:05.763470 29479 solver.cpp:610] Iteration 52020, lr = 7.62528e-09
I0315 15:50:05.763484 29479 solver.cpp:613] Iteration 52020, avg_grad_norm = 549464
I0315 15:50:31.072967 29479 solver.cpp:214] Iteration 52040, loss = 5923.03
I0315 15:50:31.073040 29479 solver.cpp:229]     Train net output #0: loss = 5254.99 (* 1 = 5254.99 loss)
I0315 15:50:31.185969 29479 solver.cpp:610] Iteration 52040, lr = 7.62435e-09
I0315 15:50:31.185983 29479 solver.cpp:613] Iteration 52040, avg_grad_norm = 557830
I0315 15:50:56.778430 29479 solver.cpp:214] Iteration 52060, loss = 6301.46
I0315 15:50:56.778558 29479 solver.cpp:229]     Train net output #0: loss = 8978.33 (* 1 = 8978.33 loss)
I0315 15:50:56.893085 29479 solver.cpp:610] Iteration 52060, lr = 7.62342e-09
I0315 15:50:56.893098 29479 solver.cpp:613] Iteration 52060, avg_grad_norm = 564953
I0315 15:51:34.220947 29479 solver.cpp:214] Iteration 52080, loss = 6119.79
I0315 15:51:34.221143 29479 solver.cpp:229]     Train net output #0: loss = 6129.29 (* 1 = 6129.29 loss)
I0315 15:51:34.325467 29479 solver.cpp:610] Iteration 52080, lr = 7.6225e-09
I0315 15:51:34.325482 29479 solver.cpp:613] Iteration 52080, avg_grad_norm = 514215
I0315 15:51:58.454944 29479 solver.cpp:214] Iteration 52100, loss = 5967.7
I0315 15:51:58.455016 29479 solver.cpp:229]     Train net output #0: loss = 6758.23 (* 1 = 6758.23 loss)
I0315 15:51:58.569696 29479 solver.cpp:610] Iteration 52100, lr = 7.62157e-09
I0315 15:51:58.569708 29479 solver.cpp:613] Iteration 52100, avg_grad_norm = 488092
I0315 15:52:24.110730 29479 solver.cpp:214] Iteration 52120, loss = 5738.19
I0315 15:52:24.110862 29479 solver.cpp:229]     Train net output #0: loss = 6355.8 (* 1 = 6355.8 loss)
I0315 15:52:24.225260 29479 solver.cpp:610] Iteration 52120, lr = 7.62064e-09
I0315 15:52:24.225272 29479 solver.cpp:613] Iteration 52120, avg_grad_norm = 512320
I0315 15:52:49.766835 29479 solver.cpp:214] Iteration 52140, loss = 5533.72
I0315 15:52:49.766897 29479 solver.cpp:229]     Train net output #0: loss = 7326.65 (* 1 = 7326.65 loss)
I0315 15:52:49.881279 29479 solver.cpp:610] Iteration 52140, lr = 7.61971e-09
I0315 15:52:49.881292 29479 solver.cpp:613] Iteration 52140, avg_grad_norm = 562382
I0315 15:53:15.476435 29479 solver.cpp:214] Iteration 52160, loss = 5881.17
I0315 15:53:15.476608 29479 solver.cpp:229]     Train net output #0: loss = 6183.88 (* 1 = 6183.88 loss)
I0315 15:53:15.591081 29479 solver.cpp:610] Iteration 52160, lr = 7.61879e-09
I0315 15:53:15.591095 29479 solver.cpp:613] Iteration 52160, avg_grad_norm = 565668
I0315 15:53:41.152597 29479 solver.cpp:214] Iteration 52180, loss = 6061.04
I0315 15:53:41.152663 29479 solver.cpp:229]     Train net output #0: loss = 4829.58 (* 1 = 4829.58 loss)
I0315 15:53:41.267199 29479 solver.cpp:610] Iteration 52180, lr = 7.61786e-09
I0315 15:53:41.267212 29479 solver.cpp:613] Iteration 52180, avg_grad_norm = 521615
I0315 15:54:29.335892 29479 solver.cpp:214] Iteration 52200, loss = 6159.3
I0315 15:54:29.335996 29479 solver.cpp:229]     Train net output #0: loss = 4766.91 (* 1 = 4766.91 loss)
I0315 15:54:29.440161 29479 solver.cpp:610] Iteration 52200, lr = 7.61693e-09
I0315 15:54:29.440174 29479 solver.cpp:613] Iteration 52200, avg_grad_norm = 504504
I0315 15:54:52.895896 29479 solver.cpp:214] Iteration 52220, loss = 5975.69
I0315 15:54:52.895963 29479 solver.cpp:229]     Train net output #0: loss = 4230.73 (* 1 = 4230.73 loss)
I0315 15:54:53.000387 29479 solver.cpp:610] Iteration 52220, lr = 7.616e-09
I0315 15:54:53.000403 29479 solver.cpp:613] Iteration 52220, avg_grad_norm = 499598
I0315 15:55:17.067294 29479 solver.cpp:214] Iteration 52240, loss = 6134.3
I0315 15:55:17.067447 29479 solver.cpp:229]     Train net output #0: loss = 10570 (* 1 = 10570 loss)
I0315 15:55:17.180419 29479 solver.cpp:610] Iteration 52240, lr = 7.61507e-09
I0315 15:55:17.180433 29479 solver.cpp:613] Iteration 52240, avg_grad_norm = 584712
I0315 15:55:42.674348 29479 solver.cpp:214] Iteration 52260, loss = 6403.53
I0315 15:55:42.674396 29479 solver.cpp:229]     Train net output #0: loss = 5814.81 (* 1 = 5814.81 loss)
I0315 15:55:42.789083 29479 solver.cpp:610] Iteration 52260, lr = 7.61415e-09
I0315 15:55:42.789096 29479 solver.cpp:613] Iteration 52260, avg_grad_norm = 550873
I0315 15:56:08.391433 29479 solver.cpp:214] Iteration 52280, loss = 6046.44
I0315 15:56:08.391615 29479 solver.cpp:229]     Train net output #0: loss = 5187.08 (* 1 = 5187.08 loss)
I0315 15:56:08.506085 29479 solver.cpp:610] Iteration 52280, lr = 7.61322e-09
I0315 15:56:08.506098 29479 solver.cpp:613] Iteration 52280, avg_grad_norm = 504937
I0315 15:56:34.116935 29479 solver.cpp:214] Iteration 52300, loss = 6227.14
I0315 15:56:34.116994 29479 solver.cpp:229]     Train net output #0: loss = 5604.59 (* 1 = 5604.59 loss)
I0315 15:56:34.231565 29479 solver.cpp:610] Iteration 52300, lr = 7.61229e-09
I0315 15:56:34.231578 29479 solver.cpp:613] Iteration 52300, avg_grad_norm = 607340
I0315 15:56:59.851200 29479 solver.cpp:214] Iteration 52320, loss = 5682.93
I0315 15:56:59.851363 29479 solver.cpp:229]     Train net output #0: loss = 4940.46 (* 1 = 4940.46 loss)
I0315 15:56:59.965811 29479 solver.cpp:610] Iteration 52320, lr = 7.61136e-09
I0315 15:56:59.965824 29479 solver.cpp:613] Iteration 52320, avg_grad_norm = 536626
I0315 15:57:36.324508 29479 solver.cpp:214] Iteration 52340, loss = 5990.59
I0315 15:57:36.324625 29479 solver.cpp:229]     Train net output #0: loss = 6405.39 (* 1 = 6405.39 loss)
I0315 15:57:36.429603 29479 solver.cpp:610] Iteration 52340, lr = 7.61044e-09
I0315 15:57:36.429616 29479 solver.cpp:613] Iteration 52340, avg_grad_norm = 543861
I0315 15:58:01.043802 29479 solver.cpp:214] Iteration 52360, loss = 6042.01
I0315 15:58:01.043875 29479 solver.cpp:229]     Train net output #0: loss = 5522 (* 1 = 5522 loss)
I0315 15:58:01.158476 29479 solver.cpp:610] Iteration 52360, lr = 7.60951e-09
I0315 15:58:01.158529 29479 solver.cpp:613] Iteration 52360, avg_grad_norm = 580557
I0315 15:58:26.770361 29479 solver.cpp:214] Iteration 52380, loss = 6056.21
I0315 15:58:26.770560 29479 solver.cpp:229]     Train net output #0: loss = 7428.15 (* 1 = 7428.15 loss)
I0315 15:58:26.884970 29479 solver.cpp:610] Iteration 52380, lr = 7.60858e-09
I0315 15:58:26.884984 29479 solver.cpp:613] Iteration 52380, avg_grad_norm = 525584
I0315 15:58:52.481163 29479 solver.cpp:214] Iteration 52400, loss = 5631.46
I0315 15:58:52.481206 29479 solver.cpp:229]     Train net output #0: loss = 7091.73 (* 1 = 7091.73 loss)
I0315 15:58:52.595576 29479 solver.cpp:610] Iteration 52400, lr = 7.60765e-09
I0315 15:58:52.595588 29479 solver.cpp:613] Iteration 52400, avg_grad_norm = 543352
I0315 15:59:18.204548 29479 solver.cpp:214] Iteration 52420, loss = 6009.66
I0315 15:59:18.204752 29479 solver.cpp:229]     Train net output #0: loss = 7331.46 (* 1 = 7331.46 loss)
I0315 15:59:18.319141 29479 solver.cpp:610] Iteration 52420, lr = 7.60673e-09
I0315 15:59:18.319154 29479 solver.cpp:613] Iteration 52420, avg_grad_norm = 639561
I0315 15:59:43.636905 29479 solver.cpp:214] Iteration 52440, loss = 5946.59
I0315 15:59:43.636961 29479 solver.cpp:229]     Train net output #0: loss = 5539.45 (* 1 = 5539.45 loss)
I0315 15:59:43.750813 29479 solver.cpp:610] Iteration 52440, lr = 7.6058e-09
I0315 15:59:43.750826 29479 solver.cpp:613] Iteration 52440, avg_grad_norm = 639364
I0315 16:00:26.483531 29479 solver.cpp:214] Iteration 52460, loss = 5790.48
I0315 16:00:26.483667 29479 solver.cpp:229]     Train net output #0: loss = 8874.29 (* 1 = 8874.29 loss)
I0315 16:00:26.588726 29479 solver.cpp:610] Iteration 52460, lr = 7.60487e-09
I0315 16:00:26.588752 29479 solver.cpp:613] Iteration 52460, avg_grad_norm = 554733
I0315 16:00:50.049304 29479 solver.cpp:214] Iteration 52480, loss = 5800.52
I0315 16:00:50.049384 29479 solver.cpp:229]     Train net output #0: loss = 5646.24 (* 1 = 5646.24 loss)
I0315 16:00:50.154397 29479 solver.cpp:610] Iteration 52480, lr = 7.60394e-09
I0315 16:00:50.154409 29479 solver.cpp:613] Iteration 52480, avg_grad_norm = 537230
I0315 16:01:15.632843 29479 solver.cpp:214] Iteration 52500, loss = 5902.13
I0315 16:01:15.633091 29479 solver.cpp:229]     Train net output #0: loss = 8041.55 (* 1 = 8041.55 loss)
I0315 16:01:15.747345 29479 solver.cpp:610] Iteration 52500, lr = 7.60302e-09
I0315 16:01:15.747360 29479 solver.cpp:613] Iteration 52500, avg_grad_norm = 592604
I0315 16:01:41.348456 29479 solver.cpp:214] Iteration 52520, loss = 5990.96
I0315 16:01:41.348507 29479 solver.cpp:229]     Train net output #0: loss = 3310.87 (* 1 = 3310.87 loss)
I0315 16:01:41.462966 29479 solver.cpp:610] Iteration 52520, lr = 7.60209e-09
I0315 16:01:41.462981 29479 solver.cpp:613] Iteration 52520, avg_grad_norm = 536127
I0315 16:02:07.082103 29479 solver.cpp:214] Iteration 52540, loss = 5894.33
I0315 16:02:07.082249 29479 solver.cpp:229]     Train net output #0: loss = 3023.96 (* 1 = 3023.96 loss)
I0315 16:02:07.196699 29479 solver.cpp:610] Iteration 52540, lr = 7.60116e-09
I0315 16:02:07.196756 29479 solver.cpp:613] Iteration 52540, avg_grad_norm = 528194
I0315 16:02:32.815121 29479 solver.cpp:214] Iteration 52560, loss = 6015.42
I0315 16:02:32.815171 29479 solver.cpp:229]     Train net output #0: loss = 6964.33 (* 1 = 6964.33 loss)
I0315 16:02:32.929646 29479 solver.cpp:610] Iteration 52560, lr = 7.60023e-09
I0315 16:02:32.929661 29479 solver.cpp:613] Iteration 52560, avg_grad_norm = 572854
I0315 16:03:40.203964 29479 solver.cpp:214] Iteration 52580, loss = 6015.31
I0315 16:03:40.204104 29479 solver.cpp:229]     Train net output #0: loss = 10460.2 (* 1 = 10460.2 loss)
I0315 16:03:40.307816 29479 solver.cpp:610] Iteration 52580, lr = 7.5993e-09
I0315 16:03:40.307828 29479 solver.cpp:613] Iteration 52580, avg_grad_norm = 628515
I0315 16:04:03.703263 29479 solver.cpp:214] Iteration 52600, loss = 5956.03
I0315 16:04:03.703310 29479 solver.cpp:229]     Train net output #0: loss = 4259.74 (* 1 = 4259.74 loss)
I0315 16:04:03.808583 29479 solver.cpp:610] Iteration 52600, lr = 7.59838e-09
I0315 16:04:03.808596 29479 solver.cpp:613] Iteration 52600, avg_grad_norm = 526387
I0315 16:04:27.293525 29479 solver.cpp:214] Iteration 52620, loss = 6185.49
I0315 16:04:27.293793 29479 solver.cpp:229]     Train net output #0: loss = 4971.71 (* 1 = 4971.71 loss)
I0315 16:04:27.398730 29479 solver.cpp:610] Iteration 52620, lr = 7.59745e-09
I0315 16:04:27.398743 29479 solver.cpp:613] Iteration 52620, avg_grad_norm = 555288
I0315 16:04:50.972091 29479 solver.cpp:214] Iteration 52640, loss = 5724.7
I0315 16:04:50.972151 29479 solver.cpp:229]     Train net output #0: loss = 3577.02 (* 1 = 3577.02 loss)
I0315 16:04:51.083801 29479 solver.cpp:610] Iteration 52640, lr = 7.59652e-09
I0315 16:04:51.083813 29479 solver.cpp:613] Iteration 52640, avg_grad_norm = 499295
I0315 16:05:16.192212 29479 solver.cpp:214] Iteration 52660, loss = 5859.83
I0315 16:05:16.192432 29479 solver.cpp:229]     Train net output #0: loss = 2360.73 (* 1 = 2360.73 loss)
I0315 16:05:16.305200 29479 solver.cpp:610] Iteration 52660, lr = 7.59559e-09
I0315 16:05:16.305215 29479 solver.cpp:613] Iteration 52660, avg_grad_norm = 535173
I0315 16:05:41.829586 29479 solver.cpp:214] Iteration 52680, loss = 5899.16
I0315 16:05:41.829653 29479 solver.cpp:229]     Train net output #0: loss = 9279.62 (* 1 = 9279.62 loss)
I0315 16:05:41.944150 29479 solver.cpp:610] Iteration 52680, lr = 7.59466e-09
I0315 16:05:41.944167 29479 solver.cpp:613] Iteration 52680, avg_grad_norm = 551797
I0315 16:06:07.563925 29479 solver.cpp:214] Iteration 52700, loss = 5883.3
I0315 16:06:07.564115 29479 solver.cpp:229]     Train net output #0: loss = 5711.93 (* 1 = 5711.93 loss)
I0315 16:06:07.678817 29479 solver.cpp:610] Iteration 52700, lr = 7.59374e-09
I0315 16:06:07.678830 29479 solver.cpp:613] Iteration 52700, avg_grad_norm = 532845
I0315 16:06:44.327854 29479 solver.cpp:214] Iteration 52720, loss = 5960.44
I0315 16:06:44.328009 29479 solver.cpp:229]     Train net output #0: loss = 4048.57 (* 1 = 4048.57 loss)
I0315 16:06:44.432024 29479 solver.cpp:610] Iteration 52720, lr = 7.59281e-09
I0315 16:06:44.432036 29479 solver.cpp:613] Iteration 52720, avg_grad_norm = 548407
I0315 16:07:09.016319 29479 solver.cpp:214] Iteration 52740, loss = 5985.47
I0315 16:07:09.016409 29479 solver.cpp:229]     Train net output #0: loss = 5445.53 (* 1 = 5445.53 loss)
I0315 16:07:09.130908 29479 solver.cpp:610] Iteration 52740, lr = 7.59188e-09
I0315 16:07:09.130920 29479 solver.cpp:613] Iteration 52740, avg_grad_norm = 636965
I0315 16:07:34.693809 29479 solver.cpp:214] Iteration 52760, loss = 6208.33
I0315 16:07:34.694020 29479 solver.cpp:229]     Train net output #0: loss = 6516.58 (* 1 = 6516.58 loss)
I0315 16:07:34.808485 29479 solver.cpp:610] Iteration 52760, lr = 7.59095e-09
I0315 16:07:34.808497 29479 solver.cpp:613] Iteration 52760, avg_grad_norm = 565832
I0315 16:08:00.353304 29479 solver.cpp:214] Iteration 52780, loss = 6017.24
I0315 16:08:00.353366 29479 solver.cpp:229]     Train net output #0: loss = 4848.75 (* 1 = 4848.75 loss)
I0315 16:08:00.467756 29479 solver.cpp:610] Iteration 52780, lr = 7.59002e-09
I0315 16:08:00.467769 29479 solver.cpp:613] Iteration 52780, avg_grad_norm = 522541
I0315 16:08:26.100803 29479 solver.cpp:214] Iteration 52800, loss = 5991.07
I0315 16:08:26.100926 29479 solver.cpp:229]     Train net output #0: loss = 6097.63 (* 1 = 6097.63 loss)
I0315 16:08:26.215421 29479 solver.cpp:610] Iteration 52800, lr = 7.5891e-09
I0315 16:08:26.215435 29479 solver.cpp:613] Iteration 52800, avg_grad_norm = 513719
I0315 16:08:51.729645 29479 solver.cpp:214] Iteration 52820, loss = 6171.74
I0315 16:08:51.729707 29479 solver.cpp:229]     Train net output #0: loss = 2848.59 (* 1 = 2848.59 loss)
I0315 16:08:51.842691 29479 solver.cpp:610] Iteration 52820, lr = 7.58817e-09
I0315 16:08:51.842705 29479 solver.cpp:613] Iteration 52820, avg_grad_norm = 494633
I0315 16:09:29.182400 29479 solver.cpp:214] Iteration 52840, loss = 6030.84
I0315 16:09:29.182556 29479 solver.cpp:229]     Train net output #0: loss = 2689.65 (* 1 = 2689.65 loss)
I0315 16:09:29.287400 29479 solver.cpp:610] Iteration 52840, lr = 7.58724e-09
I0315 16:09:29.287413 29479 solver.cpp:613] Iteration 52840, avg_grad_norm = 561301
I0315 16:09:53.120167 29479 solver.cpp:214] Iteration 52860, loss = 6120.31
I0315 16:09:53.120218 29479 solver.cpp:229]     Train net output #0: loss = 5917.91 (* 1 = 5917.91 loss)
I0315 16:09:53.231643 29479 solver.cpp:610] Iteration 52860, lr = 7.58631e-09
I0315 16:09:53.231655 29479 solver.cpp:613] Iteration 52860, avg_grad_norm = 536142
I0315 16:10:18.909337 29479 solver.cpp:214] Iteration 52880, loss = 6069.59
I0315 16:10:18.909502 29479 solver.cpp:229]     Train net output #0: loss = 5485.51 (* 1 = 5485.51 loss)
I0315 16:10:19.023962 29479 solver.cpp:610] Iteration 52880, lr = 7.58538e-09
I0315 16:10:19.023974 29479 solver.cpp:613] Iteration 52880, avg_grad_norm = 510963
I0315 16:10:44.223757 29479 solver.cpp:214] Iteration 52900, loss = 6016.53
I0315 16:10:44.223812 29479 solver.cpp:229]     Train net output #0: loss = 5980.84 (* 1 = 5980.84 loss)
I0315 16:10:44.336689 29479 solver.cpp:610] Iteration 52900, lr = 7.58446e-09
I0315 16:10:44.336702 29479 solver.cpp:613] Iteration 52900, avg_grad_norm = 569179
I0315 16:11:09.743077 29479 solver.cpp:214] Iteration 52920, loss = 5857.43
I0315 16:11:09.743227 29479 solver.cpp:229]     Train net output #0: loss = 8999.51 (* 1 = 8999.51 loss)
I0315 16:11:09.859320 29479 solver.cpp:610] Iteration 52920, lr = 7.58353e-09
I0315 16:11:09.859333 29479 solver.cpp:613] Iteration 52920, avg_grad_norm = 543926
I0315 16:11:35.449781 29479 solver.cpp:214] Iteration 52940, loss = 6052.29
I0315 16:11:35.449841 29479 solver.cpp:229]     Train net output #0: loss = 4607.61 (* 1 = 4607.61 loss)
I0315 16:11:35.562713 29479 solver.cpp:610] Iteration 52940, lr = 7.5826e-09
I0315 16:11:35.562726 29479 solver.cpp:613] Iteration 52940, avg_grad_norm = 541698
I0315 16:12:13.975831 29479 solver.cpp:214] Iteration 52960, loss = 5903.22
I0315 16:12:13.975996 29479 solver.cpp:229]     Train net output #0: loss = 10427.7 (* 1 = 10427.7 loss)
I0315 16:12:14.081080 29479 solver.cpp:610] Iteration 52960, lr = 7.58167e-09
I0315 16:12:14.081094 29479 solver.cpp:613] Iteration 52960, avg_grad_norm = 503399
I0315 16:12:49.076581 29479 solver.cpp:214] Iteration 52980, loss = 5707.52
I0315 16:12:49.076699 29479 solver.cpp:229]     Train net output #0: loss = 3796.03 (* 1 = 3796.03 loss)
I0315 16:12:49.435698 29479 solver.cpp:610] Iteration 52980, lr = 7.58074e-09
I0315 16:12:49.435711 29479 solver.cpp:613] Iteration 52980, avg_grad_norm = 500394
I0315 16:13:52.402580 29479 solver.cpp:214] Iteration 53000, loss = 5895.01
I0315 16:13:52.402726 29479 solver.cpp:229]     Train net output #0: loss = 3701.34 (* 1 = 3701.34 loss)
I0315 16:13:52.763254 29479 solver.cpp:610] Iteration 53000, lr = 7.57981e-09
I0315 16:13:52.763268 29479 solver.cpp:613] Iteration 53000, avg_grad_norm = 497384
I0315 16:14:26.221649 29479 solver.cpp:214] Iteration 53020, loss = 6004.65
I0315 16:14:26.221864 29479 solver.cpp:229]     Train net output #0: loss = 5988.26 (* 1 = 5988.26 loss)
I0315 16:14:26.545284 29479 solver.cpp:610] Iteration 53020, lr = 7.57889e-09
I0315 16:14:26.545296 29479 solver.cpp:613] Iteration 53020, avg_grad_norm = 474411
I0315 16:15:29.392683 29479 solver.cpp:214] Iteration 53040, loss = 5921.61
I0315 16:15:29.392818 29479 solver.cpp:229]     Train net output #0: loss = 8183.07 (* 1 = 8183.07 loss)
I0315 16:15:29.754317 29479 solver.cpp:610] Iteration 53040, lr = 7.57796e-09
I0315 16:15:29.754333 29479 solver.cpp:613] Iteration 53040, avg_grad_norm = 482753
I0315 16:16:32.925755 29479 solver.cpp:214] Iteration 53060, loss = 6445.09
I0315 16:16:32.925905 29479 solver.cpp:229]     Train net output #0: loss = 5653.97 (* 1 = 5653.97 loss)
I0315 16:16:33.283615 29479 solver.cpp:610] Iteration 53060, lr = 7.57703e-09
I0315 16:16:33.283629 29479 solver.cpp:613] Iteration 53060, avg_grad_norm = 554031
I0315 16:17:38.390444 29479 solver.cpp:214] Iteration 53080, loss = 5817.7
I0315 16:17:38.390632 29479 solver.cpp:229]     Train net output #0: loss = 5888.99 (* 1 = 5888.99 loss)
I0315 16:17:38.748772 29479 solver.cpp:610] Iteration 53080, lr = 7.5761e-09
I0315 16:17:38.748785 29479 solver.cpp:613] Iteration 53080, avg_grad_norm = 568265
I0315 16:19:25.423652 29479 solver.cpp:214] Iteration 53100, loss = 6109.66
I0315 16:19:25.423836 29479 solver.cpp:229]     Train net output #0: loss = 10141.1 (* 1 = 10141.1 loss)
I0315 16:19:25.783359 29479 solver.cpp:610] Iteration 53100, lr = 7.57517e-09
I0315 16:19:25.783371 29479 solver.cpp:613] Iteration 53100, avg_grad_norm = 591512
I0315 16:20:29.522019 29479 solver.cpp:214] Iteration 53120, loss = 6078.45
I0315 16:20:29.522181 29479 solver.cpp:229]     Train net output #0: loss = 10925 (* 1 = 10925 loss)
I0315 16:20:29.887483 29479 solver.cpp:610] Iteration 53120, lr = 7.57425e-09
I0315 16:20:29.887498 29479 solver.cpp:613] Iteration 53120, avg_grad_norm = 536220
I0315 16:21:32.301452 29479 solver.cpp:214] Iteration 53140, loss = 5980.62
I0315 16:21:32.301651 29479 solver.cpp:229]     Train net output #0: loss = 3515.85 (* 1 = 3515.85 loss)
I0315 16:21:32.406744 29479 solver.cpp:610] Iteration 53140, lr = 7.57332e-09
I0315 16:21:32.406795 29479 solver.cpp:613] Iteration 53140, avg_grad_norm = 499543
I0315 16:22:15.991827 29479 solver.cpp:214] Iteration 53160, loss = 5898.27
I0315 16:22:15.991961 29479 solver.cpp:229]     Train net output #0: loss = 8078.73 (* 1 = 8078.73 loss)
I0315 16:22:16.360087 29479 solver.cpp:610] Iteration 53160, lr = 7.57239e-09
I0315 16:22:16.360102 29479 solver.cpp:613] Iteration 53160, avg_grad_norm = 549103
I0315 16:23:20.181367 29479 solver.cpp:214] Iteration 53180, loss = 5939.72
I0315 16:23:20.181525 29479 solver.cpp:229]     Train net output #0: loss = 4263.96 (* 1 = 4263.96 loss)
I0315 16:23:20.545812 29479 solver.cpp:610] Iteration 53180, lr = 7.57146e-09
I0315 16:23:20.545826 29479 solver.cpp:613] Iteration 53180, avg_grad_norm = 528161
I0315 16:24:24.605389 29479 solver.cpp:214] Iteration 53200, loss = 6024.34
I0315 16:24:24.605510 29479 solver.cpp:229]     Train net output #0: loss = 3411.85 (* 1 = 3411.85 loss)
I0315 16:24:24.969341 29479 solver.cpp:610] Iteration 53200, lr = 7.57053e-09
I0315 16:24:24.969354 29479 solver.cpp:613] Iteration 53200, avg_grad_norm = 550766
I0315 16:25:41.614251 29479 solver.cpp:214] Iteration 53220, loss = 5760.52
I0315 16:25:41.614401 29479 solver.cpp:229]     Train net output #0: loss = 4790.91 (* 1 = 4790.91 loss)
I0315 16:25:41.982575 29479 solver.cpp:610] Iteration 53220, lr = 7.5696e-09
I0315 16:25:41.982589 29479 solver.cpp:613] Iteration 53220, avg_grad_norm = 519939
I0315 16:26:45.938606 29479 solver.cpp:214] Iteration 53240, loss = 5993.87
I0315 16:26:45.938731 29479 solver.cpp:229]     Train net output #0: loss = 4785.15 (* 1 = 4785.15 loss)
I0315 16:26:46.151453 29479 solver.cpp:610] Iteration 53240, lr = 7.56868e-09
I0315 16:26:46.151466 29479 solver.cpp:613] Iteration 53240, avg_grad_norm = 513109
I0315 16:27:50.002480 29479 solver.cpp:214] Iteration 53260, loss = 6286.53
I0315 16:27:50.002594 29479 solver.cpp:229]     Train net output #0: loss = 9483.32 (* 1 = 9483.32 loss)
I0315 16:27:50.371122 29479 solver.cpp:610] Iteration 53260, lr = 7.56775e-09
I0315 16:27:50.371135 29479 solver.cpp:613] Iteration 53260, avg_grad_norm = 492260
I0315 16:28:54.353060 29479 solver.cpp:214] Iteration 53280, loss = 5834.89
I0315 16:28:54.353206 29479 solver.cpp:229]     Train net output #0: loss = 4157.28 (* 1 = 4157.28 loss)
I0315 16:28:54.568981 29479 solver.cpp:610] Iteration 53280, lr = 7.56682e-09
I0315 16:28:54.568997 29479 solver.cpp:613] Iteration 53280, avg_grad_norm = 620990
I0315 16:29:37.045246 29479 solver.cpp:214] Iteration 53300, loss = 6136.04
I0315 16:29:37.045373 29479 solver.cpp:229]     Train net output #0: loss = 14134.2 (* 1 = 14134.2 loss)
I0315 16:29:37.480271 29479 solver.cpp:610] Iteration 53300, lr = 7.56589e-09
I0315 16:29:37.480285 29479 solver.cpp:613] Iteration 53300, avg_grad_norm = 567681
I0315 16:30:41.694670 29479 solver.cpp:214] Iteration 53320, loss = 5902.13
I0315 16:30:41.694799 29479 solver.cpp:229]     Train net output #0: loss = 8994.75 (* 1 = 8994.75 loss)
I0315 16:30:42.059046 29479 solver.cpp:610] Iteration 53320, lr = 7.56496e-09
I0315 16:30:42.059058 29479 solver.cpp:613] Iteration 53320, avg_grad_norm = 551710
I0315 16:32:04.196934 29479 solver.cpp:214] Iteration 53340, loss = 6020.89
I0315 16:32:04.197057 29479 solver.cpp:229]     Train net output #0: loss = 3848.53 (* 1 = 3848.53 loss)
I0315 16:32:04.391315 29479 solver.cpp:610] Iteration 53340, lr = 7.56403e-09
I0315 16:32:04.391331 29479 solver.cpp:613] Iteration 53340, avg_grad_norm = 549862
I0315 16:33:08.463291 29479 solver.cpp:214] Iteration 53360, loss = 5783.21
I0315 16:33:08.463431 29479 solver.cpp:229]     Train net output #0: loss = 4408.9 (* 1 = 4408.9 loss)
I0315 16:33:08.824161 29479 solver.cpp:610] Iteration 53360, lr = 7.56311e-09
I0315 16:33:08.824203 29479 solver.cpp:613] Iteration 53360, avg_grad_norm = 508309
I0315 16:34:13.472867 29479 solver.cpp:214] Iteration 53380, loss = 6169.88
I0315 16:34:13.473076 29479 solver.cpp:229]     Train net output #0: loss = 3094.39 (* 1 = 3094.39 loss)
I0315 16:34:13.836714 29479 solver.cpp:610] Iteration 53380, lr = 7.56218e-09
I0315 16:34:13.836743 29479 solver.cpp:613] Iteration 53380, avg_grad_norm = 529319
I0315 16:35:17.632477 29479 solver.cpp:214] Iteration 53400, loss = 6294.35
I0315 16:35:17.632593 29479 solver.cpp:229]     Train net output #0: loss = 10242.1 (* 1 = 10242.1 loss)
I0315 16:35:17.998894 29479 solver.cpp:610] Iteration 53400, lr = 7.56125e-09
I0315 16:35:17.998908 29479 solver.cpp:613] Iteration 53400, avg_grad_norm = 565064
I0315 16:36:25.428437 29479 solver.cpp:214] Iteration 53420, loss = 6349.08
I0315 16:36:25.428563 29479 solver.cpp:229]     Train net output #0: loss = 5382.31 (* 1 = 5382.31 loss)
I0315 16:36:25.797194 29479 solver.cpp:610] Iteration 53420, lr = 7.56032e-09
I0315 16:36:25.797209 29479 solver.cpp:613] Iteration 53420, avg_grad_norm = 586388
I0315 16:37:16.510076 29479 solver.cpp:214] Iteration 53440, loss = 6050.57
I0315 16:37:16.510239 29479 solver.cpp:229]     Train net output #0: loss = 5605.63 (* 1 = 5605.63 loss)
I0315 16:37:16.626108 29479 solver.cpp:610] Iteration 53440, lr = 7.55939e-09
I0315 16:37:16.626153 29479 solver.cpp:613] Iteration 53440, avg_grad_norm = 543612
I0315 16:38:21.279945 29479 solver.cpp:214] Iteration 53460, loss = 6103.61
I0315 16:38:21.280076 29479 solver.cpp:229]     Train net output #0: loss = 4505.91 (* 1 = 4505.91 loss)
I0315 16:38:21.638612 29479 solver.cpp:610] Iteration 53460, lr = 7.55846e-09
I0315 16:38:21.638631 29479 solver.cpp:613] Iteration 53460, avg_grad_norm = 550112
I0315 16:39:39.093366 29479 solver.cpp:214] Iteration 53480, loss = 6112.69
I0315 16:39:39.093528 29479 solver.cpp:229]     Train net output #0: loss = 7709.34 (* 1 = 7709.34 loss)
I0315 16:39:39.450644 29479 solver.cpp:610] Iteration 53480, lr = 7.55754e-09
I0315 16:39:39.450659 29479 solver.cpp:613] Iteration 53480, avg_grad_norm = 516618
I0315 16:40:43.448155 29479 solver.cpp:214] Iteration 53500, loss = 6184.33
I0315 16:40:43.448370 29479 solver.cpp:229]     Train net output #0: loss = 5350.46 (* 1 = 5350.46 loss)
I0315 16:40:43.664109 29479 solver.cpp:610] Iteration 53500, lr = 7.55661e-09
I0315 16:40:43.664122 29479 solver.cpp:613] Iteration 53500, avg_grad_norm = 507313
I0315 16:41:47.576297 29479 solver.cpp:214] Iteration 53520, loss = 5935.85
I0315 16:41:47.576503 29479 solver.cpp:229]     Train net output #0: loss = 10843.8 (* 1 = 10843.8 loss)
I0315 16:41:47.941779 29479 solver.cpp:610] Iteration 53520, lr = 7.55568e-09
I0315 16:41:47.941792 29479 solver.cpp:613] Iteration 53520, avg_grad_norm = 515091
I0315 16:42:51.700825 29479 solver.cpp:214] Iteration 53540, loss = 5953.06
I0315 16:42:51.701033 29479 solver.cpp:229]     Train net output #0: loss = 4997.09 (* 1 = 4997.09 loss)
I0315 16:42:52.060219 29479 solver.cpp:610] Iteration 53540, lr = 7.55475e-09
I0315 16:42:52.060230 29479 solver.cpp:613] Iteration 53540, avg_grad_norm = 572054
I0315 16:44:01.145182 29479 solver.cpp:214] Iteration 53560, loss = 6303.11
I0315 16:44:01.145426 29479 solver.cpp:229]     Train net output #0: loss = 10397.5 (* 1 = 10397.5 loss)
I0315 16:44:01.514758 29479 solver.cpp:610] Iteration 53560, lr = 7.55382e-09
I0315 16:44:01.514772 29479 solver.cpp:613] Iteration 53560, avg_grad_norm = 595688
I0315 16:44:55.934664 29479 solver.cpp:214] Iteration 53580, loss = 5869.83
I0315 16:44:55.934856 29479 solver.cpp:229]     Train net output #0: loss = 2944.9 (* 1 = 2944.9 loss)
I0315 16:44:56.046533 29479 solver.cpp:610] Iteration 53580, lr = 7.55289e-09
I0315 16:44:56.046546 29479 solver.cpp:613] Iteration 53580, avg_grad_norm = 628449
I0315 16:46:08.473307 29479 solver.cpp:214] Iteration 53600, loss = 6014.15
I0315 16:46:08.473459 29479 solver.cpp:229]     Train net output #0: loss = 5810.96 (* 1 = 5810.96 loss)
I0315 16:46:08.838368 29479 solver.cpp:610] Iteration 53600, lr = 7.55197e-09
I0315 16:46:08.838382 29479 solver.cpp:613] Iteration 53600, avg_grad_norm = 547984
I0315 16:47:12.553742 29479 solver.cpp:214] Iteration 53620, loss = 5884.2
I0315 16:47:12.553879 29479 solver.cpp:229]     Train net output #0: loss = 5997.84 (* 1 = 5997.84 loss)
I0315 16:47:12.911908 29479 solver.cpp:610] Iteration 53620, lr = 7.55104e-09
I0315 16:47:12.911921 29479 solver.cpp:613] Iteration 53620, avg_grad_norm = 499140
I0315 16:48:17.578424 29479 solver.cpp:214] Iteration 53640, loss = 5839.55
I0315 16:48:17.578627 29479 solver.cpp:229]     Train net output #0: loss = 4974.68 (* 1 = 4974.68 loss)
I0315 16:48:17.939473 29479 solver.cpp:610] Iteration 53640, lr = 7.55011e-09
I0315 16:48:17.939529 29479 solver.cpp:613] Iteration 53640, avg_grad_norm = 555625
I0315 16:49:26.162735 29479 solver.cpp:214] Iteration 53660, loss = 6062.04
I0315 16:49:26.162936 29479 solver.cpp:229]     Train net output #0: loss = 4619.88 (* 1 = 4619.88 loss)
I0315 16:49:26.528478 29479 solver.cpp:610] Iteration 53660, lr = 7.54918e-09
I0315 16:49:26.528491 29479 solver.cpp:613] Iteration 53660, avg_grad_norm = 499775
I0315 16:50:30.267117 29479 solver.cpp:214] Iteration 53680, loss = 6136.47
I0315 16:50:30.267333 29479 solver.cpp:229]     Train net output #0: loss = 8339.2 (* 1 = 8339.2 loss)
I0315 16:50:30.636452 29479 solver.cpp:610] Iteration 53680, lr = 7.54825e-09
I0315 16:50:30.636466 29479 solver.cpp:613] Iteration 53680, avg_grad_norm = 535913
I0315 16:51:34.629150 29479 solver.cpp:214] Iteration 53700, loss = 6231.38
I0315 16:51:34.629374 29479 solver.cpp:229]     Train net output #0: loss = 7817.32 (* 1 = 7817.32 loss)
I0315 16:51:34.993193 29479 solver.cpp:610] Iteration 53700, lr = 7.54732e-09
I0315 16:51:34.993218 29479 solver.cpp:613] Iteration 53700, avg_grad_norm = 598555
I0315 16:53:05.251456 29479 solver.cpp:214] Iteration 53720, loss = 6131.32
I0315 16:53:05.251590 29479 solver.cpp:229]     Train net output #0: loss = 10507.9 (* 1 = 10507.9 loss)
I0315 16:53:05.356745 29479 solver.cpp:610] Iteration 53720, lr = 7.54639e-09
I0315 16:53:05.356758 29479 solver.cpp:613] Iteration 53720, avg_grad_norm = 581863
I0315 16:54:06.991355 29479 solver.cpp:214] Iteration 53740, loss = 6141.68
I0315 16:54:06.991504 29479 solver.cpp:229]     Train net output #0: loss = 4910.45 (* 1 = 4910.45 loss)
I0315 16:54:07.348472 29479 solver.cpp:610] Iteration 53740, lr = 7.54546e-09
I0315 16:54:07.348487 29479 solver.cpp:613] Iteration 53740, avg_grad_norm = 558051
I0315 16:55:15.131552 29479 solver.cpp:214] Iteration 53760, loss = 5981.3
I0315 16:55:15.131690 29479 solver.cpp:229]     Train net output #0: loss = 6633 (* 1 = 6633 loss)
I0315 16:55:15.491076 29479 solver.cpp:610] Iteration 53760, lr = 7.54454e-09
I0315 16:55:15.491091 29479 solver.cpp:613] Iteration 53760, avg_grad_norm = 561891
I0315 16:56:22.871011 29479 solver.cpp:214] Iteration 53780, loss = 6108.74
I0315 16:56:22.871213 29479 solver.cpp:229]     Train net output #0: loss = 4270.8 (* 1 = 4270.8 loss)
I0315 16:56:23.225791 29479 solver.cpp:610] Iteration 53780, lr = 7.54361e-09
I0315 16:56:23.225806 29479 solver.cpp:613] Iteration 53780, avg_grad_norm = 581624
I0315 16:57:30.897528 29479 solver.cpp:214] Iteration 53800, loss = 5904.38
I0315 16:57:30.897660 29479 solver.cpp:229]     Train net output #0: loss = 5070.8 (* 1 = 5070.8 loss)
I0315 16:57:31.259436 29479 solver.cpp:610] Iteration 53800, lr = 7.54268e-09
I0315 16:57:31.259449 29479 solver.cpp:613] Iteration 53800, avg_grad_norm = 511306
I0315 16:58:35.747448 29479 solver.cpp:214] Iteration 53820, loss = 6136.9
I0315 16:58:35.747704 29479 solver.cpp:229]     Train net output #0: loss = 9498.4 (* 1 = 9498.4 loss)
I0315 16:58:35.946455 29479 solver.cpp:610] Iteration 53820, lr = 7.54175e-09
I0315 16:58:35.946468 29479 solver.cpp:613] Iteration 53820, avg_grad_norm = 503964
I0315 16:59:40.230990 29479 solver.cpp:214] Iteration 53840, loss = 5902.53
I0315 16:59:40.231133 29479 solver.cpp:229]     Train net output #0: loss = 10036.1 (* 1 = 10036.1 loss)
I0315 16:59:40.424862 29479 solver.cpp:610] Iteration 53840, lr = 7.54082e-09
I0315 16:59:40.424877 29479 solver.cpp:613] Iteration 53840, avg_grad_norm = 485550
I0315 17:00:37.317287 29479 solver.cpp:214] Iteration 53860, loss = 6399.24
I0315 17:00:37.317414 29479 solver.cpp:229]     Train net output #0: loss = 6029.99 (* 1 = 6029.99 loss)
I0315 17:00:37.428916 29479 solver.cpp:610] Iteration 53860, lr = 7.53989e-09
I0315 17:00:37.428930 29479 solver.cpp:613] Iteration 53860, avg_grad_norm = 571339
I0315 17:01:29.130652 29479 solver.cpp:214] Iteration 53880, loss = 6039.75
I0315 17:01:29.130802 29479 solver.cpp:229]     Train net output #0: loss = 9596.57 (* 1 = 9596.57 loss)
I0315 17:01:29.344738 29479 solver.cpp:610] Iteration 53880, lr = 7.53896e-09
I0315 17:01:29.344751 29479 solver.cpp:613] Iteration 53880, avg_grad_norm = 606237
I0315 17:02:33.024972 29479 solver.cpp:214] Iteration 53900, loss = 5756.58
I0315 17:02:33.025127 29479 solver.cpp:229]     Train net output #0: loss = 6466.37 (* 1 = 6466.37 loss)
I0315 17:02:33.227267 29479 solver.cpp:610] Iteration 53900, lr = 7.53804e-09
I0315 17:02:33.227280 29479 solver.cpp:613] Iteration 53900, avg_grad_norm = 534690
I0315 17:03:36.678398 29479 solver.cpp:214] Iteration 53920, loss = 5972.73
I0315 17:03:36.678508 29479 solver.cpp:229]     Train net output #0: loss = 3237.27 (* 1 = 3237.27 loss)
I0315 17:03:37.040139 29479 solver.cpp:610] Iteration 53920, lr = 7.53711e-09
I0315 17:03:37.040153 29479 solver.cpp:613] Iteration 53920, avg_grad_norm = 558206
I0315 17:04:40.682878 29479 solver.cpp:214] Iteration 53940, loss = 5895.41
I0315 17:04:40.683019 29479 solver.cpp:229]     Train net output #0: loss = 3560.13 (* 1 = 3560.13 loss)
I0315 17:04:41.040304 29479 solver.cpp:610] Iteration 53940, lr = 7.53618e-09
I0315 17:04:41.040331 29479 solver.cpp:613] Iteration 53940, avg_grad_norm = 561841
I0315 17:05:45.019067 29479 solver.cpp:214] Iteration 53960, loss = 5974.5
I0315 17:05:45.019222 29479 solver.cpp:229]     Train net output #0: loss = 4191.22 (* 1 = 4191.22 loss)
I0315 17:05:45.214759 29479 solver.cpp:610] Iteration 53960, lr = 7.53525e-09
I0315 17:05:45.214787 29479 solver.cpp:613] Iteration 53960, avg_grad_norm = 549380
I0315 17:07:02.652619 29479 solver.cpp:214] Iteration 53980, loss = 6018.96
I0315 17:07:02.652740 29479 solver.cpp:229]     Train net output #0: loss = 12034.6 (* 1 = 12034.6 loss)
I0315 17:07:02.864971 29479 solver.cpp:610] Iteration 53980, lr = 7.53432e-09
I0315 17:07:02.864984 29479 solver.cpp:613] Iteration 53980, avg_grad_norm = 502223
I0315 17:08:06.581970 29479 solver.cpp:214] Iteration 54000, loss = 6184.09
I0315 17:08:06.582116 29479 solver.cpp:229]     Train net output #0: loss = 9434.99 (* 1 = 9434.99 loss)
I0315 17:08:06.947386 29479 solver.cpp:610] Iteration 54000, lr = 7.53339e-09
I0315 17:08:06.947398 29479 solver.cpp:613] Iteration 54000, avg_grad_norm = 517620
I0315 17:08:46.583843 29479 solver.cpp:214] Iteration 54020, loss = 6086.25
I0315 17:08:46.584005 29479 solver.cpp:229]     Train net output #0: loss = 5138.84 (* 1 = 5138.84 loss)
I0315 17:08:46.950892 29479 solver.cpp:610] Iteration 54020, lr = 7.53246e-09
I0315 17:08:46.950906 29479 solver.cpp:613] Iteration 54020, avg_grad_norm = 484217
I0315 17:09:50.781982 29479 solver.cpp:214] Iteration 54040, loss = 6305.53
I0315 17:09:50.782111 29479 solver.cpp:229]     Train net output #0: loss = 4596.13 (* 1 = 4596.13 loss)
I0315 17:09:50.984429 29479 solver.cpp:610] Iteration 54040, lr = 7.53153e-09
I0315 17:09:50.984472 29479 solver.cpp:613] Iteration 54040, avg_grad_norm = 561089
I0315 17:11:00.122885 29479 solver.cpp:214] Iteration 54060, loss = 5959.01
I0315 17:11:00.123121 29479 solver.cpp:229]     Train net output #0: loss = 6351.07 (* 1 = 6351.07 loss)
I0315 17:11:00.481935 29479 solver.cpp:610] Iteration 54060, lr = 7.53061e-09
I0315 17:11:00.481950 29479 solver.cpp:613] Iteration 54060, avg_grad_norm = 525980
I0315 17:12:09.472435 29479 solver.cpp:214] Iteration 54080, loss = 6124.33
I0315 17:12:09.472643 29479 solver.cpp:229]     Train net output #0: loss = 3694.76 (* 1 = 3694.76 loss)
I0315 17:12:09.831739 29479 solver.cpp:610] Iteration 54080, lr = 7.52968e-09
I0315 17:12:09.831755 29479 solver.cpp:613] Iteration 54080, avg_grad_norm = 547443
I0315 17:13:31.789404 29479 solver.cpp:214] Iteration 54100, loss = 5998.57
I0315 17:13:31.789531 29479 solver.cpp:229]     Train net output #0: loss = 5050.84 (* 1 = 5050.84 loss)
I0315 17:13:32.103572 29479 solver.cpp:610] Iteration 54100, lr = 7.52875e-09
I0315 17:13:32.103587 29479 solver.cpp:613] Iteration 54100, avg_grad_norm = 542322
I0315 17:14:39.863652 29479 solver.cpp:214] Iteration 54120, loss = 5922.11
I0315 17:14:39.863771 29479 solver.cpp:229]     Train net output #0: loss = 8424 (* 1 = 8424 loss)
I0315 17:14:40.233345 29479 solver.cpp:610] Iteration 54120, lr = 7.52782e-09
I0315 17:14:40.233358 29479 solver.cpp:613] Iteration 54120, avg_grad_norm = 517252
I0315 17:15:48.122504 29479 solver.cpp:214] Iteration 54140, loss = 5871
I0315 17:15:48.122705 29479 solver.cpp:229]     Train net output #0: loss = 5120.05 (* 1 = 5120.05 loss)
I0315 17:15:48.486001 29479 solver.cpp:610] Iteration 54140, lr = 7.52689e-09
I0315 17:15:48.486014 29479 solver.cpp:613] Iteration 54140, avg_grad_norm = 568512
I0315 17:16:20.339066 29479 solver.cpp:214] Iteration 54160, loss = 5859.76
I0315 17:16:20.339190 29479 solver.cpp:229]     Train net output #0: loss = 4263.5 (* 1 = 4263.5 loss)
I0315 17:16:20.455334 29479 solver.cpp:610] Iteration 54160, lr = 7.52596e-09
I0315 17:16:20.455348 29479 solver.cpp:613] Iteration 54160, avg_grad_norm = 522526
I0315 17:17:06.746111 29479 solver.cpp:214] Iteration 54180, loss = 5605.4
I0315 17:17:06.746289 29479 solver.cpp:229]     Train net output #0: loss = 8456.74 (* 1 = 8456.74 loss)
I0315 17:17:07.115154 29479 solver.cpp:610] Iteration 54180, lr = 7.52503e-09
I0315 17:17:07.115169 29479 solver.cpp:613] Iteration 54180, avg_grad_norm = 503027
I0315 17:18:16.162961 29479 solver.cpp:214] Iteration 54200, loss = 5999.63
I0315 17:18:16.163110 29479 solver.cpp:229]     Train net output #0: loss = 10409.8 (* 1 = 10409.8 loss)
I0315 17:18:16.524070 29479 solver.cpp:610] Iteration 54200, lr = 7.5241e-09
I0315 17:18:16.524083 29479 solver.cpp:613] Iteration 54200, avg_grad_norm = 596890
I0315 17:19:26.003504 29479 solver.cpp:214] Iteration 54220, loss = 6046.91
I0315 17:19:26.003639 29479 solver.cpp:229]     Train net output #0: loss = 9319.71 (* 1 = 9319.71 loss)
I0315 17:19:26.367560 29479 solver.cpp:610] Iteration 54220, lr = 7.52317e-09
I0315 17:19:26.367574 29479 solver.cpp:613] Iteration 54220, avg_grad_norm = 518943
I0315 17:20:55.546360 29479 solver.cpp:214] Iteration 54240, loss = 6047.18
I0315 17:20:55.546547 29479 solver.cpp:229]     Train net output #0: loss = 3006.28 (* 1 = 3006.28 loss)
I0315 17:20:55.906882 29479 solver.cpp:610] Iteration 54240, lr = 7.52225e-09
I0315 17:20:55.906895 29479 solver.cpp:613] Iteration 54240, avg_grad_norm = 602780
I0315 17:22:04.337834 29479 solver.cpp:214] Iteration 54260, loss = 6146.39
I0315 17:22:04.337972 29479 solver.cpp:229]     Train net output #0: loss = 5142.67 (* 1 = 5142.67 loss)
I0315 17:22:04.699004 29479 solver.cpp:610] Iteration 54260, lr = 7.52132e-09
I0315 17:22:04.699018 29479 solver.cpp:613] Iteration 54260, avg_grad_norm = 551718
I0315 17:23:12.873052 29479 solver.cpp:214] Iteration 54280, loss = 5997.31
I0315 17:23:12.873317 29479 solver.cpp:229]     Train net output #0: loss = 6043.82 (* 1 = 6043.82 loss)
I0315 17:23:13.249969 29479 solver.cpp:610] Iteration 54280, lr = 7.52039e-09
I0315 17:23:13.249984 29479 solver.cpp:613] Iteration 54280, avg_grad_norm = 517980
I0315 17:24:00.368559 29479 solver.cpp:214] Iteration 54300, loss = 6043.34
I0315 17:24:00.368772 29479 solver.cpp:229]     Train net output #0: loss = 5949.81 (* 1 = 5949.81 loss)
I0315 17:24:00.484673 29479 solver.cpp:610] Iteration 54300, lr = 7.51946e-09
I0315 17:24:00.484688 29479 solver.cpp:613] Iteration 54300, avg_grad_norm = 540607
I0315 17:25:06.866546 29479 solver.cpp:214] Iteration 54320, loss = 6026
I0315 17:25:06.866714 29479 solver.cpp:229]     Train net output #0: loss = 8223.67 (* 1 = 8223.67 loss)
I0315 17:25:07.226601 29479 solver.cpp:610] Iteration 54320, lr = 7.51853e-09
I0315 17:25:07.226616 29479 solver.cpp:613] Iteration 54320, avg_grad_norm = 509093
I0315 17:26:16.143405 29479 solver.cpp:214] Iteration 54340, loss = 6109.47
I0315 17:26:16.143554 29479 solver.cpp:229]     Train net output #0: loss = 4600.46 (* 1 = 4600.46 loss)
I0315 17:26:16.505869 29479 solver.cpp:610] Iteration 54340, lr = 7.5176e-09
I0315 17:26:16.505884 29479 solver.cpp:613] Iteration 54340, avg_grad_norm = 533790
I0315 17:27:46.153317 29479 solver.cpp:214] Iteration 54360, loss = 5891.7
I0315 17:27:46.153458 29479 solver.cpp:229]     Train net output #0: loss = 4949.14 (* 1 = 4949.14 loss)
I0315 17:27:46.544433 29479 solver.cpp:610] Iteration 54360, lr = 7.51667e-09
I0315 17:27:46.544446 29479 solver.cpp:613] Iteration 54360, avg_grad_norm = 507897
I0315 17:28:54.508589 29479 solver.cpp:214] Iteration 54380, loss = 5956.9
I0315 17:28:54.508765 29479 solver.cpp:229]     Train net output #0: loss = 7638.31 (* 1 = 7638.31 loss)
I0315 17:28:54.884001 29479 solver.cpp:610] Iteration 54380, lr = 7.51574e-09
I0315 17:28:54.884014 29479 solver.cpp:613] Iteration 54380, avg_grad_norm = 591392
I0315 17:30:02.303010 29479 solver.cpp:214] Iteration 54400, loss = 6088.77
I0315 17:30:02.303136 29479 solver.cpp:229]     Train net output #0: loss = 4848.55 (* 1 = 4848.55 loss)
I0315 17:30:02.680078 29479 solver.cpp:610] Iteration 54400, lr = 7.51481e-09
I0315 17:30:02.680093 29479 solver.cpp:613] Iteration 54400, avg_grad_norm = 519358
I0315 17:31:05.240043 29479 solver.cpp:214] Iteration 54420, loss = 6186.27
I0315 17:31:05.240247 29479 solver.cpp:229]     Train net output #0: loss = 5935.01 (* 1 = 5935.01 loss)
I0315 17:31:05.425943 29479 solver.cpp:610] Iteration 54420, lr = 7.51389e-09
I0315 17:31:05.425957 29479 solver.cpp:613] Iteration 54420, avg_grad_norm = 545687
I0315 17:31:39.871323 29479 solver.cpp:214] Iteration 54440, loss = 5982.48
I0315 17:31:39.871453 29479 solver.cpp:229]     Train net output #0: loss = 2914.99 (* 1 = 2914.99 loss)
I0315 17:31:39.989460 29479 solver.cpp:610] Iteration 54440, lr = 7.51296e-09
I0315 17:31:39.989475 29479 solver.cpp:613] Iteration 54440, avg_grad_norm = 513085
I0315 17:32:45.267436 29479 solver.cpp:214] Iteration 54460, loss = 5724.49
I0315 17:32:45.267642 29479 solver.cpp:229]     Train net output #0: loss = 7413.62 (* 1 = 7413.62 loss)
I0315 17:32:45.630417 29479 solver.cpp:610] Iteration 54460, lr = 7.51203e-09
I0315 17:32:45.630430 29479 solver.cpp:613] Iteration 54460, avg_grad_norm = 459713
I0315 17:34:13.294332 29479 solver.cpp:214] Iteration 54480, loss = 5620.08
I0315 17:34:13.294476 29479 solver.cpp:229]     Train net output #0: loss = 4750.94 (* 1 = 4750.94 loss)
I0315 17:34:13.647730 29479 solver.cpp:610] Iteration 54480, lr = 7.5111e-09
I0315 17:34:13.647743 29479 solver.cpp:613] Iteration 54480, avg_grad_norm = 462464
I0315 17:35:20.937789 29479 solver.cpp:214] Iteration 54500, loss = 5801.52
I0315 17:35:20.937945 29479 solver.cpp:229]     Train net output #0: loss = 7695.28 (* 1 = 7695.28 loss)
I0315 17:35:21.306870 29479 solver.cpp:610] Iteration 54500, lr = 7.51017e-09
I0315 17:35:21.306885 29479 solver.cpp:613] Iteration 54500, avg_grad_norm = 474588
I0315 17:36:29.503754 29479 solver.cpp:214] Iteration 54520, loss = 5913.1
I0315 17:36:29.503890 29479 solver.cpp:229]     Train net output #0: loss = 5282.56 (* 1 = 5282.56 loss)
I0315 17:36:29.863744 29479 solver.cpp:610] Iteration 54520, lr = 7.50924e-09
I0315 17:36:29.863757 29479 solver.cpp:613] Iteration 54520, avg_grad_norm = 554012
I0315 17:37:37.400658 29479 solver.cpp:214] Iteration 54540, loss = 5830.71
I0315 17:37:37.400871 29479 solver.cpp:229]     Train net output #0: loss = 6872.99 (* 1 = 6872.99 loss)
I0315 17:37:37.772014 29479 solver.cpp:610] Iteration 54540, lr = 7.50831e-09
I0315 17:37:37.772027 29479 solver.cpp:613] Iteration 54540, avg_grad_norm = 574885
I0315 17:38:45.759332 29479 solver.cpp:214] Iteration 54560, loss = 5807.36
I0315 17:38:45.759475 29479 solver.cpp:229]     Train net output #0: loss = 7585.08 (* 1 = 7585.08 loss)
I0315 17:38:46.120128 29479 solver.cpp:610] Iteration 54560, lr = 7.50738e-09
I0315 17:38:46.120141 29479 solver.cpp:613] Iteration 54560, avg_grad_norm = 552239
I0315 17:39:30.926048 29479 solver.cpp:214] Iteration 54580, loss = 5857.85
I0315 17:39:30.926254 29479 solver.cpp:229]     Train net output #0: loss = 6191.69 (* 1 = 6191.69 loss)
I0315 17:39:31.286186 29479 solver.cpp:610] Iteration 54580, lr = 7.50645e-09
I0315 17:39:31.286200 29479 solver.cpp:613] Iteration 54580, avg_grad_norm = 520224
I0315 17:40:39.679762 29479 solver.cpp:214] Iteration 54600, loss = 5764.69
I0315 17:40:39.679973 29479 solver.cpp:229]     Train net output #0: loss = 5265.57 (* 1 = 5265.57 loss)
I0315 17:40:40.040555 29479 solver.cpp:610] Iteration 54600, lr = 7.50552e-09
I0315 17:40:40.040568 29479 solver.cpp:613] Iteration 54600, avg_grad_norm = 509247
I0315 17:42:01.245915 29479 solver.cpp:214] Iteration 54620, loss = 6010.22
I0315 17:42:01.246078 29479 solver.cpp:229]     Train net output #0: loss = 3825.77 (* 1 = 3825.77 loss)
I0315 17:42:01.625984 29479 solver.cpp:610] Iteration 54620, lr = 7.50459e-09
I0315 17:42:01.625998 29479 solver.cpp:613] Iteration 54620, avg_grad_norm = 515186
I0315 17:43:09.834252 29479 solver.cpp:214] Iteration 54640, loss = 5947.92
I0315 17:43:09.834446 29479 solver.cpp:229]     Train net output #0: loss = 8407.95 (* 1 = 8407.95 loss)
I0315 17:43:10.194730 29479 solver.cpp:610] Iteration 54640, lr = 7.50366e-09
I0315 17:43:10.194744 29479 solver.cpp:613] Iteration 54640, avg_grad_norm = 543268
I0315 17:44:18.350792 29479 solver.cpp:214] Iteration 54660, loss = 5785.35
I0315 17:44:18.350935 29479 solver.cpp:229]     Train net output #0: loss = 4150.95 (* 1 = 4150.95 loss)
I0315 17:44:18.720847 29479 solver.cpp:610] Iteration 54660, lr = 7.50274e-09
I0315 17:44:18.720896 29479 solver.cpp:613] Iteration 54660, avg_grad_norm = 588989
I0315 17:45:27.621160 29479 solver.cpp:214] Iteration 54680, loss = 6089.23
I0315 17:45:27.621403 29479 solver.cpp:229]     Train net output #0: loss = 4558.75 (* 1 = 4558.75 loss)
I0315 17:45:28.010586 29479 solver.cpp:610] Iteration 54680, lr = 7.50181e-09
I0315 17:45:28.010601 29479 solver.cpp:613] Iteration 54680, avg_grad_norm = 593623
I0315 17:46:32.677374 29479 solver.cpp:214] Iteration 54700, loss = 5631.35
I0315 17:46:32.677611 29479 solver.cpp:229]     Train net output #0: loss = 5746.17 (* 1 = 5746.17 loss)
I0315 17:46:32.782655 29479 solver.cpp:610] Iteration 54700, lr = 7.50088e-09
I0315 17:46:32.782667 29479 solver.cpp:613] Iteration 54700, avg_grad_norm = 521030
I0315 17:47:12.865206 29479 solver.cpp:214] Iteration 54720, loss = 5872.28
I0315 17:47:12.865418 29479 solver.cpp:229]     Train net output #0: loss = 5699.33 (* 1 = 5699.33 loss)
I0315 17:47:13.230039 29479 solver.cpp:610] Iteration 54720, lr = 7.49995e-09
I0315 17:47:13.230052 29479 solver.cpp:613] Iteration 54720, avg_grad_norm = 512836
I0315 17:48:43.759274 29479 solver.cpp:214] Iteration 54740, loss = 5807.72
I0315 17:48:43.759459 29479 solver.cpp:229]     Train net output #0: loss = 7404.03 (* 1 = 7404.03 loss)
I0315 17:48:43.943586 29479 solver.cpp:610] Iteration 54740, lr = 7.49902e-09
I0315 17:48:43.943600 29479 solver.cpp:613] Iteration 54740, avg_grad_norm = 575346
I0315 17:49:52.442368 29479 solver.cpp:214] Iteration 54760, loss = 5873.64
I0315 17:49:52.442582 29479 solver.cpp:229]     Train net output #0: loss = 5005.07 (* 1 = 5005.07 loss)
I0315 17:49:52.808743 29479 solver.cpp:610] Iteration 54760, lr = 7.49809e-09
I0315 17:49:52.808766 29479 solver.cpp:613] Iteration 54760, avg_grad_norm = 524864
I0315 17:51:01.086007 29479 solver.cpp:214] Iteration 54780, loss = 6234.34
I0315 17:51:01.086189 29479 solver.cpp:229]     Train net output #0: loss = 4625.66 (* 1 = 4625.66 loss)
I0315 17:51:01.453971 29479 solver.cpp:610] Iteration 54780, lr = 7.49716e-09
I0315 17:51:01.453984 29479 solver.cpp:613] Iteration 54780, avg_grad_norm = 514142
I0315 17:52:10.480026 29479 solver.cpp:214] Iteration 54800, loss = 5841.38
I0315 17:52:10.480147 29479 solver.cpp:229]     Train net output #0: loss = 4438.42 (* 1 = 4438.42 loss)
I0315 17:52:10.843173 29479 solver.cpp:610] Iteration 54800, lr = 7.49623e-09
I0315 17:52:10.843186 29479 solver.cpp:613] Iteration 54800, avg_grad_norm = 502329
I0315 17:53:17.255115 29479 solver.cpp:214] Iteration 54820, loss = 5781.13
I0315 17:53:17.255269 29479 solver.cpp:229]     Train net output #0: loss = 5713.51 (* 1 = 5713.51 loss)
I0315 17:53:17.618939 29479 solver.cpp:610] Iteration 54820, lr = 7.4953e-09
I0315 17:53:17.618953 29479 solver.cpp:613] Iteration 54820, avg_grad_norm = 518883
I0315 17:54:12.297118 29479 solver.cpp:214] Iteration 54840, loss = 6299.49
I0315 17:54:12.297284 29479 solver.cpp:229]     Train net output #0: loss = 10777.6 (* 1 = 10777.6 loss)
I0315 17:54:12.411792 29479 solver.cpp:610] Iteration 54840, lr = 7.49437e-09
I0315 17:54:12.411805 29479 solver.cpp:613] Iteration 54840, avg_grad_norm = 651198
I0315 17:55:09.978047 29479 solver.cpp:214] Iteration 54860, loss = 6028.21
I0315 17:55:09.978179 29479 solver.cpp:229]     Train net output #0: loss = 10356.1 (* 1 = 10356.1 loss)
I0315 17:55:10.338351 29479 solver.cpp:610] Iteration 54860, lr = 7.49344e-09
I0315 17:55:10.338366 29479 solver.cpp:613] Iteration 54860, avg_grad_norm = 644823
I0315 17:56:29.102788 29479 solver.cpp:214] Iteration 54880, loss = 5948.33
I0315 17:56:29.102911 29479 solver.cpp:229]     Train net output #0: loss = 2524.72 (* 1 = 2524.72 loss)
I0315 17:56:29.466325 29479 solver.cpp:610] Iteration 54880, lr = 7.49251e-09
I0315 17:56:29.466338 29479 solver.cpp:613] Iteration 54880, avg_grad_norm = 604117
I0315 17:57:37.256438 29479 solver.cpp:214] Iteration 54900, loss = 5880.97
I0315 17:57:37.256574 29479 solver.cpp:229]     Train net output #0: loss = 5082.4 (* 1 = 5082.4 loss)
I0315 17:57:37.616816 29479 solver.cpp:610] Iteration 54900, lr = 7.49158e-09
I0315 17:57:37.616829 29479 solver.cpp:613] Iteration 54900, avg_grad_norm = 533962
I0315 17:58:44.328297 29479 solver.cpp:214] Iteration 54920, loss = 5870.3
I0315 17:58:44.328423 29479 solver.cpp:229]     Train net output #0: loss = 4815.3 (* 1 = 4815.3 loss)
I0315 17:58:44.701627 29479 solver.cpp:610] Iteration 54920, lr = 7.49065e-09
I0315 17:58:44.701642 29479 solver.cpp:613] Iteration 54920, avg_grad_norm = 546935
I0315 17:59:52.512030 29479 solver.cpp:214] Iteration 54940, loss = 6154.11
I0315 17:59:52.512143 29479 solver.cpp:229]     Train net output #0: loss = 3859.28 (* 1 = 3859.28 loss)
I0315 17:59:52.874961 29479 solver.cpp:610] Iteration 54940, lr = 7.48973e-09
I0315 17:59:52.874974 29479 solver.cpp:613] Iteration 54940, avg_grad_norm = 508321
I0315 18:01:01.547760 29479 solver.cpp:214] Iteration 54960, loss = 5795.09
I0315 18:01:01.547950 29479 solver.cpp:229]     Train net output #0: loss = 5498.31 (* 1 = 5498.31 loss)
I0315 18:01:01.912871 29479 solver.cpp:610] Iteration 54960, lr = 7.4888e-09
I0315 18:01:01.912885 29479 solver.cpp:613] Iteration 54960, avg_grad_norm = 500710
I0315 18:01:52.141814 29479 solver.cpp:214] Iteration 54980, loss = 5947.22
I0315 18:01:52.141973 29479 solver.cpp:229]     Train net output #0: loss = 7066.39 (* 1 = 7066.39 loss)
I0315 18:01:52.258030 29479 solver.cpp:610] Iteration 54980, lr = 7.48787e-09
I0315 18:01:52.258080 29479 solver.cpp:613] Iteration 54980, avg_grad_norm = 511866
I0315 18:03:17.032723 29479 solver.cpp:214] Iteration 55000, loss = 6074.54
I0315 18:03:17.032912 29479 solver.cpp:229]     Train net output #0: loss = 5056.49 (* 1 = 5056.49 loss)
I0315 18:03:17.387629 29479 solver.cpp:610] Iteration 55000, lr = 7.48694e-09
I0315 18:03:17.387644 29479 solver.cpp:613] Iteration 55000, avg_grad_norm = 544034
I0315 18:04:25.184937 29479 solver.cpp:214] Iteration 55020, loss = 5938.19
I0315 18:04:25.185171 29479 solver.cpp:229]     Train net output #0: loss = 6340.28 (* 1 = 6340.28 loss)
I0315 18:04:25.548043 29479 solver.cpp:610] Iteration 55020, lr = 7.48601e-09
I0315 18:04:25.548056 29479 solver.cpp:613] Iteration 55020, avg_grad_norm = 518549
I0315 18:05:33.691382 29479 solver.cpp:214] Iteration 55040, loss = 6103.39
I0315 18:05:33.691589 29479 solver.cpp:229]     Train net output #0: loss = 5081.24 (* 1 = 5081.24 loss)
I0315 18:05:34.052117 29479 solver.cpp:610] Iteration 55040, lr = 7.48508e-09
I0315 18:05:34.052135 29479 solver.cpp:613] Iteration 55040, avg_grad_norm = 511392
I0315 18:06:41.912425 29479 solver.cpp:214] Iteration 55060, loss = 6341.23
I0315 18:06:41.912540 29479 solver.cpp:229]     Train net output #0: loss = 6777.3 (* 1 = 6777.3 loss)
I0315 18:06:42.299440 29479 solver.cpp:610] Iteration 55060, lr = 7.48415e-09
I0315 18:06:42.299454 29479 solver.cpp:613] Iteration 55060, avg_grad_norm = 493419
I0315 18:07:50.462401 29479 solver.cpp:214] Iteration 55080, loss = 5916.44
I0315 18:07:50.462532 29479 solver.cpp:229]     Train net output #0: loss = 3192.13 (* 1 = 3192.13 loss)
I0315 18:07:50.821635 29479 solver.cpp:610] Iteration 55080, lr = 7.48322e-09
I0315 18:07:50.821653 29479 solver.cpp:613] Iteration 55080, avg_grad_norm = 576797
I0315 18:09:00.055624 29479 solver.cpp:214] Iteration 55100, loss = 5998.85
I0315 18:09:00.055829 29479 solver.cpp:229]     Train net output #0: loss = 4002.64 (* 1 = 4002.64 loss)
I0315 18:09:00.422345 29479 solver.cpp:610] Iteration 55100, lr = 7.48229e-09
I0315 18:09:00.422359 29479 solver.cpp:613] Iteration 55100, avg_grad_norm = 549998
I0315 18:10:12.257968 29479 solver.cpp:214] Iteration 55120, loss = 6370.68
I0315 18:10:12.258110 29479 solver.cpp:229]     Train net output #0: loss = 9459.95 (* 1 = 9459.95 loss)
I0315 18:10:12.614985 29479 solver.cpp:610] Iteration 55120, lr = 7.48136e-09
I0315 18:10:12.614998 29479 solver.cpp:613] Iteration 55120, avg_grad_norm = 597025
I0315 18:11:20.798921 29479 solver.cpp:214] Iteration 55140, loss = 5599.38
I0315 18:11:20.799056 29479 solver.cpp:229]     Train net output #0: loss = 4518.14 (* 1 = 4518.14 loss)
I0315 18:11:21.161486 29479 solver.cpp:610] Iteration 55140, lr = 7.48043e-09
I0315 18:11:21.161500 29479 solver.cpp:613] Iteration 55140, avg_grad_norm = 521983
I0315 18:12:29.266434 29479 solver.cpp:214] Iteration 55160, loss = 5820.72
I0315 18:12:29.266563 29479 solver.cpp:229]     Train net output #0: loss = 4932.78 (* 1 = 4932.78 loss)
I0315 18:12:29.624562 29479 solver.cpp:610] Iteration 55160, lr = 7.4795e-09
I0315 18:12:29.624577 29479 solver.cpp:613] Iteration 55160, avg_grad_norm = 558678
I0315 18:13:37.453749 29479 solver.cpp:214] Iteration 55180, loss = 6052.96
I0315 18:13:37.453934 29479 solver.cpp:229]     Train net output #0: loss = 4149.48 (* 1 = 4149.48 loss)
I0315 18:13:37.815011 29479 solver.cpp:610] Iteration 55180, lr = 7.47857e-09
I0315 18:13:37.815026 29479 solver.cpp:613] Iteration 55180, avg_grad_norm = 561748
I0315 18:14:45.904356 29479 solver.cpp:214] Iteration 55200, loss = 6291.06
I0315 18:14:45.904503 29479 solver.cpp:229]     Train net output #0: loss = 4671.05 (* 1 = 4671.05 loss)
I0315 18:14:46.264837 29479 solver.cpp:610] Iteration 55200, lr = 7.47764e-09
I0315 18:14:46.264849 29479 solver.cpp:613] Iteration 55200, avg_grad_norm = 571522
I0315 18:15:55.011940 29479 solver.cpp:214] Iteration 55220, loss = 6151.94
I0315 18:15:55.012133 29479 solver.cpp:229]     Train net output #0: loss = 5417.63 (* 1 = 5417.63 loss)
I0315 18:15:55.378221 29479 solver.cpp:610] Iteration 55220, lr = 7.47671e-09
I0315 18:15:55.378233 29479 solver.cpp:613] Iteration 55220, avg_grad_norm = 513601
I0315 18:17:03.535101 29479 solver.cpp:214] Iteration 55240, loss = 5743.29
I0315 18:17:03.535361 29479 solver.cpp:229]     Train net output #0: loss = 4143.48 (* 1 = 4143.48 loss)
I0315 18:17:03.640363 29479 solver.cpp:610] Iteration 55240, lr = 7.47578e-09
I0315 18:17:03.640377 29479 solver.cpp:613] Iteration 55240, avg_grad_norm = 498320
I0315 18:19:31.249194 29479 solver.cpp:214] Iteration 55260, loss = 5769.81
I0315 18:19:31.249313 29479 solver.cpp:229]     Train net output #0: loss = 5321.16 (* 1 = 5321.16 loss)
I0315 18:19:31.605556 29479 solver.cpp:610] Iteration 55260, lr = 7.47485e-09
I0315 18:19:31.605567 29479 solver.cpp:613] Iteration 55260, avg_grad_norm = 565165
I0315 18:20:39.023586 29479 solver.cpp:214] Iteration 55280, loss = 5841.07
I0315 18:20:39.023702 29479 solver.cpp:229]     Train net output #0: loss = 3896.29 (* 1 = 3896.29 loss)
I0315 18:20:39.351825 29479 solver.cpp:610] Iteration 55280, lr = 7.47392e-09
I0315 18:20:39.351840 29479 solver.cpp:613] Iteration 55280, avg_grad_norm = 534101
I0315 18:21:45.803546 29479 solver.cpp:214] Iteration 55300, loss = 5841.62
I0315 18:21:45.803738 29479 solver.cpp:229]     Train net output #0: loss = 8907.38 (* 1 = 8907.38 loss)
I0315 18:21:46.140512 29479 solver.cpp:610] Iteration 55300, lr = 7.47299e-09
I0315 18:21:46.140527 29479 solver.cpp:613] Iteration 55300, avg_grad_norm = 576437
I0315 18:22:53.283977 29479 solver.cpp:214] Iteration 55320, loss = 6274.39
I0315 18:22:53.284137 29479 solver.cpp:229]     Train net output #0: loss = 12302.9 (* 1 = 12302.9 loss)
I0315 18:22:53.646445 29479 solver.cpp:610] Iteration 55320, lr = 7.47207e-09
I0315 18:22:53.646463 29479 solver.cpp:613] Iteration 55320, avg_grad_norm = 569958
I0315 18:23:57.999404 29479 solver.cpp:214] Iteration 55340, loss = 5837.03
I0315 18:23:57.999512 29479 solver.cpp:229]     Train net output #0: loss = 4362.66 (* 1 = 4362.66 loss)
I0315 18:23:58.359647 29479 solver.cpp:610] Iteration 55340, lr = 7.47114e-09
I0315 18:23:58.359661 29479 solver.cpp:613] Iteration 55340, avg_grad_norm = 515810
I0315 18:25:02.192677 29479 solver.cpp:214] Iteration 55360, loss = 6065.89
I0315 18:25:02.192864 29479 solver.cpp:229]     Train net output #0: loss = 5720.98 (* 1 = 5720.98 loss)
I0315 18:25:02.552788 29479 solver.cpp:610] Iteration 55360, lr = 7.47021e-09
I0315 18:25:02.552800 29479 solver.cpp:613] Iteration 55360, avg_grad_norm = 520254
I0315 18:26:08.051671 29479 solver.cpp:214] Iteration 55380, loss = 6089.59
I0315 18:26:08.051786 29479 solver.cpp:229]     Train net output #0: loss = 6819.9 (* 1 = 6819.9 loss)
I0315 18:26:08.409970 29479 solver.cpp:610] Iteration 55380, lr = 7.46928e-09
I0315 18:26:08.409983 29479 solver.cpp:613] Iteration 55380, avg_grad_norm = 521207
I0315 18:27:12.943212 29479 solver.cpp:214] Iteration 55400, loss = 5688.23
I0315 18:27:12.943425 29479 solver.cpp:229]     Train net output #0: loss = 3795.64 (* 1 = 3795.64 loss)
I0315 18:27:13.306445 29479 solver.cpp:610] Iteration 55400, lr = 7.46835e-09
I0315 18:27:13.306459 29479 solver.cpp:613] Iteration 55400, avg_grad_norm = 495272
I0315 18:28:21.081452 29479 solver.cpp:214] Iteration 55420, loss = 5991.53
I0315 18:28:21.081585 29479 solver.cpp:229]     Train net output #0: loss = 3692.65 (* 1 = 3692.65 loss)
I0315 18:28:21.438983 29479 solver.cpp:610] Iteration 55420, lr = 7.46742e-09
I0315 18:28:21.438997 29479 solver.cpp:613] Iteration 55420, avg_grad_norm = 499058
I0315 18:29:28.717774 29479 solver.cpp:214] Iteration 55440, loss = 6140.05
I0315 18:29:28.717912 29479 solver.cpp:229]     Train net output #0: loss = 4446.69 (* 1 = 4446.69 loss)
I0315 18:29:29.074739 29479 solver.cpp:610] Iteration 55440, lr = 7.46649e-09
I0315 18:29:29.074753 29479 solver.cpp:613] Iteration 55440, avg_grad_norm = 673629
I0315 18:30:37.151443 29479 solver.cpp:214] Iteration 55460, loss = 6100.38
I0315 18:30:37.151595 29479 solver.cpp:229]     Train net output #0: loss = 5381.31 (* 1 = 5381.31 loss)
I0315 18:30:37.511248 29479 solver.cpp:610] Iteration 55460, lr = 7.46556e-09
I0315 18:30:37.511267 29479 solver.cpp:613] Iteration 55460, avg_grad_norm = 556164
I0315 18:31:46.561358 29479 solver.cpp:214] Iteration 55480, loss = 5823.77
I0315 18:31:46.561543 29479 solver.cpp:229]     Train net output #0: loss = 5100.3 (* 1 = 5100.3 loss)
I0315 18:31:46.926882 29479 solver.cpp:610] Iteration 55480, lr = 7.46463e-09
I0315 18:31:46.926898 29479 solver.cpp:613] Iteration 55480, avg_grad_norm = 553055
I0315 18:33:53.937100 29479 solver.cpp:214] Iteration 55500, loss = 5847.26
I0315 18:33:53.937284 29479 solver.cpp:229]     Train net output #0: loss = 5035.44 (* 1 = 5035.44 loss)
I0315 18:33:54.042250 29479 solver.cpp:610] Iteration 55500, lr = 7.4637e-09
I0315 18:33:54.042274 29479 solver.cpp:613] Iteration 55500, avg_grad_norm = 558421
I0315 18:34:17.479979 29479 solver.cpp:214] Iteration 55520, loss = 6016.31
I0315 18:34:17.480036 29479 solver.cpp:229]     Train net output #0: loss = 8443.65 (* 1 = 8443.65 loss)
I0315 18:34:17.585387 29479 solver.cpp:610] Iteration 55520, lr = 7.46277e-09
I0315 18:34:17.585399 29479 solver.cpp:613] Iteration 55520, avg_grad_norm = 542889
I0315 18:35:22.561640 29479 solver.cpp:214] Iteration 55540, loss = 5694.05
I0315 18:35:22.561836 29479 solver.cpp:229]     Train net output #0: loss = 10706.7 (* 1 = 10706.7 loss)
I0315 18:35:22.919428 29479 solver.cpp:610] Iteration 55540, lr = 7.46184e-09
I0315 18:35:22.919442 29479 solver.cpp:613] Iteration 55540, avg_grad_norm = 508325
I0315 18:36:30.778147 29479 solver.cpp:214] Iteration 55560, loss = 5997.51
I0315 18:36:30.778265 29479 solver.cpp:229]     Train net output #0: loss = 5274.63 (* 1 = 5274.63 loss)
I0315 18:36:31.100955 29479 solver.cpp:610] Iteration 55560, lr = 7.46091e-09
I0315 18:36:31.100970 29479 solver.cpp:613] Iteration 55560, avg_grad_norm = 505828
I0315 18:37:37.658668 29479 solver.cpp:214] Iteration 55580, loss = 6151.68
I0315 18:37:37.658884 29479 solver.cpp:229]     Train net output #0: loss = 4405.66 (* 1 = 4405.66 loss)
I0315 18:37:37.991336 29479 solver.cpp:610] Iteration 55580, lr = 7.45998e-09
I0315 18:37:37.991351 29479 solver.cpp:613] Iteration 55580, avg_grad_norm = 539340
I0315 18:38:43.531718 29479 solver.cpp:214] Iteration 55600, loss = 5652.18
I0315 18:38:43.531872 29479 solver.cpp:229]     Train net output #0: loss = 6770.02 (* 1 = 6770.02 loss)
I0315 18:38:43.859345 29479 solver.cpp:610] Iteration 55600, lr = 7.45905e-09
I0315 18:38:43.859359 29479 solver.cpp:613] Iteration 55600, avg_grad_norm = 587281
I0315 18:39:50.023583 29479 solver.cpp:214] Iteration 55620, loss = 6098.41
I0315 18:39:50.023725 29479 solver.cpp:229]     Train net output #0: loss = 8020.13 (* 1 = 8020.13 loss)
I0315 18:39:50.380048 29479 solver.cpp:610] Iteration 55620, lr = 7.45812e-09
I0315 18:39:50.380061 29479 solver.cpp:613] Iteration 55620, avg_grad_norm = 540080
I0315 18:41:11.291366 29479 solver.cpp:214] Iteration 55640, loss = 6276.71
I0315 18:41:11.291508 29479 solver.cpp:229]     Train net output #0: loss = 6411.34 (* 1 = 6411.34 loss)
I0315 18:41:11.615190 29479 solver.cpp:610] Iteration 55640, lr = 7.45719e-09
I0315 18:41:11.615203 29479 solver.cpp:613] Iteration 55640, avg_grad_norm = 553713
I0315 18:41:50.012915 29479 solver.cpp:214] Iteration 55660, loss = 6024.03
I0315 18:41:50.013124 29479 solver.cpp:229]     Train net output #0: loss = 2992.16 (* 1 = 2992.16 loss)
I0315 18:41:50.127569 29479 solver.cpp:610] Iteration 55660, lr = 7.45626e-09
I0315 18:41:50.127588 29479 solver.cpp:613] Iteration 55660, avg_grad_norm = 515450
I0315 18:42:54.582377 29479 solver.cpp:214] Iteration 55680, loss = 6182.86
I0315 18:42:54.582530 29479 solver.cpp:229]     Train net output #0: loss = 5218.97 (* 1 = 5218.97 loss)
I0315 18:42:54.942595 29479 solver.cpp:610] Iteration 55680, lr = 7.45533e-09
I0315 18:42:54.942610 29479 solver.cpp:613] Iteration 55680, avg_grad_norm = 559852
I0315 18:44:03.465572 29479 solver.cpp:214] Iteration 55700, loss = 6169.28
I0315 18:44:03.465821 29479 solver.cpp:229]     Train net output #0: loss = 4965.09 (* 1 = 4965.09 loss)
I0315 18:44:03.831399 29479 solver.cpp:610] Iteration 55700, lr = 7.4544e-09
I0315 18:44:03.831413 29479 solver.cpp:613] Iteration 55700, avg_grad_norm = 566578
I0315 18:45:12.009768 29479 solver.cpp:214] Iteration 55720, loss = 5712.77
I0315 18:45:12.010049 29479 solver.cpp:229]     Train net output #0: loss = 11736.8 (* 1 = 11736.8 loss)
I0315 18:45:12.379240 29479 solver.cpp:610] Iteration 55720, lr = 7.45347e-09
I0315 18:45:12.379256 29479 solver.cpp:613] Iteration 55720, avg_grad_norm = 526044
I0315 18:46:20.993008 29479 solver.cpp:214] Iteration 55740, loss = 6169.52
I0315 18:46:20.993180 29479 solver.cpp:229]     Train net output #0: loss = 8377.83 (* 1 = 8377.83 loss)
I0315 18:46:21.351275 29479 solver.cpp:610] Iteration 55740, lr = 7.45254e-09
I0315 18:46:21.351289 29479 solver.cpp:613] Iteration 55740, avg_grad_norm = 523811
I0315 18:47:53.100194 29479 solver.cpp:214] Iteration 55760, loss = 5916.4
I0315 18:47:53.100412 29479 solver.cpp:229]     Train net output #0: loss = 11679.5 (* 1 = 11679.5 loss)
I0315 18:47:53.457835 29479 solver.cpp:610] Iteration 55760, lr = 7.45161e-09
I0315 18:47:53.457849 29479 solver.cpp:613] Iteration 55760, avg_grad_norm = 571248
I0315 18:49:00.912087 29479 solver.cpp:214] Iteration 55780, loss = 5903.66
I0315 18:49:00.912227 29479 solver.cpp:229]     Train net output #0: loss = 7694.13 (* 1 = 7694.13 loss)
I0315 18:49:01.276798 29479 solver.cpp:610] Iteration 55780, lr = 7.45068e-09
I0315 18:49:01.276813 29479 solver.cpp:613] Iteration 55780, avg_grad_norm = 556196
I0315 18:49:35.693686 29479 solver.cpp:214] Iteration 55800, loss = 6152.7
I0315 18:49:35.693850 29479 solver.cpp:229]     Train net output #0: loss = 12617.5 (* 1 = 12617.5 loss)
I0315 18:49:35.808328 29479 solver.cpp:610] Iteration 55800, lr = 7.44975e-09
I0315 18:49:35.808342 29479 solver.cpp:613] Iteration 55800, avg_grad_norm = 459541
I0315 18:50:24.027658 29479 solver.cpp:214] Iteration 55820, loss = 5995.72
I0315 18:50:24.027798 29479 solver.cpp:229]     Train net output #0: loss = 6743.98 (* 1 = 6743.98 loss)
I0315 18:50:24.396723 29479 solver.cpp:610] Iteration 55820, lr = 7.44882e-09
I0315 18:50:24.396741 29479 solver.cpp:613] Iteration 55820, avg_grad_norm = 523586
I0315 18:51:31.806594 29479 solver.cpp:214] Iteration 55840, loss = 5882.88
I0315 18:51:31.806740 29479 solver.cpp:229]     Train net output #0: loss = 3600.42 (* 1 = 3600.42 loss)
I0315 18:51:32.166388 29479 solver.cpp:610] Iteration 55840, lr = 7.44789e-09
I0315 18:51:32.166404 29479 solver.cpp:613] Iteration 55840, avg_grad_norm = 507318
I0315 18:52:41.325793 29479 solver.cpp:214] Iteration 55860, loss = 5715.82
I0315 18:52:41.325937 29479 solver.cpp:229]     Train net output #0: loss = 9548.93 (* 1 = 9548.93 loss)
I0315 18:52:41.685196 29479 solver.cpp:610] Iteration 55860, lr = 7.44696e-09
I0315 18:52:41.685210 29479 solver.cpp:613] Iteration 55860, avg_grad_norm = 561825
I0315 18:54:05.717283 29479 solver.cpp:214] Iteration 55880, loss = 5852.7
I0315 18:54:05.717422 29479 solver.cpp:229]     Train net output #0: loss = 5388.34 (* 1 = 5388.34 loss)
I0315 18:54:06.078023 29479 solver.cpp:610] Iteration 55880, lr = 7.44603e-09
I0315 18:54:06.078037 29479 solver.cpp:613] Iteration 55880, avg_grad_norm = 555427
I0315 18:55:14.222846 29479 solver.cpp:214] Iteration 55900, loss = 5829.83
I0315 18:55:14.222971 29479 solver.cpp:229]     Train net output #0: loss = 2844.41 (* 1 = 2844.41 loss)
I0315 18:55:14.582455 29479 solver.cpp:610] Iteration 55900, lr = 7.4451e-09
I0315 18:55:14.582469 29479 solver.cpp:613] Iteration 55900, avg_grad_norm = 559743
I0315 18:56:22.008188 29479 solver.cpp:214] Iteration 55920, loss = 5816.44
I0315 18:56:22.008357 29479 solver.cpp:229]     Train net output #0: loss = 6453.38 (* 1 = 6453.38 loss)
I0315 18:56:22.352777 29479 solver.cpp:610] Iteration 55920, lr = 7.44417e-09
I0315 18:56:22.352790 29479 solver.cpp:613] Iteration 55920, avg_grad_norm = 501574
I0315 18:57:13.952839 29479 solver.cpp:214] Iteration 55940, loss = 5875.51
I0315 18:57:13.952991 29479 solver.cpp:229]     Train net output #0: loss = 3396.99 (* 1 = 3396.99 loss)
I0315 18:57:14.067562 29479 solver.cpp:610] Iteration 55940, lr = 7.44324e-09
I0315 18:57:14.067610 29479 solver.cpp:613] Iteration 55940, avg_grad_norm = 475086
I0315 18:58:15.515732 29479 solver.cpp:214] Iteration 55960, loss = 5841.41
I0315 18:58:15.515919 29479 solver.cpp:229]     Train net output #0: loss = 5853.16 (* 1 = 5853.16 loss)
I0315 18:58:15.876482 29479 solver.cpp:610] Iteration 55960, lr = 7.44231e-09
I0315 18:58:15.876497 29479 solver.cpp:613] Iteration 55960, avg_grad_norm = 570734
I0315 18:59:24.880839 29479 solver.cpp:214] Iteration 55980, loss = 5841.02
I0315 18:59:24.881011 29479 solver.cpp:229]     Train net output #0: loss = 10860.2 (* 1 = 10860.2 loss)
I0315 18:59:25.247023 29479 solver.cpp:610] Iteration 55980, lr = 7.44138e-09
I0315 18:59:25.247045 29479 solver.cpp:613] Iteration 55980, avg_grad_norm = 582365
I0315 19:00:33.708539 29479 solver.cpp:214] Iteration 56000, loss = 5809.37
I0315 19:00:33.708675 29479 solver.cpp:229]     Train net output #0: loss = 7664.39 (* 1 = 7664.39 loss)
I0315 19:00:34.066452 29479 solver.cpp:610] Iteration 56000, lr = 7.44045e-09
I0315 19:00:34.066469 29479 solver.cpp:613] Iteration 56000, avg_grad_norm = 556747
I0315 19:02:03.493341 29479 solver.cpp:214] Iteration 56020, loss = 5870.08
I0315 19:02:03.493537 29479 solver.cpp:229]     Train net output #0: loss = 7375.15 (* 1 = 7375.15 loss)
I0315 19:02:03.856122 29479 solver.cpp:610] Iteration 56020, lr = 7.43952e-09
I0315 19:02:03.856135 29479 solver.cpp:613] Iteration 56020, avg_grad_norm = 517406
I0315 19:03:12.331056 29479 solver.cpp:214] Iteration 56040, loss = 5784.53
I0315 19:03:12.331185 29479 solver.cpp:229]     Train net output #0: loss = 4233.53 (* 1 = 4233.53 loss)
I0315 19:03:12.672317 29479 solver.cpp:610] Iteration 56040, lr = 7.43859e-09
I0315 19:03:12.672330 29479 solver.cpp:613] Iteration 56040, avg_grad_norm = 505261
I0315 19:04:19.672902 29479 solver.cpp:214] Iteration 56060, loss = 5809.94
I0315 19:04:19.673058 29479 solver.cpp:229]     Train net output #0: loss = 7360.68 (* 1 = 7360.68 loss)
I0315 19:04:20.008774 29479 solver.cpp:610] Iteration 56060, lr = 7.43766e-09
I0315 19:04:20.008790 29479 solver.cpp:613] Iteration 56060, avg_grad_norm = 548929
I0315 19:04:53.899513 29479 solver.cpp:214] Iteration 56080, loss = 5824.07
I0315 19:04:53.899652 29479 solver.cpp:229]     Train net output #0: loss = 5537.78 (* 1 = 5537.78 loss)
I0315 19:04:54.017400 29479 solver.cpp:610] Iteration 56080, lr = 7.43673e-09
I0315 19:04:54.017415 29479 solver.cpp:613] Iteration 56080, avg_grad_norm = 520522
I0315 19:05:24.515528 29479 solver.cpp:214] Iteration 56100, loss = 6076.48
I0315 19:05:24.515700 29479 solver.cpp:229]     Train net output #0: loss = 5116.37 (* 1 = 5116.37 loss)
I0315 19:05:24.847259 29479 solver.cpp:610] Iteration 56100, lr = 7.4358e-09
I0315 19:05:24.847272 29479 solver.cpp:613] Iteration 56100, avg_grad_norm = 525848
I0315 19:06:29.635439 29479 solver.cpp:214] Iteration 56120, loss = 6100.57
I0315 19:06:29.635589 29479 solver.cpp:229]     Train net output #0: loss = 5326.48 (* 1 = 5326.48 loss)
I0315 19:06:29.994149 29479 solver.cpp:610] Iteration 56120, lr = 7.43487e-09
I0315 19:06:29.994164 29479 solver.cpp:613] Iteration 56120, avg_grad_norm = 528368
I0315 19:07:50.822008 29479 solver.cpp:214] Iteration 56140, loss = 5946.26
I0315 19:07:50.822191 29479 solver.cpp:229]     Train net output #0: loss = 4041.95 (* 1 = 4041.95 loss)
I0315 19:07:51.192128 29479 solver.cpp:610] Iteration 56140, lr = 7.43394e-09
I0315 19:07:51.192145 29479 solver.cpp:613] Iteration 56140, avg_grad_norm = 564840
I0315 19:08:59.371188 29479 solver.cpp:214] Iteration 56160, loss = 5617.68
I0315 19:08:59.371323 29479 solver.cpp:229]     Train net output #0: loss = 4205.11 (* 1 = 4205.11 loss)
I0315 19:08:59.740679 29479 solver.cpp:610] Iteration 56160, lr = 7.43301e-09
I0315 19:08:59.740691 29479 solver.cpp:613] Iteration 56160, avg_grad_norm = 609349
I0315 19:10:08.063755 29479 solver.cpp:214] Iteration 56180, loss = 6429.47
I0315 19:10:08.063933 29479 solver.cpp:229]     Train net output #0: loss = 6506.91 (* 1 = 6506.91 loss)
I0315 19:10:08.452863 29479 solver.cpp:610] Iteration 56180, lr = 7.43208e-09
I0315 19:10:08.452877 29479 solver.cpp:613] Iteration 56180, avg_grad_norm = 594609
I0315 19:11:15.414122 29479 solver.cpp:214] Iteration 56200, loss = 6056.1
I0315 19:11:15.414329 29479 solver.cpp:229]     Train net output #0: loss = 3152.16 (* 1 = 3152.16 loss)
I0315 19:11:15.600193 29479 solver.cpp:610] Iteration 56200, lr = 7.43115e-09
I0315 19:11:15.600208 29479 solver.cpp:613] Iteration 56200, avg_grad_norm = 504021
I0315 19:12:23.841486 29479 solver.cpp:214] Iteration 56220, loss = 5580.21
I0315 19:12:23.841616 29479 solver.cpp:229]     Train net output #0: loss = 5241.4 (* 1 = 5241.4 loss)
I0315 19:12:24.207850 29479 solver.cpp:610] Iteration 56220, lr = 7.43022e-09
I0315 19:12:24.207869 29479 solver.cpp:613] Iteration 56220, avg_grad_norm = 558984
I0315 19:13:09.667156 29479 solver.cpp:214] Iteration 56240, loss = 6054.46
I0315 19:13:09.667299 29479 solver.cpp:229]     Train net output #0: loss = 4710.98 (* 1 = 4710.98 loss)
I0315 19:13:10.029347 29479 solver.cpp:610] Iteration 56240, lr = 7.42929e-09
I0315 19:13:10.029362 29479 solver.cpp:613] Iteration 56240, avg_grad_norm = 548707
I0315 19:14:32.359874 29479 solver.cpp:214] Iteration 56260, loss = 5748.19
I0315 19:14:32.359998 29479 solver.cpp:229]     Train net output #0: loss = 5482.61 (* 1 = 5482.61 loss)
I0315 19:14:32.722659 29479 solver.cpp:610] Iteration 56260, lr = 7.42836e-09
I0315 19:14:32.722672 29479 solver.cpp:613] Iteration 56260, avg_grad_norm = 568699
I0315 19:15:40.829965 29479 solver.cpp:214] Iteration 56280, loss = 6137.04
I0315 19:15:40.830095 29479 solver.cpp:229]     Train net output #0: loss = 6563.91 (* 1 = 6563.91 loss)
I0315 19:15:41.154750 29479 solver.cpp:610] Iteration 56280, lr = 7.42743e-09
I0315 19:15:41.154764 29479 solver.cpp:613] Iteration 56280, avg_grad_norm = 554364
I0315 19:16:49.209213 29479 solver.cpp:214] Iteration 56300, loss = 5781.01
I0315 19:16:49.209411 29479 solver.cpp:229]     Train net output #0: loss = 4629.4 (* 1 = 4629.4 loss)
I0315 19:16:49.576203 29479 solver.cpp:610] Iteration 56300, lr = 7.4265e-09
I0315 19:16:49.576237 29479 solver.cpp:613] Iteration 56300, avg_grad_norm = 599594
I0315 19:17:57.756580 29479 solver.cpp:214] Iteration 56320, loss = 5678.1
I0315 19:17:57.756717 29479 solver.cpp:229]     Train net output #0: loss = 3274.17 (* 1 = 3274.17 loss)
I0315 19:17:58.094761 29479 solver.cpp:610] Iteration 56320, lr = 7.42557e-09
I0315 19:17:58.094775 29479 solver.cpp:613] Iteration 56320, avg_grad_norm = 536074
I0315 19:19:06.430129 29479 solver.cpp:214] Iteration 56340, loss = 5695.52
I0315 19:19:06.430338 29479 solver.cpp:229]     Train net output #0: loss = 3254.62 (* 1 = 3254.62 loss)
I0315 19:19:06.796061 29479 solver.cpp:610] Iteration 56340, lr = 7.42464e-09
I0315 19:19:06.796078 29479 solver.cpp:613] Iteration 56340, avg_grad_norm = 487278
I0315 19:20:14.296399 29479 solver.cpp:214] Iteration 56360, loss = 5828.8
I0315 19:20:14.296561 29479 solver.cpp:229]     Train net output #0: loss = 5763.07 (* 1 = 5763.07 loss)
I0315 19:20:14.402066 29479 solver.cpp:610] Iteration 56360, lr = 7.42371e-09
I0315 19:20:14.402112 29479 solver.cpp:613] Iteration 56360, avg_grad_norm = 500512
I0315 19:20:58.132175 29479 solver.cpp:214] Iteration 56380, loss = 5752.38
I0315 19:20:58.132342 29479 solver.cpp:229]     Train net output #0: loss = 3700.24 (* 1 = 3700.24 loss)
I0315 19:20:58.348026 29479 solver.cpp:610] Iteration 56380, lr = 7.42278e-09
I0315 19:20:58.348042 29479 solver.cpp:613] Iteration 56380, avg_grad_norm = 474156
I0315 19:22:23.518410 29479 solver.cpp:214] Iteration 56400, loss = 5879.4
I0315 19:22:23.518599 29479 solver.cpp:229]     Train net output #0: loss = 10077.4 (* 1 = 10077.4 loss)
I0315 19:22:23.878657 29479 solver.cpp:610] Iteration 56400, lr = 7.42185e-09
I0315 19:22:23.878671 29479 solver.cpp:613] Iteration 56400, avg_grad_norm = 484348
I0315 19:23:32.531589 29479 solver.cpp:214] Iteration 56420, loss = 5870.12
I0315 19:23:32.531709 29479 solver.cpp:229]     Train net output #0: loss = 4421.68 (* 1 = 4421.68 loss)
I0315 19:23:32.892151 29479 solver.cpp:610] Iteration 56420, lr = 7.42092e-09
I0315 19:23:32.892165 29479 solver.cpp:613] Iteration 56420, avg_grad_norm = 528772
I0315 19:24:41.581626 29479 solver.cpp:214] Iteration 56440, loss = 5796.45
I0315 19:24:41.581887 29479 solver.cpp:229]     Train net output #0: loss = 9351.36 (* 1 = 9351.36 loss)
I0315 19:24:41.951759 29479 solver.cpp:610] Iteration 56440, lr = 7.41999e-09
I0315 19:24:41.951773 29479 solver.cpp:613] Iteration 56440, avg_grad_norm = 613376
I0315 19:25:50.788018 29479 solver.cpp:214] Iteration 56460, loss = 6053.91
I0315 19:25:50.788167 29479 solver.cpp:229]     Train net output #0: loss = 11909.7 (* 1 = 11909.7 loss)
I0315 19:25:51.148128 29479 solver.cpp:610] Iteration 56460, lr = 7.41906e-09
I0315 19:25:51.148166 29479 solver.cpp:613] Iteration 56460, avg_grad_norm = 547325
I0315 19:27:00.285547 29479 solver.cpp:214] Iteration 56480, loss = 5865.41
I0315 19:27:00.285751 29479 solver.cpp:229]     Train net output #0: loss = 7329.17 (* 1 = 7329.17 loss)
I0315 19:27:00.653635 29479 solver.cpp:610] Iteration 56480, lr = 7.41813e-09
I0315 19:27:00.653657 29479 solver.cpp:613] Iteration 56480, avg_grad_norm = 529357
I0315 19:27:54.061249 29479 solver.cpp:214] Iteration 56500, loss = 6141.02
I0315 19:27:54.061393 29479 solver.cpp:229]     Train net output #0: loss = 7326.76 (* 1 = 7326.76 loss)
I0315 19:27:54.177275 29479 solver.cpp:610] Iteration 56500, lr = 7.41719e-09
I0315 19:27:54.177326 29479 solver.cpp:613] Iteration 56500, avg_grad_norm = 535870
I0315 19:29:08.945410 29479 solver.cpp:214] Iteration 56520, loss = 5733.74
I0315 19:29:08.945550 29479 solver.cpp:229]     Train net output #0: loss = 2527.15 (* 1 = 2527.15 loss)
I0315 19:29:09.305521 29479 solver.cpp:610] Iteration 56520, lr = 7.41626e-09
I0315 19:29:09.305536 29479 solver.cpp:613] Iteration 56520, avg_grad_norm = 509535
I0315 19:30:17.352272 29479 solver.cpp:214] Iteration 56540, loss = 6110.51
I0315 19:30:17.352386 29479 solver.cpp:229]     Train net output #0: loss = 9829.36 (* 1 = 9829.36 loss)
I0315 19:30:17.712697 29479 solver.cpp:610] Iteration 56540, lr = 7.41533e-09
I0315 19:30:17.712710 29479 solver.cpp:613] Iteration 56540, avg_grad_norm = 547720
I0315 19:31:26.618414 29479 solver.cpp:214] Iteration 56560, loss = 5908.3
I0315 19:31:26.618624 29479 solver.cpp:229]     Train net output #0: loss = 7880.02 (* 1 = 7880.02 loss)
I0315 19:31:26.949406 29479 solver.cpp:610] Iteration 56560, lr = 7.4144e-09
I0315 19:31:26.949419 29479 solver.cpp:613] Iteration 56560, avg_grad_norm = 548898
I0315 19:32:35.149888 29479 solver.cpp:214] Iteration 56580, loss = 5812.33
I0315 19:32:35.150013 29479 solver.cpp:229]     Train net output #0: loss = 7988.8 (* 1 = 7988.8 loss)
I0315 19:32:35.515437 29479 solver.cpp:610] Iteration 56580, lr = 7.41347e-09
I0315 19:32:35.515450 29479 solver.cpp:613] Iteration 56580, avg_grad_norm = 502280
I0315 19:33:44.589064 29479 solver.cpp:214] Iteration 56600, loss = 6217.87
I0315 19:33:44.589304 29479 solver.cpp:229]     Train net output #0: loss = 4378.21 (* 1 = 4378.21 loss)
I0315 19:33:44.949110 29479 solver.cpp:610] Iteration 56600, lr = 7.41254e-09
I0315 19:33:44.949138 29479 solver.cpp:613] Iteration 56600, avg_grad_norm = 551694
I0315 19:34:54.181253 29479 solver.cpp:214] Iteration 56620, loss = 6011.95
I0315 19:34:54.181455 29479 solver.cpp:229]     Train net output #0: loss = 7393.38 (* 1 = 7393.38 loss)
I0315 19:34:54.541954 29479 solver.cpp:610] Iteration 56620, lr = 7.41161e-09
I0315 19:34:54.541966 29479 solver.cpp:613] Iteration 56620, avg_grad_norm = 513155
I0315 19:35:53.146509 29479 solver.cpp:214] Iteration 56640, loss = 5809.27
I0315 19:35:53.146622 29479 solver.cpp:229]     Train net output #0: loss = 4252.88 (* 1 = 4252.88 loss)
I0315 19:35:53.510331 29479 solver.cpp:610] Iteration 56640, lr = 7.41068e-09
I0315 19:35:53.510344 29479 solver.cpp:613] Iteration 56640, avg_grad_norm = 472883
I0315 19:37:01.787653 29479 solver.cpp:214] Iteration 56660, loss = 6270.94
I0315 19:37:01.787787 29479 solver.cpp:229]     Train net output #0: loss = 4238.15 (* 1 = 4238.15 loss)
I0315 19:37:01.973603 29479 solver.cpp:610] Iteration 56660, lr = 7.40975e-09
I0315 19:37:01.973616 29479 solver.cpp:613] Iteration 56660, avg_grad_norm = 494540
I0315 19:38:10.754642 29479 solver.cpp:214] Iteration 56680, loss = 5792.98
I0315 19:38:10.754828 29479 solver.cpp:229]     Train net output #0: loss = 10582.5 (* 1 = 10582.5 loss)
I0315 19:38:11.115145 29479 solver.cpp:610] Iteration 56680, lr = 7.40882e-09
I0315 19:38:11.115159 29479 solver.cpp:613] Iteration 56680, avg_grad_norm = 510461
I0315 19:39:18.949990 29479 solver.cpp:214] Iteration 56700, loss = 5857.83
I0315 19:39:18.950120 29479 solver.cpp:229]     Train net output #0: loss = 4633.32 (* 1 = 4633.32 loss)
I0315 19:39:19.321766 29479 solver.cpp:610] Iteration 56700, lr = 7.40789e-09
I0315 19:39:19.321780 29479 solver.cpp:613] Iteration 56700, avg_grad_norm = 503516
I0315 19:40:28.127961 29479 solver.cpp:214] Iteration 56720, loss = 6103.91
I0315 19:40:28.128108 29479 solver.cpp:229]     Train net output #0: loss = 4689.32 (* 1 = 4689.32 loss)
I0315 19:40:28.488517 29479 solver.cpp:610] Iteration 56720, lr = 7.40696e-09
I0315 19:40:28.488530 29479 solver.cpp:613] Iteration 56720, avg_grad_norm = 543385
I0315 19:41:37.015455 29479 solver.cpp:214] Iteration 56740, loss = 5923.6
I0315 19:41:37.015594 29479 solver.cpp:229]     Train net output #0: loss = 4397.58 (* 1 = 4397.58 loss)
I0315 19:41:37.378633 29479 solver.cpp:610] Iteration 56740, lr = 7.40603e-09
I0315 19:41:37.378646 29479 solver.cpp:613] Iteration 56740, avg_grad_norm = 492971
I0315 19:42:46.676264 29479 solver.cpp:214] Iteration 56760, loss = 5989.24
I0315 19:42:46.676398 29479 solver.cpp:229]     Train net output #0: loss = 10483.6 (* 1 = 10483.6 loss)
I0315 19:42:47.041285 29479 solver.cpp:610] Iteration 56760, lr = 7.4051e-09
I0315 19:42:47.041299 29479 solver.cpp:613] Iteration 56760, avg_grad_norm = 549310
I0315 19:44:04.395761 29479 solver.cpp:214] Iteration 56780, loss = 5762.18
I0315 19:44:04.395917 29479 solver.cpp:229]     Train net output #0: loss = 5493.18 (* 1 = 5493.18 loss)
I0315 19:44:04.756291 29479 solver.cpp:610] Iteration 56780, lr = 7.40417e-09
I0315 19:44:04.756306 29479 solver.cpp:613] Iteration 56780, avg_grad_norm = 538100
I0315 19:45:13.085543 29479 solver.cpp:214] Iteration 56800, loss = 5457.44
I0315 19:45:13.085678 29479 solver.cpp:229]     Train net output #0: loss = 4002 (* 1 = 4002 loss)
I0315 19:45:13.445361 29479 solver.cpp:610] Iteration 56800, lr = 7.40324e-09
I0315 19:45:13.445374 29479 solver.cpp:613] Iteration 56800, avg_grad_norm = 498838
I0315 19:46:21.494128 29479 solver.cpp:214] Iteration 56820, loss = 5835.52
I0315 19:46:21.494223 29479 solver.cpp:229]     Train net output #0: loss = 3421.55 (* 1 = 3421.55 loss)
I0315 19:46:21.854285 29479 solver.cpp:610] Iteration 56820, lr = 7.40231e-09
I0315 19:46:21.854297 29479 solver.cpp:613] Iteration 56820, avg_grad_norm = 512654
I0315 19:47:29.330999 29479 solver.cpp:214] Iteration 56840, loss = 6015.05
I0315 19:47:29.331125 29479 solver.cpp:229]     Train net output #0: loss = 7154.16 (* 1 = 7154.16 loss)
I0315 19:47:29.693541 29479 solver.cpp:610] Iteration 56840, lr = 7.40138e-09
I0315 19:47:29.693553 29479 solver.cpp:613] Iteration 56840, avg_grad_norm = 540825
I0315 19:48:37.734910 29479 solver.cpp:214] Iteration 56860, loss = 5953.95
I0315 19:48:37.735118 29479 solver.cpp:229]     Train net output #0: loss = 2592.02 (* 1 = 2592.02 loss)
I0315 19:48:38.095260 29479 solver.cpp:610] Iteration 56860, lr = 7.40045e-09
I0315 19:48:38.095274 29479 solver.cpp:613] Iteration 56860, avg_grad_norm = 537222
I0315 19:49:45.310724 29479 solver.cpp:214] Iteration 56880, loss = 5943.5
I0315 19:49:45.310864 29479 solver.cpp:229]     Train net output #0: loss = 3945.03 (* 1 = 3945.03 loss)
I0315 19:49:45.503967 29479 solver.cpp:610] Iteration 56880, lr = 7.39952e-09
I0315 19:49:45.503979 29479 solver.cpp:613] Iteration 56880, avg_grad_norm = 500665
I0315 19:51:22.502233 29479 solver.cpp:214] Iteration 56900, loss = 6090.43
I0315 19:51:22.502454 29479 solver.cpp:229]     Train net output #0: loss = 7610.42 (* 1 = 7610.42 loss)
I0315 19:51:22.857357 29479 solver.cpp:610] Iteration 56900, lr = 7.39859e-09
I0315 19:51:22.857411 29479 solver.cpp:613] Iteration 56900, avg_grad_norm = 540633
I0315 19:52:30.627261 29479 solver.cpp:214] Iteration 56920, loss = 5995.29
I0315 19:52:30.627528 29479 solver.cpp:229]     Train net output #0: loss = 4898.65 (* 1 = 4898.65 loss)
I0315 19:52:30.983695 29479 solver.cpp:610] Iteration 56920, lr = 7.39765e-09
I0315 19:52:30.983710 29479 solver.cpp:613] Iteration 56920, avg_grad_norm = 578568
I0315 19:53:38.488453 29479 solver.cpp:214] Iteration 56940, loss = 5968.79
I0315 19:53:38.488584 29479 solver.cpp:229]     Train net output #0: loss = 2802.2 (* 1 = 2802.2 loss)
I0315 19:53:38.848482 29479 solver.cpp:610] Iteration 56940, lr = 7.39672e-09
I0315 19:53:38.848495 29479 solver.cpp:613] Iteration 56940, avg_grad_norm = 576977
I0315 19:54:45.901108 29479 solver.cpp:214] Iteration 56960, loss = 5797.41
I0315 19:54:45.901290 29479 solver.cpp:229]     Train net output #0: loss = 8786.31 (* 1 = 8786.31 loss)
I0315 19:54:46.227306 29479 solver.cpp:610] Iteration 56960, lr = 7.39579e-09
I0315 19:54:46.227320 29479 solver.cpp:613] Iteration 56960, avg_grad_norm = 506030
I0315 19:55:54.298470 29479 solver.cpp:214] Iteration 56980, loss = 5968.15
I0315 19:55:54.298671 29479 solver.cpp:229]     Train net output #0: loss = 5844.11 (* 1 = 5844.11 loss)
I0315 19:55:54.658426 29479 solver.cpp:610] Iteration 56980, lr = 7.39486e-09
I0315 19:55:54.658439 29479 solver.cpp:613] Iteration 56980, avg_grad_norm = 558606
I0315 19:57:03.280282 29479 solver.cpp:214] Iteration 57000, loss = 5927.13
I0315 19:57:03.280406 29479 solver.cpp:229]     Train net output #0: loss = 5276.87 (* 1 = 5276.87 loss)
I0315 19:57:03.641175 29479 solver.cpp:610] Iteration 57000, lr = 7.39393e-09
I0315 19:57:03.641188 29479 solver.cpp:613] Iteration 57000, avg_grad_norm = 623647
I0315 19:58:31.837323 29479 solver.cpp:214] Iteration 57020, loss = 6017.09
I0315 19:58:31.837461 29479 solver.cpp:229]     Train net output #0: loss = 3983.47 (* 1 = 3983.47 loss)
I0315 19:58:31.941756 29479 solver.cpp:610] Iteration 57020, lr = 7.393e-09
I0315 19:58:31.941793 29479 solver.cpp:613] Iteration 57020, avg_grad_norm = 519933
I0315 19:59:31.085678 29479 solver.cpp:214] Iteration 57040, loss = 5745.15
I0315 19:59:31.085889 29479 solver.cpp:229]     Train net output #0: loss = 3362.87 (* 1 = 3362.87 loss)
I0315 19:59:31.443096 29479 solver.cpp:610] Iteration 57040, lr = 7.39207e-09
I0315 19:59:31.443115 29479 solver.cpp:613] Iteration 57040, avg_grad_norm = 521381
I0315 20:00:39.988118 29479 solver.cpp:214] Iteration 57060, loss = 5896.39
I0315 20:00:39.988309 29479 solver.cpp:229]     Train net output #0: loss = 10015.2 (* 1 = 10015.2 loss)
I0315 20:00:40.348263 29479 solver.cpp:610] Iteration 57060, lr = 7.39114e-09
I0315 20:00:40.348278 29479 solver.cpp:613] Iteration 57060, avg_grad_norm = 559412
I0315 20:01:48.354286 29479 solver.cpp:214] Iteration 57080, loss = 5764.66
I0315 20:01:48.354435 29479 solver.cpp:229]     Train net output #0: loss = 5193.29 (* 1 = 5193.29 loss)
I0315 20:01:48.712250 29479 solver.cpp:610] Iteration 57080, lr = 7.39021e-09
I0315 20:01:48.712265 29479 solver.cpp:613] Iteration 57080, avg_grad_norm = 515913
I0315 20:02:51.079607 29479 solver.cpp:214] Iteration 57100, loss = 6365.53
I0315 20:02:51.079720 29479 solver.cpp:229]     Train net output #0: loss = 5286.4 (* 1 = 5286.4 loss)
I0315 20:02:51.440184 29479 solver.cpp:610] Iteration 57100, lr = 7.38928e-09
I0315 20:02:51.440198 29479 solver.cpp:613] Iteration 57100, avg_grad_norm = 535137
I0315 20:03:59.774538 29479 solver.cpp:214] Iteration 57120, loss = 5654.45
I0315 20:03:59.774667 29479 solver.cpp:229]     Train net output #0: loss = 5500.5 (* 1 = 5500.5 loss)
I0315 20:04:00.157054 29479 solver.cpp:610] Iteration 57120, lr = 7.38835e-09
I0315 20:04:00.157068 29479 solver.cpp:613] Iteration 57120, avg_grad_norm = 524568
I0315 20:05:07.153023 29479 solver.cpp:214] Iteration 57140, loss = 6055.15
I0315 20:05:07.153199 29479 solver.cpp:229]     Train net output #0: loss = 3804.89 (* 1 = 3804.89 loss)
I0315 20:05:07.510615 29479 solver.cpp:610] Iteration 57140, lr = 7.38742e-09
I0315 20:05:07.510628 29479 solver.cpp:613] Iteration 57140, avg_grad_norm = 498201
I0315 20:06:05.381815 29479 solver.cpp:214] Iteration 57160, loss = 5968.43
I0315 20:06:05.382015 29479 solver.cpp:229]     Train net output #0: loss = 4933.51 (* 1 = 4933.51 loss)
I0315 20:06:05.499428 29479 solver.cpp:610] Iteration 57160, lr = 7.38649e-09
I0315 20:06:05.499441 29479 solver.cpp:613] Iteration 57160, avg_grad_norm = 515942
I0315 20:07:08.359733 29479 solver.cpp:214] Iteration 57180, loss = 5716.03
I0315 20:07:08.359892 29479 solver.cpp:229]     Train net output #0: loss = 4416.14 (* 1 = 4416.14 loss)
I0315 20:07:08.722625 29479 solver.cpp:610] Iteration 57180, lr = 7.38555e-09
I0315 20:07:08.722640 29479 solver.cpp:613] Iteration 57180, avg_grad_norm = 518463
I0315 20:08:15.730003 29479 solver.cpp:214] Iteration 57200, loss = 5936.48
I0315 20:08:15.730154 29479 solver.cpp:229]     Train net output #0: loss = 4298.35 (* 1 = 4298.35 loss)
I0315 20:08:16.093116 29479 solver.cpp:610] Iteration 57200, lr = 7.38462e-09
I0315 20:08:16.093132 29479 solver.cpp:613] Iteration 57200, avg_grad_norm = 602543
I0315 20:09:25.105420 29479 solver.cpp:214] Iteration 57220, loss = 6065.84
I0315 20:09:25.105567 29479 solver.cpp:229]     Train net output #0: loss = 7376.35 (* 1 = 7376.35 loss)
I0315 20:09:25.475142 29479 solver.cpp:610] Iteration 57220, lr = 7.38369e-09
I0315 20:09:25.475155 29479 solver.cpp:613] Iteration 57220, avg_grad_norm = 536512
I0315 20:10:34.299018 29479 solver.cpp:214] Iteration 57240, loss = 5736.31
I0315 20:10:34.299146 29479 solver.cpp:229]     Train net output #0: loss = 4085.63 (* 1 = 4085.63 loss)
I0315 20:10:34.664993 29479 solver.cpp:610] Iteration 57240, lr = 7.38276e-09
I0315 20:10:34.665009 29479 solver.cpp:613] Iteration 57240, avg_grad_norm = 480224
I0315 20:11:43.946668 29479 solver.cpp:214] Iteration 57260, loss = 6064.82
I0315 20:11:43.946806 29479 solver.cpp:229]     Train net output #0: loss = 5430.02 (* 1 = 5430.02 loss)
I0315 20:11:44.306619 29479 solver.cpp:610] Iteration 57260, lr = 7.38183e-09
I0315 20:11:44.306635 29479 solver.cpp:613] Iteration 57260, avg_grad_norm = 534585
I0315 20:13:15.904374 29479 solver.cpp:214] Iteration 57280, loss = 5982.77
I0315 20:13:15.904532 29479 solver.cpp:229]     Train net output #0: loss = 5820.29 (* 1 = 5820.29 loss)
I0315 20:13:16.272596 29479 solver.cpp:610] Iteration 57280, lr = 7.3809e-09
I0315 20:13:16.272611 29479 solver.cpp:613] Iteration 57280, avg_grad_norm = 521193
I0315 20:14:00.866659 29479 solver.cpp:214] Iteration 57300, loss = 5818.61
I0315 20:14:00.866794 29479 solver.cpp:229]     Train net output #0: loss = 8417.35 (* 1 = 8417.35 loss)
I0315 20:14:01.229877 29479 solver.cpp:610] Iteration 57300, lr = 7.37997e-09
I0315 20:14:01.229892 29479 solver.cpp:613] Iteration 57300, avg_grad_norm = 578471
I0315 20:15:09.197161 29479 solver.cpp:214] Iteration 57320, loss = 6049.54
I0315 20:15:09.197402 29479 solver.cpp:229]     Train net output #0: loss = 10269.4 (* 1 = 10269.4 loss)
I0315 20:15:09.563110 29479 solver.cpp:610] Iteration 57320, lr = 7.37904e-09
I0315 20:15:09.563125 29479 solver.cpp:613] Iteration 57320, avg_grad_norm = 624180
I0315 20:16:18.391425 29479 solver.cpp:214] Iteration 57340, loss = 6081.11
I0315 20:16:18.391571 29479 solver.cpp:229]     Train net output #0: loss = 10898.6 (* 1 = 10898.6 loss)
I0315 20:16:18.753422 29479 solver.cpp:610] Iteration 57340, lr = 7.37811e-09
I0315 20:16:18.753437 29479 solver.cpp:613] Iteration 57340, avg_grad_norm = 555591
I0315 20:17:27.112452 29479 solver.cpp:214] Iteration 57360, loss = 5800.27
I0315 20:17:27.112646 29479 solver.cpp:229]     Train net output #0: loss = 8736.96 (* 1 = 8736.96 loss)
I0315 20:17:27.472033 29479 solver.cpp:610] Iteration 57360, lr = 7.37718e-09
I0315 20:17:27.472048 29479 solver.cpp:613] Iteration 57360, avg_grad_norm = 568354
I0315 20:18:36.855840 29479 solver.cpp:214] Iteration 57380, loss = 5927.05
I0315 20:18:36.855968 29479 solver.cpp:229]     Train net output #0: loss = 5893.76 (* 1 = 5893.76 loss)
I0315 20:18:37.221079 29479 solver.cpp:610] Iteration 57380, lr = 7.37625e-09
I0315 20:18:37.221093 29479 solver.cpp:613] Iteration 57380, avg_grad_norm = 570498
I0315 20:19:46.596729 29479 solver.cpp:214] Iteration 57400, loss = 6120.29
I0315 20:19:46.596904 29479 solver.cpp:229]     Train net output #0: loss = 6452.19 (* 1 = 6452.19 loss)
I0315 20:19:46.955343 29479 solver.cpp:610] Iteration 57400, lr = 7.37532e-09
I0315 20:19:46.955358 29479 solver.cpp:613] Iteration 57400, avg_grad_norm = 502655
I0315 20:21:11.738605 29479 solver.cpp:214] Iteration 57420, loss = 5723.14
I0315 20:21:11.738723 29479 solver.cpp:229]     Train net output #0: loss = 5793.11 (* 1 = 5793.11 loss)
I0315 20:21:12.102387 29479 solver.cpp:610] Iteration 57420, lr = 7.37438e-09
I0315 20:21:12.102401 29479 solver.cpp:613] Iteration 57420, avg_grad_norm = 502940
I0315 20:22:20.690636 29479 solver.cpp:214] Iteration 57440, loss = 6071.53
I0315 20:22:20.690764 29479 solver.cpp:229]     Train net output #0: loss = 6499.28 (* 1 = 6499.28 loss)
I0315 20:22:21.080662 29479 solver.cpp:610] Iteration 57440, lr = 7.37345e-09
I0315 20:22:21.080674 29479 solver.cpp:613] Iteration 57440, avg_grad_norm = 506216
I0315 20:23:29.263893 29479 solver.cpp:214] Iteration 57460, loss = 5787.12
I0315 20:23:29.264020 29479 solver.cpp:229]     Train net output #0: loss = 3345.28 (* 1 = 3345.28 loss)
I0315 20:23:29.655977 29479 solver.cpp:610] Iteration 57460, lr = 7.37252e-09
I0315 20:23:29.655990 29479 solver.cpp:613] Iteration 57460, avg_grad_norm = 486893
I0315 20:24:37.825136 29479 solver.cpp:214] Iteration 57480, loss = 5881.37
I0315 20:24:37.825280 29479 solver.cpp:229]     Train net output #0: loss = 4409.61 (* 1 = 4409.61 loss)
I0315 20:24:38.188889 29479 solver.cpp:610] Iteration 57480, lr = 7.37159e-09
I0315 20:24:38.188904 29479 solver.cpp:613] Iteration 57480, avg_grad_norm = 591881
I0315 20:25:47.130157 29479 solver.cpp:214] Iteration 57500, loss = 5916.57
I0315 20:25:47.130297 29479 solver.cpp:229]     Train net output #0: loss = 5062 (* 1 = 5062 loss)
I0315 20:25:47.500186 29479 solver.cpp:610] Iteration 57500, lr = 7.37066e-09
I0315 20:25:47.500200 29479 solver.cpp:613] Iteration 57500, avg_grad_norm = 559377
I0315 20:26:56.530042 29479 solver.cpp:214] Iteration 57520, loss = 5791.84
I0315 20:26:56.530235 29479 solver.cpp:229]     Train net output #0: loss = 5248.41 (* 1 = 5248.41 loss)
I0315 20:26:56.896054 29479 solver.cpp:610] Iteration 57520, lr = 7.36973e-09
I0315 20:26:56.896069 29479 solver.cpp:613] Iteration 57520, avg_grad_norm = 511901
I0315 20:28:12.562621 29479 solver.cpp:214] Iteration 57540, loss = 5845.51
I0315 20:28:12.562780 29479 solver.cpp:229]     Train net output #0: loss = 3665.48 (* 1 = 3665.48 loss)
I0315 20:28:12.673041 29479 solver.cpp:610] Iteration 57540, lr = 7.3688e-09
I0315 20:28:12.673115 29479 solver.cpp:613] Iteration 57540, avg_grad_norm = 480519
I0315 20:29:02.110877 29479 solver.cpp:214] Iteration 57560, loss = 5967.28
I0315 20:29:02.110973 29479 solver.cpp:229]     Train net output #0: loss = 7400.79 (* 1 = 7400.79 loss)
I0315 20:29:02.471267 29479 solver.cpp:610] Iteration 57560, lr = 7.36787e-09
I0315 20:29:02.471284 29479 solver.cpp:613] Iteration 57560, avg_grad_norm = 535388
I0315 20:30:10.265177 29479 solver.cpp:214] Iteration 57580, loss = 6213.84
I0315 20:30:10.265362 29479 solver.cpp:229]     Train net output #0: loss = 5622.72 (* 1 = 5622.72 loss)
I0315 20:30:10.628551 29479 solver.cpp:610] Iteration 57580, lr = 7.36694e-09
I0315 20:30:10.628566 29479 solver.cpp:613] Iteration 57580, avg_grad_norm = 526896
I0315 20:31:19.353539 29479 solver.cpp:214] Iteration 57600, loss = 5799.86
I0315 20:31:19.353739 29479 solver.cpp:229]     Train net output #0: loss = 8907.01 (* 1 = 8907.01 loss)
I0315 20:31:19.720072 29479 solver.cpp:610] Iteration 57600, lr = 7.366e-09
I0315 20:31:19.720085 29479 solver.cpp:613] Iteration 57600, avg_grad_norm = 537793
I0315 20:32:27.911474 29479 solver.cpp:214] Iteration 57620, loss = 6136.22
I0315 20:32:27.911607 29479 solver.cpp:229]     Train net output #0: loss = 4816.75 (* 1 = 4816.75 loss)
I0315 20:32:28.271670 29479 solver.cpp:610] Iteration 57620, lr = 7.36507e-09
I0315 20:32:28.271683 29479 solver.cpp:613] Iteration 57620, avg_grad_norm = 527702
I0315 20:33:37.377220 29479 solver.cpp:214] Iteration 57640, loss = 5706.32
I0315 20:33:37.377511 29479 solver.cpp:229]     Train net output #0: loss = 3470.02 (* 1 = 3470.02 loss)
I0315 20:33:37.736768 29479 solver.cpp:610] Iteration 57640, lr = 7.36414e-09
I0315 20:33:37.736783 29479 solver.cpp:613] Iteration 57640, avg_grad_norm = 529935
I0315 20:35:21.519875 29479 solver.cpp:214] Iteration 57660, loss = 6047.17
I0315 20:35:21.520007 29479 solver.cpp:229]     Train net output #0: loss = 5041.31 (* 1 = 5041.31 loss)
I0315 20:35:21.882644 29479 solver.cpp:610] Iteration 57660, lr = 7.36321e-09
I0315 20:35:21.882659 29479 solver.cpp:613] Iteration 57660, avg_grad_norm = 502481
I0315 20:36:01.614233 29479 solver.cpp:214] Iteration 57680, loss = 5871.66
I0315 20:36:01.614372 29479 solver.cpp:229]     Train net output #0: loss = 5620.34 (* 1 = 5620.34 loss)
I0315 20:36:01.974388 29479 solver.cpp:610] Iteration 57680, lr = 7.36228e-09
I0315 20:36:01.974406 29479 solver.cpp:613] Iteration 57680, avg_grad_norm = 514860
I0315 20:37:10.116307 29479 solver.cpp:214] Iteration 57700, loss = 6379.19
I0315 20:37:10.116448 29479 solver.cpp:229]     Train net output #0: loss = 7445.96 (* 1 = 7445.96 loss)
I0315 20:37:10.447235 29479 solver.cpp:610] Iteration 57700, lr = 7.36135e-09
I0315 20:37:10.447252 29479 solver.cpp:613] Iteration 57700, avg_grad_norm = 573921
I0315 20:38:18.968230 29479 solver.cpp:214] Iteration 57720, loss = 5928.29
I0315 20:38:18.968359 29479 solver.cpp:229]     Train net output #0: loss = 3458.99 (* 1 = 3458.99 loss)
I0315 20:38:19.338057 29479 solver.cpp:610] Iteration 57720, lr = 7.36042e-09
I0315 20:38:19.338069 29479 solver.cpp:613] Iteration 57720, avg_grad_norm = 530825
I0315 20:39:26.792112 29479 solver.cpp:214] Iteration 57740, loss = 6231.25
I0315 20:39:26.792297 29479 solver.cpp:229]     Train net output #0: loss = 9421.32 (* 1 = 9421.32 loss)
I0315 20:39:27.158437 29479 solver.cpp:610] Iteration 57740, lr = 7.35949e-09
I0315 20:39:27.158452 29479 solver.cpp:613] Iteration 57740, avg_grad_norm = 488810
I0315 20:40:36.120005 29479 solver.cpp:214] Iteration 57760, loss = 6263.34
I0315 20:40:36.120152 29479 solver.cpp:229]     Train net output #0: loss = 2938.47 (* 1 = 2938.47 loss)
I0315 20:40:36.480041 29479 solver.cpp:610] Iteration 57760, lr = 7.35856e-09
I0315 20:40:36.480054 29479 solver.cpp:613] Iteration 57760, avg_grad_norm = 512053
I0315 20:41:45.566380 29479 solver.cpp:214] Iteration 57780, loss = 5834.27
I0315 20:41:45.566583 29479 solver.cpp:229]     Train net output #0: loss = 7146.95 (* 1 = 7146.95 loss)
I0315 20:41:45.924978 29479 solver.cpp:610] Iteration 57780, lr = 7.35762e-09
I0315 20:41:45.924993 29479 solver.cpp:613] Iteration 57780, avg_grad_norm = 521343
I0315 20:43:05.822010 29479 solver.cpp:214] Iteration 57800, loss = 6029.5
I0315 20:43:05.822165 29479 solver.cpp:229]     Train net output #0: loss = 11016.5 (* 1 = 11016.5 loss)
I0315 20:43:05.933743 29479 solver.cpp:610] Iteration 57800, lr = 7.35669e-09
I0315 20:43:05.933797 29479 solver.cpp:613] Iteration 57800, avg_grad_norm = 483541
I0315 20:44:01.766963 29479 solver.cpp:214] Iteration 57820, loss = 5777.84
I0315 20:44:01.767096 29479 solver.cpp:229]     Train net output #0: loss = 2435.85 (* 1 = 2435.85 loss)
I0315 20:44:02.133632 29479 solver.cpp:610] Iteration 57820, lr = 7.35576e-09
I0315 20:44:02.133647 29479 solver.cpp:613] Iteration 57820, avg_grad_norm = 467308
I0315 20:45:09.430390 29479 solver.cpp:214] Iteration 57840, loss = 5690.66
I0315 20:45:09.430586 29479 solver.cpp:229]     Train net output #0: loss = 11002 (* 1 = 11002 loss)
I0315 20:45:09.768905 29479 solver.cpp:610] Iteration 57840, lr = 7.35483e-09
I0315 20:45:09.768918 29479 solver.cpp:613] Iteration 57840, avg_grad_norm = 521499
I0315 20:46:17.937574 29479 solver.cpp:214] Iteration 57860, loss = 5714.32
I0315 20:46:17.937690 29479 solver.cpp:229]     Train net output #0: loss = 3371.02 (* 1 = 3371.02 loss)
I0315 20:46:18.306290 29479 solver.cpp:610] Iteration 57860, lr = 7.3539e-09
I0315 20:46:18.306303 29479 solver.cpp:613] Iteration 57860, avg_grad_norm = 464633
I0315 20:47:26.780704 29479 solver.cpp:214] Iteration 57880, loss = 5892.93
I0315 20:47:26.780983 29479 solver.cpp:229]     Train net output #0: loss = 12702.8 (* 1 = 12702.8 loss)
I0315 20:47:27.141149 29479 solver.cpp:610] Iteration 57880, lr = 7.35297e-09
I0315 20:47:27.141183 29479 solver.cpp:613] Iteration 57880, avg_grad_norm = 473761
I0315 20:48:36.661013 29479 solver.cpp:214] Iteration 57900, loss = 5650.98
I0315 20:48:36.661206 29479 solver.cpp:229]     Train net output #0: loss = 5424.74 (* 1 = 5424.74 loss)
I0315 20:48:37.021473 29479 solver.cpp:610] Iteration 57900, lr = 7.35204e-09
I0315 20:48:37.021487 29479 solver.cpp:613] Iteration 57900, avg_grad_norm = 460818
I0315 20:50:09.257773 29479 solver.cpp:214] Iteration 57920, loss = 5946.26
I0315 20:50:09.257900 29479 solver.cpp:229]     Train net output #0: loss = 6514.63 (* 1 = 6514.63 loss)
I0315 20:50:09.621068 29479 solver.cpp:610] Iteration 57920, lr = 7.35111e-09
I0315 20:50:09.621081 29479 solver.cpp:613] Iteration 57920, avg_grad_norm = 480216
I0315 20:50:52.620188 29479 solver.cpp:214] Iteration 57940, loss = 5825.28
I0315 20:50:52.620321 29479 solver.cpp:229]     Train net output #0: loss = 3927.5 (* 1 = 3927.5 loss)
I0315 20:50:52.986105 29479 solver.cpp:610] Iteration 57940, lr = 7.35017e-09
I0315 20:50:52.986119 29479 solver.cpp:613] Iteration 57940, avg_grad_norm = 554476
I0315 20:52:01.008680 29479 solver.cpp:214] Iteration 57960, loss = 5921.1
I0315 20:52:01.008816 29479 solver.cpp:229]     Train net output #0: loss = 4350.27 (* 1 = 4350.27 loss)
I0315 20:52:01.368610 29479 solver.cpp:610] Iteration 57960, lr = 7.34924e-09
I0315 20:52:01.368623 29479 solver.cpp:613] Iteration 57960, avg_grad_norm = 559241
I0315 20:53:09.889140 29479 solver.cpp:214] Iteration 57980, loss = 5917.84
I0315 20:53:09.889369 29479 solver.cpp:229]     Train net output #0: loss = 4838.26 (* 1 = 4838.26 loss)
I0315 20:53:10.252553 29479 solver.cpp:610] Iteration 57980, lr = 7.34831e-09
I0315 20:53:10.252578 29479 solver.cpp:613] Iteration 57980, avg_grad_norm = 485212
I0315 20:54:18.664399 29479 solver.cpp:214] Iteration 58000, loss = 6006.77
I0315 20:54:18.664540 29479 solver.cpp:229]     Train net output #0: loss = 4355.31 (* 1 = 4355.31 loss)
I0315 20:54:19.027693 29479 solver.cpp:610] Iteration 58000, lr = 7.34738e-09
I0315 20:54:19.027712 29479 solver.cpp:613] Iteration 58000, avg_grad_norm = 498116
I0315 20:55:28.129988 29479 solver.cpp:214] Iteration 58020, loss = 6134.84
I0315 20:55:28.130134 29479 solver.cpp:229]     Train net output #0: loss = 3885.84 (* 1 = 3885.84 loss)
I0315 20:55:28.495530 29479 solver.cpp:610] Iteration 58020, lr = 7.34645e-09
I0315 20:55:28.495581 29479 solver.cpp:613] Iteration 58020, avg_grad_norm = 532701
I0315 20:56:50.995317 29479 solver.cpp:214] Iteration 58040, loss = 6135.33
I0315 20:56:50.995462 29479 solver.cpp:229]     Train net output #0: loss = 7564.69 (* 1 = 7564.69 loss)
I0315 20:56:51.364542 29479 solver.cpp:610] Iteration 58040, lr = 7.34552e-09
I0315 20:56:51.364557 29479 solver.cpp:613] Iteration 58040, avg_grad_norm = 643484
I0315 20:57:58.191193 29479 solver.cpp:214] Iteration 58060, loss = 5686.02
I0315 20:57:58.191398 29479 solver.cpp:229]     Train net output #0: loss = 5275.27 (* 1 = 5275.27 loss)
I0315 20:57:58.556205 29479 solver.cpp:610] Iteration 58060, lr = 7.34459e-09
I0315 20:57:58.556219 29479 solver.cpp:613] Iteration 58060, avg_grad_norm = 601290
I0315 20:58:40.368029 29479 solver.cpp:214] Iteration 58080, loss = 5942.58
I0315 20:58:40.368160 29479 solver.cpp:229]     Train net output #0: loss = 10884.2 (* 1 = 10884.2 loss)
I0315 20:58:40.728301 29479 solver.cpp:610] Iteration 58080, lr = 7.34365e-09
I0315 20:58:40.728314 29479 solver.cpp:613] Iteration 58080, avg_grad_norm = 497713
I0315 20:59:49.886123 29479 solver.cpp:214] Iteration 58100, loss = 5909.77
I0315 20:59:49.886246 29479 solver.cpp:229]     Train net output #0: loss = 11080.7 (* 1 = 11080.7 loss)
I0315 20:59:50.255908 29479 solver.cpp:610] Iteration 58100, lr = 7.34272e-09
I0315 20:59:50.255923 29479 solver.cpp:613] Iteration 58100, avg_grad_norm = 501764
I0315 21:00:59.024061 29479 solver.cpp:214] Iteration 58120, loss = 6015.95
I0315 21:00:59.024250 29479 solver.cpp:229]     Train net output #0: loss = 3729.71 (* 1 = 3729.71 loss)
I0315 21:00:59.389966 29479 solver.cpp:610] Iteration 58120, lr = 7.34179e-09
I0315 21:00:59.389981 29479 solver.cpp:613] Iteration 58120, avg_grad_norm = 581450
I0315 21:02:06.544920 29479 solver.cpp:214] Iteration 58140, loss = 5999.38
I0315 21:02:06.545068 29479 solver.cpp:229]     Train net output #0: loss = 5266.19 (* 1 = 5266.19 loss)
I0315 21:02:06.905810 29479 solver.cpp:610] Iteration 58140, lr = 7.34086e-09
I0315 21:02:06.905823 29479 solver.cpp:613] Iteration 58140, avg_grad_norm = 582560
I0315 21:03:16.313379 29479 solver.cpp:214] Iteration 58160, loss = 6109.19
I0315 21:03:16.313499 29479 solver.cpp:229]     Train net output #0: loss = 6762.23 (* 1 = 6762.23 loss)
I0315 21:03:16.672106 29479 solver.cpp:610] Iteration 58160, lr = 7.33993e-09
I0315 21:03:16.672121 29479 solver.cpp:613] Iteration 58160, avg_grad_norm = 572368
I0315 21:04:46.149531 29479 solver.cpp:214] Iteration 58180, loss = 5940
I0315 21:04:46.149664 29479 solver.cpp:229]     Train net output #0: loss = 8645.65 (* 1 = 8645.65 loss)
I0315 21:04:46.337816 29479 solver.cpp:610] Iteration 58180, lr = 7.339e-09
I0315 21:04:46.337829 29479 solver.cpp:613] Iteration 58180, avg_grad_norm = 541739
I0315 21:05:39.593478 29479 solver.cpp:214] Iteration 58200, loss = 6233.51
I0315 21:05:39.593592 29479 solver.cpp:229]     Train net output #0: loss = 9421.58 (* 1 = 9421.58 loss)
I0315 21:05:39.709470 29479 solver.cpp:610] Iteration 58200, lr = 7.33807e-09
I0315 21:05:39.709518 29479 solver.cpp:613] Iteration 58200, avg_grad_norm = 528371
I0315 21:06:39.752600 29479 solver.cpp:214] Iteration 58220, loss = 6076.96
I0315 21:06:39.752758 29479 solver.cpp:229]     Train net output #0: loss = 5782.75 (* 1 = 5782.75 loss)
I0315 21:06:40.113170 29479 solver.cpp:610] Iteration 58220, lr = 7.33713e-09
I0315 21:06:40.113185 29479 solver.cpp:613] Iteration 58220, avg_grad_norm = 530756
I0315 21:07:49.142248 29479 solver.cpp:214] Iteration 58240, loss = 6194.45
I0315 21:07:49.142385 29479 solver.cpp:229]     Train net output #0: loss = 3859.31 (* 1 = 3859.31 loss)
I0315 21:07:49.508375 29479 solver.cpp:610] Iteration 58240, lr = 7.3362e-09
I0315 21:07:49.508415 29479 solver.cpp:613] Iteration 58240, avg_grad_norm = 522848
I0315 21:08:58.379005 29479 solver.cpp:214] Iteration 58260, loss = 5776.33
I0315 21:08:58.379132 29479 solver.cpp:229]     Train net output #0: loss = 9134.34 (* 1 = 9134.34 loss)
I0315 21:08:58.739027 29479 solver.cpp:610] Iteration 58260, lr = 7.33527e-09
I0315 21:08:58.739042 29479 solver.cpp:613] Iteration 58260, avg_grad_norm = 574881
I0315 21:10:08.106434 29479 solver.cpp:214] Iteration 58280, loss = 5964.06
I0315 21:10:08.106575 29479 solver.cpp:229]     Train net output #0: loss = 4298.71 (* 1 = 4298.71 loss)
I0315 21:10:08.473379 29479 solver.cpp:610] Iteration 58280, lr = 7.33434e-09
I0315 21:10:08.473393 29479 solver.cpp:613] Iteration 58280, avg_grad_norm = 567626
I0315 21:11:36.904400 29479 solver.cpp:214] Iteration 58300, loss = 5718.68
I0315 21:11:36.904613 29479 solver.cpp:229]     Train net output #0: loss = 5280.77 (* 1 = 5280.77 loss)
I0315 21:11:37.269820 29479 solver.cpp:610] Iteration 58300, lr = 7.33341e-09
I0315 21:11:37.269834 29479 solver.cpp:613] Iteration 58300, avg_grad_norm = 536150
I0315 21:12:45.676420 29479 solver.cpp:214] Iteration 58320, loss = 5860.79
I0315 21:12:45.676600 29479 solver.cpp:229]     Train net output #0: loss = 5423.95 (* 1 = 5423.95 loss)
I0315 21:12:46.045114 29479 solver.cpp:610] Iteration 58320, lr = 7.33248e-09
I0315 21:12:46.045130 29479 solver.cpp:613] Iteration 58320, avg_grad_norm = 554342
I0315 21:13:30.322093 29479 solver.cpp:214] Iteration 58340, loss = 6020.9
I0315 21:13:30.322218 29479 solver.cpp:229]     Train net output #0: loss = 4356.24 (* 1 = 4356.24 loss)
I0315 21:13:30.681689 29479 solver.cpp:610] Iteration 58340, lr = 7.33155e-09
I0315 21:13:30.681702 29479 solver.cpp:613] Iteration 58340, avg_grad_norm = 483898
I0315 21:14:39.172596 29479 solver.cpp:214] Iteration 58360, loss = 5584.03
I0315 21:14:39.172801 29479 solver.cpp:229]     Train net output #0: loss = 5573.88 (* 1 = 5573.88 loss)
I0315 21:14:39.538975 29479 solver.cpp:610] Iteration 58360, lr = 7.33061e-09
I0315 21:14:39.538990 29479 solver.cpp:613] Iteration 58360, avg_grad_norm = 453530
I0315 21:15:47.101027 29479 solver.cpp:214] Iteration 58380, loss = 6086.46
I0315 21:15:47.101161 29479 solver.cpp:229]     Train net output #0: loss = 7444.32 (* 1 = 7444.32 loss)
I0315 21:15:47.466241 29479 solver.cpp:610] Iteration 58380, lr = 7.32968e-09
I0315 21:15:47.466260 29479 solver.cpp:613] Iteration 58380, avg_grad_norm = 587353
I0315 21:16:51.073834 29479 solver.cpp:214] Iteration 58400, loss = 6100.38
I0315 21:16:51.073989 29479 solver.cpp:229]     Train net output #0: loss = 9736.34 (* 1 = 9736.34 loss)
I0315 21:16:51.439335 29479 solver.cpp:610] Iteration 58400, lr = 7.32875e-09
I0315 21:16:51.439349 29479 solver.cpp:613] Iteration 58400, avg_grad_norm = 570772
I0315 21:18:15.117835 29479 solver.cpp:214] Iteration 58420, loss = 6196.76
I0315 21:18:15.117986 29479 solver.cpp:229]     Train net output #0: loss = 4329.39 (* 1 = 4329.39 loss)
I0315 21:18:15.478797 29479 solver.cpp:610] Iteration 58420, lr = 7.32782e-09
I0315 21:18:15.478811 29479 solver.cpp:613] Iteration 58420, avg_grad_norm = 514798
I0315 21:19:23.378954 29479 solver.cpp:214] Iteration 58440, loss = 5722.19
I0315 21:19:23.379142 29479 solver.cpp:229]     Train net output #0: loss = 3361.56 (* 1 = 3361.56 loss)
I0315 21:19:23.741643 29479 solver.cpp:610] Iteration 58440, lr = 7.32689e-09
I0315 21:19:23.741657 29479 solver.cpp:613] Iteration 58440, avg_grad_norm = 579195
I0315 21:20:32.845566 29479 solver.cpp:214] Iteration 58460, loss = 5987.38
I0315 21:20:32.845687 29479 solver.cpp:229]     Train net output #0: loss = 4865.12 (* 1 = 4865.12 loss)
I0315 21:20:33.213050 29479 solver.cpp:610] Iteration 58460, lr = 7.32596e-09
I0315 21:20:33.213063 29479 solver.cpp:613] Iteration 58460, avg_grad_norm = 569957
I0315 21:21:17.967684 29479 solver.cpp:214] Iteration 58480, loss = 5636.63
I0315 21:21:17.967833 29479 solver.cpp:229]     Train net output #0: loss = 4528.71 (* 1 = 4528.71 loss)
I0315 21:21:18.301802 29479 solver.cpp:610] Iteration 58480, lr = 7.32502e-09
I0315 21:21:18.301815 29479 solver.cpp:613] Iteration 58480, avg_grad_norm = 602503
I0315 21:22:26.895290 29479 solver.cpp:214] Iteration 58500, loss = 5747.27
I0315 21:22:26.895408 29479 solver.cpp:229]     Train net output #0: loss = 6576.07 (* 1 = 6576.07 loss)
I0315 21:22:27.255092 29479 solver.cpp:610] Iteration 58500, lr = 7.32409e-09
I0315 21:22:27.255107 29479 solver.cpp:613] Iteration 58500, avg_grad_norm = 512578
I0315 21:23:36.338419 29479 solver.cpp:214] Iteration 58520, loss = 5674.49
I0315 21:23:36.338536 29479 solver.cpp:229]     Train net output #0: loss = 4874.41 (* 1 = 4874.41 loss)
I0315 21:23:36.705196 29479 solver.cpp:610] Iteration 58520, lr = 7.32316e-09
I0315 21:23:36.705214 29479 solver.cpp:613] Iteration 58520, avg_grad_norm = 535638
I0315 21:24:45.954929 29479 solver.cpp:214] Iteration 58540, loss = 5946.5
I0315 21:24:45.955055 29479 solver.cpp:229]     Train net output #0: loss = 6891.56 (* 1 = 6891.56 loss)
I0315 21:24:46.314173 29479 solver.cpp:610] Iteration 58540, lr = 7.32223e-09
I0315 21:24:46.314188 29479 solver.cpp:613] Iteration 58540, avg_grad_norm = 549274
I0315 21:26:08.270490 29479 solver.cpp:214] Iteration 58560, loss = 5812.93
I0315 21:26:08.270691 29479 solver.cpp:229]     Train net output #0: loss = 8234.48 (* 1 = 8234.48 loss)
I0315 21:26:08.629946 29479 solver.cpp:610] Iteration 58560, lr = 7.3213e-09
I0315 21:26:08.629971 29479 solver.cpp:613] Iteration 58560, avg_grad_norm = 629971
I0315 21:27:16.790073 29479 solver.cpp:214] Iteration 58580, loss = 5826.61
I0315 21:27:16.790196 29479 solver.cpp:229]     Train net output #0: loss = 3562.23 (* 1 = 3562.23 loss)
I0315 21:27:17.180392 29479 solver.cpp:610] Iteration 58580, lr = 7.32037e-09
I0315 21:27:17.180405 29479 solver.cpp:613] Iteration 58580, avg_grad_norm = 668466
I0315 21:28:12.864193 29479 solver.cpp:214] Iteration 58600, loss = 5891.05
I0315 21:28:12.864377 29479 solver.cpp:229]     Train net output #0: loss = 7179.1 (* 1 = 7179.1 loss)
I0315 21:28:12.980331 29479 solver.cpp:610] Iteration 58600, lr = 7.31943e-09
I0315 21:28:12.980368 29479 solver.cpp:613] Iteration 58600, avg_grad_norm = 608196
I0315 21:28:56.592535 29479 solver.cpp:214] Iteration 58620, loss = 5945.41
I0315 21:28:56.592666 29479 solver.cpp:229]     Train net output #0: loss = 2188.83 (* 1 = 2188.83 loss)
I0315 21:28:56.953222 29479 solver.cpp:610] Iteration 58620, lr = 7.3185e-09
I0315 21:28:56.953235 29479 solver.cpp:613] Iteration 58620, avg_grad_norm = 493471
I0315 21:30:06.185386 29479 solver.cpp:214] Iteration 58640, loss = 5536.18
I0315 21:30:06.185523 29479 solver.cpp:229]     Train net output #0: loss = 3518.24 (* 1 = 3518.24 loss)
I0315 21:30:06.552011 29479 solver.cpp:610] Iteration 58640, lr = 7.31757e-09
I0315 21:30:06.552027 29479 solver.cpp:613] Iteration 58640, avg_grad_norm = 584203
I0315 21:31:15.693518 29479 solver.cpp:214] Iteration 58660, loss = 5972.69
I0315 21:31:15.693758 29479 solver.cpp:229]     Train net output #0: loss = 4038.44 (* 1 = 4038.44 loss)
I0315 21:31:16.060520 29479 solver.cpp:610] Iteration 58660, lr = 7.31664e-09
I0315 21:31:16.060534 29479 solver.cpp:613] Iteration 58660, avg_grad_norm = 513783
I0315 21:32:42.505765 29479 solver.cpp:214] Iteration 58680, loss = 5952.78
I0315 21:32:42.505969 29479 solver.cpp:229]     Train net output #0: loss = 3841.98 (* 1 = 3841.98 loss)
I0315 21:32:42.869689 29479 solver.cpp:610] Iteration 58680, lr = 7.31571e-09
I0315 21:32:42.869704 29479 solver.cpp:613] Iteration 58680, avg_grad_norm = 573718
I0315 21:33:51.613497 29479 solver.cpp:214] Iteration 58700, loss = 6007.56
I0315 21:33:51.613629 29479 solver.cpp:229]     Train net output #0: loss = 3573.08 (* 1 = 3573.08 loss)
I0315 21:33:51.980931 29479 solver.cpp:610] Iteration 58700, lr = 7.31477e-09
I0315 21:33:51.980945 29479 solver.cpp:613] Iteration 58700, avg_grad_norm = 500409
I0315 21:35:00.706226 29479 solver.cpp:214] Iteration 58720, loss = 5803.32
I0315 21:35:00.706338 29479 solver.cpp:229]     Train net output #0: loss = 5044.74 (* 1 = 5044.74 loss)
I0315 21:35:01.072615 29479 solver.cpp:610] Iteration 58720, lr = 7.31384e-09
I0315 21:35:01.072628 29479 solver.cpp:613] Iteration 58720, avg_grad_norm = 550277
I0315 21:35:53.133386 29479 solver.cpp:214] Iteration 58740, loss = 5863.21
I0315 21:35:53.133508 29479 solver.cpp:229]     Train net output #0: loss = 4497.95 (* 1 = 4497.95 loss)
I0315 21:35:53.249485 29479 solver.cpp:610] Iteration 58740, lr = 7.31291e-09
I0315 21:35:53.249519 29479 solver.cpp:613] Iteration 58740, avg_grad_norm = 599270
I0315 21:36:56.625458 29479 solver.cpp:214] Iteration 58760, loss = 6060.19
I0315 21:36:56.625593 29479 solver.cpp:229]     Train net output #0: loss = 7839.29 (* 1 = 7839.29 loss)
I0315 21:36:56.994406 29479 solver.cpp:610] Iteration 58760, lr = 7.31198e-09
I0315 21:36:56.994421 29479 solver.cpp:613] Iteration 58760, avg_grad_norm = 576682
I0315 21:38:06.199089 29479 solver.cpp:214] Iteration 58780, loss = 6323.75
I0315 21:38:06.199218 29479 solver.cpp:229]     Train net output #0: loss = 8443.65 (* 1 = 8443.65 loss)
I0315 21:38:06.565083 29479 solver.cpp:610] Iteration 58780, lr = 7.31105e-09
I0315 21:38:06.565098 29479 solver.cpp:613] Iteration 58780, avg_grad_norm = 520605
I0315 21:39:39.732625 29479 solver.cpp:214] Iteration 58800, loss = 6014.65
I0315 21:39:39.732782 29479 solver.cpp:229]     Train net output #0: loss = 5770.29 (* 1 = 5770.29 loss)
I0315 21:39:40.094964 29479 solver.cpp:610] Iteration 58800, lr = 7.31012e-09
I0315 21:39:40.094979 29479 solver.cpp:613] Iteration 58800, avg_grad_norm = 528985
I0315 21:40:47.810477 29479 solver.cpp:214] Iteration 58820, loss = 5731.92
I0315 21:40:47.810595 29479 solver.cpp:229]     Train net output #0: loss = 7258.16 (* 1 = 7258.16 loss)
I0315 21:40:48.179054 29479 solver.cpp:610] Iteration 58820, lr = 7.30918e-09
I0315 21:40:48.179067 29479 solver.cpp:613] Iteration 58820, avg_grad_norm = 569196
I0315 21:41:56.393993 29479 solver.cpp:214] Iteration 58840, loss = 5951.48
I0315 21:41:56.394246 29479 solver.cpp:229]     Train net output #0: loss = 5755.52 (* 1 = 5755.52 loss)
I0315 21:41:56.754360 29479 solver.cpp:610] Iteration 58840, lr = 7.30825e-09
I0315 21:41:56.754374 29479 solver.cpp:613] Iteration 58840, avg_grad_norm = 666027
I0315 21:43:04.362562 29479 solver.cpp:214] Iteration 58860, loss = 5938.32
I0315 21:43:04.362689 29479 solver.cpp:229]     Train net output #0: loss = 2037.5 (* 1 = 2037.5 loss)
I0315 21:43:04.731009 29479 solver.cpp:610] Iteration 58860, lr = 7.30732e-09
I0315 21:43:04.731027 29479 solver.cpp:613] Iteration 58860, avg_grad_norm = 638459
I0315 21:43:49.685179 29479 solver.cpp:214] Iteration 58880, loss = 5775.12
I0315 21:43:49.685374 29479 solver.cpp:229]     Train net output #0: loss = 4409.38 (* 1 = 4409.38 loss)
I0315 21:43:50.048178 29479 solver.cpp:610] Iteration 58880, lr = 7.30639e-09
I0315 21:43:50.048192 29479 solver.cpp:613] Iteration 58880, avg_grad_norm = 537393
I0315 21:44:59.252661 29479 solver.cpp:214] Iteration 58900, loss = 5790.75
I0315 21:44:59.252878 29479 solver.cpp:229]     Train net output #0: loss = 5504.6 (* 1 = 5504.6 loss)
I0315 21:44:59.611379 29479 solver.cpp:610] Iteration 58900, lr = 7.30546e-09
I0315 21:44:59.611393 29479 solver.cpp:613] Iteration 58900, avg_grad_norm = 493525
I0315 21:46:08.845758 29479 solver.cpp:214] Iteration 58920, loss = 5876.5
I0315 21:46:08.845890 29479 solver.cpp:229]     Train net output #0: loss = 5158.2 (* 1 = 5158.2 loss)
I0315 21:46:09.230911 29479 solver.cpp:610] Iteration 58920, lr = 7.30452e-09
I0315 21:46:09.230924 29479 solver.cpp:613] Iteration 58920, avg_grad_norm = 523143
I0315 21:47:32.736809 29479 solver.cpp:214] Iteration 58940, loss = 5929.63
I0315 21:47:32.737025 29479 solver.cpp:229]     Train net output #0: loss = 5842.96 (* 1 = 5842.96 loss)
I0315 21:47:33.102465 29479 solver.cpp:610] Iteration 58940, lr = 7.30359e-09
I0315 21:47:33.102501 29479 solver.cpp:613] Iteration 58940, avg_grad_norm = 552498
I0315 21:48:41.688458 29479 solver.cpp:214] Iteration 58960, loss = 5789.8
I0315 21:48:41.688580 29479 solver.cpp:229]     Train net output #0: loss = 3476.32 (* 1 = 3476.32 loss)
I0315 21:48:42.078904 29479 solver.cpp:610] Iteration 58960, lr = 7.30266e-09
I0315 21:48:42.078920 29479 solver.cpp:613] Iteration 58960, avg_grad_norm = 493403
I0315 21:49:49.963240 29479 solver.cpp:214] Iteration 58980, loss = 5666.54
I0315 21:49:49.963376 29479 solver.cpp:229]     Train net output #0: loss = 5308.85 (* 1 = 5308.85 loss)
I0315 21:49:50.353298 29479 solver.cpp:610] Iteration 58980, lr = 7.30173e-09
I0315 21:49:50.353312 29479 solver.cpp:613] Iteration 58980, avg_grad_norm = 500418
I0315 21:50:46.393851 29479 solver.cpp:214] Iteration 59000, loss = 5638.27
I0315 21:50:46.393985 29479 solver.cpp:229]     Train net output #0: loss = 3309.57 (* 1 = 3309.57 loss)
I0315 21:50:46.510059 29479 solver.cpp:610] Iteration 59000, lr = 7.3008e-09
I0315 21:50:46.510077 29479 solver.cpp:613] Iteration 59000, avg_grad_norm = 533722
I0315 21:51:41.604257 29479 solver.cpp:214] Iteration 59020, loss = 5912.13
I0315 21:51:41.604404 29479 solver.cpp:229]     Train net output #0: loss = 5945.65 (* 1 = 5945.65 loss)
I0315 21:51:41.791900 29479 solver.cpp:610] Iteration 59020, lr = 7.29986e-09
I0315 21:51:41.791913 29479 solver.cpp:613] Iteration 59020, avg_grad_norm = 482937
I0315 21:52:48.807312 29479 solver.cpp:214] Iteration 59040, loss = 6008.29
I0315 21:52:48.807500 29479 solver.cpp:229]     Train net output #0: loss = 6248.36 (* 1 = 6248.36 loss)
I0315 21:52:49.165997 29479 solver.cpp:610] Iteration 59040, lr = 7.29893e-09
I0315 21:52:49.166009 29479 solver.cpp:613] Iteration 59040, avg_grad_norm = 485390
I0315 21:54:10.962198 29479 solver.cpp:214] Iteration 59060, loss = 5786.25
I0315 21:54:10.962316 29479 solver.cpp:229]     Train net output #0: loss = 7894.36 (* 1 = 7894.36 loss)
I0315 21:54:11.337666 29479 solver.cpp:610] Iteration 59060, lr = 7.298e-09
I0315 21:54:11.337679 29479 solver.cpp:613] Iteration 59060, avg_grad_norm = 493748
I0315 21:55:18.918114 29479 solver.cpp:214] Iteration 59080, loss = 5995.74
I0315 21:55:18.918303 29479 solver.cpp:229]     Train net output #0: loss = 9203.33 (* 1 = 9203.33 loss)
I0315 21:55:19.277623 29479 solver.cpp:610] Iteration 59080, lr = 7.29707e-09
I0315 21:55:19.277637 29479 solver.cpp:613] Iteration 59080, avg_grad_norm = 475499
I0315 21:56:28.206910 29479 solver.cpp:214] Iteration 59100, loss = 5978.21
I0315 21:56:28.207100 29479 solver.cpp:229]     Train net output #0: loss = 5757.9 (* 1 = 5757.9 loss)
I0315 21:56:28.572744 29479 solver.cpp:610] Iteration 59100, lr = 7.29614e-09
I0315 21:56:28.572758 29479 solver.cpp:613] Iteration 59100, avg_grad_norm = 539492
I0315 21:57:36.965657 29479 solver.cpp:214] Iteration 59120, loss = 5579.88
I0315 21:57:36.965858 29479 solver.cpp:229]     Train net output #0: loss = 4403.54 (* 1 = 4403.54 loss)
I0315 21:57:37.334825 29479 solver.cpp:610] Iteration 59120, lr = 7.2952e-09
I0315 21:57:37.334838 29479 solver.cpp:613] Iteration 59120, avg_grad_norm = 537283
I0315 21:58:26.177115 29479 solver.cpp:214] Iteration 59140, loss = 6139.69
I0315 21:58:26.177250 29479 solver.cpp:229]     Train net output #0: loss = 9733.34 (* 1 = 9733.34 loss)
I0315 21:58:26.293310 29479 solver.cpp:610] Iteration 59140, lr = 7.29427e-09
I0315 21:58:26.293349 29479 solver.cpp:613] Iteration 59140, avg_grad_norm = 568209
I0315 21:59:32.395354 29479 solver.cpp:214] Iteration 59160, loss = 5688.9
I0315 21:59:32.395560 29479 solver.cpp:229]     Train net output #0: loss = 4734.41 (* 1 = 4734.41 loss)
I0315 21:59:32.756211 29479 solver.cpp:610] Iteration 59160, lr = 7.29334e-09
I0315 21:59:32.756227 29479 solver.cpp:613] Iteration 59160, avg_grad_norm = 570301
I0315 22:01:03.183851 29479 solver.cpp:214] Iteration 59180, loss = 5984.12
I0315 22:01:03.183984 29479 solver.cpp:229]     Train net output #0: loss = 5636.95 (* 1 = 5636.95 loss)
I0315 22:01:03.542850 29479 solver.cpp:610] Iteration 59180, lr = 7.29241e-09
I0315 22:01:03.542867 29479 solver.cpp:613] Iteration 59180, avg_grad_norm = 537798
I0315 22:02:11.775110 29479 solver.cpp:214] Iteration 59200, loss = 5679.82
I0315 22:02:11.775251 29479 solver.cpp:229]     Train net output #0: loss = 5223.71 (* 1 = 5223.71 loss)
I0315 22:02:12.150801 29479 solver.cpp:610] Iteration 59200, lr = 7.29147e-09
I0315 22:02:12.150815 29479 solver.cpp:613] Iteration 59200, avg_grad_norm = 551103
I0315 22:03:20.591737 29479 solver.cpp:214] Iteration 59220, loss = 5843.51
I0315 22:03:20.591857 29479 solver.cpp:229]     Train net output #0: loss = 4011.31 (* 1 = 4011.31 loss)
I0315 22:03:20.788579 29479 solver.cpp:610] Iteration 59220, lr = 7.29054e-09
I0315 22:03:20.788592 29479 solver.cpp:613] Iteration 59220, avg_grad_norm = 522774
I0315 22:04:28.599283 29479 solver.cpp:214] Iteration 59240, loss = 6086.96
I0315 22:04:28.599421 29479 solver.cpp:229]     Train net output #0: loss = 7307.26 (* 1 = 7307.26 loss)
I0315 22:04:28.962702 29479 solver.cpp:610] Iteration 59240, lr = 7.28961e-09
I0315 22:04:28.962714 29479 solver.cpp:613] Iteration 59240, avg_grad_norm = 562879
I0315 22:05:36.920264 29479 solver.cpp:214] Iteration 59260, loss = 5948.4
I0315 22:05:36.920415 29479 solver.cpp:229]     Train net output #0: loss = 6386.14 (* 1 = 6386.14 loss)
I0315 22:05:37.289053 29479 solver.cpp:610] Iteration 59260, lr = 7.28868e-09
I0315 22:05:37.289068 29479 solver.cpp:613] Iteration 59260, avg_grad_norm = 509194
I0315 22:06:22.677016 29479 solver.cpp:214] Iteration 59280, loss = 5995.39
I0315 22:06:22.677191 29479 solver.cpp:229]     Train net output #0: loss = 4251.05 (* 1 = 4251.05 loss)
I0315 22:06:23.037667 29479 solver.cpp:610] Iteration 59280, lr = 7.28775e-09
I0315 22:06:23.037680 29479 solver.cpp:613] Iteration 59280, avg_grad_norm = 512381
I0315 22:07:32.224023 29479 solver.cpp:214] Iteration 59300, loss = 6015.96
I0315 22:07:32.224218 29479 solver.cpp:229]     Train net output #0: loss = 5329.65 (* 1 = 5329.65 loss)
I0315 22:07:32.584769 29479 solver.cpp:610] Iteration 59300, lr = 7.28681e-09
I0315 22:07:32.584782 29479 solver.cpp:613] Iteration 59300, avg_grad_norm = 507945
I0315 22:08:54.658128 29479 solver.cpp:214] Iteration 59320, loss = 6193
I0315 22:08:54.658370 29479 solver.cpp:229]     Train net output #0: loss = 7222.12 (* 1 = 7222.12 loss)
I0315 22:08:55.020889 29479 solver.cpp:610] Iteration 59320, lr = 7.28588e-09
I0315 22:08:55.020903 29479 solver.cpp:613] Iteration 59320, avg_grad_norm = 547793
I0315 22:10:02.696296 29479 solver.cpp:214] Iteration 59340, loss = 5856.98
I0315 22:10:02.696435 29479 solver.cpp:229]     Train net output #0: loss = 6223.38 (* 1 = 6223.38 loss)
I0315 22:10:02.900624 29479 solver.cpp:610] Iteration 59340, lr = 7.28495e-09
I0315 22:10:02.900637 29479 solver.cpp:613] Iteration 59340, avg_grad_norm = 505666
I0315 22:11:10.693362 29479 solver.cpp:214] Iteration 59360, loss = 5868.17
I0315 22:11:10.693496 29479 solver.cpp:229]     Train net output #0: loss = 4659.39 (* 1 = 4659.39 loss)
I0315 22:11:11.063377 29479 solver.cpp:610] Iteration 59360, lr = 7.28402e-09
I0315 22:11:11.063390 29479 solver.cpp:613] Iteration 59360, avg_grad_norm = 510190
I0315 22:12:18.958853 29479 solver.cpp:214] Iteration 59380, loss = 5753.42
I0315 22:12:18.958986 29479 solver.cpp:229]     Train net output #0: loss = 5698.9 (* 1 = 5698.9 loss)
I0315 22:12:19.328263 29479 solver.cpp:610] Iteration 59380, lr = 7.28308e-09
I0315 22:12:19.328275 29479 solver.cpp:613] Iteration 59380, avg_grad_norm = 498941
I0315 22:13:20.243454 29479 solver.cpp:214] Iteration 59400, loss = 6214.51
I0315 22:13:20.243592 29479 solver.cpp:229]     Train net output #0: loss = 8028.09 (* 1 = 8028.09 loss)
I0315 22:13:20.352434 29479 solver.cpp:610] Iteration 59400, lr = 7.28215e-09
I0315 22:13:20.352448 29479 solver.cpp:613] Iteration 59400, avg_grad_norm = 549133
I0315 22:14:13.702425 29479 solver.cpp:214] Iteration 59420, loss = 6104.29
I0315 22:14:13.702613 29479 solver.cpp:229]     Train net output #0: loss = 8315.41 (* 1 = 8315.41 loss)
I0315 22:14:14.071704 29479 solver.cpp:610] Iteration 59420, lr = 7.28122e-09
I0315 22:14:14.071718 29479 solver.cpp:613] Iteration 59420, avg_grad_norm = 628277
I0315 22:15:36.777223 29479 solver.cpp:214] Iteration 59440, loss = 6039.67
I0315 22:15:36.777428 29479 solver.cpp:229]     Train net output #0: loss = 4424.57 (* 1 = 4424.57 loss)
I0315 22:15:37.106493 29479 solver.cpp:610] Iteration 59440, lr = 7.28029e-09
I0315 22:15:37.106525 29479 solver.cpp:613] Iteration 59440, avg_grad_norm = 652402
I0315 22:16:44.321319 29479 solver.cpp:214] Iteration 59460, loss = 5923.19
I0315 22:16:44.321449 29479 solver.cpp:229]     Train net output #0: loss = 9391.44 (* 1 = 9391.44 loss)
I0315 22:16:44.688246 29479 solver.cpp:610] Iteration 59460, lr = 7.27936e-09
I0315 22:16:44.688258 29479 solver.cpp:613] Iteration 59460, avg_grad_norm = 550838
I0315 22:17:52.446730 29479 solver.cpp:214] Iteration 59480, loss = 5845.68
I0315 22:17:52.446841 29479 solver.cpp:229]     Train net output #0: loss = 8440.21 (* 1 = 8440.21 loss)
I0315 22:17:52.809710 29479 solver.cpp:610] Iteration 59480, lr = 7.27842e-09
I0315 22:17:52.809723 29479 solver.cpp:613] Iteration 59480, avg_grad_norm = 520007
I0315 22:19:00.356436 29479 solver.cpp:214] Iteration 59500, loss = 6148.79
I0315 22:19:00.356627 29479 solver.cpp:229]     Train net output #0: loss = 4384.32 (* 1 = 4384.32 loss)
I0315 22:19:00.699527 29479 solver.cpp:610] Iteration 59500, lr = 7.27749e-09
I0315 22:19:00.699542 29479 solver.cpp:613] Iteration 59500, avg_grad_norm = 536015
I0315 22:20:08.939601 29479 solver.cpp:214] Iteration 59520, loss = 5561.17
I0315 22:20:08.939729 29479 solver.cpp:229]     Train net output #0: loss = 4380.14 (* 1 = 4380.14 loss)
I0315 22:20:09.303426 29479 solver.cpp:610] Iteration 59520, lr = 7.27656e-09
I0315 22:20:09.303439 29479 solver.cpp:613] Iteration 59520, avg_grad_norm = 531293
I0315 22:21:00.172996 29479 solver.cpp:214] Iteration 59540, loss = 5932.68
I0315 22:21:00.173161 29479 solver.cpp:229]     Train net output #0: loss = 4465.63 (* 1 = 4465.63 loss)
I0315 22:21:00.287782 29479 solver.cpp:610] Iteration 59540, lr = 7.27563e-09
I0315 22:21:00.287832 29479 solver.cpp:613] Iteration 59540, avg_grad_norm = 509078
I0315 22:22:16.416808 29479 solver.cpp:214] Iteration 59560, loss = 6019.58
I0315 22:22:16.416977 29479 solver.cpp:229]     Train net output #0: loss = 9248.42 (* 1 = 9248.42 loss)
I0315 22:22:16.775133 29479 solver.cpp:610] Iteration 59560, lr = 7.27469e-09
I0315 22:22:16.775147 29479 solver.cpp:613] Iteration 59560, avg_grad_norm = 514535
I0315 22:23:23.904263 29479 solver.cpp:214] Iteration 59580, loss = 5540.86
I0315 22:23:23.904441 29479 solver.cpp:229]     Train net output #0: loss = 4988.95 (* 1 = 4988.95 loss)
I0315 22:23:24.265460 29479 solver.cpp:610] Iteration 59580, lr = 7.27376e-09
I0315 22:23:24.265472 29479 solver.cpp:613] Iteration 59580, avg_grad_norm = 477309
I0315 22:24:32.323611 29479 solver.cpp:214] Iteration 59600, loss = 5759.16
I0315 22:24:32.323755 29479 solver.cpp:229]     Train net output #0: loss = 6328.34 (* 1 = 6328.34 loss)
I0315 22:24:32.532387 29479 solver.cpp:610] Iteration 59600, lr = 7.27283e-09
I0315 22:24:32.532399 29479 solver.cpp:613] Iteration 59600, avg_grad_norm = 480502
I0315 22:25:40.236846 29479 solver.cpp:214] Iteration 59620, loss = 5868.47
I0315 22:25:40.237021 29479 solver.cpp:229]     Train net output #0: loss = 6931.2 (* 1 = 6931.2 loss)
I0315 22:25:40.602442 29479 solver.cpp:610] Iteration 59620, lr = 7.2719e-09
I0315 22:25:40.602455 29479 solver.cpp:613] Iteration 59620, avg_grad_norm = 484951
I0315 22:26:48.339465 29479 solver.cpp:214] Iteration 59640, loss = 6072.71
I0315 22:26:48.339615 29479 solver.cpp:229]     Train net output #0: loss = 3562 (* 1 = 3562 loss)
I0315 22:26:48.703250 29479 solver.cpp:610] Iteration 59640, lr = 7.27096e-09
I0315 22:26:48.703264 29479 solver.cpp:613] Iteration 59640, avg_grad_norm = 615954
I0315 22:27:56.806404 29479 solver.cpp:214] Iteration 59660, loss = 5844.4
I0315 22:27:56.806541 29479 solver.cpp:229]     Train net output #0: loss = 7223.18 (* 1 = 7223.18 loss)
I0315 22:27:57.171411 29479 solver.cpp:610] Iteration 59660, lr = 7.27003e-09
I0315 22:27:57.171427 29479 solver.cpp:613] Iteration 59660, avg_grad_norm = 521148
I0315 22:28:42.596972 29479 solver.cpp:214] Iteration 59680, loss = 6164.69
I0315 22:28:42.597159 29479 solver.cpp:229]     Train net output #0: loss = 10675.1 (* 1 = 10675.1 loss)
I0315 22:28:42.988378 29479 solver.cpp:610] Iteration 59680, lr = 7.2691e-09
I0315 22:28:42.988390 29479 solver.cpp:613] Iteration 59680, avg_grad_norm = 518967
I0315 22:30:04.578434 29479 solver.cpp:214] Iteration 59700, loss = 6010.4
I0315 22:30:04.578570 29479 solver.cpp:229]     Train net output #0: loss = 4701.03 (* 1 = 4701.03 loss)
I0315 22:30:04.782601 29479 solver.cpp:610] Iteration 59700, lr = 7.26817e-09
I0315 22:30:04.782614 29479 solver.cpp:613] Iteration 59700, avg_grad_norm = 599299
I0315 22:31:08.445158 29479 solver.cpp:214] Iteration 59720, loss = 5876.09
I0315 22:31:08.446633 29479 solver.cpp:229]     Train net output #0: loss = 4517.42 (* 1 = 4517.42 loss)
I0315 22:31:08.811414 29479 solver.cpp:610] Iteration 59720, lr = 7.26724e-09
I0315 22:31:08.811427 29479 solver.cpp:613] Iteration 59720, avg_grad_norm = 596071
I0315 22:32:17.274364 29479 solver.cpp:214] Iteration 59740, loss = 5656.1
I0315 22:32:17.274509 29479 solver.cpp:229]     Train net output #0: loss = 4138.02 (* 1 = 4138.02 loss)
I0315 22:32:17.634601 29479 solver.cpp:610] Iteration 59740, lr = 7.2663e-09
I0315 22:32:17.634614 29479 solver.cpp:613] Iteration 59740, avg_grad_norm = 580311
I0315 22:33:25.063032 29479 solver.cpp:214] Iteration 59760, loss = 5468.86
I0315 22:33:25.063233 29479 solver.cpp:229]     Train net output #0: loss = 7544.51 (* 1 = 7544.51 loss)
I0315 22:33:25.423421 29479 solver.cpp:610] Iteration 59760, lr = 7.26537e-09
I0315 22:33:25.423435 29479 solver.cpp:613] Iteration 59760, avg_grad_norm = 545281
I0315 22:34:33.384567 29479 solver.cpp:214] Iteration 59780, loss = 5781.59
I0315 22:34:33.384675 29479 solver.cpp:229]     Train net output #0: loss = 3882.02 (* 1 = 3882.02 loss)
I0315 22:34:33.753973 29479 solver.cpp:610] Iteration 59780, lr = 7.26444e-09
I0315 22:34:33.753986 29479 solver.cpp:613] Iteration 59780, avg_grad_norm = 553240
I0315 22:35:42.630905 29479 solver.cpp:214] Iteration 59800, loss = 5902.63
I0315 22:35:42.631088 29479 solver.cpp:229]     Train net output #0: loss = 5717.97 (* 1 = 5717.97 loss)
I0315 22:35:42.996940 29479 solver.cpp:610] Iteration 59800, lr = 7.2635e-09
I0315 22:35:42.996953 29479 solver.cpp:613] Iteration 59800, avg_grad_norm = 508874
I0315 22:36:50.308555 29479 solver.cpp:214] Iteration 59820, loss = 6074.36
I0315 22:36:50.308713 29479 solver.cpp:229]     Train net output #0: loss = 6232.3 (* 1 = 6232.3 loss)
I0315 22:36:50.698343 29479 solver.cpp:610] Iteration 59820, lr = 7.26257e-09
I0315 22:36:50.698356 29479 solver.cpp:613] Iteration 59820, avg_grad_norm = 555723
I0315 22:37:59.071630 29479 solver.cpp:214] Iteration 59840, loss = 5940.91
I0315 22:37:59.071760 29479 solver.cpp:229]     Train net output #0: loss = 4569.72 (* 1 = 4569.72 loss)
I0315 22:37:59.434986 29479 solver.cpp:610] Iteration 59840, lr = 7.26164e-09
I0315 22:37:59.434999 29479 solver.cpp:613] Iteration 59840, avg_grad_norm = 544821
I0315 22:39:07.407444 29479 solver.cpp:214] Iteration 59860, loss = 5974.56
I0315 22:39:07.407567 29479 solver.cpp:229]     Train net output #0: loss = 4245.58 (* 1 = 4245.58 loss)
I0315 22:39:07.776690 29479 solver.cpp:610] Iteration 59860, lr = 7.26071e-09
I0315 22:39:07.776705 29479 solver.cpp:613] Iteration 59860, avg_grad_norm = 612404
I0315 22:40:16.270102 29479 solver.cpp:214] Iteration 59880, loss = 6338.22
I0315 22:40:16.270232 29479 solver.cpp:229]     Train net output #0: loss = 4260.36 (* 1 = 4260.36 loss)
I0315 22:40:16.636363 29479 solver.cpp:610] Iteration 59880, lr = 7.25977e-09
I0315 22:40:16.636379 29479 solver.cpp:613] Iteration 59880, avg_grad_norm = 546582
I0315 22:41:26.170507 29479 solver.cpp:214] Iteration 59900, loss = 5952.84
I0315 22:41:26.170706 29479 solver.cpp:229]     Train net output #0: loss = 4631.23 (* 1 = 4631.23 loss)
I0315 22:41:26.384444 29479 solver.cpp:610] Iteration 59900, lr = 7.25884e-09
I0315 22:41:26.384459 29479 solver.cpp:613] Iteration 59900, avg_grad_norm = 495399
I0315 22:42:35.595803 29479 solver.cpp:214] Iteration 59920, loss = 6130.65
I0315 22:42:35.595939 29479 solver.cpp:229]     Train net output #0: loss = 5601.96 (* 1 = 5601.96 loss)
I0315 22:42:35.953804 29479 solver.cpp:610] Iteration 59920, lr = 7.25791e-09
I0315 22:42:35.953817 29479 solver.cpp:613] Iteration 59920, avg_grad_norm = 521921
I0315 22:43:38.043500 29479 solver.cpp:214] Iteration 59940, loss = 5538.84
I0315 22:43:38.043653 29479 solver.cpp:229]     Train net output #0: loss = 8036.83 (* 1 = 8036.83 loss)
I0315 22:43:38.155398 29479 solver.cpp:610] Iteration 59940, lr = 7.25698e-09
I0315 22:43:38.155450 29479 solver.cpp:613] Iteration 59940, avg_grad_norm = 530737
I0315 22:45:05.937908 29479 solver.cpp:214] Iteration 59960, loss = 5931.41
I0315 22:45:05.938040 29479 solver.cpp:229]     Train net output #0: loss = 6851.45 (* 1 = 6851.45 loss)
I0315 22:45:06.301920 29479 solver.cpp:610] Iteration 59960, lr = 7.25604e-09
I0315 22:45:06.301934 29479 solver.cpp:613] Iteration 59960, avg_grad_norm = 506236
I0315 22:46:13.237079 29479 solver.cpp:214] Iteration 59980, loss = 5898.01
I0315 22:46:13.237252 29479 solver.cpp:229]     Train net output #0: loss = 3448.78 (* 1 = 3448.78 loss)
I0315 22:46:13.597559 29479 solver.cpp:610] Iteration 59980, lr = 7.25511e-09
I0315 22:46:13.597581 29479 solver.cpp:613] Iteration 59980, avg_grad_norm = 543040
I0315 22:47:18.899606 29479 solver.cpp:458] Snapshotting to models/pnet/VGG_VOC2012ext_iter_60000.caffemodel
I0315 22:47:20.967260 29479 solver.cpp:466] Snapshotting solver state to models/pnet/VGG_VOC2012ext_iter_60000.solverstate
I0315 22:47:25.505691 29479 solver.cpp:214] Iteration 60000, loss = 6004.18
I0315 22:47:25.505758 29479 solver.cpp:229]     Train net output #0: loss = 8514.31 (* 1 = 8514.31 loss)
I0315 22:47:25.864300 29479 solver.cpp:610] Iteration 60000, lr = 7.25418e-09
I0315 22:47:25.864315 29479 solver.cpp:613] Iteration 60000, avg_grad_norm = 499059
I0315 22:48:33.942330 29479 solver.cpp:214] Iteration 60020, loss = 5496.64
I0315 22:48:33.942513 29479 solver.cpp:229]     Train net output #0: loss = 6821.27 (* 1 = 6821.27 loss)
I0315 22:48:34.302032 29479 solver.cpp:610] Iteration 60020, lr = 7.25325e-09
I0315 22:48:34.302045 29479 solver.cpp:613] Iteration 60020, avg_grad_norm = 526119
I0315 22:49:43.204545 29479 solver.cpp:214] Iteration 60040, loss = 5873.57
I0315 22:49:43.204761 29479 solver.cpp:229]     Train net output #0: loss = 4543.52 (* 1 = 4543.52 loss)
I0315 22:49:43.565836 29479 solver.cpp:610] Iteration 60040, lr = 7.25231e-09
I0315 22:49:43.565850 29479 solver.cpp:613] Iteration 60040, avg_grad_norm = 540596
I0315 22:50:52.593490 29479 solver.cpp:214] Iteration 60060, loss = 5852.07
I0315 22:50:52.593672 29479 solver.cpp:229]     Train net output #0: loss = 7225.6 (* 1 = 7225.6 loss)
I0315 22:50:52.952714 29479 solver.cpp:610] Iteration 60060, lr = 7.25138e-09
I0315 22:50:52.952740 29479 solver.cpp:613] Iteration 60060, avg_grad_norm = 574925
I0315 22:52:17.174468 29479 solver.cpp:214] Iteration 60080, loss = 5683.75
I0315 22:52:17.174617 29479 solver.cpp:229]     Train net output #0: loss = 4476.08 (* 1 = 4476.08 loss)
I0315 22:52:17.530424 29479 solver.cpp:610] Iteration 60080, lr = 7.25045e-09
I0315 22:52:17.530439 29479 solver.cpp:613] Iteration 60080, avg_grad_norm = 519589
I0315 22:53:25.696252 29479 solver.cpp:214] Iteration 60100, loss = 5723.83
I0315 22:53:25.696379 29479 solver.cpp:229]     Train net output #0: loss = 8366.34 (* 1 = 8366.34 loss)
I0315 22:53:26.054833 29479 solver.cpp:610] Iteration 60100, lr = 7.24951e-09
I0315 22:53:26.054847 29479 solver.cpp:613] Iteration 60100, avg_grad_norm = 606104
I0315 22:54:34.354409 29479 solver.cpp:214] Iteration 60120, loss = 5790.01
I0315 22:54:34.354534 29479 solver.cpp:229]     Train net output #0: loss = 2988.32 (* 1 = 2988.32 loss)
I0315 22:54:34.714351 29479 solver.cpp:610] Iteration 60120, lr = 7.24858e-09
I0315 22:54:34.714365 29479 solver.cpp:613] Iteration 60120, avg_grad_norm = 548643
I0315 22:55:42.563096 29479 solver.cpp:214] Iteration 60140, loss = 5853.75
I0315 22:55:42.563217 29479 solver.cpp:229]     Train net output #0: loss = 3542.15 (* 1 = 3542.15 loss)
I0315 22:55:42.923668 29479 solver.cpp:610] Iteration 60140, lr = 7.24765e-09
I0315 22:55:42.923682 29479 solver.cpp:613] Iteration 60140, avg_grad_norm = 506681
I0315 22:56:50.130863 29479 solver.cpp:214] Iteration 60160, loss = 5816.01
I0315 22:56:50.131077 29479 solver.cpp:229]     Train net output #0: loss = 5066.94 (* 1 = 5066.94 loss)
I0315 22:56:50.490279 29479 solver.cpp:610] Iteration 60160, lr = 7.24672e-09
I0315 22:56:50.490293 29479 solver.cpp:613] Iteration 60160, avg_grad_norm = 475828
I0315 22:57:58.465996 29479 solver.cpp:214] Iteration 60180, loss = 5932.99
I0315 22:57:58.466122 29479 solver.cpp:229]     Train net output #0: loss = 5332.44 (* 1 = 5332.44 loss)
I0315 22:57:58.827436 29479 solver.cpp:610] Iteration 60180, lr = 7.24578e-09
I0315 22:57:58.827450 29479 solver.cpp:613] Iteration 60180, avg_grad_norm = 541674
I0315 22:59:31.851399 29479 solver.cpp:214] Iteration 60200, loss = 5946.8
I0315 22:59:31.851605 29479 solver.cpp:229]     Train net output #0: loss = 6917.8 (* 1 = 6917.8 loss)
I0315 22:59:32.206826 29479 solver.cpp:610] Iteration 60200, lr = 7.24485e-09
I0315 22:59:32.206840 29479 solver.cpp:613] Iteration 60200, avg_grad_norm = 620470
I0315 23:00:39.416348 29479 solver.cpp:214] Iteration 60220, loss = 5812.18
I0315 23:00:39.416471 29479 solver.cpp:229]     Train net output #0: loss = 4631.25 (* 1 = 4631.25 loss)
I0315 23:00:39.771771 29479 solver.cpp:610] Iteration 60220, lr = 7.24392e-09
I0315 23:00:39.771785 29479 solver.cpp:613] Iteration 60220, avg_grad_norm = 529559
I0315 23:01:47.777845 29479 solver.cpp:214] Iteration 60240, loss = 6096.54
I0315 23:01:47.777953 29479 solver.cpp:229]     Train net output #0: loss = 6030.64 (* 1 = 6030.64 loss)
I0315 23:01:48.138368 29479 solver.cpp:610] Iteration 60240, lr = 7.24298e-09
I0315 23:01:48.138384 29479 solver.cpp:613] Iteration 60240, avg_grad_norm = 579134
I0315 23:02:55.837185 29479 solver.cpp:214] Iteration 60260, loss = 5625.63
I0315 23:02:55.837435 29479 solver.cpp:229]     Train net output #0: loss = 4441.08 (* 1 = 4441.08 loss)
I0315 23:02:56.197955 29479 solver.cpp:610] Iteration 60260, lr = 7.24205e-09
I0315 23:02:56.197971 29479 solver.cpp:613] Iteration 60260, avg_grad_norm = 539699
I0315 23:04:04.794544 29479 solver.cpp:214] Iteration 60280, loss = 5821.27
I0315 23:04:04.794687 29479 solver.cpp:229]     Train net output #0: loss = 7703.61 (* 1 = 7703.61 loss)
I0315 23:04:05.157536 29479 solver.cpp:610] Iteration 60280, lr = 7.24112e-09
I0315 23:04:05.157551 29479 solver.cpp:613] Iteration 60280, avg_grad_norm = 519726
I0315 23:05:13.484251 29479 solver.cpp:214] Iteration 60300, loss = 5764.31
I0315 23:05:13.484382 29479 solver.cpp:229]     Train net output #0: loss = 2768.27 (* 1 = 2768.27 loss)
I0315 23:05:13.844487 29479 solver.cpp:610] Iteration 60300, lr = 7.24019e-09
I0315 23:05:13.844502 29479 solver.cpp:613] Iteration 60300, avg_grad_norm = 533037
I0315 23:06:22.189163 29479 solver.cpp:214] Iteration 60320, loss = 5805.62
I0315 23:06:22.189285 29479 solver.cpp:229]     Train net output #0: loss = 3211.16 (* 1 = 3211.16 loss)
I0315 23:06:22.551821 29479 solver.cpp:610] Iteration 60320, lr = 7.23925e-09
I0315 23:06:22.551836 29479 solver.cpp:613] Iteration 60320, avg_grad_norm = 532865
I0315 23:07:48.040611 29479 solver.cpp:214] Iteration 60340, loss = 5855.75
I0315 23:07:48.040750 29479 solver.cpp:229]     Train net output #0: loss = 11013.6 (* 1 = 11013.6 loss)
I0315 23:07:48.398589 29479 solver.cpp:610] Iteration 60340, lr = 7.23832e-09
I0315 23:07:48.398603 29479 solver.cpp:613] Iteration 60340, avg_grad_norm = 538440
I0315 23:08:56.396154 29479 solver.cpp:214] Iteration 60360, loss = 5863.54
I0315 23:08:56.396281 29479 solver.cpp:229]     Train net output #0: loss = 3507.06 (* 1 = 3507.06 loss)
I0315 23:08:56.758049 29479 solver.cpp:610] Iteration 60360, lr = 7.23739e-09
I0315 23:08:56.758062 29479 solver.cpp:613] Iteration 60360, avg_grad_norm = 589997
I0315 23:10:05.010740 29479 solver.cpp:214] Iteration 60380, loss = 6076.09
I0315 23:10:05.010867 29479 solver.cpp:229]     Train net output #0: loss = 3433.46 (* 1 = 3433.46 loss)
I0315 23:10:05.371378 29479 solver.cpp:610] Iteration 60380, lr = 7.23645e-09
I0315 23:10:05.371392 29479 solver.cpp:613] Iteration 60380, avg_grad_norm = 568554
I0315 23:11:13.454979 29479 solver.cpp:214] Iteration 60400, loss = 5901.68
I0315 23:11:13.455127 29479 solver.cpp:229]     Train net output #0: loss = 3037.01 (* 1 = 3037.01 loss)
I0315 23:11:13.814987 29479 solver.cpp:610] Iteration 60400, lr = 7.23552e-09
I0315 23:11:13.815006 29479 solver.cpp:613] Iteration 60400, avg_grad_norm = 528561
I0315 23:12:22.129333 29479 solver.cpp:214] Iteration 60420, loss = 5909.77
I0315 23:12:22.129472 29479 solver.cpp:229]     Train net output #0: loss = 4809.48 (* 1 = 4809.48 loss)
I0315 23:12:22.492779 29479 solver.cpp:610] Iteration 60420, lr = 7.23459e-09
I0315 23:12:22.492794 29479 solver.cpp:613] Iteration 60420, avg_grad_norm = 499150
I0315 23:13:31.129333 29479 solver.cpp:214] Iteration 60440, loss = 6076.12
I0315 23:13:31.129480 29479 solver.cpp:229]     Train net output #0: loss = 4633.33 (* 1 = 4633.33 loss)
I0315 23:13:31.489648 29479 solver.cpp:610] Iteration 60440, lr = 7.23366e-09
I0315 23:13:31.489665 29479 solver.cpp:613] Iteration 60440, avg_grad_norm = 595253
I0315 23:14:38.268271 29479 solver.cpp:214] Iteration 60460, loss = 5977.73
I0315 23:14:38.268404 29479 solver.cpp:229]     Train net output #0: loss = 4888.8 (* 1 = 4888.8 loss)
I0315 23:14:38.625982 29479 solver.cpp:610] Iteration 60460, lr = 7.23272e-09
I0315 23:14:38.625996 29479 solver.cpp:613] Iteration 60460, avg_grad_norm = 585178
I0315 23:15:47.168712 29479 solver.cpp:214] Iteration 60480, loss = 6057.1
I0315 23:15:47.168843 29479 solver.cpp:229]     Train net output #0: loss = 8302.05 (* 1 = 8302.05 loss)
I0315 23:15:47.526115 29479 solver.cpp:610] Iteration 60480, lr = 7.23179e-09
I0315 23:15:47.526129 29479 solver.cpp:613] Iteration 60480, avg_grad_norm = 517140
I0315 23:16:55.978471 29479 solver.cpp:214] Iteration 60500, loss = 5922.22
I0315 23:16:55.978694 29479 solver.cpp:229]     Train net output #0: loss = 6403.86 (* 1 = 6403.86 loss)
I0315 23:16:56.338997 29479 solver.cpp:610] Iteration 60500, lr = 7.23086e-09
I0315 23:16:56.339011 29479 solver.cpp:613] Iteration 60500, avg_grad_norm = 471645
I0315 23:18:04.781280 29479 solver.cpp:214] Iteration 60520, loss = 5935.21
I0315 23:18:04.781443 29479 solver.cpp:229]     Train net output #0: loss = 5575.66 (* 1 = 5575.66 loss)
I0315 23:18:05.164578 29479 solver.cpp:610] Iteration 60520, lr = 7.22992e-09
I0315 23:18:05.164592 29479 solver.cpp:613] Iteration 60520, avg_grad_norm = 493863
I0315 23:19:13.579795 29479 solver.cpp:214] Iteration 60540, loss = 5728.02
I0315 23:19:13.579998 29479 solver.cpp:229]     Train net output #0: loss = 7945.44 (* 1 = 7945.44 loss)
I0315 23:19:13.940767 29479 solver.cpp:610] Iteration 60540, lr = 7.22899e-09
I0315 23:19:13.940780 29479 solver.cpp:613] Iteration 60540, avg_grad_norm = 483386
I0315 23:20:22.777814 29479 solver.cpp:214] Iteration 60560, loss = 5952.81
I0315 23:20:22.777945 29479 solver.cpp:229]     Train net output #0: loss = 3671.26 (* 1 = 3671.26 loss)
I0315 23:20:23.145045 29479 solver.cpp:610] Iteration 60560, lr = 7.22806e-09
I0315 23:20:23.145059 29479 solver.cpp:613] Iteration 60560, avg_grad_norm = 551192
I0315 23:21:39.984102 29479 solver.cpp:214] Iteration 60580, loss = 5772.36
I0315 23:21:39.984242 29479 solver.cpp:229]     Train net output #0: loss = 3604.96 (* 1 = 3604.96 loss)
I0315 23:21:40.093340 29479 solver.cpp:610] Iteration 60580, lr = 7.22713e-09
I0315 23:21:40.093377 29479 solver.cpp:613] Iteration 60580, avg_grad_norm = 522037
I0315 23:22:28.979581 29479 solver.cpp:214] Iteration 60600, loss = 5690.59
I0315 23:22:28.979708 29479 solver.cpp:229]     Train net output #0: loss = 5946.38 (* 1 = 5946.38 loss)
I0315 23:22:29.340371 29479 solver.cpp:610] Iteration 60600, lr = 7.22619e-09
I0315 23:22:29.340384 29479 solver.cpp:613] Iteration 60600, avg_grad_norm = 541381
I0315 23:23:37.949606 29479 solver.cpp:214] Iteration 60620, loss = 5769.74
I0315 23:23:37.949717 29479 solver.cpp:229]     Train net output #0: loss = 9944.11 (* 1 = 9944.11 loss)
I0315 23:23:38.312551 29479 solver.cpp:610] Iteration 60620, lr = 7.22526e-09
I0315 23:23:38.312564 29479 solver.cpp:613] Iteration 60620, avg_grad_norm = 517125
I0315 23:24:47.412003 29479 solver.cpp:214] Iteration 60640, loss = 5881.34
I0315 23:24:47.412123 29479 solver.cpp:229]     Train net output #0: loss = 3348.67 (* 1 = 3348.67 loss)
I0315 23:24:47.794863 29479 solver.cpp:610] Iteration 60640, lr = 7.22433e-09
I0315 23:24:47.794877 29479 solver.cpp:613] Iteration 60640, avg_grad_norm = 493764
I0315 23:25:56.442181 29479 solver.cpp:214] Iteration 60660, loss = 5884.28
I0315 23:25:56.442291 29479 solver.cpp:229]     Train net output #0: loss = 4001.18 (* 1 = 4001.18 loss)
I0315 23:25:56.811689 29479 solver.cpp:610] Iteration 60660, lr = 7.22339e-09
I0315 23:25:56.811702 29479 solver.cpp:613] Iteration 60660, avg_grad_norm = 481808
I0315 23:27:05.372326 29479 solver.cpp:214] Iteration 60680, loss = 6266.99
I0315 23:27:05.372452 29479 solver.cpp:229]     Train net output #0: loss = 3390.59 (* 1 = 3390.59 loss)
I0315 23:27:05.585057 29479 solver.cpp:610] Iteration 60680, lr = 7.22246e-09
I0315 23:27:05.585072 29479 solver.cpp:613] Iteration 60680, avg_grad_norm = 517177
I0315 23:28:14.786736 29479 solver.cpp:214] Iteration 60700, loss = 5744.43
I0315 23:28:14.786947 29479 solver.cpp:229]     Train net output #0: loss = 2665.31 (* 1 = 2665.31 loss)
I0315 23:28:15.147274 29479 solver.cpp:610] Iteration 60700, lr = 7.22153e-09
I0315 23:28:15.147289 29479 solver.cpp:613] Iteration 60700, avg_grad_norm = 533720
I0315 23:29:20.915460 29479 solver.cpp:214] Iteration 60720, loss = 6024.97
I0315 23:29:20.915583 29479 solver.cpp:229]     Train net output #0: loss = 3254.47 (* 1 = 3254.47 loss)
I0315 23:29:21.314779 29479 solver.cpp:610] Iteration 60720, lr = 7.22059e-09
I0315 23:29:21.314792 29479 solver.cpp:613] Iteration 60720, avg_grad_norm = 576687
I0315 23:30:29.944145 29479 solver.cpp:214] Iteration 60740, loss = 5973.02
I0315 23:30:29.944347 29479 solver.cpp:229]     Train net output #0: loss = 5733.18 (* 1 = 5733.18 loss)
I0315 23:30:30.312824 29479 solver.cpp:610] Iteration 60740, lr = 7.21966e-09
I0315 23:30:30.312839 29479 solver.cpp:613] Iteration 60740, avg_grad_norm = 577151
I0315 23:31:39.440011 29479 solver.cpp:214] Iteration 60760, loss = 5901.84
I0315 23:31:39.440145 29479 solver.cpp:229]     Train net output #0: loss = 3370.81 (* 1 = 3370.81 loss)
I0315 23:31:39.809504 29479 solver.cpp:610] Iteration 60760, lr = 7.21873e-09
I0315 23:31:39.809517 29479 solver.cpp:613] Iteration 60760, avg_grad_norm = 541532
I0315 23:32:47.918403 29479 solver.cpp:214] Iteration 60780, loss = 5836.77
I0315 23:32:47.918627 29479 solver.cpp:229]     Train net output #0: loss = 4896.03 (* 1 = 4896.03 loss)
I0315 23:32:48.291787 29479 solver.cpp:610] Iteration 60780, lr = 7.21779e-09
I0315 23:32:48.291822 29479 solver.cpp:613] Iteration 60780, avg_grad_norm = 562747
I0315 23:33:56.040262 29479 solver.cpp:214] Iteration 60800, loss = 5809.72
I0315 23:33:56.040467 29479 solver.cpp:229]     Train net output #0: loss = 5442.79 (* 1 = 5442.79 loss)
I0315 23:33:56.253342 29479 solver.cpp:610] Iteration 60800, lr = 7.21686e-09
I0315 23:33:56.253356 29479 solver.cpp:613] Iteration 60800, avg_grad_norm = 526993
I0315 23:35:03.836455 29479 solver.cpp:214] Iteration 60820, loss = 5970.33
I0315 23:35:03.836573 29479 solver.cpp:229]     Train net output #0: loss = 4409.13 (* 1 = 4409.13 loss)
I0315 23:35:04.025817 29479 solver.cpp:610] Iteration 60820, lr = 7.21593e-09
I0315 23:35:04.025830 29479 solver.cpp:613] Iteration 60820, avg_grad_norm = 538628
I0315 23:36:23.834070 29479 solver.cpp:214] Iteration 60840, loss = 5655.6
I0315 23:36:23.834194 29479 solver.cpp:229]     Train net output #0: loss = 3598.38 (* 1 = 3598.38 loss)
I0315 23:36:24.196805 29479 solver.cpp:610] Iteration 60840, lr = 7.21499e-09
I0315 23:36:24.196820 29479 solver.cpp:613] Iteration 60840, avg_grad_norm = 501424
I0315 23:37:10.942806 29479 solver.cpp:214] Iteration 60860, loss = 5931.73
I0315 23:37:10.942971 29479 solver.cpp:229]     Train net output #0: loss = 8671.75 (* 1 = 8671.75 loss)
I0315 23:37:11.302785 29479 solver.cpp:610] Iteration 60860, lr = 7.21406e-09
I0315 23:37:11.302798 29479 solver.cpp:613] Iteration 60860, avg_grad_norm = 540091
I0315 23:38:20.402427 29479 solver.cpp:214] Iteration 60880, loss = 6152.86
I0315 23:38:20.402539 29479 solver.cpp:229]     Train net output #0: loss = 4857.6 (* 1 = 4857.6 loss)
I0315 23:38:20.761963 29479 solver.cpp:610] Iteration 60880, lr = 7.21313e-09
I0315 23:38:20.761976 29479 solver.cpp:613] Iteration 60880, avg_grad_norm = 508239
I0315 23:39:29.846099 29479 solver.cpp:214] Iteration 60900, loss = 5761.77
I0315 23:39:29.846231 29479 solver.cpp:229]     Train net output #0: loss = 3642.19 (* 1 = 3642.19 loss)
I0315 23:39:30.207473 29479 solver.cpp:610] Iteration 60900, lr = 7.21219e-09
I0315 23:39:30.207486 29479 solver.cpp:613] Iteration 60900, avg_grad_norm = 599445
I0315 23:40:39.246291 29479 solver.cpp:214] Iteration 60920, loss = 6002.3
I0315 23:40:39.246423 29479 solver.cpp:229]     Train net output #0: loss = 4532.47 (* 1 = 4532.47 loss)
I0315 23:40:39.575239 29479 solver.cpp:610] Iteration 60920, lr = 7.21126e-09
I0315 23:40:39.575253 29479 solver.cpp:613] Iteration 60920, avg_grad_norm = 539427
I0315 23:41:48.128423 29479 solver.cpp:214] Iteration 60940, loss = 5793.25
I0315 23:41:48.128551 29479 solver.cpp:229]     Train net output #0: loss = 5794.1 (* 1 = 5794.1 loss)
I0315 23:41:48.486310 29479 solver.cpp:610] Iteration 60940, lr = 7.21033e-09
I0315 23:41:48.486325 29479 solver.cpp:613] Iteration 60940, avg_grad_norm = 493236
I0315 23:43:10.211897 29479 solver.cpp:214] Iteration 60960, loss = 5948.21
I0315 23:43:10.212005 29479 solver.cpp:229]     Train net output #0: loss = 4913.57 (* 1 = 4913.57 loss)
I0315 23:43:10.571738 29479 solver.cpp:610] Iteration 60960, lr = 7.20939e-09
I0315 23:43:10.571753 29479 solver.cpp:613] Iteration 60960, avg_grad_norm = 560156
I0315 23:44:17.670007 29479 solver.cpp:214] Iteration 60980, loss = 5698.91
I0315 23:44:17.670169 29479 solver.cpp:229]     Train net output #0: loss = 4135.63 (* 1 = 4135.63 loss)
I0315 23:44:18.039427 29479 solver.cpp:610] Iteration 60980, lr = 7.20846e-09
I0315 23:44:18.039441 29479 solver.cpp:613] Iteration 60980, avg_grad_norm = 526337
I0315 23:45:23.353286 29479 solver.cpp:214] Iteration 61000, loss = 6066.25
I0315 23:45:23.353420 29479 solver.cpp:229]     Train net output #0: loss = 7921.64 (* 1 = 7921.64 loss)
I0315 23:45:23.719213 29479 solver.cpp:610] Iteration 61000, lr = 7.20753e-09
I0315 23:45:23.719226 29479 solver.cpp:613] Iteration 61000, avg_grad_norm = 489970
I0315 23:46:32.972369 29479 solver.cpp:214] Iteration 61020, loss = 6163.32
I0315 23:46:32.972497 29479 solver.cpp:229]     Train net output #0: loss = 5790.22 (* 1 = 5790.22 loss)
I0315 23:46:33.339231 29479 solver.cpp:610] Iteration 61020, lr = 7.20659e-09
I0315 23:46:33.339246 29479 solver.cpp:613] Iteration 61020, avg_grad_norm = 563304
I0315 23:47:41.562578 29479 solver.cpp:214] Iteration 61040, loss = 6254.18
I0315 23:47:41.562695 29479 solver.cpp:229]     Train net output #0: loss = 3876.83 (* 1 = 3876.83 loss)
I0315 23:47:41.922912 29479 solver.cpp:610] Iteration 61040, lr = 7.20566e-09
I0315 23:47:41.922926 29479 solver.cpp:613] Iteration 61040, avg_grad_norm = 573005
I0315 23:48:50.887801 29479 solver.cpp:214] Iteration 61060, loss = 5975.73
I0315 23:48:50.887939 29479 solver.cpp:229]     Train net output #0: loss = 5286.24 (* 1 = 5286.24 loss)
I0315 23:48:51.257421 29479 solver.cpp:610] Iteration 61060, lr = 7.20473e-09
I0315 23:48:51.257436 29479 solver.cpp:613] Iteration 61060, avg_grad_norm = 520789
I0315 23:49:58.441025 29479 solver.cpp:214] Iteration 61080, loss = 6004.13
I0315 23:49:58.441159 29479 solver.cpp:229]     Train net output #0: loss = 3335.85 (* 1 = 3335.85 loss)
I0315 23:49:58.806375 29479 solver.cpp:610] Iteration 61080, lr = 7.20379e-09
I0315 23:49:58.806392 29479 solver.cpp:613] Iteration 61080, avg_grad_norm = 530633
I0315 23:51:19.693711 29479 solver.cpp:214] Iteration 61100, loss = 6009.06
I0315 23:51:19.693835 29479 solver.cpp:229]     Train net output #0: loss = 5333.05 (* 1 = 5333.05 loss)
I0315 23:51:20.021078 29479 solver.cpp:610] Iteration 61100, lr = 7.20286e-09
I0315 23:51:20.021092 29479 solver.cpp:613] Iteration 61100, avg_grad_norm = 513194
I0315 23:52:06.511229 29479 solver.cpp:214] Iteration 61120, loss = 6028.75
I0315 23:52:06.511379 29479 solver.cpp:229]     Train net output #0: loss = 3409.35 (* 1 = 3409.35 loss)
I0315 23:52:06.874095 29479 solver.cpp:610] Iteration 61120, lr = 7.20193e-09
I0315 23:52:06.874109 29479 solver.cpp:613] Iteration 61120, avg_grad_norm = 525130
I0315 23:53:16.287155 29479 solver.cpp:214] Iteration 61140, loss = 5892.03
I0315 23:53:16.287291 29479 solver.cpp:229]     Train net output #0: loss = 11091 (* 1 = 11091 loss)
I0315 23:53:16.652698 29479 solver.cpp:610] Iteration 61140, lr = 7.20099e-09
I0315 23:53:16.652711 29479 solver.cpp:613] Iteration 61140, avg_grad_norm = 490723
I0315 23:54:25.825444 29479 solver.cpp:214] Iteration 61160, loss = 5872.33
I0315 23:54:25.825584 29479 solver.cpp:229]     Train net output #0: loss = 4716.49 (* 1 = 4716.49 loss)
I0315 23:54:26.186296 29479 solver.cpp:610] Iteration 61160, lr = 7.20006e-09
I0315 23:54:26.186311 29479 solver.cpp:613] Iteration 61160, avg_grad_norm = 553509
I0315 23:55:34.789114 29479 solver.cpp:214] Iteration 61180, loss = 6191.01
I0315 23:55:34.789314 29479 solver.cpp:229]     Train net output #0: loss = 4338.9 (* 1 = 4338.9 loss)
I0315 23:55:35.158885 29479 solver.cpp:610] Iteration 61180, lr = 7.19913e-09
I0315 23:55:35.158907 29479 solver.cpp:613] Iteration 61180, avg_grad_norm = 627506
I0315 23:56:43.445874 29479 solver.cpp:214] Iteration 61200, loss = 5779.72
I0315 23:56:43.446002 29479 solver.cpp:229]     Train net output #0: loss = 9432.11 (* 1 = 9432.11 loss)
I0315 23:56:43.806674 29479 solver.cpp:610] Iteration 61200, lr = 7.19819e-09
I0315 23:56:43.806689 29479 solver.cpp:613] Iteration 61200, avg_grad_norm = 564172
I0315 23:58:04.874011 29479 solver.cpp:214] Iteration 61220, loss = 5899.28
I0315 23:58:04.874202 29479 solver.cpp:229]     Train net output #0: loss = 4988.95 (* 1 = 4988.95 loss)
I0315 23:58:05.236443 29479 solver.cpp:610] Iteration 61220, lr = 7.19726e-09
I0315 23:58:05.236456 29479 solver.cpp:613] Iteration 61220, avg_grad_norm = 502535
I0315 23:59:05.409657 29479 solver.cpp:214] Iteration 61240, loss = 5834.45
I0315 23:59:05.409796 29479 solver.cpp:229]     Train net output #0: loss = 11227 (* 1 = 11227 loss)
I0315 23:59:05.523218 29479 solver.cpp:610] Iteration 61240, lr = 7.19633e-09
I0315 23:59:05.523268 29479 solver.cpp:613] Iteration 61240, avg_grad_norm = 516489
I0316 00:00:01.674082 29479 solver.cpp:214] Iteration 61260, loss = 5705.95
I0316 00:00:01.674204 29479 solver.cpp:229]     Train net output #0: loss = 4753.6 (* 1 = 4753.6 loss)
I0316 00:00:01.847873 29479 solver.cpp:610] Iteration 61260, lr = 7.19539e-09
I0316 00:00:01.847887 29479 solver.cpp:613] Iteration 61260, avg_grad_norm = 554482
I0316 00:01:10.556483 29479 solver.cpp:214] Iteration 61280, loss = 5951.75
I0316 00:01:10.556608 29479 solver.cpp:229]     Train net output #0: loss = 4623.27 (* 1 = 4623.27 loss)
I0316 00:01:10.922107 29479 solver.cpp:610] Iteration 61280, lr = 7.19446e-09
I0316 00:01:10.922122 29479 solver.cpp:613] Iteration 61280, avg_grad_norm = 533805
I0316 00:02:18.839419 29479 solver.cpp:214] Iteration 61300, loss = 6045.88
I0316 00:02:18.839550 29479 solver.cpp:229]     Train net output #0: loss = 6963.61 (* 1 = 6963.61 loss)
I0316 00:02:19.199393 29479 solver.cpp:610] Iteration 61300, lr = 7.19353e-09
I0316 00:02:19.199409 29479 solver.cpp:613] Iteration 61300, avg_grad_norm = 527470
I0316 00:03:27.096068 29479 solver.cpp:214] Iteration 61320, loss = 6117.2
I0316 00:03:27.096190 29479 solver.cpp:229]     Train net output #0: loss = 4977.52 (* 1 = 4977.52 loss)
I0316 00:03:27.464920 29479 solver.cpp:610] Iteration 61320, lr = 7.19259e-09
I0316 00:03:27.464939 29479 solver.cpp:613] Iteration 61320, avg_grad_norm = 503204
I0316 00:04:48.980828 29479 solver.cpp:214] Iteration 61340, loss = 6006.27
I0316 00:04:48.981006 29479 solver.cpp:229]     Train net output #0: loss = 4642.25 (* 1 = 4642.25 loss)
I0316 00:04:49.341362 29479 solver.cpp:610] Iteration 61340, lr = 7.19166e-09
I0316 00:04:49.341377 29479 solver.cpp:613] Iteration 61340, avg_grad_norm = 563973
I0316 00:05:57.629254 29479 solver.cpp:214] Iteration 61360, loss = 6057.84
I0316 00:05:57.629390 29479 solver.cpp:229]     Train net output #0: loss = 5946.43 (* 1 = 5946.43 loss)
I0316 00:05:57.990859 29479 solver.cpp:610] Iteration 61360, lr = 7.19073e-09
I0316 00:05:57.990872 29479 solver.cpp:613] Iteration 61360, avg_grad_norm = 545219
I0316 00:06:45.063164 29479 solver.cpp:214] Iteration 61380, loss = 5862.84
I0316 00:06:45.063319 29479 solver.cpp:229]     Train net output #0: loss = 3818.23 (* 1 = 3818.23 loss)
I0316 00:06:45.179270 29479 solver.cpp:610] Iteration 61380, lr = 7.18979e-09
I0316 00:06:45.179285 29479 solver.cpp:613] Iteration 61380, avg_grad_norm = 504075
I0316 00:07:54.039705 29479 solver.cpp:214] Iteration 61400, loss = 6015.5
I0316 00:07:54.039914 29479 solver.cpp:229]     Train net output #0: loss = 5021.35 (* 1 = 5021.35 loss)
I0316 00:07:54.377099 29479 solver.cpp:610] Iteration 61400, lr = 7.18886e-09
I0316 00:07:54.377122 29479 solver.cpp:613] Iteration 61400, avg_grad_norm = 534623
I0316 00:09:03.380030 29479 solver.cpp:214] Iteration 61420, loss = 5797.5
I0316 00:09:03.380165 29479 solver.cpp:229]     Train net output #0: loss = 7322.12 (* 1 = 7322.12 loss)
I0316 00:09:03.743312 29479 solver.cpp:610] Iteration 61420, lr = 7.18792e-09
I0316 00:09:03.743326 29479 solver.cpp:613] Iteration 61420, avg_grad_norm = 487317
I0316 00:10:11.901701 29479 solver.cpp:214] Iteration 61440, loss = 5998.3
I0316 00:10:11.901852 29479 solver.cpp:229]     Train net output #0: loss = 3830.91 (* 1 = 3830.91 loss)
I0316 00:10:12.270620 29479 solver.cpp:610] Iteration 61440, lr = 7.18699e-09
I0316 00:10:12.270634 29479 solver.cpp:613] Iteration 61440, avg_grad_norm = 507219
I0316 00:11:20.838337 29479 solver.cpp:214] Iteration 61460, loss = 5834.21
I0316 00:11:20.838529 29479 solver.cpp:229]     Train net output #0: loss = 3071.73 (* 1 = 3071.73 loss)
I0316 00:11:21.198598 29479 solver.cpp:610] Iteration 61460, lr = 7.18606e-09
I0316 00:11:21.198612 29479 solver.cpp:613] Iteration 61460, avg_grad_norm = 477383
I0316 00:12:42.379418 29479 solver.cpp:214] Iteration 61480, loss = 6285.81
I0316 00:12:42.379582 29479 solver.cpp:229]     Train net output #0: loss = 5487.93 (* 1 = 5487.93 loss)
I0316 00:12:42.555960 29479 solver.cpp:610] Iteration 61480, lr = 7.18512e-09
I0316 00:12:42.555974 29479 solver.cpp:613] Iteration 61480, avg_grad_norm = 537913
I0316 00:13:50.943940 29479 solver.cpp:214] Iteration 61500, loss = 5975.35
I0316 00:13:50.944067 29479 solver.cpp:229]     Train net output #0: loss = 6183 (* 1 = 6183 loss)
I0316 00:13:51.262104 29479 solver.cpp:610] Iteration 61500, lr = 7.18419e-09
I0316 00:13:51.262116 29479 solver.cpp:613] Iteration 61500, avg_grad_norm = 532889
I0316 00:14:35.644361 29479 solver.cpp:214] Iteration 61520, loss = 5633.2
I0316 00:14:35.644500 29479 solver.cpp:229]     Train net output #0: loss = 9748.31 (* 1 = 9748.31 loss)
I0316 00:14:36.005260 29479 solver.cpp:610] Iteration 61520, lr = 7.18326e-09
I0316 00:14:36.005275 29479 solver.cpp:613] Iteration 61520, avg_grad_norm = 484069
I0316 00:15:45.417522 29479 solver.cpp:214] Iteration 61540, loss = 5814.37
I0316 00:15:45.417654 29479 solver.cpp:229]     Train net output #0: loss = 4205.07 (* 1 = 4205.07 loss)
I0316 00:15:45.785131 29479 solver.cpp:610] Iteration 61540, lr = 7.18232e-09
I0316 00:15:45.785146 29479 solver.cpp:613] Iteration 61540, avg_grad_norm = 553917
I0316 00:16:54.295630 29479 solver.cpp:214] Iteration 61560, loss = 5849.05
I0316 00:16:54.295821 29479 solver.cpp:229]     Train net output #0: loss = 3480.64 (* 1 = 3480.64 loss)
I0316 00:16:54.661360 29479 solver.cpp:610] Iteration 61560, lr = 7.18139e-09
I0316 00:16:54.661373 29479 solver.cpp:613] Iteration 61560, avg_grad_norm = 507148
I0316 00:18:03.427973 29479 solver.cpp:214] Iteration 61580, loss = 5870.84
I0316 00:18:03.428107 29479 solver.cpp:229]     Train net output #0: loss = 6273.32 (* 1 = 6273.32 loss)
I0316 00:18:03.788080 29479 solver.cpp:610] Iteration 61580, lr = 7.18045e-09
I0316 00:18:03.788094 29479 solver.cpp:613] Iteration 61580, avg_grad_norm = 514349
I0316 00:19:40.755545 29479 solver.cpp:214] Iteration 61600, loss = 5916.81
I0316 00:19:40.755688 29479 solver.cpp:229]     Train net output #0: loss = 6016.1 (* 1 = 6016.1 loss)
I0316 00:19:41.093479 29479 solver.cpp:610] Iteration 61600, lr = 7.17952e-09
I0316 00:19:41.093493 29479 solver.cpp:613] Iteration 61600, avg_grad_norm = 506962
I0316 00:20:48.766696 29479 solver.cpp:214] Iteration 61620, loss = 6047.24
I0316 00:20:48.766814 29479 solver.cpp:229]     Train net output #0: loss = 2878.55 (* 1 = 2878.55 loss)
I0316 00:20:48.939374 29479 solver.cpp:610] Iteration 61620, lr = 7.17859e-09
I0316 00:20:48.939388 29479 solver.cpp:613] Iteration 61620, avg_grad_norm = 513063
I0316 00:21:38.884356 29479 solver.cpp:214] Iteration 61640, loss = 5996.34
I0316 00:21:38.884496 29479 solver.cpp:229]     Train net output #0: loss = 3357.88 (* 1 = 3357.88 loss)
I0316 00:21:39.000563 29479 solver.cpp:610] Iteration 61640, lr = 7.17765e-09
I0316 00:21:39.000602 29479 solver.cpp:613] Iteration 61640, avg_grad_norm = 484007
I0316 00:22:44.075305 29479 solver.cpp:214] Iteration 61660, loss = 6264.63
I0316 00:22:44.075417 29479 solver.cpp:229]     Train net output #0: loss = 9377.32 (* 1 = 9377.32 loss)
I0316 00:22:44.435648 29479 solver.cpp:610] Iteration 61660, lr = 7.17672e-09
I0316 00:22:44.435663 29479 solver.cpp:613] Iteration 61660, avg_grad_norm = 503984
I0316 00:23:51.538534 29479 solver.cpp:214] Iteration 61680, loss = 5829.28
I0316 00:23:51.538664 29479 solver.cpp:229]     Train net output #0: loss = 6793.94 (* 1 = 6793.94 loss)
I0316 00:23:51.753867 29479 solver.cpp:610] Iteration 61680, lr = 7.17579e-09
I0316 00:23:51.753881 29479 solver.cpp:613] Iteration 61680, avg_grad_norm = 544403
I0316 00:24:55.862134 29479 solver.cpp:214] Iteration 61700, loss = 6044.3
I0316 00:24:55.862330 29479 solver.cpp:229]     Train net output #0: loss = 5774.31 (* 1 = 5774.31 loss)
I0316 00:24:56.053035 29479 solver.cpp:610] Iteration 61700, lr = 7.17485e-09
I0316 00:24:56.053050 29479 solver.cpp:613] Iteration 61700, avg_grad_norm = 577912
I0316 00:26:16.610030 29479 solver.cpp:214] Iteration 61720, loss = 5942.81
I0316 00:26:16.610136 29479 solver.cpp:229]     Train net output #0: loss = 10226 (* 1 = 10226 loss)
I0316 00:26:16.970846 29479 solver.cpp:610] Iteration 61720, lr = 7.17392e-09
I0316 00:26:16.970860 29479 solver.cpp:613] Iteration 61720, avg_grad_norm = 568594
I0316 00:27:21.318095 29479 solver.cpp:214] Iteration 61740, loss = 5839.88
I0316 00:27:21.318298 29479 solver.cpp:229]     Train net output #0: loss = 9188.98 (* 1 = 9188.98 loss)
I0316 00:27:21.676717 29479 solver.cpp:610] Iteration 61740, lr = 7.17298e-09
I0316 00:27:21.676748 29479 solver.cpp:613] Iteration 61740, avg_grad_norm = 519633
I0316 00:28:30.207047 29479 solver.cpp:214] Iteration 61760, loss = 5686.17
I0316 00:28:30.207188 29479 solver.cpp:229]     Train net output #0: loss = 4958.14 (* 1 = 4958.14 loss)
I0316 00:28:30.570268 29479 solver.cpp:610] Iteration 61760, lr = 7.17205e-09
I0316 00:28:30.570282 29479 solver.cpp:613] Iteration 61760, avg_grad_norm = 487771
I0316 00:29:18.413748 29479 solver.cpp:214] Iteration 61780, loss = 5771.32
I0316 00:29:18.413907 29479 solver.cpp:229]     Train net output #0: loss = 4402.47 (* 1 = 4402.47 loss)
I0316 00:29:18.530071 29479 solver.cpp:610] Iteration 61780, lr = 7.17112e-09
I0316 00:29:18.530107 29479 solver.cpp:613] Iteration 61780, avg_grad_norm = 558319
I0316 00:30:26.531605 29479 solver.cpp:214] Iteration 61800, loss = 5539.22
I0316 00:30:26.531718 29479 solver.cpp:229]     Train net output #0: loss = 8781.1 (* 1 = 8781.1 loss)
I0316 00:30:26.897927 29479 solver.cpp:610] Iteration 61800, lr = 7.17018e-09
I0316 00:30:26.897943 29479 solver.cpp:613] Iteration 61800, avg_grad_norm = 525559
I0316 00:31:34.962391 29479 solver.cpp:214] Iteration 61820, loss = 5888.69
I0316 00:31:34.962508 29479 solver.cpp:229]     Train net output #0: loss = 5553.88 (* 1 = 5553.88 loss)
I0316 00:31:35.324494 29479 solver.cpp:610] Iteration 61820, lr = 7.16925e-09
I0316 00:31:35.324507 29479 solver.cpp:613] Iteration 61820, avg_grad_norm = 490521
I0316 00:32:44.488418 29479 solver.cpp:214] Iteration 61840, loss = 5896.15
I0316 00:32:44.488550 29479 solver.cpp:229]     Train net output #0: loss = 5371.26 (* 1 = 5371.26 loss)
I0316 00:32:44.848361 29479 solver.cpp:610] Iteration 61840, lr = 7.16832e-09
I0316 00:32:44.848373 29479 solver.cpp:613] Iteration 61840, avg_grad_norm = 513219
I0316 00:34:10.341002 29479 solver.cpp:214] Iteration 61860, loss = 5968.6
I0316 00:34:10.341251 29479 solver.cpp:229]     Train net output #0: loss = 8755.58 (* 1 = 8755.58 loss)
I0316 00:34:10.699360 29479 solver.cpp:610] Iteration 61860, lr = 7.16738e-09
I0316 00:34:10.699378 29479 solver.cpp:613] Iteration 61860, avg_grad_norm = 517897
I0316 00:35:19.049103 29479 solver.cpp:214] Iteration 61880, loss = 6064.65
I0316 00:35:19.049304 29479 solver.cpp:229]     Train net output #0: loss = 5053.9 (* 1 = 5053.9 loss)
I0316 00:35:19.409730 29479 solver.cpp:610] Iteration 61880, lr = 7.16645e-09
I0316 00:35:19.409744 29479 solver.cpp:613] Iteration 61880, avg_grad_norm = 537209
I0316 00:36:23.253808 29479 solver.cpp:214] Iteration 61900, loss = 5876.11
I0316 00:36:23.253937 29479 solver.cpp:229]     Train net output #0: loss = 3960.63 (* 1 = 3960.63 loss)
I0316 00:36:23.618079 29479 solver.cpp:610] Iteration 61900, lr = 7.16551e-09
I0316 00:36:23.618093 29479 solver.cpp:613] Iteration 61900, avg_grad_norm = 557355
I0316 00:37:09.468158 29479 solver.cpp:214] Iteration 61920, loss = 6033.84
I0316 00:37:09.468284 29479 solver.cpp:229]     Train net output #0: loss = 9580.67 (* 1 = 9580.67 loss)
I0316 00:37:09.828366 29479 solver.cpp:610] Iteration 61920, lr = 7.16458e-09
I0316 00:37:09.828382 29479 solver.cpp:613] Iteration 61920, avg_grad_norm = 537432
I0316 00:38:18.257948 29479 solver.cpp:214] Iteration 61940, loss = 5914.41
I0316 00:38:18.258116 29479 solver.cpp:229]     Train net output #0: loss = 10189.7 (* 1 = 10189.7 loss)
I0316 00:38:18.627419 29479 solver.cpp:610] Iteration 61940, lr = 7.16365e-09
I0316 00:38:18.627434 29479 solver.cpp:613] Iteration 61940, avg_grad_norm = 549874
I0316 00:39:27.497392 29479 solver.cpp:214] Iteration 61960, loss = 5961.33
I0316 00:39:27.497530 29479 solver.cpp:229]     Train net output #0: loss = 6455.65 (* 1 = 6455.65 loss)
I0316 00:39:27.857625 29479 solver.cpp:610] Iteration 61960, lr = 7.16271e-09
I0316 00:39:27.857638 29479 solver.cpp:613] Iteration 61960, avg_grad_norm = 541069
I0316 00:40:49.203745 29479 solver.cpp:214] Iteration 61980, loss = 5797.18
I0316 00:40:49.203871 29479 solver.cpp:229]     Train net output #0: loss = 3809.49 (* 1 = 3809.49 loss)
I0316 00:40:49.539968 29479 solver.cpp:610] Iteration 61980, lr = 7.16178e-09
I0316 00:40:49.539980 29479 solver.cpp:613] Iteration 61980, avg_grad_norm = 507378
I0316 00:41:57.897099 29479 solver.cpp:214] Iteration 62000, loss = 5924.14
I0316 00:41:57.897224 29479 solver.cpp:229]     Train net output #0: loss = 11754.5 (* 1 = 11754.5 loss)
I0316 00:41:58.257649 29479 solver.cpp:610] Iteration 62000, lr = 7.16084e-09
I0316 00:41:58.257663 29479 solver.cpp:613] Iteration 62000, avg_grad_norm = 588154
I0316 00:43:07.035151 29479 solver.cpp:214] Iteration 62020, loss = 5971.59
I0316 00:43:07.035250 29479 solver.cpp:229]     Train net output #0: loss = 3704.97 (* 1 = 3704.97 loss)
I0316 00:43:07.403976 29479 solver.cpp:610] Iteration 62020, lr = 7.15991e-09
I0316 00:43:07.403990 29479 solver.cpp:613] Iteration 62020, avg_grad_norm = 592656
I0316 00:44:11.455626 29479 solver.cpp:214] Iteration 62040, loss = 6082.05
I0316 00:44:11.455760 29479 solver.cpp:229]     Train net output #0: loss = 4534.41 (* 1 = 4534.41 loss)
I0316 00:44:11.565958 29479 solver.cpp:610] Iteration 62040, lr = 7.15898e-09
I0316 00:44:11.565991 29479 solver.cpp:613] Iteration 62040, avg_grad_norm = 513375
I0316 00:45:03.245996 29479 solver.cpp:214] Iteration 62060, loss = 5840.6
I0316 00:45:03.246111 29479 solver.cpp:229]     Train net output #0: loss = 5055.62 (* 1 = 5055.62 loss)
I0316 00:45:03.615959 29479 solver.cpp:610] Iteration 62060, lr = 7.15804e-09
I0316 00:45:03.615974 29479 solver.cpp:613] Iteration 62060, avg_grad_norm = 527644
I0316 00:46:12.498570 29479 solver.cpp:214] Iteration 62080, loss = 5645.48
I0316 00:46:12.498687 29479 solver.cpp:229]     Train net output #0: loss = 3852.33 (* 1 = 3852.33 loss)
I0316 00:46:12.859282 29479 solver.cpp:610] Iteration 62080, lr = 7.15711e-09
I0316 00:46:12.859297 29479 solver.cpp:613] Iteration 62080, avg_grad_norm = 536685
I0316 00:47:49.663915 29479 solver.cpp:214] Iteration 62100, loss = 5588.81
I0316 00:47:49.664041 29479 solver.cpp:229]     Train net output #0: loss = 7757.75 (* 1 = 7757.75 loss)
I0316 00:47:50.020067 29479 solver.cpp:610] Iteration 62100, lr = 7.15617e-09
I0316 00:47:50.020081 29479 solver.cpp:613] Iteration 62100, avg_grad_norm = 472229
I0316 00:48:58.966629 29479 solver.cpp:214] Iteration 62120, loss = 5704.27
I0316 00:48:58.966749 29479 solver.cpp:229]     Train net output #0: loss = 7357.39 (* 1 = 7357.39 loss)
I0316 00:48:59.332445 29479 solver.cpp:610] Iteration 62120, lr = 7.15524e-09
I0316 00:48:59.332459 29479 solver.cpp:613] Iteration 62120, avg_grad_norm = 461715
I0316 00:50:08.230434 29479 solver.cpp:214] Iteration 62140, loss = 5793.91
I0316 00:50:08.230563 29479 solver.cpp:229]     Train net output #0: loss = 3835.64 (* 1 = 3835.64 loss)
I0316 00:50:08.424722 29479 solver.cpp:610] Iteration 62140, lr = 7.15431e-09
I0316 00:50:08.424743 29479 solver.cpp:613] Iteration 62140, avg_grad_norm = 520751
I0316 00:51:17.431674 29479 solver.cpp:214] Iteration 62160, loss = 5816.82
I0316 00:51:17.431782 29479 solver.cpp:229]     Train net output #0: loss = 11956.4 (* 1 = 11956.4 loss)
I0316 00:51:17.820725 29479 solver.cpp:610] Iteration 62160, lr = 7.15337e-09
I0316 00:51:17.820744 29479 solver.cpp:613] Iteration 62160, avg_grad_norm = 578997
I0316 00:52:04.380506 29479 solver.cpp:214] Iteration 62180, loss = 5692.99
I0316 00:52:04.380669 29479 solver.cpp:229]     Train net output #0: loss = 5349.8 (* 1 = 5349.8 loss)
I0316 00:52:04.742874 29479 solver.cpp:610] Iteration 62180, lr = 7.15244e-09
I0316 00:52:04.742888 29479 solver.cpp:613] Iteration 62180, avg_grad_norm = 566415
I0316 00:53:12.312688 29479 solver.cpp:214] Iteration 62200, loss = 5722.22
I0316 00:53:12.312891 29479 solver.cpp:229]     Train net output #0: loss = 3641.21 (* 1 = 3641.21 loss)
I0316 00:53:12.682149 29479 solver.cpp:610] Iteration 62200, lr = 7.1515e-09
I0316 00:53:12.682171 29479 solver.cpp:613] Iteration 62200, avg_grad_norm = 513052
I0316 00:54:21.214301 29479 solver.cpp:214] Iteration 62220, loss = 5670.06
I0316 00:54:21.214421 29479 solver.cpp:229]     Train net output #0: loss = 7444.08 (* 1 = 7444.08 loss)
I0316 00:54:21.575512 29479 solver.cpp:610] Iteration 62220, lr = 7.15057e-09
I0316 00:54:21.575530 29479 solver.cpp:613] Iteration 62220, avg_grad_norm = 495984
I0316 00:55:43.731075 29479 solver.cpp:214] Iteration 62240, loss = 5904.22
I0316 00:55:43.731207 29479 solver.cpp:229]     Train net output #0: loss = 7599.8 (* 1 = 7599.8 loss)
I0316 00:55:44.092111 29479 solver.cpp:610] Iteration 62240, lr = 7.14963e-09
I0316 00:55:44.092125 29479 solver.cpp:613] Iteration 62240, avg_grad_norm = 458027
I0316 00:56:52.267438 29479 solver.cpp:214] Iteration 62260, loss = 5837.52
I0316 00:56:52.267566 29479 solver.cpp:229]     Train net output #0: loss = 4863.03 (* 1 = 4863.03 loss)
I0316 00:56:52.637398 29479 solver.cpp:610] Iteration 62260, lr = 7.1487e-09
I0316 00:56:52.637413 29479 solver.cpp:613] Iteration 62260, avg_grad_norm = 513030
I0316 00:58:02.029017 29479 solver.cpp:214] Iteration 62280, loss = 5738.42
I0316 00:58:02.029139 29479 solver.cpp:229]     Train net output #0: loss = 5221.7 (* 1 = 5221.7 loss)
I0316 00:58:02.395392 29479 solver.cpp:610] Iteration 62280, lr = 7.14777e-09
I0316 00:58:02.395406 29479 solver.cpp:613] Iteration 62280, avg_grad_norm = 547238
I0316 00:59:05.793819 29479 solver.cpp:214] Iteration 62300, loss = 5925.93
I0316 00:59:05.793961 29479 solver.cpp:229]     Train net output #0: loss = 4890.62 (* 1 = 4890.62 loss)
I0316 00:59:05.900439 29479 solver.cpp:610] Iteration 62300, lr = 7.14683e-09
I0316 00:59:05.900488 29479 solver.cpp:613] Iteration 62300, avg_grad_norm = 503024
I0316 00:59:55.133213 29479 solver.cpp:214] Iteration 62320, loss = 5584.31
I0316 00:59:55.133330 29479 solver.cpp:229]     Train net output #0: loss = 9418.32 (* 1 = 9418.32 loss)
I0316 00:59:55.494176 29479 solver.cpp:610] Iteration 62320, lr = 7.1459e-09
I0316 00:59:55.494190 29479 solver.cpp:613] Iteration 62320, avg_grad_norm = 560658
I0316 01:01:04.116353 29479 solver.cpp:214] Iteration 62340, loss = 5753.44
I0316 01:01:04.116444 29479 solver.cpp:229]     Train net output #0: loss = 3307.59 (* 1 = 3307.59 loss)
I0316 01:01:04.483500 29479 solver.cpp:610] Iteration 62340, lr = 7.14496e-09
I0316 01:01:04.483513 29479 solver.cpp:613] Iteration 62340, avg_grad_norm = 565002
I0316 01:02:32.351208 29479 solver.cpp:214] Iteration 62360, loss = 5715.36
I0316 01:02:32.351297 29479 solver.cpp:229]     Train net output #0: loss = 2956.78 (* 1 = 2956.78 loss)
I0316 01:02:32.717676 29479 solver.cpp:610] Iteration 62360, lr = 7.14403e-09
I0316 01:02:32.717690 29479 solver.cpp:613] Iteration 62360, avg_grad_norm = 585061
I0316 01:03:41.371794 29479 solver.cpp:214] Iteration 62380, loss = 5783.62
I0316 01:03:41.371896 29479 solver.cpp:229]     Train net output #0: loss = 4142.54 (* 1 = 4142.54 loss)
I0316 01:03:41.704632 29479 solver.cpp:610] Iteration 62380, lr = 7.14309e-09
I0316 01:03:41.704648 29479 solver.cpp:613] Iteration 62380, avg_grad_norm = 509687
I0316 01:04:50.218056 29479 solver.cpp:214] Iteration 62400, loss = 6212.27
I0316 01:04:50.218190 29479 solver.cpp:229]     Train net output #0: loss = 5014.41 (* 1 = 5014.41 loss)
I0316 01:04:50.578274 29479 solver.cpp:610] Iteration 62400, lr = 7.14216e-09
I0316 01:04:50.578289 29479 solver.cpp:613] Iteration 62400, avg_grad_norm = 568306
I0316 01:05:59.779489 29479 solver.cpp:214] Iteration 62420, loss = 5657.79
I0316 01:05:59.779651 29479 solver.cpp:229]     Train net output #0: loss = 4357.63 (* 1 = 4357.63 loss)
I0316 01:06:00.143193 29479 solver.cpp:610] Iteration 62420, lr = 7.14123e-09
I0316 01:06:00.143208 29479 solver.cpp:613] Iteration 62420, avg_grad_norm = 527617
I0316 01:06:45.927103 29479 solver.cpp:214] Iteration 62440, loss = 5728.62
I0316 01:06:45.927212 29479 solver.cpp:229]     Train net output #0: loss = 7427.44 (* 1 = 7427.44 loss)
I0316 01:06:46.148108 29479 solver.cpp:610] Iteration 62440, lr = 7.14029e-09
I0316 01:06:46.148120 29479 solver.cpp:613] Iteration 62440, avg_grad_norm = 507618
I0316 01:07:55.026685 29479 solver.cpp:214] Iteration 62460, loss = 6190.46
I0316 01:07:55.026823 29479 solver.cpp:229]     Train net output #0: loss = 4055.06 (* 1 = 4055.06 loss)
I0316 01:07:55.393182 29479 solver.cpp:610] Iteration 62460, lr = 7.13936e-09
I0316 01:07:55.393196 29479 solver.cpp:613] Iteration 62460, avg_grad_norm = 596166
I0316 01:09:17.086799 29479 solver.cpp:214] Iteration 62480, loss = 5953
I0316 01:09:17.086938 29479 solver.cpp:229]     Train net output #0: loss = 5040.84 (* 1 = 5040.84 loss)
I0316 01:09:17.414911 29479 solver.cpp:610] Iteration 62480, lr = 7.13842e-09
I0316 01:09:17.414927 29479 solver.cpp:613] Iteration 62480, avg_grad_norm = 647303
I0316 01:10:24.391039 29479 solver.cpp:214] Iteration 62500, loss = 5959.1
I0316 01:10:24.391192 29479 solver.cpp:229]     Train net output #0: loss = 5055.6 (* 1 = 5055.6 loss)
I0316 01:10:24.754606 29479 solver.cpp:610] Iteration 62500, lr = 7.13749e-09
I0316 01:10:24.754619 29479 solver.cpp:613] Iteration 62500, avg_grad_norm = 753827
I0316 01:11:28.537727 29479 solver.cpp:214] Iteration 62520, loss = 5692.22
I0316 01:11:28.537866 29479 solver.cpp:229]     Train net output #0: loss = 3525.91 (* 1 = 3525.91 loss)
I0316 01:11:28.903230 29479 solver.cpp:610] Iteration 62520, lr = 7.13655e-09
I0316 01:11:28.903245 29479 solver.cpp:613] Iteration 62520, avg_grad_norm = 520631
I0316 01:12:34.317256 29479 solver.cpp:214] Iteration 62540, loss = 5796.25
I0316 01:12:34.317391 29479 solver.cpp:229]     Train net output #0: loss = 4877.45 (* 1 = 4877.45 loss)
I0316 01:12:34.655807 29479 solver.cpp:610] Iteration 62540, lr = 7.13562e-09
I0316 01:12:34.655822 29479 solver.cpp:613] Iteration 62540, avg_grad_norm = 538327
I0316 01:13:43.407230 29479 solver.cpp:214] Iteration 62560, loss = 6042.75
I0316 01:13:43.407376 29479 solver.cpp:229]     Train net output #0: loss = 5057.99 (* 1 = 5057.99 loss)
I0316 01:13:43.768198 29479 solver.cpp:610] Iteration 62560, lr = 7.13469e-09
I0316 01:13:43.768211 29479 solver.cpp:613] Iteration 62560, avg_grad_norm = 496279
I0316 01:14:30.011018 29479 solver.cpp:214] Iteration 62580, loss = 5723.07
I0316 01:14:30.011217 29479 solver.cpp:229]     Train net output #0: loss = 5272.11 (* 1 = 5272.11 loss)
I0316 01:14:30.340855 29479 solver.cpp:610] Iteration 62580, lr = 7.13375e-09
I0316 01:14:30.340872 29479 solver.cpp:613] Iteration 62580, avg_grad_norm = 487594
I0316 01:15:38.154299 29479 solver.cpp:214] Iteration 62600, loss = 5901.7
I0316 01:15:38.154585 29479 solver.cpp:229]     Train net output #0: loss = 5605.8 (* 1 = 5605.8 loss)
I0316 01:15:38.342270 29479 solver.cpp:610] Iteration 62600, lr = 7.13282e-09
I0316 01:15:38.342284 29479 solver.cpp:613] Iteration 62600, avg_grad_norm = 538389
I0316 01:17:10.936971 29479 solver.cpp:214] Iteration 62620, loss = 5997.94
I0316 01:17:10.937217 29479 solver.cpp:229]     Train net output #0: loss = 4659.02 (* 1 = 4659.02 loss)
I0316 01:17:11.302736 29479 solver.cpp:610] Iteration 62620, lr = 7.13188e-09
I0316 01:17:11.302749 29479 solver.cpp:613] Iteration 62620, avg_grad_norm = 576417
I0316 01:18:17.333899 29479 solver.cpp:214] Iteration 62640, loss = 5830.44
I0316 01:18:17.334079 29479 solver.cpp:229]     Train net output #0: loss = 4252.21 (* 1 = 4252.21 loss)
I0316 01:18:17.693542 29479 solver.cpp:610] Iteration 62640, lr = 7.13095e-09
I0316 01:18:17.693555 29479 solver.cpp:613] Iteration 62640, avg_grad_norm = 522287
I0316 01:19:26.059665 29479 solver.cpp:214] Iteration 62660, loss = 5970.01
I0316 01:19:26.059804 29479 solver.cpp:229]     Train net output #0: loss = 2893.27 (* 1 = 2893.27 loss)
I0316 01:19:26.425386 29479 solver.cpp:610] Iteration 62660, lr = 7.13001e-09
I0316 01:19:26.425400 29479 solver.cpp:613] Iteration 62660, avg_grad_norm = 479958
I0316 01:20:35.775583 29479 solver.cpp:214] Iteration 62680, loss = 6278.23
I0316 01:20:35.775710 29479 solver.cpp:229]     Train net output #0: loss = 4492.19 (* 1 = 4492.19 loss)
I0316 01:20:36.135571 29479 solver.cpp:610] Iteration 62680, lr = 7.12908e-09
I0316 01:20:36.135586 29479 solver.cpp:613] Iteration 62680, avg_grad_norm = 487132
I0316 01:21:37.669831 29479 solver.cpp:214] Iteration 62700, loss = 5840.27
I0316 01:21:37.669973 29479 solver.cpp:229]     Train net output #0: loss = 7568.44 (* 1 = 7568.44 loss)
I0316 01:21:37.779857 29479 solver.cpp:610] Iteration 62700, lr = 7.12814e-09
I0316 01:21:37.779911 29479 solver.cpp:613] Iteration 62700, avg_grad_norm = 545704
I0316 01:22:31.509774 29479 solver.cpp:214] Iteration 62720, loss = 5903.97
I0316 01:22:31.510002 29479 solver.cpp:229]     Train net output #0: loss = 3450.71 (* 1 = 3450.71 loss)
I0316 01:22:31.876253 29479 solver.cpp:610] Iteration 62720, lr = 7.12721e-09
I0316 01:22:31.876277 29479 solver.cpp:613] Iteration 62720, avg_grad_norm = 587700
I0316 01:24:01.525290 29479 solver.cpp:214] Iteration 62740, loss = 6256.06
I0316 01:24:01.525416 29479 solver.cpp:229]     Train net output #0: loss = 4863.72 (* 1 = 4863.72 loss)
I0316 01:24:01.860641 29479 solver.cpp:610] Iteration 62740, lr = 7.12628e-09
I0316 01:24:01.860654 29479 solver.cpp:613] Iteration 62740, avg_grad_norm = 621688
I0316 01:25:10.160393 29479 solver.cpp:214] Iteration 62760, loss = 5545
I0316 01:25:10.160528 29479 solver.cpp:229]     Train net output #0: loss = 6494.07 (* 1 = 6494.07 loss)
I0316 01:25:10.523910 29479 solver.cpp:610] Iteration 62760, lr = 7.12534e-09
I0316 01:25:10.523923 29479 solver.cpp:613] Iteration 62760, avg_grad_norm = 570689
I0316 01:26:19.133286 29479 solver.cpp:214] Iteration 62780, loss = 5707.04
I0316 01:26:19.133497 29479 solver.cpp:229]     Train net output #0: loss = 4866.5 (* 1 = 4866.5 loss)
I0316 01:26:19.521042 29479 solver.cpp:610] Iteration 62780, lr = 7.12441e-09
I0316 01:26:19.521056 29479 solver.cpp:613] Iteration 62780, avg_grad_norm = 542454
I0316 01:27:27.969903 29479 solver.cpp:214] Iteration 62800, loss = 5986.11
I0316 01:27:27.970036 29479 solver.cpp:229]     Train net output #0: loss = 4397.55 (* 1 = 4397.55 loss)
I0316 01:27:28.339068 29479 solver.cpp:610] Iteration 62800, lr = 7.12347e-09
I0316 01:27:28.339082 29479 solver.cpp:613] Iteration 62800, avg_grad_norm = 581588
I0316 01:28:37.243767 29479 solver.cpp:214] Iteration 62820, loss = 6191.02
I0316 01:28:37.243924 29479 solver.cpp:229]     Train net output #0: loss = 8697.54 (* 1 = 8697.54 loss)
I0316 01:28:37.606390 29479 solver.cpp:610] Iteration 62820, lr = 7.12254e-09
I0316 01:28:37.606403 29479 solver.cpp:613] Iteration 62820, avg_grad_norm = 536741
I0316 01:29:24.238390 29479 solver.cpp:214] Iteration 62840, loss = 6033.24
I0316 01:29:24.238509 29479 solver.cpp:229]     Train net output #0: loss = 3229.31 (* 1 = 3229.31 loss)
I0316 01:29:24.602942 29479 solver.cpp:610] Iteration 62840, lr = 7.1216e-09
I0316 01:29:24.602955 29479 solver.cpp:613] Iteration 62840, avg_grad_norm = 513842
I0316 01:30:34.160403 29479 solver.cpp:214] Iteration 62860, loss = 5631.42
I0316 01:30:34.160511 29479 solver.cpp:229]     Train net output #0: loss = 5181.36 (* 1 = 5181.36 loss)
I0316 01:30:34.519769 29479 solver.cpp:610] Iteration 62860, lr = 7.12067e-09
I0316 01:30:34.519783 29479 solver.cpp:613] Iteration 62860, avg_grad_norm = 553696
I0316 01:31:59.771916 29479 solver.cpp:214] Iteration 62880, loss = 5687.02
I0316 01:31:59.772162 29479 solver.cpp:229]     Train net output #0: loss = 7706.04 (* 1 = 7706.04 loss)
I0316 01:32:00.162590 29479 solver.cpp:610] Iteration 62880, lr = 7.11973e-09
I0316 01:32:00.162603 29479 solver.cpp:613] Iteration 62880, avg_grad_norm = 521094
I0316 01:33:08.895911 29479 solver.cpp:214] Iteration 62900, loss = 5818.08
I0316 01:33:08.896035 29479 solver.cpp:229]     Train net output #0: loss = 10089.5 (* 1 = 10089.5 loss)
I0316 01:33:09.261874 29479 solver.cpp:610] Iteration 62900, lr = 7.1188e-09
I0316 01:33:09.261888 29479 solver.cpp:613] Iteration 62900, avg_grad_norm = 496733
I0316 01:34:18.704329 29479 solver.cpp:214] Iteration 62920, loss = 5677.12
I0316 01:34:18.704459 29479 solver.cpp:229]     Train net output #0: loss = 6722.71 (* 1 = 6722.71 loss)
I0316 01:34:19.064584 29479 solver.cpp:610] Iteration 62920, lr = 7.11786e-09
I0316 01:34:19.064625 29479 solver.cpp:613] Iteration 62920, avg_grad_norm = 514241
I0316 01:35:27.556795 29479 solver.cpp:214] Iteration 62940, loss = 6144.81
I0316 01:35:27.556926 29479 solver.cpp:229]     Train net output #0: loss = 5060.36 (* 1 = 5060.36 loss)
I0316 01:35:27.947372 29479 solver.cpp:610] Iteration 62940, lr = 7.11693e-09
I0316 01:35:27.947386 29479 solver.cpp:613] Iteration 62940, avg_grad_norm = 537757
I0316 01:36:31.398352 29479 solver.cpp:214] Iteration 62960, loss = 5783.72
I0316 01:36:31.398494 29479 solver.cpp:229]     Train net output #0: loss = 5166.15 (* 1 = 5166.15 loss)
I0316 01:36:31.503725 29479 solver.cpp:610] Iteration 62960, lr = 7.11599e-09
I0316 01:36:31.503773 29479 solver.cpp:613] Iteration 62960, avg_grad_norm = 564590
I0316 01:37:22.691730 29479 solver.cpp:214] Iteration 62980, loss = 5952.97
I0316 01:37:22.691850 29479 solver.cpp:229]     Train net output #0: loss = 5053.47 (* 1 = 5053.47 loss)
I0316 01:37:23.058070 29479 solver.cpp:610] Iteration 62980, lr = 7.11506e-09
I0316 01:37:23.058086 29479 solver.cpp:613] Iteration 62980, avg_grad_norm = 504915
I0316 01:38:43.853844 29479 solver.cpp:214] Iteration 63000, loss = 5955.52
I0316 01:38:43.853965 29479 solver.cpp:229]     Train net output #0: loss = 2982.11 (* 1 = 2982.11 loss)
I0316 01:38:44.220427 29479 solver.cpp:610] Iteration 63000, lr = 7.11413e-09
I0316 01:38:44.220441 29479 solver.cpp:613] Iteration 63000, avg_grad_norm = 512762
I0316 01:39:53.071055 29479 solver.cpp:214] Iteration 63020, loss = 5653.83
I0316 01:39:53.071162 29479 solver.cpp:229]     Train net output #0: loss = 5888.12 (* 1 = 5888.12 loss)
I0316 01:39:53.431676 29479 solver.cpp:610] Iteration 63020, lr = 7.11319e-09
I0316 01:39:53.431689 29479 solver.cpp:613] Iteration 63020, avg_grad_norm = 474403
I0316 01:41:01.377022 29479 solver.cpp:214] Iteration 63040, loss = 5873.82
I0316 01:41:01.377212 29479 solver.cpp:229]     Train net output #0: loss = 3457.35 (* 1 = 3457.35 loss)
I0316 01:41:01.745606 29479 solver.cpp:610] Iteration 63040, lr = 7.11226e-09
I0316 01:41:01.745620 29479 solver.cpp:613] Iteration 63040, avg_grad_norm = 488594
I0316 01:42:10.219938 29479 solver.cpp:214] Iteration 63060, loss = 6015.82
I0316 01:42:10.220091 29479 solver.cpp:229]     Train net output #0: loss = 6202.57 (* 1 = 6202.57 loss)
I0316 01:42:10.580317 29479 solver.cpp:610] Iteration 63060, lr = 7.11132e-09
I0316 01:42:10.580334 29479 solver.cpp:613] Iteration 63060, avg_grad_norm = 568775
I0316 01:43:19.199998 29479 solver.cpp:214] Iteration 63080, loss = 6017.1
I0316 01:43:19.200126 29479 solver.cpp:229]     Train net output #0: loss = 3899.35 (* 1 = 3899.35 loss)
I0316 01:43:19.416460 29479 solver.cpp:610] Iteration 63080, lr = 7.11039e-09
I0316 01:43:19.416476 29479 solver.cpp:613] Iteration 63080, avg_grad_norm = 512778
I0316 01:44:10.590386 29479 solver.cpp:214] Iteration 63100, loss = 5724.35
I0316 01:44:10.590522 29479 solver.cpp:229]     Train net output #0: loss = 9921.42 (* 1 = 9921.42 loss)
I0316 01:44:10.708478 29479 solver.cpp:610] Iteration 63100, lr = 7.10945e-09
I0316 01:44:10.708524 29479 solver.cpp:613] Iteration 63100, avg_grad_norm = 505177
I0316 01:45:28.362808 29479 solver.cpp:214] Iteration 63120, loss = 5742.45
I0316 01:45:28.363000 29479 solver.cpp:229]     Train net output #0: loss = 4874.24 (* 1 = 4874.24 loss)
I0316 01:45:28.722919 29479 solver.cpp:610] Iteration 63120, lr = 7.10852e-09
I0316 01:45:28.722959 29479 solver.cpp:613] Iteration 63120, avg_grad_norm = 555460
I0316 01:46:36.645432 29479 solver.cpp:214] Iteration 63140, loss = 5916.22
I0316 01:46:36.645634 29479 solver.cpp:229]     Train net output #0: loss = 4777.13 (* 1 = 4777.13 loss)
I0316 01:46:37.008610 29479 solver.cpp:610] Iteration 63140, lr = 7.10758e-09
I0316 01:46:37.008625 29479 solver.cpp:613] Iteration 63140, avg_grad_norm = 508884
I0316 01:47:45.671355 29479 solver.cpp:214] Iteration 63160, loss = 5632.02
I0316 01:47:45.671497 29479 solver.cpp:229]     Train net output #0: loss = 10323.8 (* 1 = 10323.8 loss)
I0316 01:47:45.992166 29479 solver.cpp:610] Iteration 63160, lr = 7.10665e-09
I0316 01:47:45.992180 29479 solver.cpp:613] Iteration 63160, avg_grad_norm = 511901
I0316 01:48:54.831742 29479 solver.cpp:214] Iteration 63180, loss = 5904.45
I0316 01:48:54.831867 29479 solver.cpp:229]     Train net output #0: loss = 3399.3 (* 1 = 3399.3 loss)
I0316 01:48:55.194599 29479 solver.cpp:610] Iteration 63180, lr = 7.10571e-09
I0316 01:48:55.194614 29479 solver.cpp:613] Iteration 63180, avg_grad_norm = 518021
I0316 01:50:03.242624 29479 solver.cpp:214] Iteration 63200, loss = 5978.96
I0316 01:50:03.242801 29479 solver.cpp:229]     Train net output #0: loss = 3121.71 (* 1 = 3121.71 loss)
I0316 01:50:03.602998 29479 solver.cpp:610] Iteration 63200, lr = 7.10478e-09
I0316 01:50:03.603013 29479 solver.cpp:613] Iteration 63200, avg_grad_norm = 483258
I0316 01:51:11.751505 29479 solver.cpp:214] Iteration 63220, loss = 5622.3
I0316 01:51:11.751641 29479 solver.cpp:229]     Train net output #0: loss = 9296.01 (* 1 = 9296.01 loss)
I0316 01:51:12.110932 29479 solver.cpp:610] Iteration 63220, lr = 7.10384e-09
I0316 01:51:12.110947 29479 solver.cpp:613] Iteration 63220, avg_grad_norm = 495087
I0316 01:51:59.704727 29479 solver.cpp:214] Iteration 63240, loss = 5989.83
I0316 01:51:59.704932 29479 solver.cpp:229]     Train net output #0: loss = 9890.32 (* 1 = 9890.32 loss)
I0316 01:52:00.064095 29479 solver.cpp:610] Iteration 63240, lr = 7.10291e-09
I0316 01:52:00.064110 29479 solver.cpp:613] Iteration 63240, avg_grad_norm = 524056
I0316 01:53:21.364593 29479 solver.cpp:214] Iteration 63260, loss = 6143.11
I0316 01:53:21.364722 29479 solver.cpp:229]     Train net output #0: loss = 4333.23 (* 1 = 4333.23 loss)
I0316 01:53:21.725795 29479 solver.cpp:610] Iteration 63260, lr = 7.10197e-09
I0316 01:53:21.725808 29479 solver.cpp:613] Iteration 63260, avg_grad_norm = 492025
I0316 01:54:29.461894 29479 solver.cpp:214] Iteration 63280, loss = 5941.83
I0316 01:54:29.462021 29479 solver.cpp:229]     Train net output #0: loss = 5809.14 (* 1 = 5809.14 loss)
I0316 01:54:29.822420 29479 solver.cpp:610] Iteration 63280, lr = 7.10104e-09
I0316 01:54:29.822434 29479 solver.cpp:613] Iteration 63280, avg_grad_norm = 535818
I0316 01:55:38.703372 29479 solver.cpp:214] Iteration 63300, loss = 6108.64
I0316 01:55:38.703508 29479 solver.cpp:229]     Train net output #0: loss = 6716.76 (* 1 = 6716.76 loss)
I0316 01:55:39.063716 29479 solver.cpp:610] Iteration 63300, lr = 7.1001e-09
I0316 01:55:39.063730 29479 solver.cpp:613] Iteration 63300, avg_grad_norm = 631336
I0316 01:56:47.080572 29479 solver.cpp:214] Iteration 63320, loss = 6107.83
I0316 01:56:47.080718 29479 solver.cpp:229]     Train net output #0: loss = 4142.57 (* 1 = 4142.57 loss)
I0316 01:56:47.446913 29479 solver.cpp:610] Iteration 63320, lr = 7.09917e-09
I0316 01:56:47.446926 29479 solver.cpp:613] Iteration 63320, avg_grad_norm = 546808
I0316 01:57:56.173804 29479 solver.cpp:214] Iteration 63340, loss = 5591.44
I0316 01:57:56.174018 29479 solver.cpp:229]     Train net output #0: loss = 4357.73 (* 1 = 4357.73 loss)
I0316 01:57:56.533704 29479 solver.cpp:610] Iteration 63340, lr = 7.09823e-09
I0316 01:57:56.533740 29479 solver.cpp:613] Iteration 63340, avg_grad_norm = 549802
I0316 01:59:03.233937 29479 solver.cpp:214] Iteration 63360, loss = 6097.88
I0316 01:59:03.234138 29479 solver.cpp:229]     Train net output #0: loss = 5171.07 (* 1 = 5171.07 loss)
I0316 01:59:03.340517 29479 solver.cpp:610] Iteration 63360, lr = 7.0973e-09
I0316 01:59:03.340556 29479 solver.cpp:613] Iteration 63360, avg_grad_norm = 510314
I0316 02:00:05.286028 29479 solver.cpp:214] Iteration 63380, loss = 5836.99
I0316 02:00:05.286175 29479 solver.cpp:229]     Train net output #0: loss = 7435.26 (* 1 = 7435.26 loss)
I0316 02:00:05.650534 29479 solver.cpp:610] Iteration 63380, lr = 7.09636e-09
I0316 02:00:05.650549 29479 solver.cpp:613] Iteration 63380, avg_grad_norm = 522943
I0316 02:01:13.829730 29479 solver.cpp:214] Iteration 63400, loss = 5760.41
I0316 02:01:13.829851 29479 solver.cpp:229]     Train net output #0: loss = 3573.9 (* 1 = 3573.9 loss)
I0316 02:01:14.164741 29479 solver.cpp:610] Iteration 63400, lr = 7.09543e-09
I0316 02:01:14.164757 29479 solver.cpp:613] Iteration 63400, avg_grad_norm = 569314
I0316 02:02:23.114095 29479 solver.cpp:214] Iteration 63420, loss = 6148.92
I0316 02:02:23.114222 29479 solver.cpp:229]     Train net output #0: loss = 8650.86 (* 1 = 8650.86 loss)
I0316 02:02:23.480839 29479 solver.cpp:610] Iteration 63420, lr = 7.09449e-09
I0316 02:02:23.480854 29479 solver.cpp:613] Iteration 63420, avg_grad_norm = 545308
I0316 02:03:31.741808 29479 solver.cpp:214] Iteration 63440, loss = 5831.06
I0316 02:03:31.741932 29479 solver.cpp:229]     Train net output #0: loss = 6877.04 (* 1 = 6877.04 loss)
I0316 02:03:32.124575 29479 solver.cpp:610] Iteration 63440, lr = 7.09356e-09
I0316 02:03:32.124589 29479 solver.cpp:613] Iteration 63440, avg_grad_norm = 492967
I0316 02:04:40.959214 29479 solver.cpp:214] Iteration 63460, loss = 5795.67
I0316 02:04:40.959362 29479 solver.cpp:229]     Train net output #0: loss = 3494.21 (* 1 = 3494.21 loss)
I0316 02:04:41.327918 29479 solver.cpp:610] Iteration 63460, lr = 7.09262e-09
I0316 02:04:41.327931 29479 solver.cpp:613] Iteration 63460, avg_grad_norm = 506914
I0316 02:05:50.538393 29479 solver.cpp:214] Iteration 63480, loss = 5667.06
I0316 02:05:50.538506 29479 solver.cpp:229]     Train net output #0: loss = 8562.07 (* 1 = 8562.07 loss)
I0316 02:05:50.909397 29479 solver.cpp:610] Iteration 63480, lr = 7.09169e-09
I0316 02:05:50.909411 29479 solver.cpp:613] Iteration 63480, avg_grad_norm = 517309
I0316 02:07:11.998699 29479 solver.cpp:214] Iteration 63500, loss = 5725.55
I0316 02:07:11.998831 29479 solver.cpp:229]     Train net output #0: loss = 3012.81 (* 1 = 3012.81 loss)
I0316 02:07:12.355726 29479 solver.cpp:610] Iteration 63500, lr = 7.09075e-09
I0316 02:07:12.355739 29479 solver.cpp:613] Iteration 63500, avg_grad_norm = 524722
I0316 02:08:20.220693 29479 solver.cpp:214] Iteration 63520, loss = 5700.23
I0316 02:08:20.220895 29479 solver.cpp:229]     Train net output #0: loss = 5120.93 (* 1 = 5120.93 loss)
I0316 02:08:20.581673 29479 solver.cpp:610] Iteration 63520, lr = 7.08982e-09
I0316 02:08:20.581708 29479 solver.cpp:613] Iteration 63520, avg_grad_norm = 524391
I0316 02:09:28.811002 29479 solver.cpp:214] Iteration 63540, loss = 5772.14
I0316 02:09:28.811137 29479 solver.cpp:229]     Train net output #0: loss = 7373.27 (* 1 = 7373.27 loss)
I0316 02:09:29.171300 29479 solver.cpp:610] Iteration 63540, lr = 7.08888e-09
I0316 02:09:29.171316 29479 solver.cpp:613] Iteration 63540, avg_grad_norm = 493578
I0316 02:10:37.803793 29479 solver.cpp:214] Iteration 63560, loss = 5771.52
I0316 02:10:37.803925 29479 solver.cpp:229]     Train net output #0: loss = 5013.15 (* 1 = 5013.15 loss)
I0316 02:10:38.163919 29479 solver.cpp:610] Iteration 63560, lr = 7.08795e-09
I0316 02:10:38.163934 29479 solver.cpp:613] Iteration 63560, avg_grad_norm = 588350
I0316 02:11:45.709547 29479 solver.cpp:214] Iteration 63580, loss = 5766.82
I0316 02:11:45.709661 29479 solver.cpp:229]     Train net output #0: loss = 8388.52 (* 1 = 8388.52 loss)
I0316 02:11:46.069810 29479 solver.cpp:610] Iteration 63580, lr = 7.08701e-09
I0316 02:11:46.069824 29479 solver.cpp:613] Iteration 63580, avg_grad_norm = 502116
I0316 02:12:49.939609 29479 solver.cpp:214] Iteration 63600, loss = 5687.39
I0316 02:12:49.939779 29479 solver.cpp:229]     Train net output #0: loss = 1965.04 (* 1 = 1965.04 loss)
I0316 02:12:50.301982 29479 solver.cpp:610] Iteration 63600, lr = 7.08608e-09
I0316 02:12:50.301995 29479 solver.cpp:613] Iteration 63600, avg_grad_norm = 531721
I0316 02:13:58.952965 29479 solver.cpp:214] Iteration 63620, loss = 5735.01
I0316 02:13:58.953229 29479 solver.cpp:229]     Train net output #0: loss = 4632.55 (* 1 = 4632.55 loss)
I0316 02:13:59.312274 29479 solver.cpp:610] Iteration 63620, lr = 7.08514e-09
I0316 02:13:59.312289 29479 solver.cpp:613] Iteration 63620, avg_grad_norm = 585322
I0316 02:15:24.455184 29479 solver.cpp:214] Iteration 63640, loss = 5731.21
I0316 02:15:24.455323 29479 solver.cpp:229]     Train net output #0: loss = 3551.28 (* 1 = 3551.28 loss)
I0316 02:15:24.810186 29479 solver.cpp:610] Iteration 63640, lr = 7.08421e-09
I0316 02:15:24.810201 29479 solver.cpp:613] Iteration 63640, avg_grad_norm = 476148
I0316 02:16:32.228536 29479 solver.cpp:214] Iteration 63660, loss = 5739.75
I0316 02:16:32.228668 29479 solver.cpp:229]     Train net output #0: loss = 8825.83 (* 1 = 8825.83 loss)
I0316 02:16:32.591716 29479 solver.cpp:610] Iteration 63660, lr = 7.08327e-09
I0316 02:16:32.591728 29479 solver.cpp:613] Iteration 63660, avg_grad_norm = 496836
I0316 02:17:41.087285 29479 solver.cpp:214] Iteration 63680, loss = 5703.91
I0316 02:17:41.087419 29479 solver.cpp:229]     Train net output #0: loss = 7103.21 (* 1 = 7103.21 loss)
I0316 02:17:41.447857 29479 solver.cpp:610] Iteration 63680, lr = 7.08234e-09
I0316 02:17:41.447871 29479 solver.cpp:613] Iteration 63680, avg_grad_norm = 523293
I0316 02:18:49.419157 29479 solver.cpp:214] Iteration 63700, loss = 5711.45
I0316 02:18:49.419292 29479 solver.cpp:229]     Train net output #0: loss = 5130.01 (* 1 = 5130.01 loss)
I0316 02:18:49.781311 29479 solver.cpp:610] Iteration 63700, lr = 7.0814e-09
I0316 02:18:49.781323 29479 solver.cpp:613] Iteration 63700, avg_grad_norm = 543433
I0316 02:19:57.806155 29479 solver.cpp:214] Iteration 63720, loss = 6023.61
I0316 02:19:57.806277 29479 solver.cpp:229]     Train net output #0: loss = 4133.32 (* 1 = 4133.32 loss)
I0316 02:19:58.165949 29479 solver.cpp:610] Iteration 63720, lr = 7.08047e-09
I0316 02:19:58.165966 29479 solver.cpp:613] Iteration 63720, avg_grad_norm = 553955
I0316 02:21:06.518272 29479 solver.cpp:214] Iteration 63740, loss = 6021.23
I0316 02:21:06.518383 29479 solver.cpp:229]     Train net output #0: loss = 6734.69 (* 1 = 6734.69 loss)
I0316 02:21:06.879297 29479 solver.cpp:610] Iteration 63740, lr = 7.07953e-09
I0316 02:21:06.879312 29479 solver.cpp:613] Iteration 63740, avg_grad_norm = 520419
I0316 02:22:16.462805 29479 solver.cpp:214] Iteration 63760, loss = 5828.25
I0316 02:22:16.462925 29479 solver.cpp:229]     Train net output #0: loss = 5783.81 (* 1 = 5783.81 loss)
I0316 02:22:16.821764 29479 solver.cpp:610] Iteration 63760, lr = 7.0786e-09
I0316 02:22:16.821779 29479 solver.cpp:613] Iteration 63760, avg_grad_norm = 492128
I0316 02:23:24.913210 29479 solver.cpp:214] Iteration 63780, loss = 5500.62
I0316 02:23:24.913334 29479 solver.cpp:229]     Train net output #0: loss = 3902.17 (* 1 = 3902.17 loss)
I0316 02:23:25.295570 29479 solver.cpp:610] Iteration 63780, lr = 7.07766e-09
I0316 02:23:25.295584 29479 solver.cpp:613] Iteration 63780, avg_grad_norm = 509514
I0316 02:24:33.589010 29479 solver.cpp:214] Iteration 63800, loss = 6373.27
I0316 02:24:33.589232 29479 solver.cpp:229]     Train net output #0: loss = 4812.93 (* 1 = 4812.93 loss)
I0316 02:24:33.949877 29479 solver.cpp:610] Iteration 63800, lr = 7.07673e-09
I0316 02:24:33.949899 29479 solver.cpp:613] Iteration 63800, avg_grad_norm = 548019
I0316 02:25:42.639021 29479 solver.cpp:214] Iteration 63820, loss = 5936.23
I0316 02:25:42.639168 29479 solver.cpp:229]     Train net output #0: loss = 4488.16 (* 1 = 4488.16 loss)
I0316 02:25:43.001165 29479 solver.cpp:610] Iteration 63820, lr = 7.07579e-09
I0316 02:25:43.001178 29479 solver.cpp:613] Iteration 63820, avg_grad_norm = 475891
I0316 02:26:51.016458 29479 solver.cpp:214] Iteration 63840, loss = 5542.37
I0316 02:26:51.016652 29479 solver.cpp:229]     Train net output #0: loss = 8091 (* 1 = 8091 loss)
I0316 02:26:51.376663 29479 solver.cpp:610] Iteration 63840, lr = 7.07486e-09
I0316 02:26:51.376677 29479 solver.cpp:613] Iteration 63840, avg_grad_norm = 529144
I0316 02:27:59.655305 29479 solver.cpp:214] Iteration 63860, loss = 5943.98
I0316 02:27:59.655511 29479 solver.cpp:229]     Train net output #0: loss = 6148.39 (* 1 = 6148.39 loss)
I0316 02:28:00.015367 29479 solver.cpp:610] Iteration 63860, lr = 7.07392e-09
I0316 02:28:00.015383 29479 solver.cpp:613] Iteration 63860, avg_grad_norm = 539199
I0316 02:29:20.076017 29479 solver.cpp:214] Iteration 63880, loss = 5601.76
I0316 02:29:20.076167 29479 solver.cpp:229]     Train net output #0: loss = 7567.95 (* 1 = 7567.95 loss)
I0316 02:29:20.180759 29479 solver.cpp:610] Iteration 63880, lr = 7.07299e-09
I0316 02:29:20.180797 29479 solver.cpp:613] Iteration 63880, avg_grad_norm = 565152
I0316 02:30:08.158221 29479 solver.cpp:214] Iteration 63900, loss = 6041.8
I0316 02:30:08.158362 29479 solver.cpp:229]     Train net output #0: loss = 4418.64 (* 1 = 4418.64 loss)
I0316 02:30:08.519183 29479 solver.cpp:610] Iteration 63900, lr = 7.07205e-09
I0316 02:30:08.519197 29479 solver.cpp:613] Iteration 63900, avg_grad_norm = 583169
I0316 02:31:17.286113 29479 solver.cpp:214] Iteration 63920, loss = 5703.31
I0316 02:31:17.286234 29479 solver.cpp:229]     Train net output #0: loss = 5195.42 (* 1 = 5195.42 loss)
I0316 02:31:17.646121 29479 solver.cpp:610] Iteration 63920, lr = 7.07111e-09
I0316 02:31:17.646133 29479 solver.cpp:613] Iteration 63920, avg_grad_norm = 499012
I0316 02:32:25.994351 29479 solver.cpp:214] Iteration 63940, loss = 5586.49
I0316 02:32:25.994482 29479 solver.cpp:229]     Train net output #0: loss = 5087.05 (* 1 = 5087.05 loss)
I0316 02:32:26.363049 29479 solver.cpp:610] Iteration 63940, lr = 7.07018e-09
I0316 02:32:26.363062 29479 solver.cpp:613] Iteration 63940, avg_grad_norm = 487566
I0316 02:33:35.549093 29479 solver.cpp:214] Iteration 63960, loss = 5619.51
I0316 02:33:35.549317 29479 solver.cpp:229]     Train net output #0: loss = 4547.48 (* 1 = 4547.48 loss)
I0316 02:33:35.911708 29479 solver.cpp:610] Iteration 63960, lr = 7.06924e-09
I0316 02:33:35.911722 29479 solver.cpp:613] Iteration 63960, avg_grad_norm = 499090
I0316 02:34:44.767217 29479 solver.cpp:214] Iteration 63980, loss = 5749.52
I0316 02:34:44.767374 29479 solver.cpp:229]     Train net output #0: loss = 8156.14 (* 1 = 8156.14 loss)
I0316 02:34:45.132556 29479 solver.cpp:610] Iteration 63980, lr = 7.06831e-09
I0316 02:34:45.132575 29479 solver.cpp:613] Iteration 63980, avg_grad_norm = 483082
I0316 02:35:54.564679 29479 solver.cpp:214] Iteration 64000, loss = 5666.26
I0316 02:35:54.564872 29479 solver.cpp:229]     Train net output #0: loss = 7390.36 (* 1 = 7390.36 loss)
I0316 02:35:54.931380 29479 solver.cpp:610] Iteration 64000, lr = 7.06737e-09
I0316 02:35:54.931406 29479 solver.cpp:613] Iteration 64000, avg_grad_norm = 544193
I0316 02:36:59.027571 29479 solver.cpp:214] Iteration 64020, loss = 5809.76
I0316 02:36:59.027719 29479 solver.cpp:229]     Train net output #0: loss = 10351.8 (* 1 = 10351.8 loss)
I0316 02:36:59.142216 29479 solver.cpp:610] Iteration 64020, lr = 7.06644e-09
I0316 02:36:59.142233 29479 solver.cpp:613] Iteration 64020, avg_grad_norm = 517613
I0316 02:37:47.813369 29479 solver.cpp:214] Iteration 64040, loss = 5730.09
I0316 02:37:47.813558 29479 solver.cpp:229]     Train net output #0: loss = 4194.42 (* 1 = 4194.42 loss)
I0316 02:37:48.188009 29479 solver.cpp:610] Iteration 64040, lr = 7.0655e-09
I0316 02:37:48.188024 29479 solver.cpp:613] Iteration 64040, avg_grad_norm = 487652
I0316 02:38:57.590206 29479 solver.cpp:214] Iteration 64060, loss = 5689.73
I0316 02:38:57.590390 29479 solver.cpp:229]     Train net output #0: loss = 4288.37 (* 1 = 4288.37 loss)
I0316 02:38:57.953071 29479 solver.cpp:610] Iteration 64060, lr = 7.06457e-09
I0316 02:38:57.953086 29479 solver.cpp:613] Iteration 64060, avg_grad_norm = 566551
I0316 02:40:06.583923 29479 solver.cpp:214] Iteration 64080, loss = 5933.34
I0316 02:40:06.584177 29479 solver.cpp:229]     Train net output #0: loss = 2088.33 (* 1 = 2088.33 loss)
I0316 02:40:06.944380 29479 solver.cpp:610] Iteration 64080, lr = 7.06363e-09
I0316 02:40:06.944399 29479 solver.cpp:613] Iteration 64080, avg_grad_norm = 531208
I0316 02:41:16.076326 29479 solver.cpp:214] Iteration 64100, loss = 5825.65
I0316 02:41:16.076484 29479 solver.cpp:229]     Train net output #0: loss = 4273.68 (* 1 = 4273.68 loss)
I0316 02:41:16.438647 29479 solver.cpp:610] Iteration 64100, lr = 7.0627e-09
I0316 02:41:16.438662 29479 solver.cpp:613] Iteration 64100, avg_grad_norm = 531716
I0316 02:42:25.731942 29479 solver.cpp:214] Iteration 64120, loss = 5995.74
I0316 02:42:25.732151 29479 solver.cpp:229]     Train net output #0: loss = 3504.59 (* 1 = 3504.59 loss)
I0316 02:42:26.106026 29479 solver.cpp:610] Iteration 64120, lr = 7.06176e-09
I0316 02:42:26.106040 29479 solver.cpp:613] Iteration 64120, avg_grad_norm = 570197
I0316 02:43:48.086320 29479 solver.cpp:214] Iteration 64140, loss = 5701.63
I0316 02:43:48.086412 29479 solver.cpp:229]     Train net output #0: loss = 4442.93 (* 1 = 4442.93 loss)
I0316 02:43:48.456274 29479 solver.cpp:610] Iteration 64140, lr = 7.06083e-09
I0316 02:43:48.456289 29479 solver.cpp:613] Iteration 64140, avg_grad_norm = 497082
I0316 02:44:38.552212 29479 solver.cpp:214] Iteration 64160, loss = 6045.05
I0316 02:44:38.552350 29479 solver.cpp:229]     Train net output #0: loss = 7013.11 (* 1 = 7013.11 loss)
I0316 02:44:38.668936 29479 solver.cpp:610] Iteration 64160, lr = 7.05989e-09
I0316 02:44:38.668972 29479 solver.cpp:613] Iteration 64160, avg_grad_norm = 545158
I0316 02:45:32.344703 29479 solver.cpp:214] Iteration 64180, loss = 5754.96
I0316 02:45:32.344828 29479 solver.cpp:229]     Train net output #0: loss = 3803.9 (* 1 = 3803.9 loss)
I0316 02:45:32.713876 29479 solver.cpp:610] Iteration 64180, lr = 7.05895e-09
I0316 02:45:32.713889 29479 solver.cpp:613] Iteration 64180, avg_grad_norm = 549505
I0316 02:46:41.972080 29479 solver.cpp:214] Iteration 64200, loss = 5782.4
I0316 02:46:41.972213 29479 solver.cpp:229]     Train net output #0: loss = 8389 (* 1 = 8389 loss)
I0316 02:46:42.332211 29479 solver.cpp:610] Iteration 64200, lr = 7.05802e-09
I0316 02:46:42.332249 29479 solver.cpp:613] Iteration 64200, avg_grad_norm = 567264
I0316 02:47:50.157912 29479 solver.cpp:214] Iteration 64220, loss = 6080.51
I0316 02:47:50.158064 29479 solver.cpp:229]     Train net output #0: loss = 4842.85 (* 1 = 4842.85 loss)
I0316 02:47:50.518936 29479 solver.cpp:610] Iteration 64220, lr = 7.05708e-09
I0316 02:47:50.518951 29479 solver.cpp:613] Iteration 64220, avg_grad_norm = 529300
I0316 02:48:59.091750 29479 solver.cpp:214] Iteration 64240, loss = 5902.2
I0316 02:48:59.091878 29479 solver.cpp:229]     Train net output #0: loss = 3675.5 (* 1 = 3675.5 loss)
I0316 02:48:59.452096 29479 solver.cpp:610] Iteration 64240, lr = 7.05615e-09
I0316 02:48:59.452110 29479 solver.cpp:613] Iteration 64240, avg_grad_norm = 501768
I0316 02:50:21.447345 29479 solver.cpp:214] Iteration 64260, loss = 5710.77
I0316 02:50:21.447434 29479 solver.cpp:229]     Train net output #0: loss = 4340.86 (* 1 = 4340.86 loss)
I0316 02:50:21.810078 29479 solver.cpp:610] Iteration 64260, lr = 7.05521e-09
I0316 02:50:21.810093 29479 solver.cpp:613] Iteration 64260, avg_grad_norm = 507299
I0316 02:51:29.390537 29479 solver.cpp:214] Iteration 64280, loss = 6179.39
I0316 02:51:29.390668 29479 solver.cpp:229]     Train net output #0: loss = 3935.19 (* 1 = 3935.19 loss)
I0316 02:51:29.759856 29479 solver.cpp:610] Iteration 64280, lr = 7.05428e-09
I0316 02:51:29.759871 29479 solver.cpp:613] Iteration 64280, avg_grad_norm = 524226
I0316 02:52:17.919121 29479 solver.cpp:214] Iteration 64300, loss = 5711.91
I0316 02:52:17.919260 29479 solver.cpp:229]     Train net output #0: loss = 3764.72 (* 1 = 3764.72 loss)
I0316 02:52:18.035208 29479 solver.cpp:610] Iteration 64300, lr = 7.05334e-09
I0316 02:52:18.035257 29479 solver.cpp:613] Iteration 64300, avg_grad_norm = 510408
I0316 02:53:25.948210 29479 solver.cpp:214] Iteration 64320, loss = 5766.99
I0316 02:53:25.948379 29479 solver.cpp:229]     Train net output #0: loss = 7106.69 (* 1 = 7106.69 loss)
I0316 02:53:26.308095 29479 solver.cpp:610] Iteration 64320, lr = 7.05241e-09
I0316 02:53:26.308112 29479 solver.cpp:613] Iteration 64320, avg_grad_norm = 470352
I0316 02:54:34.551098 29479 solver.cpp:214] Iteration 64340, loss = 6006.87
I0316 02:54:34.551223 29479 solver.cpp:229]     Train net output #0: loss = 9637.48 (* 1 = 9637.48 loss)
I0316 02:54:34.920764 29479 solver.cpp:610] Iteration 64340, lr = 7.05147e-09
I0316 02:54:34.920778 29479 solver.cpp:613] Iteration 64340, avg_grad_norm = 501583
I0316 02:55:43.416908 29479 solver.cpp:214] Iteration 64360, loss = 5870.4
I0316 02:55:43.417021 29479 solver.cpp:229]     Train net output #0: loss = 8360.55 (* 1 = 8360.55 loss)
I0316 02:55:43.782706 29479 solver.cpp:610] Iteration 64360, lr = 7.05053e-09
I0316 02:55:43.782719 29479 solver.cpp:613] Iteration 64360, avg_grad_norm = 468729
I0316 02:56:53.048323 29479 solver.cpp:214] Iteration 64380, loss = 5894.65
I0316 02:56:53.048418 29479 solver.cpp:229]     Train net output #0: loss = 4830.46 (* 1 = 4830.46 loss)
I0316 02:56:53.409721 29479 solver.cpp:610] Iteration 64380, lr = 7.0496e-09
I0316 02:56:53.409734 29479 solver.cpp:613] Iteration 64380, avg_grad_norm = 570305
I0316 02:58:14.295042 29479 solver.cpp:214] Iteration 64400, loss = 5700.56
I0316 02:58:14.295248 29479 solver.cpp:229]     Train net output #0: loss = 4967.58 (* 1 = 4967.58 loss)
I0316 02:58:14.658334 29479 solver.cpp:610] Iteration 64400, lr = 7.04866e-09
I0316 02:58:14.658347 29479 solver.cpp:613] Iteration 64400, avg_grad_norm = 527616
I0316 02:59:22.506253 29479 solver.cpp:214] Iteration 64420, loss = 5312.04
I0316 02:59:22.506335 29479 solver.cpp:229]     Train net output #0: loss = 4443.84 (* 1 = 4443.84 loss)
I0316 02:59:22.703040 29479 solver.cpp:610] Iteration 64420, lr = 7.04773e-09
I0316 02:59:22.703054 29479 solver.cpp:613] Iteration 64420, avg_grad_norm = 486045
I0316 03:00:08.756710 29479 solver.cpp:214] Iteration 64440, loss = 5765.39
I0316 03:00:08.756871 29479 solver.cpp:229]     Train net output #0: loss = 3763.7 (* 1 = 3763.7 loss)
I0316 03:00:09.117583 29479 solver.cpp:610] Iteration 64440, lr = 7.04679e-09
I0316 03:00:09.117596 29479 solver.cpp:613] Iteration 64440, avg_grad_norm = 487634
I0316 03:01:17.901259 29479 solver.cpp:214] Iteration 64460, loss = 5937.24
I0316 03:01:17.901377 29479 solver.cpp:229]     Train net output #0: loss = 5122.13 (* 1 = 5122.13 loss)
I0316 03:01:18.234148 29479 solver.cpp:610] Iteration 64460, lr = 7.04586e-09
I0316 03:01:18.234160 29479 solver.cpp:613] Iteration 64460, avg_grad_norm = 571461
I0316 03:02:26.691673 29479 solver.cpp:214] Iteration 64480, loss = 5901.51
I0316 03:02:26.691869 29479 solver.cpp:229]     Train net output #0: loss = 10927.1 (* 1 = 10927.1 loss)
I0316 03:02:27.050813 29479 solver.cpp:610] Iteration 64480, lr = 7.04492e-09
I0316 03:02:27.050828 29479 solver.cpp:613] Iteration 64480, avg_grad_norm = 578277
I0316 03:03:36.039271 29479 solver.cpp:214] Iteration 64500, loss = 5808.79
I0316 03:03:36.039379 29479 solver.cpp:229]     Train net output #0: loss = 6070.16 (* 1 = 6070.16 loss)
I0316 03:03:36.402550 29479 solver.cpp:610] Iteration 64500, lr = 7.04398e-09
I0316 03:03:36.402564 29479 solver.cpp:613] Iteration 64500, avg_grad_norm = 483081
I0316 03:04:58.042285 29479 solver.cpp:214] Iteration 64520, loss = 6020.01
I0316 03:04:58.042418 29479 solver.cpp:229]     Train net output #0: loss = 4523.51 (* 1 = 4523.51 loss)
I0316 03:04:58.411185 29479 solver.cpp:610] Iteration 64520, lr = 7.04305e-09
I0316 03:04:58.411200 29479 solver.cpp:613] Iteration 64520, avg_grad_norm = 536242
I0316 03:06:06.688885 29479 solver.cpp:214] Iteration 64540, loss = 5916.23
I0316 03:06:06.688997 29479 solver.cpp:229]     Train net output #0: loss = 7696.35 (* 1 = 7696.35 loss)
I0316 03:06:07.049510 29479 solver.cpp:610] Iteration 64540, lr = 7.04211e-09
I0316 03:06:07.049525 29479 solver.cpp:613] Iteration 64540, avg_grad_norm = 518811
I0316 03:07:10.921123 29479 solver.cpp:214] Iteration 64560, loss = 5786.35
I0316 03:07:10.921314 29479 solver.cpp:229]     Train net output #0: loss = 4002.1 (* 1 = 4002.1 loss)
I0316 03:07:11.030146 29479 solver.cpp:610] Iteration 64560, lr = 7.04118e-09
I0316 03:07:11.030184 29479 solver.cpp:613] Iteration 64560, avg_grad_norm = 557277
I0316 03:08:03.502931 29479 solver.cpp:214] Iteration 64580, loss = 5731.93
I0316 03:08:03.503052 29479 solver.cpp:229]     Train net output #0: loss = 5158.84 (* 1 = 5158.84 loss)
I0316 03:08:03.863680 29479 solver.cpp:610] Iteration 64580, lr = 7.04024e-09
I0316 03:08:03.863694 29479 solver.cpp:613] Iteration 64580, avg_grad_norm = 476262
I0316 03:09:11.718286 29479 solver.cpp:214] Iteration 64600, loss = 5827.98
I0316 03:09:11.718425 29479 solver.cpp:229]     Train net output #0: loss = 3142.15 (* 1 = 3142.15 loss)
I0316 03:09:12.086383 29479 solver.cpp:610] Iteration 64600, lr = 7.03931e-09
I0316 03:09:12.086400 29479 solver.cpp:613] Iteration 64600, avg_grad_norm = 516173
I0316 03:10:21.136123 29479 solver.cpp:214] Iteration 64620, loss = 5859.23
I0316 03:10:21.136227 29479 solver.cpp:229]     Train net output #0: loss = 3918.36 (* 1 = 3918.36 loss)
I0316 03:10:21.496783 29479 solver.cpp:610] Iteration 64620, lr = 7.03837e-09
I0316 03:10:21.496799 29479 solver.cpp:613] Iteration 64620, avg_grad_norm = 591376
I0316 03:11:42.923740 29479 solver.cpp:214] Iteration 64640, loss = 5946.48
I0316 03:11:42.923863 29479 solver.cpp:229]     Train net output #0: loss = 5760.06 (* 1 = 5760.06 loss)
I0316 03:11:43.284020 29479 solver.cpp:610] Iteration 64640, lr = 7.03743e-09
I0316 03:11:43.284034 29479 solver.cpp:613] Iteration 64640, avg_grad_norm = 527583
I0316 03:12:51.798923 29479 solver.cpp:214] Iteration 64660, loss = 5659.67
I0316 03:12:51.799036 29479 solver.cpp:229]     Train net output #0: loss = 5442.23 (* 1 = 5442.23 loss)
I0316 03:12:52.159777 29479 solver.cpp:610] Iteration 64660, lr = 7.0365e-09
I0316 03:12:52.159791 29479 solver.cpp:613] Iteration 64660, avg_grad_norm = 506561
I0316 03:14:00.494501 29479 solver.cpp:214] Iteration 64680, loss = 5796.82
I0316 03:14:00.494637 29479 solver.cpp:229]     Train net output #0: loss = 2298.48 (* 1 = 2298.48 loss)
I0316 03:14:00.857245 29479 solver.cpp:610] Iteration 64680, lr = 7.03556e-09
I0316 03:14:00.857257 29479 solver.cpp:613] Iteration 64680, avg_grad_norm = 497295
I0316 03:14:50.355036 29479 solver.cpp:214] Iteration 64700, loss = 5685.74
I0316 03:14:50.355170 29479 solver.cpp:229]     Train net output #0: loss = 5639.83 (* 1 = 5639.83 loss)
I0316 03:14:50.471511 29479 solver.cpp:610] Iteration 64700, lr = 7.03463e-09
I0316 03:14:50.471561 29479 solver.cpp:613] Iteration 64700, avg_grad_norm = 535333
I0316 03:15:56.087440 29479 solver.cpp:214] Iteration 64720, loss = 6270.51
I0316 03:15:56.087615 29479 solver.cpp:229]     Train net output #0: loss = 6022.4 (* 1 = 6022.4 loss)
I0316 03:15:56.413708 29479 solver.cpp:610] Iteration 64720, lr = 7.03369e-09
I0316 03:15:56.413722 29479 solver.cpp:613] Iteration 64720, avg_grad_norm = 519008
I0316 03:17:04.544348 29479 solver.cpp:214] Iteration 64740, loss = 5530.7
I0316 03:17:04.544481 29479 solver.cpp:229]     Train net output #0: loss = 3537.77 (* 1 = 3537.77 loss)
I0316 03:17:04.904557 29479 solver.cpp:610] Iteration 64740, lr = 7.03275e-09
I0316 03:17:04.904572 29479 solver.cpp:613] Iteration 64740, avg_grad_norm = 482321
I0316 03:18:14.207640 29479 solver.cpp:214] Iteration 64760, loss = 6030.3
I0316 03:18:14.207777 29479 solver.cpp:229]     Train net output #0: loss = 8420.43 (* 1 = 8420.43 loss)
I0316 03:18:14.567926 29479 solver.cpp:610] Iteration 64760, lr = 7.03182e-09
I0316 03:18:14.567940 29479 solver.cpp:613] Iteration 64760, avg_grad_norm = 541163
I0316 03:19:35.625903 29479 solver.cpp:214] Iteration 64780, loss = 5850.97
I0316 03:19:35.626037 29479 solver.cpp:229]     Train net output #0: loss = 3665.2 (* 1 = 3665.2 loss)
I0316 03:19:35.985515 29479 solver.cpp:610] Iteration 64780, lr = 7.03088e-09
I0316 03:19:35.985559 29479 solver.cpp:613] Iteration 64780, avg_grad_norm = 507295
I0316 03:20:43.745540 29479 solver.cpp:214] Iteration 64800, loss = 5574.95
I0316 03:20:43.745718 29479 solver.cpp:229]     Train net output #0: loss = 5608.31 (* 1 = 5608.31 loss)
I0316 03:20:44.115607 29479 solver.cpp:610] Iteration 64800, lr = 7.02995e-09
I0316 03:20:44.115622 29479 solver.cpp:613] Iteration 64800, avg_grad_norm = 504618
I0316 03:21:52.039079 29479 solver.cpp:214] Iteration 64820, loss = 5866.84
I0316 03:21:52.039208 29479 solver.cpp:229]     Train net output #0: loss = 3966.42 (* 1 = 3966.42 loss)
I0316 03:21:52.407924 29479 solver.cpp:610] Iteration 64820, lr = 7.02901e-09
I0316 03:21:52.407938 29479 solver.cpp:613] Iteration 64820, avg_grad_norm = 561312
I0316 03:22:39.868191 29479 solver.cpp:214] Iteration 64840, loss = 5949.27
I0316 03:22:39.868294 29479 solver.cpp:229]     Train net output #0: loss = 2857.16 (* 1 = 2857.16 loss)
I0316 03:22:40.228857 29479 solver.cpp:610] Iteration 64840, lr = 7.02807e-09
I0316 03:22:40.228871 29479 solver.cpp:613] Iteration 64840, avg_grad_norm = 476812
I0316 03:23:49.088706 29479 solver.cpp:214] Iteration 64860, loss = 5750.8
I0316 03:23:49.088897 29479 solver.cpp:229]     Train net output #0: loss = 9322.44 (* 1 = 9322.44 loss)
I0316 03:23:49.448565 29479 solver.cpp:610] Iteration 64860, lr = 7.02714e-09
I0316 03:23:49.448580 29479 solver.cpp:613] Iteration 64860, avg_grad_norm = 525708
I0316 03:24:57.259815 29479 solver.cpp:214] Iteration 64880, loss = 5938.44
I0316 03:24:57.259939 29479 solver.cpp:229]     Train net output #0: loss = 6590.62 (* 1 = 6590.62 loss)
I0316 03:24:57.621045 29479 solver.cpp:610] Iteration 64880, lr = 7.0262e-09
I0316 03:24:57.621058 29479 solver.cpp:613] Iteration 64880, avg_grad_norm = 518470
I0316 03:26:19.361250 29479 solver.cpp:214] Iteration 64900, loss = 5896.79
I0316 03:26:19.361456 29479 solver.cpp:229]     Train net output #0: loss = 5829.49 (* 1 = 5829.49 loss)
I0316 03:26:19.754334 29479 solver.cpp:610] Iteration 64900, lr = 7.02527e-09
I0316 03:26:19.754348 29479 solver.cpp:613] Iteration 64900, avg_grad_norm = 528096
I0316 03:27:22.990557 29479 solver.cpp:214] Iteration 64920, loss = 5717.46
I0316 03:27:22.990699 29479 solver.cpp:229]     Train net output #0: loss = 4452.63 (* 1 = 4452.63 loss)
I0316 03:27:23.379673 29479 solver.cpp:610] Iteration 64920, lr = 7.02433e-09
I0316 03:27:23.379686 29479 solver.cpp:613] Iteration 64920, avg_grad_norm = 527699
I0316 03:28:31.692333 29479 solver.cpp:214] Iteration 64940, loss = 5932.59
I0316 03:28:31.692476 29479 solver.cpp:229]     Train net output #0: loss = 5290.81 (* 1 = 5290.81 loss)
I0316 03:28:32.064180 29479 solver.cpp:610] Iteration 64940, lr = 7.02339e-09
I0316 03:28:32.064194 29479 solver.cpp:613] Iteration 64940, avg_grad_norm = 560966
I0316 03:29:41.192884 29479 solver.cpp:214] Iteration 64960, loss = 6036.85
I0316 03:29:41.193001 29479 solver.cpp:229]     Train net output #0: loss = 5619.24 (* 1 = 5619.24 loss)
I0316 03:29:41.553977 29479 solver.cpp:610] Iteration 64960, lr = 7.02246e-09
I0316 03:29:41.553992 29479 solver.cpp:613] Iteration 64960, avg_grad_norm = 632572
I0316 03:30:28.561540 29479 solver.cpp:214] Iteration 64980, loss = 5698.08
I0316 03:30:28.561678 29479 solver.cpp:229]     Train net output #0: loss = 5600.98 (* 1 = 5600.98 loss)
I0316 03:30:28.922250 29479 solver.cpp:610] Iteration 64980, lr = 7.02152e-09
I0316 03:30:28.922265 29479 solver.cpp:613] Iteration 64980, avg_grad_norm = 630791
I0316 03:31:36.732623 29479 solver.cpp:214] Iteration 65000, loss = 5838.79
I0316 03:31:36.732765 29479 solver.cpp:229]     Train net output #0: loss = 3856.38 (* 1 = 3856.38 loss)
I0316 03:31:37.096654 29479 solver.cpp:610] Iteration 65000, lr = 7.02059e-09
I0316 03:31:37.096668 29479 solver.cpp:613] Iteration 65000, avg_grad_norm = 520301
I0316 03:33:02.040609 29479 solver.cpp:214] Iteration 65020, loss = 6068.92
I0316 03:33:02.040715 29479 solver.cpp:229]     Train net output #0: loss = 4757.98 (* 1 = 4757.98 loss)
I0316 03:33:02.369025 29479 solver.cpp:610] Iteration 65020, lr = 7.01965e-09
I0316 03:33:02.369045 29479 solver.cpp:613] Iteration 65020, avg_grad_norm = 522300
I0316 03:34:10.884922 29479 solver.cpp:214] Iteration 65040, loss = 5582.44
I0316 03:34:10.885222 29479 solver.cpp:229]     Train net output #0: loss = 6320.2 (* 1 = 6320.2 loss)
I0316 03:34:11.247967 29479 solver.cpp:610] Iteration 65040, lr = 7.01871e-09
I0316 03:34:11.247982 29479 solver.cpp:613] Iteration 65040, avg_grad_norm = 485881
I0316 03:35:19.257753 29479 solver.cpp:214] Iteration 65060, loss = 5990.49
I0316 03:35:19.257891 29479 solver.cpp:229]     Train net output #0: loss = 3840.02 (* 1 = 3840.02 loss)
I0316 03:35:19.623277 29479 solver.cpp:610] Iteration 65060, lr = 7.01778e-09
I0316 03:35:19.623291 29479 solver.cpp:613] Iteration 65060, avg_grad_norm = 522417
I0316 03:36:27.887043 29479 solver.cpp:214] Iteration 65080, loss = 5713.28
I0316 03:36:27.887187 29479 solver.cpp:229]     Train net output #0: loss = 5986.79 (* 1 = 5986.79 loss)
I0316 03:36:28.252172 29479 solver.cpp:610] Iteration 65080, lr = 7.01684e-09
I0316 03:36:28.252185 29479 solver.cpp:613] Iteration 65080, avg_grad_norm = 462509
I0316 03:37:23.584473 29479 solver.cpp:214] Iteration 65100, loss = 5767.17
I0316 03:37:23.584628 29479 solver.cpp:229]     Train net output #0: loss = 4983.88 (* 1 = 4983.88 loss)
I0316 03:37:23.700722 29479 solver.cpp:610] Iteration 65100, lr = 7.01591e-09
I0316 03:37:23.700783 29479 solver.cpp:613] Iteration 65100, avg_grad_norm = 518473
I0316 03:38:24.490494 29479 solver.cpp:214] Iteration 65120, loss = 5866.62
I0316 03:38:24.490622 29479 solver.cpp:229]     Train net output #0: loss = 9451.23 (* 1 = 9451.23 loss)
I0316 03:38:24.850726 29479 solver.cpp:610] Iteration 65120, lr = 7.01497e-09
I0316 03:38:24.850740 29479 solver.cpp:613] Iteration 65120, avg_grad_norm = 495335
I0316 03:39:33.962844 29479 solver.cpp:214] Iteration 65140, loss = 5658.66
I0316 03:39:33.962965 29479 solver.cpp:229]     Train net output #0: loss = 3906.19 (* 1 = 3906.19 loss)
I0316 03:39:34.323120 29479 solver.cpp:610] Iteration 65140, lr = 7.01403e-09
I0316 03:39:34.323133 29479 solver.cpp:613] Iteration 65140, avg_grad_norm = 478015
I0316 03:40:55.000195 29479 solver.cpp:214] Iteration 65160, loss = 5791.08
I0316 03:40:55.000325 29479 solver.cpp:229]     Train net output #0: loss = 10069.2 (* 1 = 10069.2 loss)
I0316 03:40:55.365285 29479 solver.cpp:610] Iteration 65160, lr = 7.0131e-09
I0316 03:40:55.365299 29479 solver.cpp:613] Iteration 65160, avg_grad_norm = 499695
I0316 03:42:03.652753 29479 solver.cpp:214] Iteration 65180, loss = 5864.07
I0316 03:42:03.652894 29479 solver.cpp:229]     Train net output #0: loss = 4019.03 (* 1 = 4019.03 loss)
I0316 03:42:04.013129 29479 solver.cpp:610] Iteration 65180, lr = 7.01216e-09
I0316 03:42:04.013144 29479 solver.cpp:613] Iteration 65180, avg_grad_norm = 515565
I0316 03:43:12.795295 29479 solver.cpp:214] Iteration 65200, loss = 6087.72
I0316 03:43:12.795440 29479 solver.cpp:229]     Train net output #0: loss = 4903.46 (* 1 = 4903.46 loss)
I0316 03:43:13.162252 29479 solver.cpp:610] Iteration 65200, lr = 7.01123e-09
I0316 03:43:13.162267 29479 solver.cpp:613] Iteration 65200, avg_grad_norm = 560086
I0316 03:44:22.162114 29479 solver.cpp:214] Iteration 65220, loss = 5718.57
I0316 03:44:22.162202 29479 solver.cpp:229]     Train net output #0: loss = 9869.3 (* 1 = 9869.3 loss)
I0316 03:44:22.498495 29479 solver.cpp:610] Iteration 65220, lr = 7.01029e-09
I0316 03:44:22.498508 29479 solver.cpp:613] Iteration 65220, avg_grad_norm = 536858
I0316 03:45:09.250370 29479 solver.cpp:214] Iteration 65240, loss = 6077.81
I0316 03:45:09.250474 29479 solver.cpp:229]     Train net output #0: loss = 4519.33 (* 1 = 4519.33 loss)
I0316 03:45:09.616442 29479 solver.cpp:610] Iteration 65240, lr = 7.00935e-09
I0316 03:45:09.616457 29479 solver.cpp:613] Iteration 65240, avg_grad_norm = 506561
I0316 03:46:18.958401 29479 solver.cpp:214] Iteration 65260, loss = 5567.77
I0316 03:46:18.958525 29479 solver.cpp:229]     Train net output #0: loss = 3548.89 (* 1 = 3548.89 loss)
I0316 03:46:19.324301 29479 solver.cpp:610] Iteration 65260, lr = 7.00842e-09
I0316 03:46:19.324314 29479 solver.cpp:613] Iteration 65260, avg_grad_norm = 493254
I0316 03:47:45.849357 29479 solver.cpp:214] Iteration 65280, loss = 5977.82
I0316 03:47:45.849544 29479 solver.cpp:229]     Train net output #0: loss = 7540.81 (* 1 = 7540.81 loss)
I0316 03:47:46.209377 29479 solver.cpp:610] Iteration 65280, lr = 7.00748e-09
I0316 03:47:46.209391 29479 solver.cpp:613] Iteration 65280, avg_grad_norm = 492727
I0316 03:48:55.023275 29479 solver.cpp:214] Iteration 65300, loss = 5814.37
I0316 03:48:55.023366 29479 solver.cpp:229]     Train net output #0: loss = 11835.5 (* 1 = 11835.5 loss)
I0316 03:48:55.361291 29479 solver.cpp:610] Iteration 65300, lr = 7.00654e-09
I0316 03:48:55.361305 29479 solver.cpp:613] Iteration 65300, avg_grad_norm = 489563
I0316 03:50:03.375113 29479 solver.cpp:214] Iteration 65320, loss = 6245.9
I0316 03:50:03.375244 29479 solver.cpp:229]     Train net output #0: loss = 4300.77 (* 1 = 4300.77 loss)
I0316 03:50:03.734649 29479 solver.cpp:610] Iteration 65320, lr = 7.00561e-09
I0316 03:50:03.734663 29479 solver.cpp:613] Iteration 65320, avg_grad_norm = 541067
I0316 03:51:12.716800 29479 solver.cpp:214] Iteration 65340, loss = 5801.27
I0316 03:51:12.716897 29479 solver.cpp:229]     Train net output #0: loss = 3597.98 (* 1 = 3597.98 loss)
I0316 03:51:13.086724 29479 solver.cpp:610] Iteration 65340, lr = 7.00467e-09
I0316 03:51:13.086738 29479 solver.cpp:613] Iteration 65340, avg_grad_norm = 594189
I0316 03:52:17.315490 29479 solver.cpp:214] Iteration 65360, loss = 6169.54
I0316 03:52:17.315696 29479 solver.cpp:229]     Train net output #0: loss = 5044.71 (* 1 = 5044.71 loss)
I0316 03:52:17.425859 29479 solver.cpp:610] Iteration 65360, lr = 7.00373e-09
I0316 03:52:17.425910 29479 solver.cpp:613] Iteration 65360, avg_grad_norm = 554702
I0316 03:53:08.045531 29479 solver.cpp:214] Iteration 65380, loss = 6195.37
I0316 03:53:08.045743 29479 solver.cpp:229]     Train net output #0: loss = 8932.76 (* 1 = 8932.76 loss)
I0316 03:53:08.405331 29479 solver.cpp:610] Iteration 65380, lr = 7.0028e-09
I0316 03:53:08.405345 29479 solver.cpp:613] Iteration 65380, avg_grad_norm = 542598
I0316 03:54:17.645138 29479 solver.cpp:214] Iteration 65400, loss = 5721.82
I0316 03:54:17.645380 29479 solver.cpp:229]     Train net output #0: loss = 4277.75 (* 1 = 4277.75 loss)
I0316 03:54:18.009994 29479 solver.cpp:610] Iteration 65400, lr = 7.00186e-09
I0316 03:54:18.010057 29479 solver.cpp:613] Iteration 65400, avg_grad_norm = 508663
I0316 03:55:59.465210 29479 solver.cpp:214] Iteration 65420, loss = 5985.05
I0316 03:55:59.465340 29479 solver.cpp:229]     Train net output #0: loss = 6022.74 (* 1 = 6022.74 loss)
I0316 03:55:59.832343 29479 solver.cpp:610] Iteration 65420, lr = 7.00093e-09
I0316 03:55:59.832356 29479 solver.cpp:613] Iteration 65420, avg_grad_norm = 502655
I0316 03:57:08.549899 29479 solver.cpp:214] Iteration 65440, loss = 5678.61
I0316 03:57:08.550077 29479 solver.cpp:229]     Train net output #0: loss = 4508.16 (* 1 = 4508.16 loss)
I0316 03:57:08.919615 29479 solver.cpp:610] Iteration 65440, lr = 6.99999e-09
I0316 03:57:08.919630 29479 solver.cpp:613] Iteration 65440, avg_grad_norm = 486543
I0316 03:58:17.118577 29479 solver.cpp:214] Iteration 65460, loss = 5602.53
I0316 03:58:17.118671 29479 solver.cpp:229]     Train net output #0: loss = 4934.97 (* 1 = 4934.97 loss)
I0316 03:58:17.459432 29479 solver.cpp:610] Iteration 65460, lr = 6.99905e-09
I0316 03:58:17.459445 29479 solver.cpp:613] Iteration 65460, avg_grad_norm = 564995
I0316 03:59:26.082345 29479 solver.cpp:214] Iteration 65480, loss = 5701.44
I0316 03:59:26.082469 29479 solver.cpp:229]     Train net output #0: loss = 5298.11 (* 1 = 5298.11 loss)
I0316 03:59:26.445432 29479 solver.cpp:610] Iteration 65480, lr = 6.99812e-09
I0316 03:59:26.445446 29479 solver.cpp:613] Iteration 65480, avg_grad_norm = 556975
I0316 04:00:13.123705 29479 solver.cpp:214] Iteration 65500, loss = 5771.84
I0316 04:00:13.123797 29479 solver.cpp:229]     Train net output #0: loss = 5043.91 (* 1 = 5043.91 loss)
I0316 04:00:13.484014 29479 solver.cpp:610] Iteration 65500, lr = 6.99718e-09
I0316 04:00:13.484026 29479 solver.cpp:613] Iteration 65500, avg_grad_norm = 503190
I0316 04:01:22.932266 29479 solver.cpp:214] Iteration 65520, loss = 5563.15
I0316 04:01:22.932433 29479 solver.cpp:229]     Train net output #0: loss = 4489.96 (* 1 = 4489.96 loss)
I0316 04:01:23.292517 29479 solver.cpp:610] Iteration 65520, lr = 6.99624e-09
I0316 04:01:23.292532 29479 solver.cpp:613] Iteration 65520, avg_grad_norm = 489173
I0316 04:02:51.284216 29479 solver.cpp:214] Iteration 65540, loss = 5906.52
I0316 04:02:51.284425 29479 solver.cpp:229]     Train net output #0: loss = 10056.7 (* 1 = 10056.7 loss)
I0316 04:02:51.644919 29479 solver.cpp:610] Iteration 65540, lr = 6.99531e-09
I0316 04:02:51.644934 29479 solver.cpp:613] Iteration 65540, avg_grad_norm = 499649
I0316 04:03:59.695032 29479 solver.cpp:214] Iteration 65560, loss = 5714.43
I0316 04:03:59.695158 29479 solver.cpp:229]     Train net output #0: loss = 6682.38 (* 1 = 6682.38 loss)
I0316 04:04:00.062511 29479 solver.cpp:610] Iteration 65560, lr = 6.99437e-09
I0316 04:04:00.062525 29479 solver.cpp:613] Iteration 65560, avg_grad_norm = 661189
I0316 04:05:08.526315 29479 solver.cpp:214] Iteration 65580, loss = 5863.37
I0316 04:05:08.526434 29479 solver.cpp:229]     Train net output #0: loss = 4496.1 (* 1 = 4496.1 loss)
I0316 04:05:08.885689 29479 solver.cpp:610] Iteration 65580, lr = 6.99343e-09
I0316 04:05:08.885702 29479 solver.cpp:613] Iteration 65580, avg_grad_norm = 565942
I0316 04:06:17.467999 29479 solver.cpp:214] Iteration 65600, loss = 5826.34
I0316 04:06:17.468134 29479 solver.cpp:229]     Train net output #0: loss = 8112.26 (* 1 = 8112.26 loss)
I0316 04:06:17.828446 29479 solver.cpp:610] Iteration 65600, lr = 6.9925e-09
I0316 04:06:17.828462 29479 solver.cpp:613] Iteration 65600, avg_grad_norm = 485330
I0316 04:07:10.651985 29479 solver.cpp:214] Iteration 65620, loss = 5903.48
I0316 04:07:10.652122 29479 solver.cpp:229]     Train net output #0: loss = 5370.82 (* 1 = 5370.82 loss)
I0316 04:07:10.769896 29479 solver.cpp:610] Iteration 65620, lr = 6.99156e-09
I0316 04:07:10.769944 29479 solver.cpp:613] Iteration 65620, avg_grad_norm = 521682
I0316 04:08:13.412120 29479 solver.cpp:214] Iteration 65640, loss = 6054.8
I0316 04:08:13.412230 29479 solver.cpp:229]     Train net output #0: loss = 9423.96 (* 1 = 9423.96 loss)
I0316 04:08:13.780849 29479 solver.cpp:610] Iteration 65640, lr = 6.99062e-09
I0316 04:08:13.780864 29479 solver.cpp:613] Iteration 65640, avg_grad_norm = 586272
I0316 04:09:35.156808 29479 solver.cpp:214] Iteration 65660, loss = 6045.11
I0316 04:09:35.156940 29479 solver.cpp:229]     Train net output #0: loss = 10502.7 (* 1 = 10502.7 loss)
I0316 04:09:35.525688 29479 solver.cpp:610] Iteration 65660, lr = 6.98969e-09
I0316 04:09:35.525702 29479 solver.cpp:613] Iteration 65660, avg_grad_norm = 600571
I0316 04:10:43.256069 29479 solver.cpp:214] Iteration 65680, loss = 5548.98
I0316 04:10:43.256187 29479 solver.cpp:229]     Train net output #0: loss = 2874.53 (* 1 = 2874.53 loss)
I0316 04:10:43.618762 29479 solver.cpp:610] Iteration 65680, lr = 6.98875e-09
I0316 04:10:43.618775 29479 solver.cpp:613] Iteration 65680, avg_grad_norm = 552448
I0316 04:11:51.853049 29479 solver.cpp:214] Iteration 65700, loss = 5871.1
I0316 04:11:51.853207 29479 solver.cpp:229]     Train net output #0: loss = 4714.22 (* 1 = 4714.22 loss)
I0316 04:11:52.216502 29479 solver.cpp:610] Iteration 65700, lr = 6.98781e-09
I0316 04:11:52.216526 29479 solver.cpp:613] Iteration 65700, avg_grad_norm = 505767
I0316 04:13:01.364235 29479 solver.cpp:214] Iteration 65720, loss = 5828.42
I0316 04:13:01.364368 29479 solver.cpp:229]     Train net output #0: loss = 2652.52 (* 1 = 2652.52 loss)
I0316 04:13:01.730710 29479 solver.cpp:610] Iteration 65720, lr = 6.98688e-09
I0316 04:13:01.730722 29479 solver.cpp:613] Iteration 65720, avg_grad_norm = 540057
I0316 04:14:09.872010 29479 solver.cpp:214] Iteration 65740, loss = 5908.22
I0316 04:14:09.872126 29479 solver.cpp:229]     Train net output #0: loss = 4468.05 (* 1 = 4468.05 loss)
I0316 04:14:10.232204 29479 solver.cpp:610] Iteration 65740, lr = 6.98594e-09
I0316 04:14:10.232218 29479 solver.cpp:613] Iteration 65740, avg_grad_norm = 518272
I0316 04:14:57.015051 29479 solver.cpp:214] Iteration 65760, loss = 5971.75
I0316 04:14:57.015233 29479 solver.cpp:229]     Train net output #0: loss = 11798.4 (* 1 = 11798.4 loss)
I0316 04:14:57.210324 29479 solver.cpp:610] Iteration 65760, lr = 6.98501e-09
I0316 04:14:57.210340 29479 solver.cpp:613] Iteration 65760, avg_grad_norm = 516948
I0316 04:16:06.302369 29479 solver.cpp:214] Iteration 65780, loss = 5979.46
I0316 04:16:06.302495 29479 solver.cpp:229]     Train net output #0: loss = 4638.67 (* 1 = 4638.67 loss)
I0316 04:16:06.668143 29479 solver.cpp:610] Iteration 65780, lr = 6.98407e-09
I0316 04:16:06.668156 29479 solver.cpp:613] Iteration 65780, avg_grad_norm = 528557
I0316 04:17:32.049698 29479 solver.cpp:214] Iteration 65800, loss = 5819.77
I0316 04:17:32.049823 29479 solver.cpp:229]     Train net output #0: loss = 5064.9 (* 1 = 5064.9 loss)
I0316 04:17:32.387503 29479 solver.cpp:610] Iteration 65800, lr = 6.98313e-09
I0316 04:17:32.387516 29479 solver.cpp:613] Iteration 65800, avg_grad_norm = 502192
I0316 04:18:40.822096 29479 solver.cpp:214] Iteration 65820, loss = 6185.65
I0316 04:18:40.822206 29479 solver.cpp:229]     Train net output #0: loss = 5883.18 (* 1 = 5883.18 loss)
I0316 04:18:41.184579 29479 solver.cpp:610] Iteration 65820, lr = 6.9822e-09
I0316 04:18:41.184593 29479 solver.cpp:613] Iteration 65820, avg_grad_norm = 518613
I0316 04:19:49.685576 29479 solver.cpp:214] Iteration 65840, loss = 6058.93
I0316 04:19:49.685708 29479 solver.cpp:229]     Train net output #0: loss = 10584.5 (* 1 = 10584.5 loss)
I0316 04:19:50.044972 29479 solver.cpp:610] Iteration 65840, lr = 6.98126e-09
I0316 04:19:50.044987 29479 solver.cpp:613] Iteration 65840, avg_grad_norm = 575943
I0316 04:20:58.712718 29479 solver.cpp:214] Iteration 65860, loss = 6007.16
I0316 04:20:58.712970 29479 solver.cpp:229]     Train net output #0: loss = 2540.23 (* 1 = 2540.23 loss)
I0316 04:20:59.079637 29479 solver.cpp:610] Iteration 65860, lr = 6.98032e-09
I0316 04:20:59.079658 29479 solver.cpp:613] Iteration 65860, avg_grad_norm = 515237
I0316 04:22:04.282276 29479 solver.cpp:214] Iteration 65880, loss = 5768.97
I0316 04:22:04.282421 29479 solver.cpp:229]     Train net output #0: loss = 12941 (* 1 = 12941 loss)
I0316 04:22:04.388803 29479 solver.cpp:610] Iteration 65880, lr = 6.97939e-09
I0316 04:22:04.388851 29479 solver.cpp:613] Iteration 65880, avg_grad_norm = 525822
I0316 04:22:55.214390 29479 solver.cpp:214] Iteration 65900, loss = 5801.19
I0316 04:22:55.214486 29479 solver.cpp:229]     Train net output #0: loss = 5809.44 (* 1 = 5809.44 loss)
I0316 04:22:55.580755 29479 solver.cpp:610] Iteration 65900, lr = 6.97845e-09
I0316 04:22:55.580768 29479 solver.cpp:613] Iteration 65900, avg_grad_norm = 488651
I0316 04:24:16.648999 29479 solver.cpp:214] Iteration 65920, loss = 5675.58
I0316 04:24:16.649130 29479 solver.cpp:229]     Train net output #0: loss = 5179.13 (* 1 = 5179.13 loss)
I0316 04:24:17.039366 29479 solver.cpp:610] Iteration 65920, lr = 6.97751e-09
I0316 04:24:17.039379 29479 solver.cpp:613] Iteration 65920, avg_grad_norm = 500102
I0316 04:25:25.695127 29479 solver.cpp:214] Iteration 65940, loss = 5723.46
I0316 04:25:25.695245 29479 solver.cpp:229]     Train net output #0: loss = 7693.64 (* 1 = 7693.64 loss)
I0316 04:25:25.881435 29479 solver.cpp:610] Iteration 65940, lr = 6.97658e-09
I0316 04:25:25.881448 29479 solver.cpp:613] Iteration 65940, avg_grad_norm = 563240
I0316 04:26:34.596513 29479 solver.cpp:214] Iteration 65960, loss = 5915.43
I0316 04:26:34.596611 29479 solver.cpp:229]     Train net output #0: loss = 3644.64 (* 1 = 3644.64 loss)
I0316 04:26:34.958751 29479 solver.cpp:610] Iteration 65960, lr = 6.97564e-09
I0316 04:26:34.958765 29479 solver.cpp:613] Iteration 65960, avg_grad_norm = 524350
I0316 04:27:43.749744 29479 solver.cpp:214] Iteration 65980, loss = 5521.7
I0316 04:27:43.749874 29479 solver.cpp:229]     Train net output #0: loss = 5304.26 (* 1 = 5304.26 loss)
I0316 04:27:44.116286 29479 solver.cpp:610] Iteration 65980, lr = 6.9747e-09
I0316 04:27:44.116300 29479 solver.cpp:613] Iteration 65980, avg_grad_norm = 473690
I0316 04:28:52.998106 29479 solver.cpp:214] Iteration 66000, loss = 6042.53
I0316 04:28:52.998273 29479 solver.cpp:229]     Train net output #0: loss = 5877.34 (* 1 = 5877.34 loss)
I0316 04:28:53.370641 29479 solver.cpp:610] Iteration 66000, lr = 6.97376e-09
I0316 04:28:53.370654 29479 solver.cpp:613] Iteration 66000, avg_grad_norm = 613212
I0316 04:29:44.068872 29479 solver.cpp:214] Iteration 66020, loss = 5957.96
I0316 04:29:44.069020 29479 solver.cpp:229]     Train net output #0: loss = 5801.07 (* 1 = 5801.07 loss)
I0316 04:29:44.185087 29479 solver.cpp:610] Iteration 66020, lr = 6.97283e-09
I0316 04:29:44.185123 29479 solver.cpp:613] Iteration 66020, avg_grad_norm = 533849
I0316 04:30:42.928613 29479 solver.cpp:214] Iteration 66040, loss = 6108.78
I0316 04:30:42.928766 29479 solver.cpp:229]     Train net output #0: loss = 5633.55 (* 1 = 5633.55 loss)
I0316 04:30:43.290285 29479 solver.cpp:610] Iteration 66040, lr = 6.97189e-09
I0316 04:30:43.290300 29479 solver.cpp:613] Iteration 66040, avg_grad_norm = 537174
I0316 04:31:52.107818 29479 solver.cpp:214] Iteration 66060, loss = 5705.87
I0316 04:31:52.107947 29479 solver.cpp:229]     Train net output #0: loss = 7244.47 (* 1 = 7244.47 loss)
I0316 04:31:52.478327 29479 solver.cpp:610] Iteration 66060, lr = 6.97095e-09
I0316 04:31:52.478339 29479 solver.cpp:613] Iteration 66060, avg_grad_norm = 581107
I0316 04:33:01.170073 29479 solver.cpp:214] Iteration 66080, loss = 5870.32
I0316 04:33:01.170181 29479 solver.cpp:229]     Train net output #0: loss = 3927.87 (* 1 = 3927.87 loss)
I0316 04:33:01.507282 29479 solver.cpp:610] Iteration 66080, lr = 6.97002e-09
I0316 04:33:01.507295 29479 solver.cpp:613] Iteration 66080, avg_grad_norm = 569779
I0316 04:34:09.896958 29479 solver.cpp:214] Iteration 66100, loss = 5540.99
I0316 04:34:09.897063 29479 solver.cpp:229]     Train net output #0: loss = 5854.62 (* 1 = 5854.62 loss)
I0316 04:34:10.263402 29479 solver.cpp:610] Iteration 66100, lr = 6.96908e-09
I0316 04:34:10.263417 29479 solver.cpp:613] Iteration 66100, avg_grad_norm = 514404
I0316 04:35:19.246825 29479 solver.cpp:214] Iteration 66120, loss = 5635.22
I0316 04:35:19.246968 29479 solver.cpp:229]     Train net output #0: loss = 4261 (* 1 = 4261 loss)
I0316 04:35:19.617480 29479 solver.cpp:610] Iteration 66120, lr = 6.96814e-09
I0316 04:35:19.617496 29479 solver.cpp:613] Iteration 66120, avg_grad_norm = 499470
I0316 04:36:28.949939 29479 solver.cpp:214] Iteration 66140, loss = 5615.42
I0316 04:36:28.950057 29479 solver.cpp:229]     Train net output #0: loss = 3491.38 (* 1 = 3491.38 loss)
I0316 04:36:29.316257 29479 solver.cpp:610] Iteration 66140, lr = 6.96721e-09
I0316 04:36:29.316272 29479 solver.cpp:613] Iteration 66140, avg_grad_norm = 519982
I0316 04:37:23.764716 29479 solver.cpp:214] Iteration 66160, loss = 5856.4
I0316 04:37:23.764868 29479 solver.cpp:229]     Train net output #0: loss = 5171.29 (* 1 = 5171.29 loss)
I0316 04:37:23.880906 29479 solver.cpp:610] Iteration 66160, lr = 6.96627e-09
I0316 04:37:23.880954 29479 solver.cpp:613] Iteration 66160, avg_grad_norm = 584739
I0316 04:38:41.695246 29479 solver.cpp:214] Iteration 66180, loss = 5689.81
I0316 04:38:41.695374 29479 solver.cpp:229]     Train net output #0: loss = 4011.19 (* 1 = 4011.19 loss)
I0316 04:38:42.060364 29479 solver.cpp:610] Iteration 66180, lr = 6.96533e-09
I0316 04:38:42.060379 29479 solver.cpp:613] Iteration 66180, avg_grad_norm = 574541
I0316 04:39:50.401340 29479 solver.cpp:214] Iteration 66200, loss = 5693.63
I0316 04:39:50.401454 29479 solver.cpp:229]     Train net output #0: loss = 2968.94 (* 1 = 2968.94 loss)
I0316 04:39:50.761715 29479 solver.cpp:610] Iteration 66200, lr = 6.9644e-09
I0316 04:39:50.761729 29479 solver.cpp:613] Iteration 66200, avg_grad_norm = 629488
I0316 04:40:55.682360 29479 solver.cpp:214] Iteration 66220, loss = 5838.15
I0316 04:40:55.682459 29479 solver.cpp:229]     Train net output #0: loss = 4868.62 (* 1 = 4868.62 loss)
I0316 04:40:56.045002 29479 solver.cpp:610] Iteration 66220, lr = 6.96346e-09
I0316 04:40:56.045017 29479 solver.cpp:613] Iteration 66220, avg_grad_norm = 558820
I0316 04:42:05.078434 29479 solver.cpp:214] Iteration 66240, loss = 5861.09
I0316 04:42:05.078675 29479 solver.cpp:229]     Train net output #0: loss = 10219.9 (* 1 = 10219.9 loss)
I0316 04:42:05.439016 29479 solver.cpp:610] Iteration 66240, lr = 6.96252e-09
I0316 04:42:05.439030 29479 solver.cpp:613] Iteration 66240, avg_grad_norm = 497315
I0316 04:43:13.229820 29479 solver.cpp:214] Iteration 66260, loss = 5416.75
I0316 04:43:13.229949 29479 solver.cpp:229]     Train net output #0: loss = 5174.49 (* 1 = 5174.49 loss)
I0316 04:43:13.592207 29479 solver.cpp:610] Iteration 66260, lr = 6.96159e-09
I0316 04:43:13.592223 29479 solver.cpp:613] Iteration 66260, avg_grad_norm = 511720
I0316 04:44:22.564877 29479 solver.cpp:214] Iteration 66280, loss = 5878.31
I0316 04:44:22.565011 29479 solver.cpp:229]     Train net output #0: loss = 4478.51 (* 1 = 4478.51 loss)
I0316 04:44:22.931149 29479 solver.cpp:610] Iteration 66280, lr = 6.96065e-09
I0316 04:44:22.931162 29479 solver.cpp:613] Iteration 66280, avg_grad_norm = 495024
I0316 04:45:56.640061 29479 solver.cpp:214] Iteration 66300, loss = 5868.65
I0316 04:45:56.640179 29479 solver.cpp:229]     Train net output #0: loss = 5072.29 (* 1 = 5072.29 loss)
I0316 04:45:56.996054 29479 solver.cpp:610] Iteration 66300, lr = 6.95971e-09
I0316 04:45:56.996069 29479 solver.cpp:613] Iteration 66300, avg_grad_norm = 507573
I0316 04:47:04.686599 29479 solver.cpp:214] Iteration 66320, loss = 5947.79
I0316 04:47:04.686707 29479 solver.cpp:229]     Train net output #0: loss = 9218.29 (* 1 = 9218.29 loss)
I0316 04:47:05.047829 29479 solver.cpp:610] Iteration 66320, lr = 6.95877e-09
I0316 04:47:05.047842 29479 solver.cpp:613] Iteration 66320, avg_grad_norm = 525457
I0316 04:48:12.670390 29479 solver.cpp:214] Iteration 66340, loss = 5732.58
I0316 04:48:12.670526 29479 solver.cpp:229]     Train net output #0: loss = 6845.26 (* 1 = 6845.26 loss)
I0316 04:48:13.025491 29479 solver.cpp:610] Iteration 66340, lr = 6.95784e-09
I0316 04:48:13.025506 29479 solver.cpp:613] Iteration 66340, avg_grad_norm = 507057
I0316 04:49:21.054364 29479 solver.cpp:214] Iteration 66360, loss = 5764.36
I0316 04:49:21.054498 29479 solver.cpp:229]     Train net output #0: loss = 4731.43 (* 1 = 4731.43 loss)
I0316 04:49:21.414496 29479 solver.cpp:610] Iteration 66360, lr = 6.9569e-09
I0316 04:49:21.414510 29479 solver.cpp:613] Iteration 66360, avg_grad_norm = 601342
I0316 04:50:29.492369 29479 solver.cpp:214] Iteration 66380, loss = 5980.6
I0316 04:50:29.492488 29479 solver.cpp:229]     Train net output #0: loss = 5626.41 (* 1 = 5626.41 loss)
I0316 04:50:29.853245 29479 solver.cpp:610] Iteration 66380, lr = 6.95596e-09
I0316 04:50:29.853260 29479 solver.cpp:613] Iteration 66380, avg_grad_norm = 560212
I0316 04:51:38.150337 29479 solver.cpp:214] Iteration 66400, loss = 6232.89
I0316 04:51:38.150451 29479 solver.cpp:229]     Train net output #0: loss = 4593.12 (* 1 = 4593.12 loss)
I0316 04:51:38.509907 29479 solver.cpp:610] Iteration 66400, lr = 6.95503e-09
I0316 04:51:38.509920 29479 solver.cpp:613] Iteration 66400, avg_grad_norm = 520882
I0316 04:53:11.300344 29479 solver.cpp:214] Iteration 66420, loss = 5920.33
I0316 04:53:11.300467 29479 solver.cpp:229]     Train net output #0: loss = 7820.6 (* 1 = 7820.6 loss)
I0316 04:53:11.657261 29479 solver.cpp:610] Iteration 66420, lr = 6.95409e-09
I0316 04:53:11.657275 29479 solver.cpp:613] Iteration 66420, avg_grad_norm = 520061
I0316 04:54:19.409207 29479 solver.cpp:214] Iteration 66440, loss = 5695.36
I0316 04:54:19.409360 29479 solver.cpp:229]     Train net output #0: loss = 5686.8 (* 1 = 5686.8 loss)
I0316 04:54:19.763938 29479 solver.cpp:610] Iteration 66440, lr = 6.95315e-09
I0316 04:54:19.763993 29479 solver.cpp:613] Iteration 66440, avg_grad_norm = 569634
I0316 04:55:27.918416 29479 solver.cpp:214] Iteration 66460, loss = 5831.06
I0316 04:55:27.918530 29479 solver.cpp:229]     Train net output #0: loss = 4018.16 (* 1 = 4018.16 loss)
I0316 04:55:28.280558 29479 solver.cpp:610] Iteration 66460, lr = 6.95222e-09
I0316 04:55:28.280571 29479 solver.cpp:613] Iteration 66460, avg_grad_norm = 602763
I0316 04:56:35.696231 29479 solver.cpp:214] Iteration 66480, loss = 5849.26
I0316 04:56:35.696410 29479 solver.cpp:229]     Train net output #0: loss = 8300.58 (* 1 = 8300.58 loss)
I0316 04:56:36.057847 29479 solver.cpp:610] Iteration 66480, lr = 6.95128e-09
I0316 04:56:36.057860 29479 solver.cpp:613] Iteration 66480, avg_grad_norm = 615575
I0316 04:57:44.327481 29479 solver.cpp:214] Iteration 66500, loss = 5695.33
I0316 04:57:44.327608 29479 solver.cpp:229]     Train net output #0: loss = 8015.94 (* 1 = 8015.94 loss)
I0316 04:57:44.687537 29479 solver.cpp:610] Iteration 66500, lr = 6.95034e-09
I0316 04:57:44.687551 29479 solver.cpp:613] Iteration 66500, avg_grad_norm = 574633
I0316 04:58:51.939102 29479 solver.cpp:214] Iteration 66520, loss = 5766.64
I0316 04:58:51.939216 29479 solver.cpp:229]     Train net output #0: loss = 7135.07 (* 1 = 7135.07 loss)
I0316 04:58:52.301090 29479 solver.cpp:610] Iteration 66520, lr = 6.9494e-09
I0316 04:58:52.301105 29479 solver.cpp:613] Iteration 66520, avg_grad_norm = 556684
I0316 05:00:00.884546 29479 solver.cpp:214] Iteration 66540, loss = 5728.82
I0316 05:00:00.884665 29479 solver.cpp:229]     Train net output #0: loss = 5257.19 (* 1 = 5257.19 loss)
I0316 05:00:01.245263 29479 solver.cpp:610] Iteration 66540, lr = 6.94847e-09
I0316 05:00:01.245277 29479 solver.cpp:613] Iteration 66540, avg_grad_norm = 522738
I0316 05:01:27.225278 29479 solver.cpp:214] Iteration 66560, loss = 5868.64
I0316 05:01:27.225404 29479 solver.cpp:229]     Train net output #0: loss = 6261.07 (* 1 = 6261.07 loss)
I0316 05:01:27.585022 29479 solver.cpp:610] Iteration 66560, lr = 6.94753e-09
I0316 05:01:27.585041 29479 solver.cpp:613] Iteration 66560, avg_grad_norm = 562404
I0316 05:02:35.471894 29479 solver.cpp:214] Iteration 66580, loss = 5692.34
I0316 05:02:35.472014 29479 solver.cpp:229]     Train net output #0: loss = 3792.24 (* 1 = 3792.24 loss)
I0316 05:02:35.832368 29479 solver.cpp:610] Iteration 66580, lr = 6.94659e-09
I0316 05:02:35.832384 29479 solver.cpp:613] Iteration 66580, avg_grad_norm = 496080
I0316 05:03:43.711801 29479 solver.cpp:214] Iteration 66600, loss = 5601.16
I0316 05:03:43.711941 29479 solver.cpp:229]     Train net output #0: loss = 6670.61 (* 1 = 6670.61 loss)
I0316 05:03:44.075414 29479 solver.cpp:610] Iteration 66600, lr = 6.94566e-09
I0316 05:03:44.075428 29479 solver.cpp:613] Iteration 66600, avg_grad_norm = 477302
I0316 05:04:52.402349 29479 solver.cpp:214] Iteration 66620, loss = 5592.58
I0316 05:04:52.402494 29479 solver.cpp:229]     Train net output #0: loss = 9954.89 (* 1 = 9954.89 loss)
I0316 05:04:52.765007 29479 solver.cpp:610] Iteration 66620, lr = 6.94472e-09
I0316 05:04:52.765024 29479 solver.cpp:613] Iteration 66620, avg_grad_norm = 518999
I0316 05:06:00.748353 29479 solver.cpp:214] Iteration 66640, loss = 5774.2
I0316 05:06:00.748486 29479 solver.cpp:229]     Train net output #0: loss = 4093.14 (* 1 = 4093.14 loss)
I0316 05:06:01.111392 29479 solver.cpp:610] Iteration 66640, lr = 6.94378e-09
I0316 05:06:01.111405 29479 solver.cpp:613] Iteration 66640, avg_grad_norm = 490243
I0316 05:07:09.202540 29479 solver.cpp:214] Iteration 66660, loss = 5916.25
I0316 05:07:09.202654 29479 solver.cpp:229]     Train net output #0: loss = 4113.58 (* 1 = 4113.58 loss)
I0316 05:07:09.562163 29479 solver.cpp:610] Iteration 66660, lr = 6.94284e-09
I0316 05:07:09.562177 29479 solver.cpp:613] Iteration 66660, avg_grad_norm = 510888
I0316 05:08:11.634968 29479 solver.cpp:214] Iteration 66680, loss = 5801.22
I0316 05:08:11.635123 29479 solver.cpp:229]     Train net output #0: loss = 10519.1 (* 1 = 10519.1 loss)
I0316 05:08:11.740309 29479 solver.cpp:610] Iteration 66680, lr = 6.94191e-09
I0316 05:08:11.740324 29479 solver.cpp:613] Iteration 66680, avg_grad_norm = 486107
I0316 05:09:19.565156 29479 solver.cpp:214] Iteration 66700, loss = 5925.58
I0316 05:09:19.565269 29479 solver.cpp:229]     Train net output #0: loss = 9698.02 (* 1 = 9698.02 loss)
I0316 05:09:19.924409 29479 solver.cpp:610] Iteration 66700, lr = 6.94097e-09
I0316 05:09:19.924423 29479 solver.cpp:613] Iteration 66700, avg_grad_norm = 525483
I0316 05:10:28.073040 29479 solver.cpp:214] Iteration 66720, loss = 5837.26
I0316 05:10:28.073264 29479 solver.cpp:229]     Train net output #0: loss = 4567.31 (* 1 = 4567.31 loss)
I0316 05:10:28.436118 29479 solver.cpp:610] Iteration 66720, lr = 6.94003e-09
I0316 05:10:28.436132 29479 solver.cpp:613] Iteration 66720, avg_grad_norm = 539375
I0316 05:11:37.070041 29479 solver.cpp:214] Iteration 66740, loss = 5498.38
I0316 05:11:37.070148 29479 solver.cpp:229]     Train net output #0: loss = 4508.66 (* 1 = 4508.66 loss)
I0316 05:11:37.430157 29479 solver.cpp:610] Iteration 66740, lr = 6.9391e-09
I0316 05:11:37.430171 29479 solver.cpp:613] Iteration 66740, avg_grad_norm = 496132
I0316 05:12:46.434123 29479 solver.cpp:214] Iteration 66760, loss = 6039.21
I0316 05:12:46.434332 29479 solver.cpp:229]     Train net output #0: loss = 7613.49 (* 1 = 7613.49 loss)
I0316 05:12:46.793874 29479 solver.cpp:610] Iteration 66760, lr = 6.93816e-09
I0316 05:12:46.793889 29479 solver.cpp:613] Iteration 66760, avg_grad_norm = 527482
I0316 05:13:50.555840 29479 solver.cpp:214] Iteration 66780, loss = 5594.23
I0316 05:13:50.555995 29479 solver.cpp:229]     Train net output #0: loss = 7260.14 (* 1 = 7260.14 loss)
I0316 05:13:50.771417 29479 solver.cpp:610] Iteration 66780, lr = 6.93722e-09
I0316 05:13:50.771431 29479 solver.cpp:613] Iteration 66780, avg_grad_norm = 495882
I0316 05:15:12.422619 29479 solver.cpp:214] Iteration 66800, loss = 5865.28
I0316 05:15:12.422736 29479 solver.cpp:229]     Train net output #0: loss = 5550.5 (* 1 = 5550.5 loss)
I0316 05:15:12.782551 29479 solver.cpp:610] Iteration 66800, lr = 6.93628e-09
I0316 05:15:12.782563 29479 solver.cpp:613] Iteration 66800, avg_grad_norm = 544613
I0316 05:15:53.806437 29479 solver.cpp:214] Iteration 66820, loss = 5608.95
I0316 05:15:53.806547 29479 solver.cpp:229]     Train net output #0: loss = 3969.44 (* 1 = 3969.44 loss)
I0316 05:15:54.174849 29479 solver.cpp:610] Iteration 66820, lr = 6.93535e-09
I0316 05:15:54.174863 29479 solver.cpp:613] Iteration 66820, avg_grad_norm = 541449
I0316 05:17:03.205085 29479 solver.cpp:214] Iteration 66840, loss = 5785.71
I0316 05:17:03.205210 29479 solver.cpp:229]     Train net output #0: loss = 5800.24 (* 1 = 5800.24 loss)
I0316 05:17:03.544220 29479 solver.cpp:610] Iteration 66840, lr = 6.93441e-09
I0316 05:17:03.544234 29479 solver.cpp:613] Iteration 66840, avg_grad_norm = 514121
I0316 05:18:11.043401 29479 solver.cpp:214] Iteration 66860, loss = 5999.29
I0316 05:18:11.043520 29479 solver.cpp:229]     Train net output #0: loss = 3606.54 (* 1 = 3606.54 loss)
I0316 05:18:11.405642 29479 solver.cpp:610] Iteration 66860, lr = 6.93347e-09
I0316 05:18:11.405657 29479 solver.cpp:613] Iteration 66860, avg_grad_norm = 529218
I0316 05:19:20.063192 29479 solver.cpp:214] Iteration 66880, loss = 5854.61
I0316 05:19:20.063271 29479 solver.cpp:229]     Train net output #0: loss = 3819.68 (* 1 = 3819.68 loss)
I0316 05:19:20.429318 29479 solver.cpp:610] Iteration 66880, lr = 6.93253e-09
I0316 05:19:20.429332 29479 solver.cpp:613] Iteration 66880, avg_grad_norm = 528395
I0316 05:20:29.235301 29479 solver.cpp:214] Iteration 66900, loss = 5966.45
I0316 05:20:29.235419 29479 solver.cpp:229]     Train net output #0: loss = 5278.66 (* 1 = 5278.66 loss)
I0316 05:20:29.596294 29479 solver.cpp:610] Iteration 66900, lr = 6.9316e-09
I0316 05:20:29.596308 29479 solver.cpp:613] Iteration 66900, avg_grad_norm = 501883
I0316 05:21:38.851939 29479 solver.cpp:214] Iteration 66920, loss = 5903.45
I0316 05:21:38.852071 29479 solver.cpp:229]     Train net output #0: loss = 10309.8 (* 1 = 10309.8 loss)
I0316 05:21:39.217593 29479 solver.cpp:610] Iteration 66920, lr = 6.93066e-09
I0316 05:21:39.217607 29479 solver.cpp:613] Iteration 66920, avg_grad_norm = 530166
I0316 05:23:00.262521 29479 solver.cpp:214] Iteration 66940, loss = 6103.5
I0316 05:23:00.262634 29479 solver.cpp:229]     Train net output #0: loss = 4480.22 (* 1 = 4480.22 loss)
I0316 05:23:00.623205 29479 solver.cpp:610] Iteration 66940, lr = 6.92972e-09
I0316 05:23:00.623219 29479 solver.cpp:613] Iteration 66940, avg_grad_norm = 541385
I0316 05:23:47.353173 29479 solver.cpp:214] Iteration 66960, loss = 5750.99
I0316 05:23:47.353353 29479 solver.cpp:229]     Train net output #0: loss = 5097.99 (* 1 = 5097.99 loss)
I0316 05:23:47.711464 29479 solver.cpp:610] Iteration 66960, lr = 6.92878e-09
I0316 05:23:47.711479 29479 solver.cpp:613] Iteration 66960, avg_grad_norm = 501146
I0316 05:24:56.604346 29479 solver.cpp:214] Iteration 66980, loss = 5784.87
I0316 05:24:56.604478 29479 solver.cpp:229]     Train net output #0: loss = 5251.01 (* 1 = 5251.01 loss)
I0316 05:24:56.967746 29479 solver.cpp:610] Iteration 66980, lr = 6.92785e-09
I0316 05:24:56.967761 29479 solver.cpp:613] Iteration 66980, avg_grad_norm = 540486
I0316 05:26:05.830020 29479 solver.cpp:214] Iteration 67000, loss = 5738.45
I0316 05:26:05.830152 29479 solver.cpp:229]     Train net output #0: loss = 8608.8 (* 1 = 8608.8 loss)
I0316 05:26:06.196991 29479 solver.cpp:610] Iteration 67000, lr = 6.92691e-09
I0316 05:26:06.197005 29479 solver.cpp:613] Iteration 67000, avg_grad_norm = 492342
I0316 05:27:15.504559 29479 solver.cpp:214] Iteration 67020, loss = 6123.89
I0316 05:27:15.504693 29479 solver.cpp:229]     Train net output #0: loss = 3893.93 (* 1 = 3893.93 loss)
I0316 05:27:15.894752 29479 solver.cpp:610] Iteration 67020, lr = 6.92597e-09
I0316 05:27:15.894767 29479 solver.cpp:613] Iteration 67020, avg_grad_norm = 512388
I0316 05:28:25.223397 29479 solver.cpp:214] Iteration 67040, loss = 6013.21
I0316 05:28:25.223520 29479 solver.cpp:229]     Train net output #0: loss = 8722.97 (* 1 = 8722.97 loss)
I0316 05:28:25.589282 29479 solver.cpp:610] Iteration 67040, lr = 6.92503e-09
I0316 05:28:25.589296 29479 solver.cpp:613] Iteration 67040, avg_grad_norm = 554516
I0316 05:29:57.561736 29479 solver.cpp:214] Iteration 67060, loss = 5931.62
I0316 05:29:57.561944 29479 solver.cpp:229]     Train net output #0: loss = 6870.38 (* 1 = 6870.38 loss)
I0316 05:29:57.899312 29479 solver.cpp:610] Iteration 67060, lr = 6.9241e-09
I0316 05:29:57.899325 29479 solver.cpp:613] Iteration 67060, avg_grad_norm = 504505
I0316 05:30:42.350327 29479 solver.cpp:214] Iteration 67080, loss = 5795.3
I0316 05:30:42.350461 29479 solver.cpp:229]     Train net output #0: loss = 6030.32 (* 1 = 6030.32 loss)
I0316 05:30:42.466524 29479 solver.cpp:610] Iteration 67080, lr = 6.92316e-09
I0316 05:30:42.466562 29479 solver.cpp:613] Iteration 67080, avg_grad_norm = 504721
I0316 05:31:47.801774 29479 solver.cpp:214] Iteration 67100, loss = 5745.18
I0316 05:31:47.801884 29479 solver.cpp:229]     Train net output #0: loss = 7335.13 (* 1 = 7335.13 loss)
I0316 05:31:48.164450 29479 solver.cpp:610] Iteration 67100, lr = 6.92222e-09
I0316 05:31:48.164464 29479 solver.cpp:613] Iteration 67100, avg_grad_norm = 564245
I0316 05:32:57.098544 29479 solver.cpp:214] Iteration 67120, loss = 6086.73
I0316 05:32:57.098675 29479 solver.cpp:229]     Train net output #0: loss = 6058.93 (* 1 = 6058.93 loss)
I0316 05:32:57.461236 29479 solver.cpp:610] Iteration 67120, lr = 6.92128e-09
I0316 05:32:57.461248 29479 solver.cpp:613] Iteration 67120, avg_grad_norm = 649107
I0316 05:34:06.033984 29479 solver.cpp:214] Iteration 67140, loss = 5467.14
I0316 05:34:06.034164 29479 solver.cpp:229]     Train net output #0: loss = 3863.25 (* 1 = 3863.25 loss)
I0316 05:34:06.394486 29479 solver.cpp:610] Iteration 67140, lr = 6.92035e-09
I0316 05:34:06.394500 29479 solver.cpp:613] Iteration 67140, avg_grad_norm = 551027
I0316 05:35:14.585404 29479 solver.cpp:214] Iteration 67160, loss = 5880.73
I0316 05:35:14.585547 29479 solver.cpp:229]     Train net output #0: loss = 3655.93 (* 1 = 3655.93 loss)
I0316 05:35:14.951064 29479 solver.cpp:610] Iteration 67160, lr = 6.91941e-09
I0316 05:35:14.951078 29479 solver.cpp:613] Iteration 67160, avg_grad_norm = 542661
I0316 05:36:37.276172 29479 solver.cpp:214] Iteration 67180, loss = 5922.61
I0316 05:36:37.276294 29479 solver.cpp:229]     Train net output #0: loss = 4224.28 (* 1 = 4224.28 loss)
I0316 05:36:37.637192 29479 solver.cpp:610] Iteration 67180, lr = 6.91847e-09
I0316 05:36:37.637207 29479 solver.cpp:613] Iteration 67180, avg_grad_norm = 538254
I0316 05:37:45.971920 29479 solver.cpp:214] Iteration 67200, loss = 5421.14
I0316 05:37:45.972084 29479 solver.cpp:229]     Train net output #0: loss = 2571.09 (* 1 = 2571.09 loss)
I0316 05:37:46.338271 29479 solver.cpp:610] Iteration 67200, lr = 6.91753e-09
I0316 05:37:46.338285 29479 solver.cpp:613] Iteration 67200, avg_grad_norm = 478333
I0316 05:38:32.784332 29479 solver.cpp:214] Iteration 67220, loss = 5690.98
I0316 05:38:32.784469 29479 solver.cpp:229]     Train net output #0: loss = 2728.79 (* 1 = 2728.79 loss)
I0316 05:38:33.146313 29479 solver.cpp:610] Iteration 67220, lr = 6.9166e-09
I0316 05:38:33.146327 29479 solver.cpp:613] Iteration 67220, avg_grad_norm = 522666
I0316 05:39:42.051640 29479 solver.cpp:214] Iteration 67240, loss = 5824.28
I0316 05:39:42.051789 29479 solver.cpp:229]     Train net output #0: loss = 2591.27 (* 1 = 2591.27 loss)
I0316 05:39:42.412266 29479 solver.cpp:610] Iteration 67240, lr = 6.91566e-09
I0316 05:39:42.412282 29479 solver.cpp:613] Iteration 67240, avg_grad_norm = 548400
I0316 05:40:51.164530 29479 solver.cpp:214] Iteration 67260, loss = 5953.53
I0316 05:40:51.164659 29479 solver.cpp:229]     Train net output #0: loss = 4756.98 (* 1 = 4756.98 loss)
I0316 05:40:51.524559 29479 solver.cpp:610] Iteration 67260, lr = 6.91472e-09
I0316 05:40:51.524574 29479 solver.cpp:613] Iteration 67260, avg_grad_norm = 590710
I0316 05:42:00.390566 29479 solver.cpp:214] Iteration 67280, loss = 5796.42
I0316 05:42:00.390679 29479 solver.cpp:229]     Train net output #0: loss = 11570.1 (* 1 = 11570.1 loss)
I0316 05:42:00.750596 29479 solver.cpp:610] Iteration 67280, lr = 6.91378e-09
I0316 05:42:00.750608 29479 solver.cpp:613] Iteration 67280, avg_grad_norm = 546830
I0316 05:43:10.033108 29479 solver.cpp:214] Iteration 67300, loss = 6074.35
I0316 05:43:10.033223 29479 solver.cpp:229]     Train net output #0: loss = 5107.45 (* 1 = 5107.45 loss)
I0316 05:43:10.402547 29479 solver.cpp:610] Iteration 67300, lr = 6.91285e-09
I0316 05:43:10.402561 29479 solver.cpp:613] Iteration 67300, avg_grad_norm = 526061
I0316 05:44:31.774636 29479 solver.cpp:214] Iteration 67320, loss = 5907.01
I0316 05:44:31.774756 29479 solver.cpp:229]     Train net output #0: loss = 3742.2 (* 1 = 3742.2 loss)
I0316 05:44:32.135859 29479 solver.cpp:610] Iteration 67320, lr = 6.91191e-09
I0316 05:44:32.135872 29479 solver.cpp:613] Iteration 67320, avg_grad_norm = 534828
I0316 05:45:36.717968 29479 solver.cpp:214] Iteration 67340, loss = 5770.57
I0316 05:45:36.718109 29479 solver.cpp:229]     Train net output #0: loss = 4780.21 (* 1 = 4780.21 loss)
I0316 05:45:36.828142 29479 solver.cpp:610] Iteration 67340, lr = 6.91097e-09
I0316 05:45:36.828156 29479 solver.cpp:613] Iteration 67340, avg_grad_norm = 573378
I0316 05:46:02.646996 29479 solver.cpp:214] Iteration 67360, loss = 5566.63
I0316 05:46:02.647061 29479 solver.cpp:229]     Train net output #0: loss = 4844.99 (* 1 = 4844.99 loss)
I0316 05:46:02.763370 29479 solver.cpp:610] Iteration 67360, lr = 6.91003e-09
I0316 05:46:02.763384 29479 solver.cpp:613] Iteration 67360, avg_grad_norm = 504384
I0316 05:46:57.913489 29479 solver.cpp:214] Iteration 67380, loss = 5410.5
I0316 05:46:57.913601 29479 solver.cpp:229]     Train net output #0: loss = 5210.71 (* 1 = 5210.71 loss)
I0316 05:46:58.279435 29479 solver.cpp:610] Iteration 67380, lr = 6.90909e-09
I0316 05:46:58.279448 29479 solver.cpp:613] Iteration 67380, avg_grad_norm = 518840
I0316 05:48:07.675532 29479 solver.cpp:214] Iteration 67400, loss = 5746.97
I0316 05:48:07.675658 29479 solver.cpp:229]     Train net output #0: loss = 10741.4 (* 1 = 10741.4 loss)
I0316 05:48:08.035132 29479 solver.cpp:610] Iteration 67400, lr = 6.90816e-09
I0316 05:48:08.035147 29479 solver.cpp:613] Iteration 67400, avg_grad_norm = 543366
I0316 05:49:17.017424 29479 solver.cpp:214] Iteration 67420, loss = 5755.87
I0316 05:49:17.017637 29479 solver.cpp:229]     Train net output #0: loss = 4202.74 (* 1 = 4202.74 loss)
I0316 05:49:17.378690 29479 solver.cpp:610] Iteration 67420, lr = 6.90722e-09
I0316 05:49:17.378705 29479 solver.cpp:613] Iteration 67420, avg_grad_norm = 488894
I0316 05:50:42.984019 29479 solver.cpp:214] Iteration 67440, loss = 5985.42
I0316 05:50:42.984175 29479 solver.cpp:229]     Train net output #0: loss = 3537.39 (* 1 = 3537.39 loss)
I0316 05:50:43.312177 29479 solver.cpp:610] Iteration 67440, lr = 6.90628e-09
I0316 05:50:43.312191 29479 solver.cpp:613] Iteration 67440, avg_grad_norm = 504946
I0316 05:51:51.576326 29479 solver.cpp:214] Iteration 67460, loss = 5900.42
I0316 05:51:51.576458 29479 solver.cpp:229]     Train net output #0: loss = 5274.77 (* 1 = 5274.77 loss)
I0316 05:51:51.942448 29479 solver.cpp:610] Iteration 67460, lr = 6.90534e-09
I0316 05:51:51.942462 29479 solver.cpp:613] Iteration 67460, avg_grad_norm = 497385
I0316 05:53:00.904798 29479 solver.cpp:214] Iteration 67480, loss = 5799.05
I0316 05:53:00.904971 29479 solver.cpp:229]     Train net output #0: loss = 4421.85 (* 1 = 4421.85 loss)
I0316 05:53:01.267438 29479 solver.cpp:610] Iteration 67480, lr = 6.90441e-09
I0316 05:53:01.267455 29479 solver.cpp:613] Iteration 67480, avg_grad_norm = 551277
I0316 05:53:47.562144 29479 solver.cpp:214] Iteration 67500, loss = 6275.27
I0316 05:53:47.562255 29479 solver.cpp:229]     Train net output #0: loss = 4523.11 (* 1 = 4523.11 loss)
I0316 05:53:47.930907 29479 solver.cpp:610] Iteration 67500, lr = 6.90347e-09
I0316 05:53:47.930922 29479 solver.cpp:613] Iteration 67500, avg_grad_norm = 555653
I0316 05:54:57.107254 29479 solver.cpp:214] Iteration 67520, loss = 5956.27
I0316 05:54:57.107391 29479 solver.cpp:229]     Train net output #0: loss = 12865.7 (* 1 = 12865.7 loss)
I0316 05:54:57.467919 29479 solver.cpp:610] Iteration 67520, lr = 6.90253e-09
I0316 05:54:57.467933 29479 solver.cpp:613] Iteration 67520, avg_grad_norm = 503170
I0316 05:56:03.158797 29479 solver.cpp:214] Iteration 67540, loss = 5981.55
I0316 05:56:03.158915 29479 solver.cpp:229]     Train net output #0: loss = 4792.86 (* 1 = 4792.86 loss)
I0316 05:56:03.519716 29479 solver.cpp:610] Iteration 67540, lr = 6.90159e-09
I0316 05:56:03.519731 29479 solver.cpp:613] Iteration 67540, avg_grad_norm = 477390
I0316 05:57:25.908633 29479 solver.cpp:214] Iteration 67560, loss = 5482.21
I0316 05:57:25.908751 29479 solver.cpp:229]     Train net output #0: loss = 4165.62 (* 1 = 4165.62 loss)
I0316 05:57:26.229089 29479 solver.cpp:610] Iteration 67560, lr = 6.90065e-09
I0316 05:57:26.229102 29479 solver.cpp:613] Iteration 67560, avg_grad_norm = 522269
I0316 05:58:34.754632 29479 solver.cpp:214] Iteration 67580, loss = 5850.44
I0316 05:58:34.754760 29479 solver.cpp:229]     Train net output #0: loss = 4709.01 (* 1 = 4709.01 loss)
I0316 05:58:35.116258 29479 solver.cpp:610] Iteration 67580, lr = 6.89972e-09
I0316 05:58:35.116272 29479 solver.cpp:613] Iteration 67580, avg_grad_norm = 524949
I0316 05:59:43.643553 29479 solver.cpp:214] Iteration 67600, loss = 5790.67
I0316 05:59:43.643693 29479 solver.cpp:229]     Train net output #0: loss = 6258.38 (* 1 = 6258.38 loss)
I0316 05:59:44.012202 29479 solver.cpp:610] Iteration 67600, lr = 6.89878e-09
I0316 05:59:44.012215 29479 solver.cpp:613] Iteration 67600, avg_grad_norm = 504303
I0316 06:00:52.462107 29479 solver.cpp:214] Iteration 67620, loss = 5891.72
I0316 06:00:52.462224 29479 solver.cpp:229]     Train net output #0: loss = 5977.79 (* 1 = 5977.79 loss)
I0316 06:00:52.838250 29479 solver.cpp:610] Iteration 67620, lr = 6.89784e-09
I0316 06:00:52.838264 29479 solver.cpp:613] Iteration 67620, avg_grad_norm = 534120
I0316 06:01:32.423218 29479 solver.cpp:214] Iteration 67640, loss = 5380.23
I0316 06:01:32.423373 29479 solver.cpp:229]     Train net output #0: loss = 4266.48 (* 1 = 4266.48 loss)
I0316 06:01:32.785647 29479 solver.cpp:610] Iteration 67640, lr = 6.8969e-09
I0316 06:01:32.785661 29479 solver.cpp:613] Iteration 67640, avg_grad_norm = 502114
I0316 06:02:41.797816 29479 solver.cpp:214] Iteration 67660, loss = 5787.44
I0316 06:02:41.797932 29479 solver.cpp:229]     Train net output #0: loss = 4823.58 (* 1 = 4823.58 loss)
I0316 06:02:42.164367 29479 solver.cpp:610] Iteration 67660, lr = 6.89596e-09
I0316 06:02:42.164381 29479 solver.cpp:613] Iteration 67660, avg_grad_norm = 509669
I0316 06:03:50.895699 29479 solver.cpp:214] Iteration 67680, loss = 5834.96
I0316 06:03:50.895828 29479 solver.cpp:229]     Train net output #0: loss = 11756.1 (* 1 = 11756.1 loss)
I0316 06:03:51.255234 29479 solver.cpp:610] Iteration 67680, lr = 6.89503e-09
I0316 06:03:51.255249 29479 solver.cpp:613] Iteration 67680, avg_grad_norm = 614760
I0316 06:05:21.181867 29479 solver.cpp:214] Iteration 67700, loss = 5610.13
I0316 06:05:21.182005 29479 solver.cpp:229]     Train net output #0: loss = 9619.1 (* 1 = 9619.1 loss)
I0316 06:05:21.542007 29479 solver.cpp:610] Iteration 67700, lr = 6.89409e-09
I0316 06:05:21.542022 29479 solver.cpp:613] Iteration 67700, avg_grad_norm = 558045
I0316 06:06:29.666582 29479 solver.cpp:214] Iteration 67720, loss = 5575.26
I0316 06:06:29.666690 29479 solver.cpp:229]     Train net output #0: loss = 4547.62 (* 1 = 4547.62 loss)
I0316 06:06:29.849478 29479 solver.cpp:610] Iteration 67720, lr = 6.89315e-09
I0316 06:06:29.849493 29479 solver.cpp:613] Iteration 67720, avg_grad_norm = 523665
I0316 06:07:37.970029 29479 solver.cpp:214] Iteration 67740, loss = 5713.83
I0316 06:07:37.970157 29479 solver.cpp:229]     Train net output #0: loss = 3805.56 (* 1 = 3805.56 loss)
I0316 06:07:38.332155 29479 solver.cpp:610] Iteration 67740, lr = 6.89221e-09
I0316 06:07:38.332170 29479 solver.cpp:613] Iteration 67740, avg_grad_norm = 495851
I0316 06:08:36.168769 29479 solver.cpp:214] Iteration 67760, loss = 5780.17
I0316 06:08:36.168902 29479 solver.cpp:229]     Train net output #0: loss = 2109.14 (* 1 = 2109.14 loss)
I0316 06:08:36.283532 29479 solver.cpp:610] Iteration 67760, lr = 6.89127e-09
I0316 06:08:36.283571 29479 solver.cpp:613] Iteration 67760, avg_grad_norm = 533573
I0316 06:09:34.176141 29479 solver.cpp:214] Iteration 67780, loss = 5736.34
I0316 06:09:34.176250 29479 solver.cpp:229]     Train net output #0: loss = 5615.5 (* 1 = 5615.5 loss)
I0316 06:09:34.542367 29479 solver.cpp:610] Iteration 67780, lr = 6.89034e-09
I0316 06:09:34.542381 29479 solver.cpp:613] Iteration 67780, avg_grad_norm = 490943
I0316 06:10:43.237609 29479 solver.cpp:214] Iteration 67800, loss = 5803.4
I0316 06:10:43.237743 29479 solver.cpp:229]     Train net output #0: loss = 3960.83 (* 1 = 3960.83 loss)
I0316 06:10:43.607365 29479 solver.cpp:610] Iteration 67800, lr = 6.8894e-09
I0316 06:10:43.607380 29479 solver.cpp:613] Iteration 67800, avg_grad_norm = 524668
I0316 06:12:05.650424 29479 solver.cpp:214] Iteration 67820, loss = 5859.52
I0316 06:12:05.650521 29479 solver.cpp:229]     Train net output #0: loss = 4774.54 (* 1 = 4774.54 loss)
I0316 06:12:06.016644 29479 solver.cpp:610] Iteration 67820, lr = 6.88846e-09
I0316 06:12:06.016659 29479 solver.cpp:613] Iteration 67820, avg_grad_norm = 531722
I0316 06:13:14.668555 29479 solver.cpp:214] Iteration 67840, loss = 5726.49
I0316 06:13:14.668664 29479 solver.cpp:229]     Train net output #0: loss = 3903.73 (* 1 = 3903.73 loss)
I0316 06:13:15.038378 29479 solver.cpp:610] Iteration 67840, lr = 6.88752e-09
I0316 06:13:15.038391 29479 solver.cpp:613] Iteration 67840, avg_grad_norm = 508271
I0316 06:14:23.174401 29479 solver.cpp:214] Iteration 67860, loss = 6046.38
I0316 06:14:23.174535 29479 solver.cpp:229]     Train net output #0: loss = 6737.15 (* 1 = 6737.15 loss)
I0316 06:14:23.534227 29479 solver.cpp:610] Iteration 67860, lr = 6.88658e-09
I0316 06:14:23.534287 29479 solver.cpp:613] Iteration 67860, avg_grad_norm = 578046
I0316 06:15:32.456833 29479 solver.cpp:214] Iteration 67880, loss = 5520.8
I0316 06:15:32.456970 29479 solver.cpp:229]     Train net output #0: loss = 4571.35 (* 1 = 4571.35 loss)
I0316 06:15:32.816642 29479 solver.cpp:610] Iteration 67880, lr = 6.88565e-09
I0316 06:15:32.816655 29479 solver.cpp:613] Iteration 67880, avg_grad_norm = 513242
I0316 06:16:16.131733 29479 solver.cpp:214] Iteration 67900, loss = 5747.43
I0316 06:16:16.131841 29479 solver.cpp:229]     Train net output #0: loss = 2952.18 (* 1 = 2952.18 loss)
I0316 06:16:16.249614 29479 solver.cpp:610] Iteration 67900, lr = 6.88471e-09
I0316 06:16:16.249665 29479 solver.cpp:613] Iteration 67900, avg_grad_norm = 523011
I0316 06:17:22.451871 29479 solver.cpp:214] Iteration 67920, loss = 5698.33
I0316 06:17:22.452118 29479 solver.cpp:229]     Train net output #0: loss = 10364.6 (* 1 = 10364.6 loss)
I0316 06:17:22.820771 29479 solver.cpp:610] Iteration 67920, lr = 6.88377e-09
I0316 06:17:22.820786 29479 solver.cpp:613] Iteration 67920, avg_grad_norm = 489067
I0316 06:18:31.693248 29479 solver.cpp:214] Iteration 67940, loss = 5733.48
I0316 06:18:31.693392 29479 solver.cpp:229]     Train net output #0: loss = 4963.03 (* 1 = 4963.03 loss)
I0316 06:18:32.052201 29479 solver.cpp:610] Iteration 67940, lr = 6.88283e-09
I0316 06:18:32.052214 29479 solver.cpp:613] Iteration 67940, avg_grad_norm = 497146
I0316 06:19:53.855336 29479 solver.cpp:214] Iteration 67960, loss = 5709.21
I0316 06:19:53.855450 29479 solver.cpp:229]     Train net output #0: loss = 4588.03 (* 1 = 4588.03 loss)
I0316 06:19:54.218176 29479 solver.cpp:610] Iteration 67960, lr = 6.88189e-09
I0316 06:19:54.218191 29479 solver.cpp:613] Iteration 67960, avg_grad_norm = 502160
I0316 06:21:02.763528 29479 solver.cpp:214] Iteration 67980, loss = 5791.06
I0316 06:21:02.763670 29479 solver.cpp:229]     Train net output #0: loss = 4592.83 (* 1 = 4592.83 loss)
I0316 06:21:03.123320 29479 solver.cpp:610] Iteration 67980, lr = 6.88096e-09
I0316 06:21:03.123333 29479 solver.cpp:613] Iteration 67980, avg_grad_norm = 527329
I0316 06:22:11.306860 29479 solver.cpp:214] Iteration 68000, loss = 6003
I0316 06:22:11.307030 29479 solver.cpp:229]     Train net output #0: loss = 7075.95 (* 1 = 7075.95 loss)
I0316 06:22:11.678804 29479 solver.cpp:610] Iteration 68000, lr = 6.88002e-09
I0316 06:22:11.678818 29479 solver.cpp:613] Iteration 68000, avg_grad_norm = 550485
I0316 06:23:20.400619 29479 solver.cpp:214] Iteration 68020, loss = 5848.78
I0316 06:23:20.400768 29479 solver.cpp:229]     Train net output #0: loss = 6529.72 (* 1 = 6529.72 loss)
I0316 06:23:20.760309 29479 solver.cpp:610] Iteration 68020, lr = 6.87908e-09
I0316 06:23:20.760323 29479 solver.cpp:613] Iteration 68020, avg_grad_norm = 517251
I0316 06:24:07.558475 29479 solver.cpp:214] Iteration 68040, loss = 5790.3
I0316 06:24:07.558595 29479 solver.cpp:229]     Train net output #0: loss = 4280.17 (* 1 = 4280.17 loss)
I0316 06:24:07.918890 29479 solver.cpp:610] Iteration 68040, lr = 6.87814e-09
I0316 06:24:07.918905 29479 solver.cpp:613] Iteration 68040, avg_grad_norm = 536446
I0316 06:25:16.168942 29479 solver.cpp:214] Iteration 68060, loss = 5978.39
I0316 06:25:16.169142 29479 solver.cpp:229]     Train net output #0: loss = 5754.97 (* 1 = 5754.97 loss)
I0316 06:25:16.534809 29479 solver.cpp:610] Iteration 68060, lr = 6.8772e-09
I0316 06:25:16.534823 29479 solver.cpp:613] Iteration 68060, avg_grad_norm = 526154
I0316 06:26:38.050248 29479 solver.cpp:214] Iteration 68080, loss = 5887.46
I0316 06:26:38.050348 29479 solver.cpp:229]     Train net output #0: loss = 4145.34 (* 1 = 4145.34 loss)
I0316 06:26:38.412433 29479 solver.cpp:610] Iteration 68080, lr = 6.87626e-09
I0316 06:26:38.412447 29479 solver.cpp:613] Iteration 68080, avg_grad_norm = 569802
I0316 06:27:46.704643 29479 solver.cpp:214] Iteration 68100, loss = 5951.41
I0316 06:27:46.704763 29479 solver.cpp:229]     Train net output #0: loss = 7528.02 (* 1 = 7528.02 loss)
I0316 06:27:47.064626 29479 solver.cpp:610] Iteration 68100, lr = 6.87533e-09
I0316 06:27:47.064640 29479 solver.cpp:613] Iteration 68100, avg_grad_norm = 520256
I0316 06:28:55.426725 29479 solver.cpp:214] Iteration 68120, loss = 5876.06
I0316 06:28:55.426823 29479 solver.cpp:229]     Train net output #0: loss = 5511.78 (* 1 = 5511.78 loss)
I0316 06:28:55.795404 29479 solver.cpp:610] Iteration 68120, lr = 6.87439e-09
I0316 06:28:55.795418 29479 solver.cpp:613] Iteration 68120, avg_grad_norm = 490146
I0316 06:30:04.274462 29479 solver.cpp:214] Iteration 68140, loss = 5792.67
I0316 06:30:04.274619 29479 solver.cpp:229]     Train net output #0: loss = 2612.74 (* 1 = 2612.74 loss)
I0316 06:30:04.643973 29479 solver.cpp:610] Iteration 68140, lr = 6.87345e-09
I0316 06:30:04.643986 29479 solver.cpp:613] Iteration 68140, avg_grad_norm = 513878
I0316 06:31:10.809398 29479 solver.cpp:214] Iteration 68160, loss = 5677.33
I0316 06:31:10.809546 29479 solver.cpp:229]     Train net output #0: loss = 6435.08 (* 1 = 6435.08 loss)
I0316 06:31:10.914767 29479 solver.cpp:610] Iteration 68160, lr = 6.87251e-09
I0316 06:31:10.914803 29479 solver.cpp:613] Iteration 68160, avg_grad_norm = 463879
I0316 06:31:55.998894 29479 solver.cpp:214] Iteration 68180, loss = 5856.62
I0316 06:31:55.999024 29479 solver.cpp:229]     Train net output #0: loss = 6885.37 (* 1 = 6885.37 loss)
I0316 06:31:56.364102 29479 solver.cpp:610] Iteration 68180, lr = 6.87157e-09
I0316 06:31:56.364117 29479 solver.cpp:613] Iteration 68180, avg_grad_norm = 509163
I0316 06:33:21.828816 29479 solver.cpp:214] Iteration 68200, loss = 5674.78
I0316 06:33:21.828961 29479 solver.cpp:229]     Train net output #0: loss = 3179.8 (* 1 = 3179.8 loss)
I0316 06:33:22.189473 29479 solver.cpp:610] Iteration 68200, lr = 6.87064e-09
I0316 06:33:22.189491 29479 solver.cpp:613] Iteration 68200, avg_grad_norm = 492850
I0316 06:34:30.336839 29479 solver.cpp:214] Iteration 68220, loss = 5678.45
I0316 06:34:30.337023 29479 solver.cpp:229]     Train net output #0: loss = 7275.94 (* 1 = 7275.94 loss)
I0316 06:34:30.704027 29479 solver.cpp:610] Iteration 68220, lr = 6.8697e-09
I0316 06:34:30.704042 29479 solver.cpp:613] Iteration 68220, avg_grad_norm = 502289
I0316 06:35:39.040510 29479 solver.cpp:214] Iteration 68240, loss = 5664.18
I0316 06:35:39.040637 29479 solver.cpp:229]     Train net output #0: loss = 5568.23 (* 1 = 5568.23 loss)
I0316 06:35:39.407943 29479 solver.cpp:610] Iteration 68240, lr = 6.86876e-09
I0316 06:35:39.407958 29479 solver.cpp:613] Iteration 68240, avg_grad_norm = 487303
I0316 06:36:48.522522 29479 solver.cpp:214] Iteration 68260, loss = 5814.76
I0316 06:36:48.522631 29479 solver.cpp:229]     Train net output #0: loss = 6551 (* 1 = 6551 loss)
I0316 06:36:48.883322 29479 solver.cpp:610] Iteration 68260, lr = 6.86782e-09
I0316 06:36:48.883335 29479 solver.cpp:613] Iteration 68260, avg_grad_norm = 534197
I0316 06:37:57.979619 29479 solver.cpp:214] Iteration 68280, loss = 5845.32
I0316 06:37:57.979740 29479 solver.cpp:229]     Train net output #0: loss = 5645.57 (* 1 = 5645.57 loss)
I0316 06:37:58.339687 29479 solver.cpp:610] Iteration 68280, lr = 6.86688e-09
I0316 06:37:58.339701 29479 solver.cpp:613] Iteration 68280, avg_grad_norm = 507989
I0316 06:38:50.523675 29479 solver.cpp:214] Iteration 68300, loss = 6105.67
I0316 06:38:50.523818 29479 solver.cpp:229]     Train net output #0: loss = 3911.79 (* 1 = 3911.79 loss)
I0316 06:38:50.639994 29479 solver.cpp:610] Iteration 68300, lr = 6.86594e-09
I0316 06:38:50.640007 29479 solver.cpp:613] Iteration 68300, avg_grad_norm = 524439
I0316 06:39:54.932348 29479 solver.cpp:214] Iteration 68320, loss = 5689.88
I0316 06:39:54.932550 29479 solver.cpp:229]     Train net output #0: loss = 8433.6 (* 1 = 8433.6 loss)
I0316 06:39:55.292044 29479 solver.cpp:610] Iteration 68320, lr = 6.865e-09
I0316 06:39:55.292058 29479 solver.cpp:613] Iteration 68320, avg_grad_norm = 508452
I0316 06:41:16.321213 29479 solver.cpp:214] Iteration 68340, loss = 5935.48
I0316 06:41:16.321344 29479 solver.cpp:229]     Train net output #0: loss = 7656.17 (* 1 = 7656.17 loss)
I0316 06:41:16.684554 29479 solver.cpp:610] Iteration 68340, lr = 6.86407e-09
I0316 06:41:16.684567 29479 solver.cpp:613] Iteration 68340, avg_grad_norm = 519409
I0316 06:42:24.967428 29479 solver.cpp:214] Iteration 68360, loss = 5842.52
I0316 06:42:24.967563 29479 solver.cpp:229]     Train net output #0: loss = 5785.98 (* 1 = 5785.98 loss)
I0316 06:42:25.330173 29479 solver.cpp:610] Iteration 68360, lr = 6.86313e-09
I0316 06:42:25.330188 29479 solver.cpp:613] Iteration 68360, avg_grad_norm = 548152
I0316 06:43:34.110257 29479 solver.cpp:214] Iteration 68380, loss = 5811.01
I0316 06:43:34.110447 29479 solver.cpp:229]     Train net output #0: loss = 5152.94 (* 1 = 5152.94 loss)
I0316 06:43:34.442340 29479 solver.cpp:610] Iteration 68380, lr = 6.86219e-09
I0316 06:43:34.442354 29479 solver.cpp:613] Iteration 68380, avg_grad_norm = 517732
I0316 06:44:43.412153 29479 solver.cpp:214] Iteration 68400, loss = 5749.71
I0316 06:44:43.412273 29479 solver.cpp:229]     Train net output #0: loss = 4564.4 (* 1 = 4564.4 loss)
I0316 06:44:43.772574 29479 solver.cpp:610] Iteration 68400, lr = 6.86125e-09
I0316 06:44:43.772588 29479 solver.cpp:613] Iteration 68400, avg_grad_norm = 494728
I0316 06:45:53.031126 29479 solver.cpp:214] Iteration 68420, loss = 5709.5
I0316 06:45:53.031239 29479 solver.cpp:229]     Train net output #0: loss = 4013.06 (* 1 = 4013.06 loss)
I0316 06:45:53.219256 29479 solver.cpp:610] Iteration 68420, lr = 6.86031e-09
I0316 06:45:53.219269 29479 solver.cpp:613] Iteration 68420, avg_grad_norm = 533782
I0316 06:46:37.952205 29479 solver.cpp:214] Iteration 68440, loss = 5898.46
I0316 06:46:37.952349 29479 solver.cpp:229]     Train net output #0: loss = 3070.85 (* 1 = 3070.85 loss)
I0316 06:46:38.312573 29479 solver.cpp:610] Iteration 68440, lr = 6.85937e-09
I0316 06:46:38.312587 29479 solver.cpp:613] Iteration 68440, avg_grad_norm = 551319
I0316 06:48:06.183544 29479 solver.cpp:214] Iteration 68460, loss = 5550.58
I0316 06:48:06.183651 29479 solver.cpp:229]     Train net output #0: loss = 3746.25 (* 1 = 3746.25 loss)
I0316 06:48:06.543880 29479 solver.cpp:610] Iteration 68460, lr = 6.85844e-09
I0316 06:48:06.543895 29479 solver.cpp:613] Iteration 68460, avg_grad_norm = 539815
I0316 06:49:15.525706 29479 solver.cpp:214] Iteration 68480, loss = 5831.31
I0316 06:49:15.525841 29479 solver.cpp:229]     Train net output #0: loss = 2382.17 (* 1 = 2382.17 loss)
I0316 06:49:15.885928 29479 solver.cpp:610] Iteration 68480, lr = 6.8575e-09
I0316 06:49:15.885942 29479 solver.cpp:613] Iteration 68480, avg_grad_norm = 532620
I0316 06:50:23.778642 29479 solver.cpp:214] Iteration 68500, loss = 6121.66
I0316 06:50:23.778779 29479 solver.cpp:229]     Train net output #0: loss = 8485.66 (* 1 = 8485.66 loss)
I0316 06:50:24.147444 29479 solver.cpp:610] Iteration 68500, lr = 6.85656e-09
I0316 06:50:24.147459 29479 solver.cpp:613] Iteration 68500, avg_grad_norm = 488152
I0316 06:51:32.821063 29479 solver.cpp:214] Iteration 68520, loss = 5635.08
I0316 06:51:32.821257 29479 solver.cpp:229]     Train net output #0: loss = 5747.61 (* 1 = 5747.61 loss)
I0316 06:51:33.193830 29479 solver.cpp:610] Iteration 68520, lr = 6.85562e-09
I0316 06:51:33.193843 29479 solver.cpp:613] Iteration 68520, avg_grad_norm = 569710
I0316 06:52:39.583000 29479 solver.cpp:214] Iteration 68540, loss = 5922.29
I0316 06:52:39.583119 29479 solver.cpp:229]     Train net output #0: loss = 5089.32 (* 1 = 5089.32 loss)
I0316 06:52:39.951972 29479 solver.cpp:610] Iteration 68540, lr = 6.85468e-09
I0316 06:52:39.951984 29479 solver.cpp:613] Iteration 68540, avg_grad_norm = 504366
I0316 06:53:43.762336 29479 solver.cpp:214] Iteration 68560, loss = 5792.63
I0316 06:53:43.762473 29479 solver.cpp:229]     Train net output #0: loss = 13502.7 (* 1 = 13502.7 loss)
I0316 06:53:43.874020 29479 solver.cpp:610] Iteration 68560, lr = 6.85374e-09
I0316 06:53:43.874056 29479 solver.cpp:613] Iteration 68560, avg_grad_norm = 488081
I0316 06:54:55.950979 29479 solver.cpp:214] Iteration 68580, loss = 5794.51
I0316 06:54:55.951105 29479 solver.cpp:229]     Train net output #0: loss = 2320.89 (* 1 = 2320.89 loss)
I0316 06:54:56.312028 29479 solver.cpp:610] Iteration 68580, lr = 6.8528e-09
I0316 06:54:56.312043 29479 solver.cpp:613] Iteration 68580, avg_grad_norm = 519505
I0316 06:56:04.814059 29479 solver.cpp:214] Iteration 68600, loss = 5626.37
I0316 06:56:04.814188 29479 solver.cpp:229]     Train net output #0: loss = 2529.48 (* 1 = 2529.48 loss)
I0316 06:56:05.013979 29479 solver.cpp:610] Iteration 68600, lr = 6.85187e-09
I0316 06:56:05.013993 29479 solver.cpp:613] Iteration 68600, avg_grad_norm = 519543
I0316 06:57:12.945962 29479 solver.cpp:214] Iteration 68620, loss = 5984.56
I0316 06:57:12.946156 29479 solver.cpp:229]     Train net output #0: loss = 9436.68 (* 1 = 9436.68 loss)
I0316 06:57:13.314559 29479 solver.cpp:610] Iteration 68620, lr = 6.85093e-09
I0316 06:57:13.314574 29479 solver.cpp:613] Iteration 68620, avg_grad_norm = 495245
I0316 06:58:21.528944 29479 solver.cpp:214] Iteration 68640, loss = 6053.23
I0316 06:58:21.529103 29479 solver.cpp:229]     Train net output #0: loss = 3839.97 (* 1 = 3839.97 loss)
I0316 06:58:21.891710 29479 solver.cpp:610] Iteration 68640, lr = 6.84999e-09
I0316 06:58:21.891724 29479 solver.cpp:613] Iteration 68640, avg_grad_norm = 556060
I0316 06:59:30.932176 29479 solver.cpp:214] Iteration 68660, loss = 6177.33
I0316 06:59:30.932317 29479 solver.cpp:229]     Train net output #0: loss = 5880.03 (* 1 = 5880.03 loss)
I0316 06:59:31.294978 29479 solver.cpp:610] Iteration 68660, lr = 6.84905e-09
I0316 06:59:31.294991 29479 solver.cpp:613] Iteration 68660, avg_grad_norm = 480113
I0316 07:00:39.917975 29479 solver.cpp:214] Iteration 68680, loss = 5902.05
I0316 07:00:39.918179 29479 solver.cpp:229]     Train net output #0: loss = 7391.16 (* 1 = 7391.16 loss)
I0316 07:00:40.280607 29479 solver.cpp:610] Iteration 68680, lr = 6.84811e-09
I0316 07:00:40.280622 29479 solver.cpp:613] Iteration 68680, avg_grad_norm = 548857
I0316 07:01:24.580554 29479 solver.cpp:214] Iteration 68700, loss = 5958.37
I0316 07:01:24.580692 29479 solver.cpp:229]     Train net output #0: loss = 7412.62 (* 1 = 7412.62 loss)
I0316 07:01:24.983710 29479 solver.cpp:610] Iteration 68700, lr = 6.84717e-09
I0316 07:01:24.983723 29479 solver.cpp:613] Iteration 68700, avg_grad_norm = 476574
I0316 07:02:50.895694 29479 solver.cpp:214] Iteration 68720, loss = 5907.59
I0316 07:02:50.895817 29479 solver.cpp:229]     Train net output #0: loss = 8162.22 (* 1 = 8162.22 loss)
I0316 07:02:51.092967 29479 solver.cpp:610] Iteration 68720, lr = 6.84623e-09
I0316 07:02:51.092980 29479 solver.cpp:613] Iteration 68720, avg_grad_norm = 496209
I0316 07:03:59.850903 29479 solver.cpp:214] Iteration 68740, loss = 5972.19
I0316 07:03:59.851047 29479 solver.cpp:229]     Train net output #0: loss = 9941.33 (* 1 = 9941.33 loss)
I0316 07:04:00.213306 29479 solver.cpp:610] Iteration 68740, lr = 6.84529e-09
I0316 07:04:00.213320 29479 solver.cpp:613] Iteration 68740, avg_grad_norm = 588311
I0316 07:05:08.738317 29479 solver.cpp:214] Iteration 68760, loss = 5864.59
I0316 07:05:08.738448 29479 solver.cpp:229]     Train net output #0: loss = 4238.74 (* 1 = 4238.74 loss)
I0316 07:05:09.100479 29479 solver.cpp:610] Iteration 68760, lr = 6.84436e-09
I0316 07:05:09.100495 29479 solver.cpp:613] Iteration 68760, avg_grad_norm = 492971
I0316 07:06:17.139979 29479 solver.cpp:214] Iteration 68780, loss = 5747.89
I0316 07:06:17.140122 29479 solver.cpp:229]     Train net output #0: loss = 8724.16 (* 1 = 8724.16 loss)
I0316 07:06:17.338170 29479 solver.cpp:610] Iteration 68780, lr = 6.84342e-09
I0316 07:06:17.338183 29479 solver.cpp:613] Iteration 68780, avg_grad_norm = 569104
I0316 07:07:26.145515 29479 solver.cpp:214] Iteration 68800, loss = 6123.6
I0316 07:07:26.145639 29479 solver.cpp:229]     Train net output #0: loss = 9340.31 (* 1 = 9340.31 loss)
I0316 07:07:26.506422 29479 solver.cpp:610] Iteration 68800, lr = 6.84248e-09
I0316 07:07:26.506436 29479 solver.cpp:613] Iteration 68800, avg_grad_norm = 650775
I0316 07:08:34.945997 29479 solver.cpp:214] Iteration 68820, loss = 5660.3
I0316 07:08:34.946125 29479 solver.cpp:229]     Train net output #0: loss = 2870.5 (* 1 = 2870.5 loss)
I0316 07:08:35.312700 29479 solver.cpp:610] Iteration 68820, lr = 6.84154e-09
I0316 07:08:35.312714 29479 solver.cpp:613] Iteration 68820, avg_grad_norm = 623420
I0316 07:09:37.480482 29479 solver.cpp:214] Iteration 68840, loss = 5849.46
I0316 07:09:37.480623 29479 solver.cpp:229]     Train net output #0: loss = 3219.15 (* 1 = 3219.15 loss)
I0316 07:09:37.585855 29479 solver.cpp:610] Iteration 68840, lr = 6.8406e-09
I0316 07:09:37.585891 29479 solver.cpp:613] Iteration 68840, avg_grad_norm = 496218
I0316 07:10:43.595515 29479 solver.cpp:214] Iteration 68860, loss = 5704.2
I0316 07:10:43.595672 29479 solver.cpp:229]     Train net output #0: loss = 2068.37 (* 1 = 2068.37 loss)
I0316 07:10:43.959667 29479 solver.cpp:610] Iteration 68860, lr = 6.83966e-09
I0316 07:10:43.959681 29479 solver.cpp:613] Iteration 68860, avg_grad_norm = 485702
I0316 07:11:50.942903 29479 solver.cpp:214] Iteration 68880, loss = 5634.85
I0316 07:11:50.943065 29479 solver.cpp:229]     Train net output #0: loss = 3364.94 (* 1 = 3364.94 loss)
I0316 07:11:51.302899 29479 solver.cpp:610] Iteration 68880, lr = 6.83872e-09
I0316 07:11:51.302917 29479 solver.cpp:613] Iteration 68880, avg_grad_norm = 502936
I0316 07:12:59.222411 29479 solver.cpp:214] Iteration 68900, loss = 5889.61
I0316 07:12:59.222515 29479 solver.cpp:229]     Train net output #0: loss = 4676.04 (* 1 = 4676.04 loss)
I0316 07:12:59.592777 29479 solver.cpp:610] Iteration 68900, lr = 6.83778e-09
I0316 07:12:59.592790 29479 solver.cpp:613] Iteration 68900, avg_grad_norm = 499877
I0316 07:14:07.983824 29479 solver.cpp:214] Iteration 68920, loss = 5898.39
I0316 07:14:07.983953 29479 solver.cpp:229]     Train net output #0: loss = 2898.98 (* 1 = 2898.98 loss)
I0316 07:14:08.346529 29479 solver.cpp:610] Iteration 68920, lr = 6.83685e-09
I0316 07:14:08.346544 29479 solver.cpp:613] Iteration 68920, avg_grad_norm = 487375
I0316 07:15:16.931037 29479 solver.cpp:214] Iteration 68940, loss = 6066.14
I0316 07:15:16.931152 29479 solver.cpp:229]     Train net output #0: loss = 5305.17 (* 1 = 5305.17 loss)
I0316 07:15:17.291302 29479 solver.cpp:610] Iteration 68940, lr = 6.83591e-09
I0316 07:15:17.291316 29479 solver.cpp:613] Iteration 68940, avg_grad_norm = 568947
I0316 07:16:50.857985 29479 solver.cpp:214] Iteration 68960, loss = 5987.27
I0316 07:16:50.858170 29479 solver.cpp:229]     Train net output #0: loss = 7494.91 (* 1 = 7494.91 loss)
I0316 07:16:51.215626 29479 solver.cpp:610] Iteration 68960, lr = 6.83497e-09
I0316 07:16:51.215638 29479 solver.cpp:613] Iteration 68960, avg_grad_norm = 569487
I0316 07:17:58.422758 29479 solver.cpp:214] Iteration 68980, loss = 5935.3
I0316 07:17:58.422895 29479 solver.cpp:229]     Train net output #0: loss = 5113.56 (* 1 = 5113.56 loss)
I0316 07:17:58.781857 29479 solver.cpp:610] Iteration 68980, lr = 6.83403e-09
I0316 07:17:58.781874 29479 solver.cpp:613] Iteration 68980, avg_grad_norm = 504630
I0316 07:19:06.665016 29479 solver.cpp:214] Iteration 69000, loss = 5765.53
I0316 07:19:06.665210 29479 solver.cpp:229]     Train net output #0: loss = 4739.75 (* 1 = 4739.75 loss)
I0316 07:19:07.024126 29479 solver.cpp:610] Iteration 69000, lr = 6.83309e-09
I0316 07:19:07.024139 29479 solver.cpp:613] Iteration 69000, avg_grad_norm = 485623
I0316 07:20:14.287657 29479 solver.cpp:214] Iteration 69020, loss = 5915.85
I0316 07:20:14.287772 29479 solver.cpp:229]     Train net output #0: loss = 2052.8 (* 1 = 2052.8 loss)
I0316 07:20:14.477612 29479 solver.cpp:610] Iteration 69020, lr = 6.83215e-09
I0316 07:20:14.477627 29479 solver.cpp:613] Iteration 69020, avg_grad_norm = 510649
I0316 07:21:22.775583 29479 solver.cpp:214] Iteration 69040, loss = 5815.44
I0316 07:21:22.775694 29479 solver.cpp:229]     Train net output #0: loss = 5431.8 (* 1 = 5431.8 loss)
I0316 07:21:23.135850 29479 solver.cpp:610] Iteration 69040, lr = 6.83121e-09
I0316 07:21:23.135864 29479 solver.cpp:613] Iteration 69040, avg_grad_norm = 568306
I0316 07:22:31.513497 29479 solver.cpp:214] Iteration 69060, loss = 5891.87
I0316 07:22:31.513633 29479 solver.cpp:229]     Train net output #0: loss = 7561.87 (* 1 = 7561.87 loss)
I0316 07:22:31.874752 29479 solver.cpp:610] Iteration 69060, lr = 6.83027e-09
I0316 07:22:31.874766 29479 solver.cpp:613] Iteration 69060, avg_grad_norm = 577882
I0316 07:23:40.450652 29479 solver.cpp:214] Iteration 69080, loss = 5794.92
I0316 07:23:40.450786 29479 solver.cpp:229]     Train net output #0: loss = 5180.62 (* 1 = 5180.62 loss)
I0316 07:23:40.808954 29479 solver.cpp:610] Iteration 69080, lr = 6.82933e-09
I0316 07:23:40.808967 29479 solver.cpp:613] Iteration 69080, avg_grad_norm = 499859
I0316 07:24:44.159368 29479 solver.cpp:214] Iteration 69100, loss = 6199.44
I0316 07:24:44.159561 29479 solver.cpp:229]     Train net output #0: loss = 7848.07 (* 1 = 7848.07 loss)
I0316 07:24:44.540580 29479 solver.cpp:610] Iteration 69100, lr = 6.8284e-09
I0316 07:24:44.540596 29479 solver.cpp:613] Iteration 69100, avg_grad_norm = 518809
I0316 07:25:53.149991 29479 solver.cpp:214] Iteration 69120, loss = 5881.48
I0316 07:25:53.150218 29479 solver.cpp:229]     Train net output #0: loss = 7479.8 (* 1 = 7479.8 loss)
I0316 07:25:53.509685 29479 solver.cpp:610] Iteration 69120, lr = 6.82746e-09
I0316 07:25:53.509699 29479 solver.cpp:613] Iteration 69120, avg_grad_norm = 573868
I0316 07:27:00.975380 29479 solver.cpp:214] Iteration 69140, loss = 5609.64
I0316 07:27:00.975584 29479 solver.cpp:229]     Train net output #0: loss = 7189.85 (* 1 = 7189.85 loss)
I0316 07:27:01.335208 29479 solver.cpp:610] Iteration 69140, lr = 6.82652e-09
I0316 07:27:01.335227 29479 solver.cpp:613] Iteration 69140, avg_grad_norm = 592992
I0316 07:28:09.486454 29479 solver.cpp:214] Iteration 69160, loss = 5681.14
I0316 07:28:09.486564 29479 solver.cpp:229]     Train net output #0: loss = 5681.3 (* 1 = 5681.3 loss)
I0316 07:28:09.847470 29479 solver.cpp:610] Iteration 69160, lr = 6.82558e-09
I0316 07:28:09.847486 29479 solver.cpp:613] Iteration 69160, avg_grad_norm = 534753
I0316 07:29:17.443261 29479 solver.cpp:214] Iteration 69180, loss = 5808.51
I0316 07:29:17.443409 29479 solver.cpp:229]     Train net output #0: loss = 4935.98 (* 1 = 4935.98 loss)
I0316 07:29:17.656111 29479 solver.cpp:610] Iteration 69180, lr = 6.82464e-09
I0316 07:29:17.656174 29479 solver.cpp:613] Iteration 69180, avg_grad_norm = 519588
I0316 07:30:26.326370 29479 solver.cpp:214] Iteration 69200, loss = 5755.15
I0316 07:30:26.326500 29479 solver.cpp:229]     Train net output #0: loss = 3998.93 (* 1 = 3998.93 loss)
I0316 07:30:26.684566 29479 solver.cpp:610] Iteration 69200, lr = 6.8237e-09
I0316 07:30:26.684579 29479 solver.cpp:613] Iteration 69200, avg_grad_norm = 517792
I0316 07:31:39.735415 29479 solver.cpp:214] Iteration 69220, loss = 5889.56
I0316 07:31:39.735559 29479 solver.cpp:229]     Train net output #0: loss = 4812.43 (* 1 = 4812.43 loss)
I0316 07:31:39.850230 29479 solver.cpp:610] Iteration 69220, lr = 6.82276e-09
I0316 07:31:39.850270 29479 solver.cpp:613] Iteration 69220, avg_grad_norm = 537659
I0316 07:32:29.526119 29479 solver.cpp:214] Iteration 69240, loss = 5921.09
I0316 07:32:29.526247 29479 solver.cpp:229]     Train net output #0: loss = 4397.47 (* 1 = 4397.47 loss)
I0316 07:32:29.894951 29479 solver.cpp:610] Iteration 69240, lr = 6.82182e-09
I0316 07:32:29.894965 29479 solver.cpp:613] Iteration 69240, avg_grad_norm = 517930
I0316 07:33:38.754427 29479 solver.cpp:214] Iteration 69260, loss = 5984.77
I0316 07:33:38.754559 29479 solver.cpp:229]     Train net output #0: loss = 4321.99 (* 1 = 4321.99 loss)
I0316 07:33:39.117908 29479 solver.cpp:610] Iteration 69260, lr = 6.82088e-09
I0316 07:33:39.117925 29479 solver.cpp:613] Iteration 69260, avg_grad_norm = 477109
I0316 07:34:47.383234 29479 solver.cpp:214] Iteration 69280, loss = 6156.59
I0316 07:34:47.383345 29479 solver.cpp:229]     Train net output #0: loss = 5513.19 (* 1 = 5513.19 loss)
I0316 07:34:47.746057 29479 solver.cpp:610] Iteration 69280, lr = 6.81994e-09
I0316 07:34:47.746073 29479 solver.cpp:613] Iteration 69280, avg_grad_norm = 536571
I0316 07:35:56.474438 29479 solver.cpp:214] Iteration 69300, loss = 5733.81
I0316 07:35:56.474556 29479 solver.cpp:229]     Train net output #0: loss = 5546.1 (* 1 = 5546.1 loss)
I0316 07:35:56.843130 29479 solver.cpp:610] Iteration 69300, lr = 6.819e-09
I0316 07:35:56.843144 29479 solver.cpp:613] Iteration 69300, avg_grad_norm = 516007
I0316 07:37:04.396742 29479 solver.cpp:214] Iteration 69320, loss = 5942.9
I0316 07:37:04.396860 29479 solver.cpp:229]     Train net output #0: loss = 4619.42 (* 1 = 4619.42 loss)
I0316 07:37:04.756405 29479 solver.cpp:610] Iteration 69320, lr = 6.81807e-09
I0316 07:37:04.756420 29479 solver.cpp:613] Iteration 69320, avg_grad_norm = 567984
I0316 07:38:26.267470 29479 solver.cpp:214] Iteration 69340, loss = 5887.7
I0316 07:38:26.267660 29479 solver.cpp:229]     Train net output #0: loss = 5194.81 (* 1 = 5194.81 loss)
I0316 07:38:26.598352 29479 solver.cpp:610] Iteration 69340, lr = 6.81713e-09
I0316 07:38:26.598366 29479 solver.cpp:613] Iteration 69340, avg_grad_norm = 638629
I0316 07:39:18.901587 29479 solver.cpp:214] Iteration 69360, loss = 5775.49
I0316 07:39:18.901726 29479 solver.cpp:229]     Train net output #0: loss = 10083.5 (* 1 = 10083.5 loss)
I0316 07:39:19.016351 29479 solver.cpp:610] Iteration 69360, lr = 6.81619e-09
I0316 07:39:19.016387 29479 solver.cpp:613] Iteration 69360, avg_grad_norm = 536563
I0316 07:40:22.069936 29479 solver.cpp:214] Iteration 69380, loss = 5630.23
I0316 07:40:22.070050 29479 solver.cpp:229]     Train net output #0: loss = 3501.85 (* 1 = 3501.85 loss)
I0316 07:40:22.436328 29479 solver.cpp:610] Iteration 69380, lr = 6.81525e-09
I0316 07:40:22.436342 29479 solver.cpp:613] Iteration 69380, avg_grad_norm = 545129
I0316 07:41:30.546437 29479 solver.cpp:214] Iteration 69400, loss = 5667.29
I0316 07:41:30.546608 29479 solver.cpp:229]     Train net output #0: loss = 5439.71 (* 1 = 5439.71 loss)
I0316 07:41:30.908411 29479 solver.cpp:610] Iteration 69400, lr = 6.81431e-09
I0316 07:41:30.908424 29479 solver.cpp:613] Iteration 69400, avg_grad_norm = 498132
I0316 07:42:39.342222 29479 solver.cpp:214] Iteration 69420, loss = 5488.64
I0316 07:42:39.342336 29479 solver.cpp:229]     Train net output #0: loss = 7967.76 (* 1 = 7967.76 loss)
I0316 07:42:39.704686 29479 solver.cpp:610] Iteration 69420, lr = 6.81337e-09
I0316 07:42:39.704700 29479 solver.cpp:613] Iteration 69420, avg_grad_norm = 493110
I0316 07:43:48.851127 29479 solver.cpp:214] Iteration 69440, loss = 5827.43
I0316 07:43:48.851259 29479 solver.cpp:229]     Train net output #0: loss = 7511.33 (* 1 = 7511.33 loss)
I0316 07:43:49.211138 29479 solver.cpp:610] Iteration 69440, lr = 6.81243e-09
I0316 07:43:49.211153 29479 solver.cpp:613] Iteration 69440, avg_grad_norm = 497982
I0316 07:44:58.612344 29479 solver.cpp:214] Iteration 69460, loss = 5770.76
I0316 07:44:58.612534 29479 solver.cpp:229]     Train net output #0: loss = 3145.02 (* 1 = 3145.02 loss)
I0316 07:44:58.977674 29479 solver.cpp:610] Iteration 69460, lr = 6.81149e-09
I0316 07:44:58.977689 29479 solver.cpp:613] Iteration 69460, avg_grad_norm = 508776
I0316 07:46:24.793771 29479 solver.cpp:214] Iteration 69480, loss = 5901.24
I0316 07:46:24.793965 29479 solver.cpp:229]     Train net output #0: loss = 4602.09 (* 1 = 4602.09 loss)
I0316 07:46:25.162411 29479 solver.cpp:610] Iteration 69480, lr = 6.81055e-09
I0316 07:46:25.162426 29479 solver.cpp:613] Iteration 69480, avg_grad_norm = 505940
I0316 07:47:06.833817 29479 solver.cpp:214] Iteration 69500, loss = 5974.64
I0316 07:47:06.833912 29479 solver.cpp:229]     Train net output #0: loss = 6751.96 (* 1 = 6751.96 loss)
I0316 07:47:07.220814 29479 solver.cpp:610] Iteration 69500, lr = 6.80961e-09
I0316 07:47:07.220829 29479 solver.cpp:613] Iteration 69500, avg_grad_norm = 523197
I0316 07:48:15.761456 29479 solver.cpp:214] Iteration 69520, loss = 5825.22
I0316 07:48:15.761593 29479 solver.cpp:229]     Train net output #0: loss = 8252.26 (* 1 = 8252.26 loss)
I0316 07:48:16.127140 29479 solver.cpp:610] Iteration 69520, lr = 6.80867e-09
I0316 07:48:16.127153 29479 solver.cpp:613] Iteration 69520, avg_grad_norm = 596777
I0316 07:49:24.406332 29479 solver.cpp:214] Iteration 69540, loss = 5906.31
I0316 07:49:24.406456 29479 solver.cpp:229]     Train net output #0: loss = 4168.25 (* 1 = 4168.25 loss)
I0316 07:49:24.766064 29479 solver.cpp:610] Iteration 69540, lr = 6.80773e-09
I0316 07:49:24.766078 29479 solver.cpp:613] Iteration 69540, avg_grad_norm = 496267
I0316 07:50:33.681571 29479 solver.cpp:214] Iteration 69560, loss = 5812.95
I0316 07:50:33.681690 29479 solver.cpp:229]     Train net output #0: loss = 3965.83 (* 1 = 3965.83 loss)
I0316 07:50:34.050900 29479 solver.cpp:610] Iteration 69560, lr = 6.8068e-09
I0316 07:50:34.050915 29479 solver.cpp:613] Iteration 69560, avg_grad_norm = 495466
I0316 07:51:41.900141 29479 solver.cpp:214] Iteration 69580, loss = 5952.86
I0316 07:51:41.900331 29479 solver.cpp:229]     Train net output #0: loss = 6235.72 (* 1 = 6235.72 loss)
I0316 07:51:42.258208 29479 solver.cpp:610] Iteration 69580, lr = 6.80586e-09
I0316 07:51:42.258222 29479 solver.cpp:613] Iteration 69580, avg_grad_norm = 517838
I0316 07:53:04.083849 29479 solver.cpp:214] Iteration 69600, loss = 5705.21
I0316 07:53:04.083967 29479 solver.cpp:229]     Train net output #0: loss = 4057.4 (* 1 = 4057.4 loss)
I0316 07:53:04.453064 29479 solver.cpp:610] Iteration 69600, lr = 6.80492e-09
I0316 07:53:04.453078 29479 solver.cpp:613] Iteration 69600, avg_grad_norm = 502133
I0316 07:54:12.994995 29479 solver.cpp:214] Iteration 69620, loss = 5831.39
I0316 07:54:12.995129 29479 solver.cpp:229]     Train net output #0: loss = 4419.18 (* 1 = 4419.18 loss)
I0316 07:54:13.358083 29479 solver.cpp:610] Iteration 69620, lr = 6.80398e-09
I0316 07:54:13.358098 29479 solver.cpp:613] Iteration 69620, avg_grad_norm = 594402
I0316 07:55:00.217114 29479 solver.cpp:214] Iteration 69640, loss = 5941.36
I0316 07:55:00.217286 29479 solver.cpp:229]     Train net output #0: loss = 12202.3 (* 1 = 12202.3 loss)
I0316 07:55:00.577055 29479 solver.cpp:610] Iteration 69640, lr = 6.80304e-09
I0316 07:55:00.577076 29479 solver.cpp:613] Iteration 69640, avg_grad_norm = 546594
I0316 07:56:08.884310 29479 solver.cpp:214] Iteration 69660, loss = 5927.89
I0316 07:56:08.884433 29479 solver.cpp:229]     Train net output #0: loss = 3161.94 (* 1 = 3161.94 loss)
I0316 07:56:09.252542 29479 solver.cpp:610] Iteration 69660, lr = 6.8021e-09
I0316 07:56:09.252554 29479 solver.cpp:613] Iteration 69660, avg_grad_norm = 572886
I0316 07:57:18.242820 29479 solver.cpp:214] Iteration 69680, loss = 5769.54
I0316 07:57:18.242918 29479 solver.cpp:229]     Train net output #0: loss = 2616.68 (* 1 = 2616.68 loss)
I0316 07:57:18.603281 29479 solver.cpp:610] Iteration 69680, lr = 6.80116e-09
I0316 07:57:18.603294 29479 solver.cpp:613] Iteration 69680, avg_grad_norm = 586547
I0316 07:58:27.490197 29479 solver.cpp:214] Iteration 69700, loss = 5575.55
I0316 07:58:27.490375 29479 solver.cpp:229]     Train net output #0: loss = 5882.78 (* 1 = 5882.78 loss)
I0316 07:58:27.850816 29479 solver.cpp:610] Iteration 69700, lr = 6.80022e-09
I0316 07:58:27.850831 29479 solver.cpp:613] Iteration 69700, avg_grad_norm = 554929
I0316 07:59:54.525251 29479 solver.cpp:214] Iteration 69720, loss = 5534.68
I0316 07:59:54.525357 29479 solver.cpp:229]     Train net output #0: loss = 4404.91 (* 1 = 4404.91 loss)
I0316 07:59:54.883922 29479 solver.cpp:610] Iteration 69720, lr = 6.79928e-09
I0316 07:59:54.883935 29479 solver.cpp:613] Iteration 69720, avg_grad_norm = 514174
I0316 08:01:02.558492 29479 solver.cpp:214] Iteration 69740, loss = 5638.82
I0316 08:01:02.558609 29479 solver.cpp:229]     Train net output #0: loss = 4888.7 (* 1 = 4888.7 loss)
I0316 08:01:02.929723 29479 solver.cpp:610] Iteration 69740, lr = 6.79834e-09
I0316 08:01:02.929736 29479 solver.cpp:613] Iteration 69740, avg_grad_norm = 487104
I0316 08:01:53.062263 29479 solver.cpp:214] Iteration 69760, loss = 5739.9
I0316 08:01:53.062394 29479 solver.cpp:229]     Train net output #0: loss = 7724.92 (* 1 = 7724.92 loss)
I0316 08:01:53.178349 29479 solver.cpp:610] Iteration 69760, lr = 6.7974e-09
I0316 08:01:53.178385 29479 solver.cpp:613] Iteration 69760, avg_grad_norm = 480262
I0316 08:02:53.109946 29479 solver.cpp:214] Iteration 69780, loss = 5700.93
I0316 08:02:53.110072 29479 solver.cpp:229]     Train net output #0: loss = 5993.27 (* 1 = 5993.27 loss)
I0316 08:02:53.470582 29479 solver.cpp:610] Iteration 69780, lr = 6.79646e-09
I0316 08:02:53.470597 29479 solver.cpp:613] Iteration 69780, avg_grad_norm = 500661
I0316 08:04:02.395342 29479 solver.cpp:214] Iteration 69800, loss = 5616.72
I0316 08:04:02.395488 29479 solver.cpp:229]     Train net output #0: loss = 5220.37 (* 1 = 5220.37 loss)
I0316 08:04:02.764266 29479 solver.cpp:610] Iteration 69800, lr = 6.79552e-09
I0316 08:04:02.764279 29479 solver.cpp:613] Iteration 69800, avg_grad_norm = 534882
I0316 08:05:11.831089 29479 solver.cpp:214] Iteration 69820, loss = 5651.12
I0316 08:05:11.831275 29479 solver.cpp:229]     Train net output #0: loss = 5034.94 (* 1 = 5034.94 loss)
I0316 08:05:12.191611 29479 solver.cpp:610] Iteration 69820, lr = 6.79458e-09
I0316 08:05:12.191624 29479 solver.cpp:613] Iteration 69820, avg_grad_norm = 499370
I0316 08:06:21.498751 29479 solver.cpp:214] Iteration 69840, loss = 5585.21
I0316 08:06:21.498894 29479 solver.cpp:229]     Train net output #0: loss = 7449.13 (* 1 = 7449.13 loss)
I0316 08:06:21.857691 29479 solver.cpp:610] Iteration 69840, lr = 6.79364e-09
I0316 08:06:21.857704 29479 solver.cpp:613] Iteration 69840, avg_grad_norm = 481206
I0316 08:07:42.948899 29479 solver.cpp:214] Iteration 69860, loss = 5834.02
I0316 08:07:42.949004 29479 solver.cpp:229]     Train net output #0: loss = 3511.31 (* 1 = 3511.31 loss)
I0316 08:07:43.309079 29479 solver.cpp:610] Iteration 69860, lr = 6.7927e-09
I0316 08:07:43.309093 29479 solver.cpp:613] Iteration 69860, avg_grad_norm = 529004
I0316 08:08:51.302224 29479 solver.cpp:214] Iteration 69880, loss = 5758.71
I0316 08:08:51.302338 29479 solver.cpp:229]     Train net output #0: loss = 4266.91 (* 1 = 4266.91 loss)
I0316 08:08:51.662426 29479 solver.cpp:610] Iteration 69880, lr = 6.79176e-09
I0316 08:08:51.662439 29479 solver.cpp:613] Iteration 69880, avg_grad_norm = 565697
I0316 08:09:38.381862 29479 solver.cpp:214] Iteration 69900, loss = 5683.14
I0316 08:09:38.381963 29479 solver.cpp:229]     Train net output #0: loss = 5524.11 (* 1 = 5524.11 loss)
I0316 08:09:38.719521 29479 solver.cpp:610] Iteration 69900, lr = 6.79083e-09
I0316 08:09:38.719533 29479 solver.cpp:613] Iteration 69900, avg_grad_norm = 555007
I0316 08:10:47.033126 29479 solver.cpp:214] Iteration 69920, loss = 5830.36
I0316 08:10:47.033330 29479 solver.cpp:229]     Train net output #0: loss = 4224.49 (* 1 = 4224.49 loss)
I0316 08:10:47.401499 29479 solver.cpp:610] Iteration 69920, lr = 6.78989e-09
I0316 08:10:47.401535 29479 solver.cpp:613] Iteration 69920, avg_grad_norm = 615584
I0316 08:11:55.912492 29479 solver.cpp:214] Iteration 69940, loss = 5513.45
I0316 08:11:55.912616 29479 solver.cpp:229]     Train net output #0: loss = 4408.47 (* 1 = 4408.47 loss)
I0316 08:11:56.282117 29479 solver.cpp:610] Iteration 69940, lr = 6.78895e-09
I0316 08:11:56.282131 29479 solver.cpp:613] Iteration 69940, avg_grad_norm = 547700
I0316 08:13:05.117102 29479 solver.cpp:214] Iteration 69960, loss = 5672.13
I0316 08:13:05.117223 29479 solver.cpp:229]     Train net output #0: loss = 4713 (* 1 = 4713 loss)
I0316 08:13:05.485971 29479 solver.cpp:610] Iteration 69960, lr = 6.78801e-09
I0316 08:13:05.485985 29479 solver.cpp:613] Iteration 69960, avg_grad_norm = 509068
I0316 08:14:27.079696 29479 solver.cpp:214] Iteration 69980, loss = 5625.33
I0316 08:14:27.079833 29479 solver.cpp:229]     Train net output #0: loss = 4042.06 (* 1 = 4042.06 loss)
I0316 08:14:27.440448 29479 solver.cpp:610] Iteration 69980, lr = 6.78707e-09
I0316 08:14:27.440464 29479 solver.cpp:613] Iteration 69980, avg_grad_norm = 506660
I0316 08:15:33.605855 29479 solver.cpp:458] Snapshotting to models/pnet/VGG_VOC2012ext_iter_70000.caffemodel
I0316 08:15:35.175164 29479 solver.cpp:466] Snapshotting solver state to models/pnet/VGG_VOC2012ext_iter_70000.solverstate
I0316 08:15:39.144819 29479 solver.cpp:214] Iteration 70000, loss = 5722.3
I0316 08:15:39.144886 29479 solver.cpp:229]     Train net output #0: loss = 4898.08 (* 1 = 4898.08 loss)
I0316 08:15:39.505178 29479 solver.cpp:610] Iteration 70000, lr = 6.78613e-09
I0316 08:15:39.505194 29479 solver.cpp:613] Iteration 70000, avg_grad_norm = 577644
I0316 08:16:46.717542 29479 solver.cpp:214] Iteration 70020, loss = 6190.46
I0316 08:16:46.717679 29479 solver.cpp:229]     Train net output #0: loss = 4808.97 (* 1 = 4808.97 loss)
I0316 08:16:46.822842 29479 solver.cpp:610] Iteration 70020, lr = 6.78519e-09
I0316 08:16:46.822860 29479 solver.cpp:613] Iteration 70020, avg_grad_norm = 587165
I0316 08:17:26.117946 29479 solver.cpp:214] Iteration 70040, loss = 5521.76
I0316 08:17:26.118152 29479 solver.cpp:229]     Train net output #0: loss = 3261.17 (* 1 = 3261.17 loss)
I0316 08:17:26.479269 29479 solver.cpp:610] Iteration 70040, lr = 6.78425e-09
I0316 08:17:26.479284 29479 solver.cpp:613] Iteration 70040, avg_grad_norm = 511002
I0316 08:18:34.737498 29479 solver.cpp:214] Iteration 70060, loss = 5680.91
I0316 08:18:34.737664 29479 solver.cpp:229]     Train net output #0: loss = 5641.84 (* 1 = 5641.84 loss)
I0316 08:18:35.103844 29479 solver.cpp:610] Iteration 70060, lr = 6.78331e-09
I0316 08:18:35.103859 29479 solver.cpp:613] Iteration 70060, avg_grad_norm = 500982
I0316 08:19:44.487797 29479 solver.cpp:214] Iteration 70080, loss = 6100.5
I0316 08:19:44.487921 29479 solver.cpp:229]     Train net output #0: loss = 4553.73 (* 1 = 4553.73 loss)
I0316 08:19:44.855453 29479 solver.cpp:610] Iteration 70080, lr = 6.78237e-09
I0316 08:19:44.855468 29479 solver.cpp:613] Iteration 70080, avg_grad_norm = 586734
I0316 08:21:06.881196 29479 solver.cpp:214] Iteration 70100, loss = 5902.51
I0316 08:21:06.881306 29479 solver.cpp:229]     Train net output #0: loss = 11880.1 (* 1 = 11880.1 loss)
I0316 08:21:07.235882 29479 solver.cpp:610] Iteration 70100, lr = 6.78143e-09
I0316 08:21:07.235896 29479 solver.cpp:613] Iteration 70100, avg_grad_norm = 551742
I0316 08:22:15.703979 29479 solver.cpp:214] Iteration 70120, loss = 5800.83
I0316 08:22:15.704113 29479 solver.cpp:229]     Train net output #0: loss = 4861.78 (* 1 = 4861.78 loss)
I0316 08:22:16.069751 29479 solver.cpp:610] Iteration 70120, lr = 6.78049e-09
I0316 08:22:16.069766 29479 solver.cpp:613] Iteration 70120, avg_grad_norm = 581370
I0316 08:23:25.167011 29479 solver.cpp:214] Iteration 70140, loss = 5665.69
I0316 08:23:25.167138 29479 solver.cpp:229]     Train net output #0: loss = 9265.61 (* 1 = 9265.61 loss)
I0316 08:23:25.541095 29479 solver.cpp:610] Iteration 70140, lr = 6.77955e-09
I0316 08:23:25.541108 29479 solver.cpp:613] Iteration 70140, avg_grad_norm = 521122
I0316 08:24:26.825508 29479 solver.cpp:214] Iteration 70160, loss = 5757.43
I0316 08:24:26.825711 29479 solver.cpp:229]     Train net output #0: loss = 11123.7 (* 1 = 11123.7 loss)
I0316 08:24:26.930794 29479 solver.cpp:610] Iteration 70160, lr = 6.77861e-09
I0316 08:24:26.930807 29479 solver.cpp:613] Iteration 70160, avg_grad_norm = 523538
I0316 08:25:05.286140 29479 solver.cpp:214] Iteration 70180, loss = 5911.12
I0316 08:25:05.286269 29479 solver.cpp:229]     Train net output #0: loss = 8914.92 (* 1 = 8914.92 loss)
I0316 08:25:05.645869 29479 solver.cpp:610] Iteration 70180, lr = 6.77767e-09
I0316 08:25:05.645908 29479 solver.cpp:613] Iteration 70180, avg_grad_norm = 487144
I0316 08:26:10.486055 29479 solver.cpp:214] Iteration 70200, loss = 5610.87
I0316 08:26:10.486268 29479 solver.cpp:229]     Train net output #0: loss = 4524.56 (* 1 = 4524.56 loss)
I0316 08:26:10.855056 29479 solver.cpp:610] Iteration 70200, lr = 6.77673e-09
I0316 08:26:10.855069 29479 solver.cpp:613] Iteration 70200, avg_grad_norm = 490632
I0316 08:27:18.747133 29479 solver.cpp:214] Iteration 70220, loss = 5865.3
I0316 08:27:18.747354 29479 solver.cpp:229]     Train net output #0: loss = 8804.28 (* 1 = 8804.28 loss)
I0316 08:27:19.111160 29479 solver.cpp:610] Iteration 70220, lr = 6.77579e-09
I0316 08:27:19.111172 29479 solver.cpp:613] Iteration 70220, avg_grad_norm = 527781
I0316 08:28:40.311955 29479 solver.cpp:214] Iteration 70240, loss = 5875.6
I0316 08:28:40.312089 29479 solver.cpp:229]     Train net output #0: loss = 8013.59 (* 1 = 8013.59 loss)
I0316 08:28:40.671622 29479 solver.cpp:610] Iteration 70240, lr = 6.77485e-09
I0316 08:28:40.671634 29479 solver.cpp:613] Iteration 70240, avg_grad_norm = 502771
I0316 08:29:48.288166 29479 solver.cpp:214] Iteration 70260, loss = 5805.79
I0316 08:29:48.288357 29479 solver.cpp:229]     Train net output #0: loss = 12881.2 (* 1 = 12881.2 loss)
I0316 08:29:48.648046 29479 solver.cpp:610] Iteration 70260, lr = 6.77391e-09
I0316 08:29:48.648059 29479 solver.cpp:613] Iteration 70260, avg_grad_norm = 537236
I0316 08:30:55.987267 29479 solver.cpp:214] Iteration 70280, loss = 5847.59
I0316 08:30:55.987468 29479 solver.cpp:229]     Train net output #0: loss = 3472.61 (* 1 = 3472.61 loss)
I0316 08:30:56.330565 29479 solver.cpp:610] Iteration 70280, lr = 6.77297e-09
I0316 08:30:56.330579 29479 solver.cpp:613] Iteration 70280, avg_grad_norm = 521052
I0316 08:32:04.122921 29479 solver.cpp:214] Iteration 70300, loss = 6149.29
I0316 08:32:04.123061 29479 solver.cpp:229]     Train net output #0: loss = 4358.39 (* 1 = 4358.39 loss)
I0316 08:32:04.451474 29479 solver.cpp:610] Iteration 70300, lr = 6.77203e-09
I0316 08:32:04.451488 29479 solver.cpp:613] Iteration 70300, avg_grad_norm = 499142
I0316 08:32:43.818529 29479 solver.cpp:214] Iteration 70320, loss = 5789.28
I0316 08:32:43.818680 29479 solver.cpp:229]     Train net output #0: loss = 9958.47 (* 1 = 9958.47 loss)
I0316 08:32:44.197547 29479 solver.cpp:610] Iteration 70320, lr = 6.77109e-09
I0316 08:32:44.197562 29479 solver.cpp:613] Iteration 70320, avg_grad_norm = 587278
I0316 08:33:51.977108 29479 solver.cpp:214] Iteration 70340, loss = 5803.03
I0316 08:33:51.977327 29479 solver.cpp:229]     Train net output #0: loss = 3421.13 (* 1 = 3421.13 loss)
I0316 08:33:52.346140 29479 solver.cpp:610] Iteration 70340, lr = 6.77015e-09
I0316 08:33:52.346154 29479 solver.cpp:613] Iteration 70340, avg_grad_norm = 554567
I0316 08:35:13.472890 29479 solver.cpp:214] Iteration 70360, loss = 6159.62
I0316 08:35:13.473012 29479 solver.cpp:229]     Train net output #0: loss = 9071.45 (* 1 = 9071.45 loss)
I0316 08:35:13.817085 29479 solver.cpp:610] Iteration 70360, lr = 6.76921e-09
I0316 08:35:13.817098 29479 solver.cpp:613] Iteration 70360, avg_grad_norm = 609772
I0316 08:36:20.550097 29479 solver.cpp:214] Iteration 70380, loss = 5484.76
I0316 08:36:20.550320 29479 solver.cpp:229]     Train net output #0: loss = 4565.65 (* 1 = 4565.65 loss)
I0316 08:36:20.890792 29479 solver.cpp:610] Iteration 70380, lr = 6.76827e-09
I0316 08:36:20.890807 29479 solver.cpp:613] Iteration 70380, avg_grad_norm = 529170
I0316 08:37:28.831338 29479 solver.cpp:214] Iteration 70400, loss = 5608.85
I0316 08:37:28.831473 29479 solver.cpp:229]     Train net output #0: loss = 5883.71 (* 1 = 5883.71 loss)
I0316 08:37:29.177242 29479 solver.cpp:610] Iteration 70400, lr = 6.76733e-09
I0316 08:37:29.177258 29479 solver.cpp:613] Iteration 70400, avg_grad_norm = 540698
I0316 08:38:35.806602 29479 solver.cpp:214] Iteration 70420, loss = 5942.27
I0316 08:38:35.806802 29479 solver.cpp:229]     Train net output #0: loss = 5070.51 (* 1 = 5070.51 loss)
I0316 08:38:36.167381 29479 solver.cpp:610] Iteration 70420, lr = 6.76639e-09
I0316 08:38:36.167394 29479 solver.cpp:613] Iteration 70420, avg_grad_norm = 594588
I0316 08:39:44.359669 29479 solver.cpp:214] Iteration 70440, loss = 6133.6
I0316 08:39:44.359798 29479 solver.cpp:229]     Train net output #0: loss = 10496.8 (* 1 = 10496.8 loss)
I0316 08:39:44.749418 29479 solver.cpp:610] Iteration 70440, lr = 6.76545e-09
I0316 08:39:44.749433 29479 solver.cpp:613] Iteration 70440, avg_grad_norm = 507575
I0316 08:40:30.940927 29479 solver.cpp:214] Iteration 70460, loss = 5911.39
I0316 08:40:30.941125 29479 solver.cpp:229]     Train net output #0: loss = 3612.26 (* 1 = 3612.26 loss)
I0316 08:40:31.309772 29479 solver.cpp:610] Iteration 70460, lr = 6.76451e-09
I0316 08:40:31.309787 29479 solver.cpp:613] Iteration 70460, avg_grad_norm = 510419
I0316 08:41:40.134300 29479 solver.cpp:214] Iteration 70480, loss = 5591.66
I0316 08:41:40.134441 29479 solver.cpp:229]     Train net output #0: loss = 10093.8 (* 1 = 10093.8 loss)
I0316 08:41:40.494128 29479 solver.cpp:610] Iteration 70480, lr = 6.76357e-09
I0316 08:41:40.494141 29479 solver.cpp:613] Iteration 70480, avg_grad_norm = 492190
I0316 08:43:01.256100 29479 solver.cpp:214] Iteration 70500, loss = 5630
I0316 08:43:01.256253 29479 solver.cpp:229]     Train net output #0: loss = 6882.16 (* 1 = 6882.16 loss)
I0316 08:43:01.621532 29479 solver.cpp:610] Iteration 70500, lr = 6.76263e-09
I0316 08:43:01.621546 29479 solver.cpp:613] Iteration 70500, avg_grad_norm = 480259
I0316 08:44:09.422000 29479 solver.cpp:214] Iteration 70520, loss = 5733.93
I0316 08:44:09.422189 29479 solver.cpp:229]     Train net output #0: loss = 8235.89 (* 1 = 8235.89 loss)
I0316 08:44:09.782964 29479 solver.cpp:610] Iteration 70520, lr = 6.76169e-09
I0316 08:44:09.782979 29479 solver.cpp:613] Iteration 70520, avg_grad_norm = 505799
I0316 08:45:19.167960 29479 solver.cpp:214] Iteration 70540, loss = 5545.83
I0316 08:45:19.168108 29479 solver.cpp:229]     Train net output #0: loss = 2573.01 (* 1 = 2573.01 loss)
I0316 08:45:19.528870 29479 solver.cpp:610] Iteration 70540, lr = 6.76075e-09
I0316 08:45:19.528884 29479 solver.cpp:613] Iteration 70540, avg_grad_norm = 514541
I0316 08:46:27.895118 29479 solver.cpp:214] Iteration 70560, loss = 6066.12
I0316 08:46:27.895259 29479 solver.cpp:229]     Train net output #0: loss = 6030.92 (* 1 = 6030.92 loss)
I0316 08:46:28.230768 29479 solver.cpp:610] Iteration 70560, lr = 6.75981e-09
I0316 08:46:28.230782 29479 solver.cpp:613] Iteration 70560, avg_grad_norm = 577297
I0316 08:47:24.722744 29479 solver.cpp:214] Iteration 70580, loss = 5794.13
I0316 08:47:24.722884 29479 solver.cpp:229]     Train net output #0: loss = 9818.84 (* 1 = 9818.84 loss)
I0316 08:47:24.839076 29479 solver.cpp:610] Iteration 70580, lr = 6.75887e-09
I0316 08:47:24.839112 29479 solver.cpp:613] Iteration 70580, avg_grad_norm = 571254
I0316 08:48:21.281688 29479 solver.cpp:214] Iteration 70600, loss = 5818.95
I0316 08:48:21.281824 29479 solver.cpp:229]     Train net output #0: loss = 5747.27 (* 1 = 5747.27 loss)
I0316 08:48:21.641791 29479 solver.cpp:610] Iteration 70600, lr = 6.75793e-09
I0316 08:48:21.641808 29479 solver.cpp:613] Iteration 70600, avg_grad_norm = 524287
I0316 08:49:43.517679 29479 solver.cpp:214] Iteration 70620, loss = 5899.54
I0316 08:49:43.517817 29479 solver.cpp:229]     Train net output #0: loss = 3470.55 (* 1 = 3470.55 loss)
I0316 08:49:43.881321 29479 solver.cpp:610] Iteration 70620, lr = 6.75699e-09
I0316 08:49:43.881335 29479 solver.cpp:613] Iteration 70620, avg_grad_norm = 570229
I0316 08:50:51.706990 29479 solver.cpp:214] Iteration 70640, loss = 5619.84
I0316 08:50:51.707115 29479 solver.cpp:229]     Train net output #0: loss = 4894.13 (* 1 = 4894.13 loss)
I0316 08:50:52.066886 29479 solver.cpp:610] Iteration 70640, lr = 6.75605e-09
I0316 08:50:52.066900 29479 solver.cpp:613] Iteration 70640, avg_grad_norm = 624269
I0316 08:52:00.923251 29479 solver.cpp:214] Iteration 70660, loss = 5787.92
I0316 08:52:00.923444 29479 solver.cpp:229]     Train net output #0: loss = 3131.39 (* 1 = 3131.39 loss)
I0316 08:52:01.292513 29479 solver.cpp:610] Iteration 70660, lr = 6.75511e-09
I0316 08:52:01.292527 29479 solver.cpp:613] Iteration 70660, avg_grad_norm = 520722
I0316 08:53:10.132681 29479 solver.cpp:214] Iteration 70680, loss = 5948.7
I0316 08:53:10.132876 29479 solver.cpp:229]     Train net output #0: loss = 10295.8 (* 1 = 10295.8 loss)
I0316 08:53:10.499029 29479 solver.cpp:610] Iteration 70680, lr = 6.75417e-09
I0316 08:53:10.499044 29479 solver.cpp:613] Iteration 70680, avg_grad_norm = 581306
I0316 08:54:19.073256 29479 solver.cpp:214] Iteration 70700, loss = 5917.39
I0316 08:54:19.073456 29479 solver.cpp:229]     Train net output #0: loss = 8041.75 (* 1 = 8041.75 loss)
I0316 08:54:19.439491 29479 solver.cpp:610] Iteration 70700, lr = 6.75323e-09
I0316 08:54:19.439507 29479 solver.cpp:613] Iteration 70700, avg_grad_norm = 536805
I0316 08:55:04.602588 29479 solver.cpp:214] Iteration 70720, loss = 5668.88
I0316 08:55:04.602737 29479 solver.cpp:229]     Train net output #0: loss = 9418.95 (* 1 = 9418.95 loss)
I0316 08:55:04.720360 29479 solver.cpp:610] Iteration 70720, lr = 6.75229e-09
I0316 08:55:04.720409 29479 solver.cpp:613] Iteration 70720, avg_grad_norm = 548301
I0316 08:56:15.055685 29479 solver.cpp:214] Iteration 70740, loss = 5659.71
I0316 08:56:15.055817 29479 solver.cpp:229]     Train net output #0: loss = 4874.16 (* 1 = 4874.16 loss)
I0316 08:56:15.418815 29479 solver.cpp:610] Iteration 70740, lr = 6.75135e-09
I0316 08:56:15.418830 29479 solver.cpp:613] Iteration 70740, avg_grad_norm = 560159
I0316 08:57:23.811211 29479 solver.cpp:214] Iteration 70760, loss = 5821.9
I0316 08:57:23.811398 29479 solver.cpp:229]     Train net output #0: loss = 4047.2 (* 1 = 4047.2 loss)
I0316 08:57:24.176692 29479 solver.cpp:610] Iteration 70760, lr = 6.75041e-09
I0316 08:57:24.176705 29479 solver.cpp:613] Iteration 70760, avg_grad_norm = 509754
I0316 08:58:32.399497 29479 solver.cpp:214] Iteration 70780, loss = 5599.44
I0316 08:58:32.399646 29479 solver.cpp:229]     Train net output #0: loss = 10659.8 (* 1 = 10659.8 loss)
I0316 08:58:32.759564 29479 solver.cpp:610] Iteration 70780, lr = 6.74947e-09
I0316 08:58:32.759577 29479 solver.cpp:613] Iteration 70780, avg_grad_norm = 560137
I0316 08:59:41.358330 29479 solver.cpp:214] Iteration 70800, loss = 5800.29
I0316 08:59:41.358474 29479 solver.cpp:229]     Train net output #0: loss = 3247 (* 1 = 3247 loss)
I0316 08:59:41.718310 29479 solver.cpp:610] Iteration 70800, lr = 6.74853e-09
I0316 08:59:41.718324 29479 solver.cpp:613] Iteration 70800, avg_grad_norm = 515901
I0316 09:00:49.828933 29479 solver.cpp:214] Iteration 70820, loss = 5899.02
I0316 09:00:49.829088 29479 solver.cpp:229]     Train net output #0: loss = 3858.01 (* 1 = 3858.01 loss)
I0316 09:00:50.172431 29479 solver.cpp:610] Iteration 70820, lr = 6.74759e-09
I0316 09:00:50.172456 29479 solver.cpp:613] Iteration 70820, avg_grad_norm = 477365
I0316 09:01:58.535660 29479 solver.cpp:214] Iteration 70840, loss = 5612.67
I0316 09:01:58.535876 29479 solver.cpp:229]     Train net output #0: loss = 5689.55 (* 1 = 5689.55 loss)
I0316 09:01:58.898780 29479 solver.cpp:610] Iteration 70840, lr = 6.74665e-09
I0316 09:01:58.898795 29479 solver.cpp:613] Iteration 70840, avg_grad_norm = 517633
I0316 09:02:44.817994 29479 solver.cpp:214] Iteration 70860, loss = 5891.92
I0316 09:02:44.818148 29479 solver.cpp:229]     Train net output #0: loss = 3459.82 (* 1 = 3459.82 loss)
I0316 09:02:44.935958 29479 solver.cpp:610] Iteration 70860, lr = 6.74571e-09
I0316 09:02:44.935972 29479 solver.cpp:613] Iteration 70860, avg_grad_norm = 513201
I0316 09:04:05.455693 29479 solver.cpp:214] Iteration 70880, loss = 6132.4
I0316 09:04:05.455852 29479 solver.cpp:229]     Train net output #0: loss = 4638.65 (* 1 = 4638.65 loss)
I0316 09:04:05.817893 29479 solver.cpp:610] Iteration 70880, lr = 6.74477e-09
I0316 09:04:05.817908 29479 solver.cpp:613] Iteration 70880, avg_grad_norm = 534087
I0316 09:05:12.700126 29479 solver.cpp:214] Iteration 70900, loss = 5831.34
I0316 09:05:12.700248 29479 solver.cpp:229]     Train net output #0: loss = 7950.82 (* 1 = 7950.82 loss)
I0316 09:05:12.909636 29479 solver.cpp:610] Iteration 70900, lr = 6.74383e-09
I0316 09:05:12.909651 29479 solver.cpp:613] Iteration 70900, avg_grad_norm = 512433
I0316 09:06:20.643721 29479 solver.cpp:214] Iteration 70920, loss = 5995.32
I0316 09:06:20.643867 29479 solver.cpp:229]     Train net output #0: loss = 3623.24 (* 1 = 3623.24 loss)
I0316 09:06:20.987854 29479 solver.cpp:610] Iteration 70920, lr = 6.74289e-09
I0316 09:06:20.987867 29479 solver.cpp:613] Iteration 70920, avg_grad_norm = 521426
I0316 09:07:27.951939 29479 solver.cpp:214] Iteration 70940, loss = 6024.46
I0316 09:07:27.952054 29479 solver.cpp:229]     Train net output #0: loss = 9635.38 (* 1 = 9635.38 loss)
I0316 09:07:28.294968 29479 solver.cpp:610] Iteration 70940, lr = 6.74195e-09
I0316 09:07:28.294982 29479 solver.cpp:613] Iteration 70940, avg_grad_norm = 497198
I0316 09:08:36.034363 29479 solver.cpp:214] Iteration 70960, loss = 5500.7
I0316 09:08:36.034512 29479 solver.cpp:229]     Train net output #0: loss = 6820.62 (* 1 = 6820.62 loss)
I0316 09:08:36.397819 29479 solver.cpp:610] Iteration 70960, lr = 6.74101e-09
I0316 09:08:36.397832 29479 solver.cpp:613] Iteration 70960, avg_grad_norm = 478158
I0316 09:09:45.431298 29479 solver.cpp:214] Iteration 70980, loss = 6005.17
I0316 09:09:45.431428 29479 solver.cpp:229]     Train net output #0: loss = 7312.04 (* 1 = 7312.04 loss)
I0316 09:09:45.774865 29479 solver.cpp:610] Iteration 70980, lr = 6.74007e-09
I0316 09:09:45.774879 29479 solver.cpp:613] Iteration 70980, avg_grad_norm = 502214
I0316 09:11:10.559351 29479 solver.cpp:214] Iteration 71000, loss = 5770.63
I0316 09:11:10.559551 29479 solver.cpp:229]     Train net output #0: loss = 8656.92 (* 1 = 8656.92 loss)
I0316 09:11:10.915261 29479 solver.cpp:610] Iteration 71000, lr = 6.73913e-09
I0316 09:11:10.915274 29479 solver.cpp:613] Iteration 71000, avg_grad_norm = 521026
I0316 09:12:18.418110 29479 solver.cpp:214] Iteration 71020, loss = 5720.26
I0316 09:12:18.418328 29479 solver.cpp:229]     Train net output #0: loss = 9930.03 (* 1 = 9930.03 loss)
I0316 09:12:18.777777 29479 solver.cpp:610] Iteration 71020, lr = 6.73819e-09
I0316 09:12:18.777792 29479 solver.cpp:613] Iteration 71020, avg_grad_norm = 515351
I0316 09:13:26.172397 29479 solver.cpp:214] Iteration 71040, loss = 6026.3
I0316 09:13:26.172523 29479 solver.cpp:229]     Train net output #0: loss = 4691.17 (* 1 = 4691.17 loss)
I0316 09:13:26.529180 29479 solver.cpp:610] Iteration 71040, lr = 6.73725e-09
I0316 09:13:26.529193 29479 solver.cpp:613] Iteration 71040, avg_grad_norm = 521984
I0316 09:14:34.316231 29479 solver.cpp:214] Iteration 71060, loss = 5753.48
I0316 09:14:34.316427 29479 solver.cpp:229]     Train net output #0: loss = 5423.06 (* 1 = 5423.06 loss)
I0316 09:14:34.676713 29479 solver.cpp:610] Iteration 71060, lr = 6.73631e-09
I0316 09:14:34.676743 29479 solver.cpp:613] Iteration 71060, avg_grad_norm = 516539
I0316 09:15:42.454423 29479 solver.cpp:214] Iteration 71080, loss = 5699.15
I0316 09:15:42.454607 29479 solver.cpp:229]     Train net output #0: loss = 3824.43 (* 1 = 3824.43 loss)
I0316 09:15:42.814482 29479 solver.cpp:610] Iteration 71080, lr = 6.73537e-09
I0316 09:15:42.814496 29479 solver.cpp:613] Iteration 71080, avg_grad_norm = 504947
I0316 09:16:50.069661 29479 solver.cpp:214] Iteration 71100, loss = 5647.42
I0316 09:16:50.069849 29479 solver.cpp:229]     Train net output #0: loss = 5616.84 (* 1 = 5616.84 loss)
I0316 09:16:50.267340 29479 solver.cpp:610] Iteration 71100, lr = 6.73443e-09
I0316 09:16:50.267354 29479 solver.cpp:613] Iteration 71100, avg_grad_norm = 549060
I0316 09:18:27.292794 29479 solver.cpp:214] Iteration 71120, loss = 5650.69
I0316 09:18:27.292969 29479 solver.cpp:229]     Train net output #0: loss = 11641.8 (* 1 = 11641.8 loss)
I0316 09:18:27.398289 29479 solver.cpp:610] Iteration 71120, lr = 6.73349e-09
I0316 09:18:27.398330 29479 solver.cpp:613] Iteration 71120, avg_grad_norm = 513739
I0316 09:19:33.802439 29479 solver.cpp:214] Iteration 71140, loss = 5571.17
I0316 09:19:33.802585 29479 solver.cpp:229]     Train net output #0: loss = 3685.05 (* 1 = 3685.05 loss)
I0316 09:19:34.154007 29479 solver.cpp:610] Iteration 71140, lr = 6.73255e-09
I0316 09:19:34.154021 29479 solver.cpp:613] Iteration 71140, avg_grad_norm = 519527
I0316 09:20:41.304620 29479 solver.cpp:214] Iteration 71160, loss = 5701.31
I0316 09:20:41.304811 29479 solver.cpp:229]     Train net output #0: loss = 2975.63 (* 1 = 2975.63 loss)
I0316 09:20:41.667114 29479 solver.cpp:610] Iteration 71160, lr = 6.73161e-09
I0316 09:20:41.667129 29479 solver.cpp:613] Iteration 71160, avg_grad_norm = 538536
I0316 09:21:49.299662 29479 solver.cpp:214] Iteration 71180, loss = 5691.44
I0316 09:21:49.299788 29479 solver.cpp:229]     Train net output #0: loss = 3242.96 (* 1 = 3242.96 loss)
I0316 09:21:49.662269 29479 solver.cpp:610] Iteration 71180, lr = 6.73066e-09
I0316 09:21:49.662282 29479 solver.cpp:613] Iteration 71180, avg_grad_norm = 504501
I0316 09:22:57.083030 29479 solver.cpp:214] Iteration 71200, loss = 5696.61
I0316 09:22:57.083165 29479 solver.cpp:229]     Train net output #0: loss = 5085.51 (* 1 = 5085.51 loss)
I0316 09:22:57.462678 29479 solver.cpp:610] Iteration 71200, lr = 6.72972e-09
I0316 09:22:57.462692 29479 solver.cpp:613] Iteration 71200, avg_grad_norm = 537510
I0316 09:24:05.177965 29479 solver.cpp:214] Iteration 71220, loss = 5582.09
I0316 09:24:05.178112 29479 solver.cpp:229]     Train net output #0: loss = 3607.12 (* 1 = 3607.12 loss)
I0316 09:24:05.537745 29479 solver.cpp:610] Iteration 71220, lr = 6.72878e-09
I0316 09:24:05.537760 29479 solver.cpp:613] Iteration 71220, avg_grad_norm = 529901
I0316 09:25:13.027940 29479 solver.cpp:214] Iteration 71240, loss = 5694.76
I0316 09:25:13.028118 29479 solver.cpp:229]     Train net output #0: loss = 6178.68 (* 1 = 6178.68 loss)
I0316 09:25:13.388311 29479 solver.cpp:610] Iteration 71240, lr = 6.72784e-09
I0316 09:25:13.388324 29479 solver.cpp:613] Iteration 71240, avg_grad_norm = 506831
I0316 09:26:10.773989 29479 solver.cpp:214] Iteration 71260, loss = 5628.43
I0316 09:26:10.774140 29479 solver.cpp:229]     Train net output #0: loss = 2589.88 (* 1 = 2589.88 loss)
I0316 09:26:11.128396 29479 solver.cpp:610] Iteration 71260, lr = 6.7269e-09
I0316 09:26:11.128410 29479 solver.cpp:613] Iteration 71260, avg_grad_norm = 469157
I0316 09:27:19.509428 29479 solver.cpp:214] Iteration 71280, loss = 5732.6
I0316 09:27:19.509548 29479 solver.cpp:229]     Train net output #0: loss = 8980.54 (* 1 = 8980.54 loss)
I0316 09:27:19.869637 29479 solver.cpp:610] Iteration 71280, lr = 6.72596e-09
I0316 09:27:19.869653 29479 solver.cpp:613] Iteration 71280, avg_grad_norm = 515914
I0316 09:28:28.528264 29479 solver.cpp:214] Iteration 71300, loss = 5551.29
I0316 09:28:28.528364 29479 solver.cpp:229]     Train net output #0: loss = 3634.43 (* 1 = 3634.43 loss)
I0316 09:28:28.888936 29479 solver.cpp:610] Iteration 71300, lr = 6.72502e-09
I0316 09:28:28.888950 29479 solver.cpp:613] Iteration 71300, avg_grad_norm = 547128
I0316 09:29:37.267472 29479 solver.cpp:214] Iteration 71320, loss = 5711.85
I0316 09:29:37.267604 29479 solver.cpp:229]     Train net output #0: loss = 11395.3 (* 1 = 11395.3 loss)
I0316 09:29:37.629619 29479 solver.cpp:610] Iteration 71320, lr = 6.72408e-09
I0316 09:29:37.629655 29479 solver.cpp:613] Iteration 71320, avg_grad_norm = 531794
I0316 09:30:44.337787 29479 solver.cpp:214] Iteration 71340, loss = 5869.31
I0316 09:30:44.337982 29479 solver.cpp:229]     Train net output #0: loss = 7002.19 (* 1 = 7002.19 loss)
I0316 09:30:44.698530 29479 solver.cpp:610] Iteration 71340, lr = 6.72314e-09
I0316 09:30:44.698544 29479 solver.cpp:613] Iteration 71340, avg_grad_norm = 568248
I0316 09:31:52.357887 29479 solver.cpp:214] Iteration 71360, loss = 5935.16
I0316 09:31:52.358032 29479 solver.cpp:229]     Train net output #0: loss = 4115.16 (* 1 = 4115.16 loss)
I0316 09:31:52.726902 29479 solver.cpp:610] Iteration 71360, lr = 6.7222e-09
I0316 09:31:52.726914 29479 solver.cpp:613] Iteration 71360, avg_grad_norm = 519398
I0316 09:33:18.722868 29479 solver.cpp:214] Iteration 71380, loss = 5731.09
I0316 09:33:18.723009 29479 solver.cpp:229]     Train net output #0: loss = 3499.48 (* 1 = 3499.48 loss)
I0316 09:33:18.837646 29479 solver.cpp:610] Iteration 71380, lr = 6.72126e-09
I0316 09:33:18.837659 29479 solver.cpp:613] Iteration 71380, avg_grad_norm = 490080
I0316 09:33:44.971369 29479 solver.cpp:214] Iteration 71400, loss = 5465.54
I0316 09:33:44.971421 29479 solver.cpp:229]     Train net output #0: loss = 6218.25 (* 1 = 6218.25 loss)
I0316 09:33:45.089206 29479 solver.cpp:610] Iteration 71400, lr = 6.72032e-09
I0316 09:33:45.089221 29479 solver.cpp:613] Iteration 71400, avg_grad_norm = 552732
I0316 09:34:37.744957 29479 solver.cpp:214] Iteration 71420, loss = 6273.2
I0316 09:34:37.745072 29479 solver.cpp:229]     Train net output #0: loss = 8646.96 (* 1 = 8646.96 loss)
I0316 09:34:38.074357 29479 solver.cpp:610] Iteration 71420, lr = 6.71938e-09
I0316 09:34:38.074369 29479 solver.cpp:613] Iteration 71420, avg_grad_norm = 551128
I0316 09:35:45.454412 29479 solver.cpp:214] Iteration 71440, loss = 5863.64
I0316 09:35:45.454556 29479 solver.cpp:229]     Train net output #0: loss = 4615.25 (* 1 = 4615.25 loss)
I0316 09:35:45.815035 29479 solver.cpp:610] Iteration 71440, lr = 6.71844e-09
I0316 09:35:45.815049 29479 solver.cpp:613] Iteration 71440, avg_grad_norm = 479797
I0316 09:36:53.573740 29479 solver.cpp:214] Iteration 71460, loss = 5462.98
I0316 09:36:53.573866 29479 solver.cpp:229]     Train net output #0: loss = 6842.52 (* 1 = 6842.52 loss)
I0316 09:36:53.940075 29479 solver.cpp:610] Iteration 71460, lr = 6.7175e-09
I0316 09:36:53.940089 29479 solver.cpp:613] Iteration 71460, avg_grad_norm = 478716
I0316 09:38:02.110829 29479 solver.cpp:214] Iteration 71480, loss = 5853.42
I0316 09:38:02.111024 29479 solver.cpp:229]     Train net output #0: loss = 3164.88 (* 1 = 3164.88 loss)
I0316 09:38:02.471552 29479 solver.cpp:610] Iteration 71480, lr = 6.71656e-09
I0316 09:38:02.471566 29479 solver.cpp:613] Iteration 71480, avg_grad_norm = 526159
I0316 09:39:30.420745 29479 solver.cpp:214] Iteration 71500, loss = 5508.09
I0316 09:39:30.420840 29479 solver.cpp:229]     Train net output #0: loss = 3887.05 (* 1 = 3887.05 loss)
I0316 09:39:30.783803 29479 solver.cpp:610] Iteration 71500, lr = 6.71562e-09
I0316 09:39:30.783818 29479 solver.cpp:613] Iteration 71500, avg_grad_norm = 522168
I0316 09:40:34.713796 29479 solver.cpp:214] Iteration 71520, loss = 5983.07
I0316 09:40:34.713994 29479 solver.cpp:229]     Train net output #0: loss = 4864.31 (* 1 = 4864.31 loss)
I0316 09:40:35.047740 29479 solver.cpp:610] Iteration 71520, lr = 6.71468e-09
I0316 09:40:35.047755 29479 solver.cpp:613] Iteration 71520, avg_grad_norm = 502593
I0316 09:41:24.753000 29479 solver.cpp:214] Iteration 71540, loss = 5607.97
I0316 09:41:24.753165 29479 solver.cpp:229]     Train net output #0: loss = 9968.77 (* 1 = 9968.77 loss)
I0316 09:41:24.870976 29479 solver.cpp:610] Iteration 71540, lr = 6.71373e-09
I0316 09:41:24.870991 29479 solver.cpp:613] Iteration 71540, avg_grad_norm = 474864
I0316 09:42:29.325945 29479 solver.cpp:214] Iteration 71560, loss = 5517.17
I0316 09:42:29.326136 29479 solver.cpp:229]     Train net output #0: loss = 3679.33 (* 1 = 3679.33 loss)
I0316 09:42:29.688742 29479 solver.cpp:610] Iteration 71560, lr = 6.71279e-09
I0316 09:42:29.688755 29479 solver.cpp:613] Iteration 71560, avg_grad_norm = 506905
I0316 09:43:36.746470 29479 solver.cpp:214] Iteration 71580, loss = 5536.49
I0316 09:43:36.746675 29479 solver.cpp:229]     Train net output #0: loss = 4726.54 (* 1 = 4726.54 loss)
I0316 09:43:37.071704 29479 solver.cpp:610] Iteration 71580, lr = 6.71185e-09
I0316 09:43:37.071718 29479 solver.cpp:613] Iteration 71580, avg_grad_norm = 500255
I0316 09:44:44.708683 29479 solver.cpp:214] Iteration 71600, loss = 5709.25
I0316 09:44:44.708847 29479 solver.cpp:229]     Train net output #0: loss = 9744.16 (* 1 = 9744.16 loss)
I0316 09:44:45.078368 29479 solver.cpp:610] Iteration 71600, lr = 6.71091e-09
I0316 09:44:45.078382 29479 solver.cpp:613] Iteration 71600, avg_grad_norm = 508523
I0316 09:45:52.762069 29479 solver.cpp:214] Iteration 71620, loss = 5546.87
I0316 09:45:52.762255 29479 solver.cpp:229]     Train net output #0: loss = 9271.81 (* 1 = 9271.81 loss)
I0316 09:45:53.127883 29479 solver.cpp:610] Iteration 71620, lr = 6.70997e-09
I0316 09:45:53.127897 29479 solver.cpp:613] Iteration 71620, avg_grad_norm = 509191
I0316 09:47:18.167500 29479 solver.cpp:214] Iteration 71640, loss = 5776.06
I0316 09:47:18.167655 29479 solver.cpp:229]     Train net output #0: loss = 10574.8 (* 1 = 10574.8 loss)
I0316 09:47:18.537183 29479 solver.cpp:610] Iteration 71640, lr = 6.70903e-09
I0316 09:47:18.537196 29479 solver.cpp:613] Iteration 71640, avg_grad_norm = 477181
I0316 09:48:26.075876 29479 solver.cpp:214] Iteration 71660, loss = 5599.6
I0316 09:48:26.076081 29479 solver.cpp:229]     Train net output #0: loss = 2916.96 (* 1 = 2916.96 loss)
I0316 09:48:26.435626 29479 solver.cpp:610] Iteration 71660, lr = 6.70809e-09
I0316 09:48:26.435650 29479 solver.cpp:613] Iteration 71660, avg_grad_norm = 525482
I0316 09:49:12.337663 29479 solver.cpp:214] Iteration 71680, loss = 5657.03
I0316 09:49:12.337869 29479 solver.cpp:229]     Train net output #0: loss = 6462.27 (* 1 = 6462.27 loss)
I0316 09:49:12.540544 29479 solver.cpp:610] Iteration 71680, lr = 6.70715e-09
I0316 09:49:12.540575 29479 solver.cpp:613] Iteration 71680, avg_grad_norm = 539389
I0316 09:50:21.056120 29479 solver.cpp:214] Iteration 71700, loss = 5837.96
I0316 09:50:21.056329 29479 solver.cpp:229]     Train net output #0: loss = 4237.68 (* 1 = 4237.68 loss)
I0316 09:50:21.418994 29479 solver.cpp:610] Iteration 71700, lr = 6.70621e-09
I0316 09:50:21.419008 29479 solver.cpp:613] Iteration 71700, avg_grad_norm = 560503
I0316 09:51:29.225738 29479 solver.cpp:214] Iteration 71720, loss = 5741.91
I0316 09:51:29.226003 29479 solver.cpp:229]     Train net output #0: loss = 6037.97 (* 1 = 6037.97 loss)
I0316 09:51:29.595154 29479 solver.cpp:610] Iteration 71720, lr = 6.70527e-09
I0316 09:51:29.595167 29479 solver.cpp:613] Iteration 71720, avg_grad_norm = 531279
I0316 09:52:37.497499 29479 solver.cpp:214] Iteration 71740, loss = 5891.52
I0316 09:52:37.497711 29479 solver.cpp:229]     Train net output #0: loss = 7545.98 (* 1 = 7545.98 loss)
I0316 09:52:37.842222 29479 solver.cpp:610] Iteration 71740, lr = 6.70433e-09
I0316 09:52:37.842236 29479 solver.cpp:613] Iteration 71740, avg_grad_norm = 505433
I0316 09:53:58.850831 29479 solver.cpp:214] Iteration 71760, loss = 5624.43
I0316 09:53:58.850945 29479 solver.cpp:229]     Train net output #0: loss = 5306.83 (* 1 = 5306.83 loss)
I0316 09:53:59.066768 29479 solver.cpp:610] Iteration 71760, lr = 6.70338e-09
I0316 09:53:59.066782 29479 solver.cpp:613] Iteration 71760, avg_grad_norm = 547167
I0316 09:55:06.319080 29479 solver.cpp:214] Iteration 71780, loss = 5944.07
I0316 09:55:06.319269 29479 solver.cpp:229]     Train net output #0: loss = 3627.4 (* 1 = 3627.4 loss)
I0316 09:55:06.678647 29479 solver.cpp:610] Iteration 71780, lr = 6.70244e-09
I0316 09:55:06.678661 29479 solver.cpp:613] Iteration 71780, avg_grad_norm = 503706
I0316 09:56:14.185223 29479 solver.cpp:214] Iteration 71800, loss = 5690.13
I0316 09:56:14.185369 29479 solver.cpp:229]     Train net output #0: loss = 7139.95 (* 1 = 7139.95 loss)
I0316 09:56:14.575225 29479 solver.cpp:610] Iteration 71800, lr = 6.7015e-09
I0316 09:56:14.575239 29479 solver.cpp:613] Iteration 71800, avg_grad_norm = 506806
I0316 09:57:00.943392 29479 solver.cpp:214] Iteration 71820, loss = 5685.36
I0316 09:57:00.943583 29479 solver.cpp:229]     Train net output #0: loss = 4708.16 (* 1 = 4708.16 loss)
I0316 09:57:01.308599 29479 solver.cpp:610] Iteration 71820, lr = 6.70056e-09
I0316 09:57:01.308614 29479 solver.cpp:613] Iteration 71820, avg_grad_norm = 526513
I0316 09:58:08.430125 29479 solver.cpp:214] Iteration 71840, loss = 6049.67
I0316 09:58:08.430248 29479 solver.cpp:229]     Train net output #0: loss = 5541.81 (* 1 = 5541.81 loss)
I0316 09:58:08.789944 29479 solver.cpp:610] Iteration 71840, lr = 6.69962e-09
I0316 09:58:08.789958 29479 solver.cpp:613] Iteration 71840, avg_grad_norm = 543992
I0316 09:59:16.898766 29479 solver.cpp:214] Iteration 71860, loss = 5806.5
I0316 09:59:16.898895 29479 solver.cpp:229]     Train net output #0: loss = 4197.33 (* 1 = 4197.33 loss)
I0316 09:59:17.270830 29479 solver.cpp:610] Iteration 71860, lr = 6.69868e-09
I0316 09:59:17.270844 29479 solver.cpp:613] Iteration 71860, avg_grad_norm = 490185
I0316 10:00:41.480916 29479 solver.cpp:214] Iteration 71880, loss = 5681.74
I0316 10:00:41.481042 29479 solver.cpp:229]     Train net output #0: loss = 6705.36 (* 1 = 6705.36 loss)
I0316 10:00:41.845717 29479 solver.cpp:610] Iteration 71880, lr = 6.69774e-09
I0316 10:00:41.845732 29479 solver.cpp:613] Iteration 71880, avg_grad_norm = 508166
I0316 10:01:50.179561 29479 solver.cpp:214] Iteration 71900, loss = 6055.21
I0316 10:01:50.179698 29479 solver.cpp:229]     Train net output #0: loss = 5551.75 (* 1 = 5551.75 loss)
I0316 10:01:50.523397 29479 solver.cpp:610] Iteration 71900, lr = 6.6968e-09
I0316 10:01:50.523411 29479 solver.cpp:613] Iteration 71900, avg_grad_norm = 551992
I0316 10:02:57.953618 29479 solver.cpp:214] Iteration 71920, loss = 5694.83
I0316 10:02:57.953752 29479 solver.cpp:229]     Train net output #0: loss = 7763.73 (* 1 = 7763.73 loss)
I0316 10:02:58.298063 29479 solver.cpp:610] Iteration 71920, lr = 6.69586e-09
I0316 10:02:58.298077 29479 solver.cpp:613] Iteration 71920, avg_grad_norm = 515557
I0316 10:03:59.028087 29479 solver.cpp:214] Iteration 71940, loss = 5715.43
I0316 10:03:59.028272 29479 solver.cpp:229]     Train net output #0: loss = 8190.44 (* 1 = 8190.44 loss)
I0316 10:03:59.138627 29479 solver.cpp:610] Iteration 71940, lr = 6.69492e-09
I0316 10:03:59.138640 29479 solver.cpp:613] Iteration 71940, avg_grad_norm = 501603
I0316 10:04:40.156090 29479 solver.cpp:214] Iteration 71960, loss = 5876.02
I0316 10:04:40.156255 29479 solver.cpp:229]     Train net output #0: loss = 3208.12 (* 1 = 3208.12 loss)
I0316 10:04:40.517210 29479 solver.cpp:610] Iteration 71960, lr = 6.69398e-09
I0316 10:04:40.517223 29479 solver.cpp:613] Iteration 71960, avg_grad_norm = 497423
I0316 10:05:49.353799 29479 solver.cpp:214] Iteration 71980, loss = 5863.31
I0316 10:05:49.354042 29479 solver.cpp:229]     Train net output #0: loss = 4398.07 (* 1 = 4398.07 loss)
I0316 10:05:49.697628 29479 solver.cpp:610] Iteration 71980, lr = 6.69303e-09
I0316 10:05:49.697643 29479 solver.cpp:613] Iteration 71980, avg_grad_norm = 492176
I0316 10:06:57.871460 29479 solver.cpp:214] Iteration 72000, loss = 5814.94
I0316 10:06:57.871624 29479 solver.cpp:229]     Train net output #0: loss = 6604.45 (* 1 = 6604.45 loss)
I0316 10:06:58.240376 29479 solver.cpp:610] Iteration 72000, lr = 6.69209e-09
I0316 10:06:58.240391 29479 solver.cpp:613] Iteration 72000, avg_grad_norm = 553010
I0316 10:08:28.985826 29479 solver.cpp:214] Iteration 72020, loss = 5566.81
I0316 10:08:28.985980 29479 solver.cpp:229]     Train net output #0: loss = 7111.29 (* 1 = 7111.29 loss)
I0316 10:08:29.318042 29479 solver.cpp:610] Iteration 72020, lr = 6.69115e-09
I0316 10:08:29.318058 29479 solver.cpp:613] Iteration 72020, avg_grad_norm = 494321
I0316 10:09:38.220768 29479 solver.cpp:214] Iteration 72040, loss = 5242.02
I0316 10:09:38.220947 29479 solver.cpp:229]     Train net output #0: loss = 6081.22 (* 1 = 6081.22 loss)
I0316 10:09:38.426395 29479 solver.cpp:610] Iteration 72040, lr = 6.69021e-09
I0316 10:09:38.426431 29479 solver.cpp:613] Iteration 72040, avg_grad_norm = 469968
I0316 10:10:45.761842 29479 solver.cpp:214] Iteration 72060, loss = 5685.73
I0316 10:10:45.761981 29479 solver.cpp:229]     Train net output #0: loss = 6973.13 (* 1 = 6973.13 loss)
I0316 10:10:46.132436 29479 solver.cpp:610] Iteration 72060, lr = 6.68927e-09
I0316 10:10:46.132449 29479 solver.cpp:613] Iteration 72060, avg_grad_norm = 515363
I0316 10:11:38.992015 29479 solver.cpp:214] Iteration 72080, loss = 5933.77
I0316 10:11:38.992162 29479 solver.cpp:229]     Train net output #0: loss = 13404.6 (* 1 = 13404.6 loss)
I0316 10:11:39.106716 29479 solver.cpp:610] Iteration 72080, lr = 6.68833e-09
I0316 10:11:39.106730 29479 solver.cpp:613] Iteration 72080, avg_grad_norm = 532300
I0316 10:12:40.200736 29479 solver.cpp:214] Iteration 72100, loss = 5720.13
I0316 10:12:40.200855 29479 solver.cpp:229]     Train net output #0: loss = 5496.97 (* 1 = 5496.97 loss)
I0316 10:12:40.558709 29479 solver.cpp:610] Iteration 72100, lr = 6.68739e-09
I0316 10:12:40.558723 29479 solver.cpp:613] Iteration 72100, avg_grad_norm = 514448
I0316 10:13:48.537202 29479 solver.cpp:214] Iteration 72120, loss = 5747.2
I0316 10:13:48.537299 29479 solver.cpp:229]     Train net output #0: loss = 7134.34 (* 1 = 7134.34 loss)
I0316 10:13:48.880744 29479 solver.cpp:610] Iteration 72120, lr = 6.68645e-09
I0316 10:13:48.880759 29479 solver.cpp:613] Iteration 72120, avg_grad_norm = 484850
I0316 10:15:08.262918 29479 solver.cpp:214] Iteration 72140, loss = 5965.97
I0316 10:15:08.263065 29479 solver.cpp:229]     Train net output #0: loss = 5450.34 (* 1 = 5450.34 loss)
I0316 10:15:08.634587 29479 solver.cpp:610] Iteration 72140, lr = 6.68551e-09
I0316 10:15:08.634600 29479 solver.cpp:613] Iteration 72140, avg_grad_norm = 541031
I0316 10:16:16.561661 29479 solver.cpp:214] Iteration 72160, loss = 5801.19
I0316 10:16:16.561795 29479 solver.cpp:229]     Train net output #0: loss = 6488.42 (* 1 = 6488.42 loss)
I0316 10:16:16.904537 29479 solver.cpp:610] Iteration 72160, lr = 6.68456e-09
I0316 10:16:16.904551 29479 solver.cpp:613] Iteration 72160, avg_grad_norm = 559101
I0316 10:17:24.455811 29479 solver.cpp:214] Iteration 72180, loss = 5756.25
I0316 10:17:24.455943 29479 solver.cpp:229]     Train net output #0: loss = 3518.05 (* 1 = 3518.05 loss)
I0316 10:17:24.816810 29479 solver.cpp:610] Iteration 72180, lr = 6.68362e-09
I0316 10:17:24.816824 29479 solver.cpp:613] Iteration 72180, avg_grad_norm = 495922
I0316 10:18:32.501560 29479 solver.cpp:214] Iteration 72200, loss = 5643.31
I0316 10:18:32.501755 29479 solver.cpp:229]     Train net output #0: loss = 5197.87 (* 1 = 5197.87 loss)
I0316 10:18:32.873636 29479 solver.cpp:610] Iteration 72200, lr = 6.68268e-09
I0316 10:18:32.873651 29479 solver.cpp:613] Iteration 72200, avg_grad_norm = 528146
I0316 10:19:19.276494 29479 solver.cpp:214] Iteration 72220, loss = 5804.68
I0316 10:19:19.276628 29479 solver.cpp:229]     Train net output #0: loss = 8451.9 (* 1 = 8451.9 loss)
I0316 10:19:19.392596 29479 solver.cpp:610] Iteration 72220, lr = 6.68174e-09
I0316 10:19:19.392611 29479 solver.cpp:613] Iteration 72220, avg_grad_norm = 584732
I0316 10:20:27.120144 29479 solver.cpp:214] Iteration 72240, loss = 5780.74
I0316 10:20:27.120343 29479 solver.cpp:229]     Train net output #0: loss = 7212.8 (* 1 = 7212.8 loss)
I0316 10:20:27.486815 29479 solver.cpp:610] Iteration 72240, lr = 6.6808e-09
I0316 10:20:27.486829 29479 solver.cpp:613] Iteration 72240, avg_grad_norm = 679636
I0316 10:21:48.636847 29479 solver.cpp:214] Iteration 72260, loss = 5893.63
I0316 10:21:48.636981 29479 solver.cpp:229]     Train net output #0: loss = 9718.38 (* 1 = 9718.38 loss)
I0316 10:21:48.997647 29479 solver.cpp:610] Iteration 72260, lr = 6.67986e-09
I0316 10:21:48.997660 29479 solver.cpp:613] Iteration 72260, avg_grad_norm = 485199
I0316 10:22:56.481549 29479 solver.cpp:214] Iteration 72280, loss = 5624.96
I0316 10:22:56.481670 29479 solver.cpp:229]     Train net output #0: loss = 7141.12 (* 1 = 7141.12 loss)
I0316 10:22:56.850381 29479 solver.cpp:610] Iteration 72280, lr = 6.67892e-09
I0316 10:22:56.850395 29479 solver.cpp:613] Iteration 72280, avg_grad_norm = 482372
I0316 10:24:04.370452 29479 solver.cpp:214] Iteration 72300, loss = 5639.94
I0316 10:24:04.370646 29479 solver.cpp:229]     Train net output #0: loss = 4020.89 (* 1 = 4020.89 loss)
I0316 10:24:04.735913 29479 solver.cpp:610] Iteration 72300, lr = 6.67798e-09
I0316 10:24:04.735927 29479 solver.cpp:613] Iteration 72300, avg_grad_norm = 508862
I0316 10:25:12.320111 29479 solver.cpp:214] Iteration 72320, loss = 5654.72
I0316 10:25:12.320262 29479 solver.cpp:229]     Train net output #0: loss = 8463.17 (* 1 = 8463.17 loss)
I0316 10:25:12.689088 29479 solver.cpp:610] Iteration 72320, lr = 6.67703e-09
I0316 10:25:12.689102 29479 solver.cpp:613] Iteration 72320, avg_grad_norm = 534156
I0316 10:26:20.417039 29479 solver.cpp:214] Iteration 72340, loss = 6150.14
I0316 10:26:20.417167 29479 solver.cpp:229]     Train net output #0: loss = 4335.07 (* 1 = 4335.07 loss)
I0316 10:26:20.777164 29479 solver.cpp:610] Iteration 72340, lr = 6.67609e-09
I0316 10:26:20.777179 29479 solver.cpp:613] Iteration 72340, avg_grad_norm = 482771
I0316 10:27:06.877918 29479 solver.cpp:214] Iteration 72360, loss = 5462.51
I0316 10:27:06.878134 29479 solver.cpp:229]     Train net output #0: loss = 7071.57 (* 1 = 7071.57 loss)
I0316 10:27:07.247915 29479 solver.cpp:610] Iteration 72360, lr = 6.67515e-09
I0316 10:27:07.247930 29479 solver.cpp:613] Iteration 72360, avg_grad_norm = 552802
I0316 10:28:14.182469 29479 solver.cpp:214] Iteration 72380, loss = 5991.69
I0316 10:28:14.182668 29479 solver.cpp:229]     Train net output #0: loss = 5995.55 (* 1 = 5995.55 loss)
I0316 10:28:14.520587 29479 solver.cpp:610] Iteration 72380, lr = 6.67421e-09
I0316 10:28:14.520601 29479 solver.cpp:613] Iteration 72380, avg_grad_norm = 529185
I0316 10:29:34.259883 29479 solver.cpp:214] Iteration 72400, loss = 5751.4
I0316 10:29:34.260128 29479 solver.cpp:229]     Train net output #0: loss = 2905.31 (* 1 = 2905.31 loss)
I0316 10:29:34.590909 29479 solver.cpp:610] Iteration 72400, lr = 6.67327e-09
I0316 10:29:34.590924 29479 solver.cpp:613] Iteration 72400, avg_grad_norm = 565745
I0316 10:30:41.959506 29479 solver.cpp:214] Iteration 72420, loss = 5512.62
I0316 10:30:41.959630 29479 solver.cpp:229]     Train net output #0: loss = 3826.06 (* 1 = 3826.06 loss)
I0316 10:30:42.162524 29479 solver.cpp:610] Iteration 72420, lr = 6.67233e-09
I0316 10:30:42.162538 29479 solver.cpp:613] Iteration 72420, avg_grad_norm = 483808
I0316 10:31:50.227522 29479 solver.cpp:214] Iteration 72440, loss = 5807.75
I0316 10:31:50.227746 29479 solver.cpp:229]     Train net output #0: loss = 5855.79 (* 1 = 5855.79 loss)
I0316 10:31:50.571763 29479 solver.cpp:610] Iteration 72440, lr = 6.67139e-09
I0316 10:31:50.571776 29479 solver.cpp:613] Iteration 72440, avg_grad_norm = 505280
I0316 10:32:57.321147 29479 solver.cpp:214] Iteration 72460, loss = 5884.88
I0316 10:32:57.321362 29479 solver.cpp:229]     Train net output #0: loss = 5956.14 (* 1 = 5956.14 loss)
I0316 10:32:57.684819 29479 solver.cpp:610] Iteration 72460, lr = 6.67044e-09
I0316 10:32:57.684840 29479 solver.cpp:613] Iteration 72460, avg_grad_norm = 503792
I0316 10:34:06.337167 29479 solver.cpp:214] Iteration 72480, loss = 5713.54
I0316 10:34:06.337293 29479 solver.cpp:229]     Train net output #0: loss = 4407.95 (* 1 = 4407.95 loss)
I0316 10:34:06.704116 29479 solver.cpp:610] Iteration 72480, lr = 6.6695e-09
I0316 10:34:06.704129 29479 solver.cpp:613] Iteration 72480, avg_grad_norm = 557577
I0316 10:34:52.891093 29479 solver.cpp:214] Iteration 72500, loss = 5873.64
I0316 10:34:52.891194 29479 solver.cpp:229]     Train net output #0: loss = 8067.74 (* 1 = 8067.74 loss)
I0316 10:34:53.257665 29479 solver.cpp:610] Iteration 72500, lr = 6.66856e-09
I0316 10:34:53.257680 29479 solver.cpp:613] Iteration 72500, avg_grad_norm = 529369
I0316 10:36:14.111799 29479 solver.cpp:214] Iteration 72520, loss = 5774.97
I0316 10:36:14.111990 29479 solver.cpp:229]     Train net output #0: loss = 5148.11 (* 1 = 5148.11 loss)
I0316 10:36:14.483836 29479 solver.cpp:610] Iteration 72520, lr = 6.66762e-09
I0316 10:36:14.483851 29479 solver.cpp:613] Iteration 72520, avg_grad_norm = 544491
I0316 10:37:22.703527 29479 solver.cpp:214] Iteration 72540, loss = 5652.43
I0316 10:37:22.703721 29479 solver.cpp:229]     Train net output #0: loss = 5745.31 (* 1 = 5745.31 loss)
I0316 10:37:23.047415 29479 solver.cpp:610] Iteration 72540, lr = 6.66668e-09
I0316 10:37:23.047428 29479 solver.cpp:613] Iteration 72540, avg_grad_norm = 531210
I0316 10:38:30.236454 29479 solver.cpp:214] Iteration 72560, loss = 5837.28
I0316 10:38:30.236595 29479 solver.cpp:229]     Train net output #0: loss = 5842.92 (* 1 = 5842.92 loss)
I0316 10:38:30.600399 29479 solver.cpp:610] Iteration 72560, lr = 6.66574e-09
I0316 10:38:30.600411 29479 solver.cpp:613] Iteration 72560, avg_grad_norm = 499940
I0316 10:39:37.862263 29479 solver.cpp:214] Iteration 72580, loss = 5947.04
I0316 10:39:37.862391 29479 solver.cpp:229]     Train net output #0: loss = 6845.85 (* 1 = 6845.85 loss)
I0316 10:39:38.229003 29479 solver.cpp:610] Iteration 72580, lr = 6.6648e-09
I0316 10:39:38.229017 29479 solver.cpp:613] Iteration 72580, avg_grad_norm = 602563
I0316 10:40:46.353879 29479 solver.cpp:214] Iteration 72600, loss = 5597.25
I0316 10:40:46.354009 29479 solver.cpp:229]     Train net output #0: loss = 5083.51 (* 1 = 5083.51 loss)
I0316 10:40:46.733615 29479 solver.cpp:610] Iteration 72600, lr = 6.66385e-09
I0316 10:40:46.733629 29479 solver.cpp:613] Iteration 72600, avg_grad_norm = 542159
I0316 10:41:54.582029 29479 solver.cpp:214] Iteration 72620, loss = 5787.65
I0316 10:41:54.582159 29479 solver.cpp:229]     Train net output #0: loss = 10179.2 (* 1 = 10179.2 loss)
I0316 10:41:54.950670 29479 solver.cpp:610] Iteration 72620, lr = 6.66291e-09
I0316 10:41:54.950683 29479 solver.cpp:613] Iteration 72620, avg_grad_norm = 466900
I0316 10:42:53.355455 29479 solver.cpp:214] Iteration 72640, loss = 5942.35
I0316 10:42:53.355579 29479 solver.cpp:229]     Train net output #0: loss = 3309.63 (* 1 = 3309.63 loss)
I0316 10:42:53.715769 29479 solver.cpp:610] Iteration 72640, lr = 6.66197e-09
I0316 10:42:53.715782 29479 solver.cpp:613] Iteration 72640, avg_grad_norm = 534407
I0316 10:44:01.971386 29479 solver.cpp:214] Iteration 72660, loss = 5543.02
I0316 10:44:01.971510 29479 solver.cpp:229]     Train net output #0: loss = 6719.74 (* 1 = 6719.74 loss)
I0316 10:44:02.314890 29479 solver.cpp:610] Iteration 72660, lr = 6.66103e-09
I0316 10:44:02.314903 29479 solver.cpp:613] Iteration 72660, avg_grad_norm = 488980
I0316 10:45:09.165709 29479 solver.cpp:214] Iteration 72680, loss = 5905.06
I0316 10:45:09.165900 29479 solver.cpp:229]     Train net output #0: loss = 8001.04 (* 1 = 8001.04 loss)
I0316 10:45:09.531433 29479 solver.cpp:610] Iteration 72680, lr = 6.66009e-09
I0316 10:45:09.531447 29479 solver.cpp:613] Iteration 72680, avg_grad_norm = 505110
I0316 10:46:16.820081 29479 solver.cpp:214] Iteration 72700, loss = 5644.39
I0316 10:46:16.820214 29479 solver.cpp:229]     Train net output #0: loss = 5953.38 (* 1 = 5953.38 loss)
I0316 10:46:17.182801 29479 solver.cpp:610] Iteration 72700, lr = 6.65915e-09
I0316 10:46:17.182813 29479 solver.cpp:613] Iteration 72700, avg_grad_norm = 468575
I0316 10:47:25.001034 29479 solver.cpp:214] Iteration 72720, loss = 5700.9
I0316 10:47:25.001165 29479 solver.cpp:229]     Train net output #0: loss = 3971.54 (* 1 = 3971.54 loss)
I0316 10:47:25.367774 29479 solver.cpp:610] Iteration 72720, lr = 6.6582e-09
I0316 10:47:25.367789 29479 solver.cpp:613] Iteration 72720, avg_grad_norm = 492004
I0316 10:48:33.117359 29479 solver.cpp:214] Iteration 72740, loss = 5790.44
I0316 10:48:33.117501 29479 solver.cpp:229]     Train net output #0: loss = 7843.39 (* 1 = 7843.39 loss)
I0316 10:48:33.477270 29479 solver.cpp:610] Iteration 72740, lr = 6.65726e-09
I0316 10:48:33.477283 29479 solver.cpp:613] Iteration 72740, avg_grad_norm = 533449
I0316 10:49:36.376973 29479 solver.cpp:214] Iteration 72760, loss = 5562.74
I0316 10:49:36.377117 29479 solver.cpp:229]     Train net output #0: loss = 4778.46 (* 1 = 4778.46 loss)
I0316 10:49:36.488246 29479 solver.cpp:610] Iteration 72760, lr = 6.65632e-09
I0316 10:49:36.488283 29479 solver.cpp:613] Iteration 72760, avg_grad_norm = 451420
I0316 10:50:44.744047 29479 solver.cpp:214] Iteration 72780, loss = 5665.19
I0316 10:50:44.744179 29479 solver.cpp:229]     Train net output #0: loss = 4171.12 (* 1 = 4171.12 loss)
I0316 10:50:45.118872 29479 solver.cpp:610] Iteration 72780, lr = 6.65538e-09
I0316 10:50:45.118887 29479 solver.cpp:613] Iteration 72780, avg_grad_norm = 460388
I0316 10:51:53.060783 29479 solver.cpp:214] Iteration 72800, loss = 5830.68
I0316 10:51:53.060894 29479 solver.cpp:229]     Train net output #0: loss = 6711.57 (* 1 = 6711.57 loss)
I0316 10:51:53.427458 29479 solver.cpp:610] Iteration 72800, lr = 6.65444e-09
I0316 10:51:53.427470 29479 solver.cpp:613] Iteration 72800, avg_grad_norm = 522443
I0316 10:53:01.645879 29479 solver.cpp:214] Iteration 72820, loss = 6029.02
I0316 10:53:01.645975 29479 solver.cpp:229]     Train net output #0: loss = 3740.66 (* 1 = 3740.66 loss)
I0316 10:53:02.036053 29479 solver.cpp:610] Iteration 72820, lr = 6.6535e-09
I0316 10:53:02.036067 29479 solver.cpp:613] Iteration 72820, avg_grad_norm = 525514
I0316 10:54:09.896018 29479 solver.cpp:214] Iteration 72840, loss = 5656.82
I0316 10:54:09.896209 29479 solver.cpp:229]     Train net output #0: loss = 10131.3 (* 1 = 10131.3 loss)
I0316 10:54:10.239128 29479 solver.cpp:610] Iteration 72840, lr = 6.65255e-09
I0316 10:54:10.239142 29479 solver.cpp:613] Iteration 72840, avg_grad_norm = 499508
I0316 10:55:14.784895 29479 solver.cpp:214] Iteration 72860, loss = 5996.21
I0316 10:55:14.785011 29479 solver.cpp:229]     Train net output #0: loss = 8969.02 (* 1 = 8969.02 loss)
I0316 10:55:15.129528 29479 solver.cpp:610] Iteration 72860, lr = 6.65161e-09
I0316 10:55:15.129541 29479 solver.cpp:613] Iteration 72860, avg_grad_norm = 492555
I0316 10:56:22.679492 29479 solver.cpp:214] Iteration 72880, loss = 5448.35
I0316 10:56:22.679631 29479 solver.cpp:229]     Train net output #0: loss = 3765.44 (* 1 = 3765.44 loss)
I0316 10:56:23.039566 29479 solver.cpp:610] Iteration 72880, lr = 6.65067e-09
I0316 10:56:23.039579 29479 solver.cpp:613] Iteration 72880, avg_grad_norm = 476732
I0316 10:57:45.945116 29479 solver.cpp:214] Iteration 72900, loss = 5904.11
I0316 10:57:45.945233 29479 solver.cpp:229]     Train net output #0: loss = 5142.17 (* 1 = 5142.17 loss)
I0316 10:57:46.301650 29479 solver.cpp:610] Iteration 72900, lr = 6.64973e-09
I0316 10:57:46.301662 29479 solver.cpp:613] Iteration 72900, avg_grad_norm = 518990
I0316 10:58:53.526274 29479 solver.cpp:214] Iteration 72920, loss = 5818.53
I0316 10:58:53.526471 29479 solver.cpp:229]     Train net output #0: loss = 4833.24 (* 1 = 4833.24 loss)
I0316 10:58:53.883909 29479 solver.cpp:610] Iteration 72920, lr = 6.64879e-09
I0316 10:58:53.883924 29479 solver.cpp:613] Iteration 72920, avg_grad_norm = 525176
I0316 11:00:01.929276 29479 solver.cpp:214] Iteration 72940, loss = 6087.6
I0316 11:00:01.929405 29479 solver.cpp:229]     Train net output #0: loss = 3489.73 (* 1 = 3489.73 loss)
I0316 11:00:02.290271 29479 solver.cpp:610] Iteration 72940, lr = 6.64785e-09
I0316 11:00:02.290284 29479 solver.cpp:613] Iteration 72940, avg_grad_norm = 541847
I0316 11:01:10.411677 29479 solver.cpp:214] Iteration 72960, loss = 5830.29
I0316 11:01:10.411815 29479 solver.cpp:229]     Train net output #0: loss = 11337.2 (* 1 = 11337.2 loss)
I0316 11:01:10.772172 29479 solver.cpp:610] Iteration 72960, lr = 6.6469e-09
I0316 11:01:10.772186 29479 solver.cpp:613] Iteration 72960, avg_grad_norm = 544030
I0316 11:02:18.576757 29479 solver.cpp:214] Iteration 72980, loss = 6007.35
I0316 11:02:18.576843 29479 solver.cpp:229]     Train net output #0: loss = 4801.85 (* 1 = 4801.85 loss)
I0316 11:02:18.940503 29479 solver.cpp:610] Iteration 72980, lr = 6.64596e-09
I0316 11:02:18.940517 29479 solver.cpp:613] Iteration 72980, avg_grad_norm = 527999
I0316 11:03:26.686084 29479 solver.cpp:214] Iteration 73000, loss = 6106.32
I0316 11:03:26.686208 29479 solver.cpp:229]     Train net output #0: loss = 4880.02 (* 1 = 4880.02 loss)
I0316 11:03:27.048212 29479 solver.cpp:610] Iteration 73000, lr = 6.64502e-09
I0316 11:03:27.048225 29479 solver.cpp:613] Iteration 73000, avg_grad_norm = 525023
I0316 11:04:35.183900 29479 solver.cpp:214] Iteration 73020, loss = 5619.79
I0316 11:04:35.184015 29479 solver.cpp:229]     Train net output #0: loss = 5101.26 (* 1 = 5101.26 loss)
I0316 11:04:35.549314 29479 solver.cpp:610] Iteration 73020, lr = 6.64408e-09
I0316 11:04:35.549327 29479 solver.cpp:613] Iteration 73020, avg_grad_norm = 515911
I0316 11:05:34.106286 29479 solver.cpp:214] Iteration 73040, loss = 5935.4
I0316 11:05:34.106420 29479 solver.cpp:229]     Train net output #0: loss = 5587.34 (* 1 = 5587.34 loss)
I0316 11:05:34.467984 29479 solver.cpp:610] Iteration 73040, lr = 6.64314e-09
I0316 11:05:34.467998 29479 solver.cpp:613] Iteration 73040, avg_grad_norm = 492703
I0316 11:06:41.887115 29479 solver.cpp:214] Iteration 73060, loss = 5623.65
I0316 11:06:41.887246 29479 solver.cpp:229]     Train net output #0: loss = 11363.5 (* 1 = 11363.5 loss)
I0316 11:06:42.276443 29479 solver.cpp:610] Iteration 73060, lr = 6.6422e-09
I0316 11:06:42.276455 29479 solver.cpp:613] Iteration 73060, avg_grad_norm = 484033
I0316 11:07:49.578841 29479 solver.cpp:214] Iteration 73080, loss = 5469.11
I0316 11:07:49.578953 29479 solver.cpp:229]     Train net output #0: loss = 4998.35 (* 1 = 4998.35 loss)
I0316 11:07:49.939512 29479 solver.cpp:610] Iteration 73080, lr = 6.64125e-09
I0316 11:07:49.939525 29479 solver.cpp:613] Iteration 73080, avg_grad_norm = 504085
I0316 11:08:57.587962 29479 solver.cpp:214] Iteration 73100, loss = 5664.13
I0316 11:08:57.588107 29479 solver.cpp:229]     Train net output #0: loss = 4901.08 (* 1 = 4901.08 loss)
I0316 11:08:57.930351 29479 solver.cpp:610] Iteration 73100, lr = 6.64031e-09
I0316 11:08:57.930364 29479 solver.cpp:613] Iteration 73100, avg_grad_norm = 522843
I0316 11:10:06.318147 29479 solver.cpp:214] Iteration 73120, loss = 5692.32
I0316 11:10:06.318280 29479 solver.cpp:229]     Train net output #0: loss = 4900.67 (* 1 = 4900.67 loss)
I0316 11:10:06.699062 29479 solver.cpp:610] Iteration 73120, lr = 6.63937e-09
I0316 11:10:06.699075 29479 solver.cpp:613] Iteration 73120, avg_grad_norm = 482499
I0316 11:11:14.272603 29479 solver.cpp:214] Iteration 73140, loss = 5440.98
I0316 11:11:14.272739 29479 solver.cpp:229]     Train net output #0: loss = 2039.39 (* 1 = 2039.39 loss)
I0316 11:11:14.480698 29479 solver.cpp:610] Iteration 73140, lr = 6.63843e-09
I0316 11:11:14.480711 29479 solver.cpp:613] Iteration 73140, avg_grad_norm = 461275
I0316 11:12:27.950225 29479 solver.cpp:214] Iteration 73160, loss = 5852.92
I0316 11:12:27.950409 29479 solver.cpp:229]     Train net output #0: loss = 3018.94 (* 1 = 3018.94 loss)
I0316 11:12:28.061956 29479 solver.cpp:610] Iteration 73160, lr = 6.63749e-09
I0316 11:12:28.061995 29479 solver.cpp:613] Iteration 73160, avg_grad_norm = 493589
I0316 11:13:03.755652 29479 solver.cpp:214] Iteration 73180, loss = 5642.29
I0316 11:13:03.755849 29479 solver.cpp:229]     Train net output #0: loss = 3705.39 (* 1 = 3705.39 loss)
I0316 11:13:04.116281 29479 solver.cpp:610] Iteration 73180, lr = 6.63654e-09
I0316 11:13:04.116296 29479 solver.cpp:613] Iteration 73180, avg_grad_norm = 580582
I0316 11:14:12.141845 29479 solver.cpp:214] Iteration 73200, loss = 5811.4
I0316 11:14:12.141963 29479 solver.cpp:229]     Train net output #0: loss = 7700.29 (* 1 = 7700.29 loss)
I0316 11:14:12.510964 29479 solver.cpp:610] Iteration 73200, lr = 6.6356e-09
I0316 11:14:12.510977 29479 solver.cpp:613] Iteration 73200, avg_grad_norm = 564709
I0316 11:15:21.000120 29479 solver.cpp:214] Iteration 73220, loss = 5779.93
I0316 11:15:21.001112 29479 solver.cpp:229]     Train net output #0: loss = 8442.72 (* 1 = 8442.72 loss)
I0316 11:15:21.368649 29479 solver.cpp:610] Iteration 73220, lr = 6.63466e-09
I0316 11:15:21.368685 29479 solver.cpp:613] Iteration 73220, avg_grad_norm = 481762
I0316 11:16:29.536082 29479 solver.cpp:214] Iteration 73240, loss = 5775.65
I0316 11:16:29.536206 29479 solver.cpp:229]     Train net output #0: loss = 4801 (* 1 = 4801 loss)
I0316 11:16:29.903067 29479 solver.cpp:610] Iteration 73240, lr = 6.63372e-09
I0316 11:16:29.903081 29479 solver.cpp:613] Iteration 73240, avg_grad_norm = 535662
I0316 11:17:37.244591 29479 solver.cpp:214] Iteration 73260, loss = 6020.42
I0316 11:17:37.244705 29479 solver.cpp:229]     Train net output #0: loss = 8419.63 (* 1 = 8419.63 loss)
I0316 11:17:37.448426 29479 solver.cpp:610] Iteration 73260, lr = 6.63278e-09
I0316 11:17:37.448439 29479 solver.cpp:613] Iteration 73260, avg_grad_norm = 535577
I0316 11:19:00.593312 29479 solver.cpp:214] Iteration 73280, loss = 5934.36
I0316 11:19:00.593447 29479 solver.cpp:229]     Train net output #0: loss = 4652.81 (* 1 = 4652.81 loss)
I0316 11:19:00.800814 29479 solver.cpp:610] Iteration 73280, lr = 6.63183e-09
I0316 11:19:00.800828 29479 solver.cpp:613] Iteration 73280, avg_grad_norm = 633311
I0316 11:20:04.910800 29479 solver.cpp:214] Iteration 73300, loss = 5499.52
I0316 11:20:04.911020 29479 solver.cpp:229]     Train net output #0: loss = 6744.23 (* 1 = 6744.23 loss)
I0316 11:20:05.275039 29479 solver.cpp:610] Iteration 73300, lr = 6.63089e-09
I0316 11:20:05.275054 29479 solver.cpp:613] Iteration 73300, avg_grad_norm = 579072
I0316 11:20:51.193543 29479 solver.cpp:214] Iteration 73320, loss = 5770.88
I0316 11:20:51.193689 29479 solver.cpp:229]     Train net output #0: loss = 4540.89 (* 1 = 4540.89 loss)
I0316 11:20:51.583961 29479 solver.cpp:610] Iteration 73320, lr = 6.62995e-09
I0316 11:20:51.583977 29479 solver.cpp:613] Iteration 73320, avg_grad_norm = 529805
I0316 11:21:57.806311 29479 solver.cpp:214] Iteration 73340, loss = 5773.47
I0316 11:21:57.806530 29479 solver.cpp:229]     Train net output #0: loss = 12388.2 (* 1 = 12388.2 loss)
I0316 11:21:58.150378 29479 solver.cpp:610] Iteration 73340, lr = 6.62901e-09
I0316 11:21:58.150393 29479 solver.cpp:613] Iteration 73340, avg_grad_norm = 536612
I0316 11:23:05.704515 29479 solver.cpp:214] Iteration 73360, loss = 5825.88
I0316 11:23:05.704704 29479 solver.cpp:229]     Train net output #0: loss = 4579.8 (* 1 = 4579.8 loss)
I0316 11:23:06.063016 29479 solver.cpp:610] Iteration 73360, lr = 6.62807e-09
I0316 11:23:06.063030 29479 solver.cpp:613] Iteration 73360, avg_grad_norm = 539147
I0316 11:24:13.705268 29479 solver.cpp:214] Iteration 73380, loss = 5897.13
I0316 11:24:13.705365 29479 solver.cpp:229]     Train net output #0: loss = 7716.3 (* 1 = 7716.3 loss)
I0316 11:24:14.075584 29479 solver.cpp:610] Iteration 73380, lr = 6.62712e-09
I0316 11:24:14.075598 29479 solver.cpp:613] Iteration 73380, avg_grad_norm = 519247
I0316 11:25:22.479446 29479 solver.cpp:214] Iteration 73400, loss = 5866.05
I0316 11:25:22.479621 29479 solver.cpp:229]     Train net output #0: loss = 3967.35 (* 1 = 3967.35 loss)
I0316 11:25:22.838312 29479 solver.cpp:610] Iteration 73400, lr = 6.62618e-09
I0316 11:25:22.838326 29479 solver.cpp:613] Iteration 73400, avg_grad_norm = 517184
I0316 11:26:42.529011 29479 solver.cpp:214] Iteration 73420, loss = 5773.13
I0316 11:26:42.529196 29479 solver.cpp:229]     Train net output #0: loss = 11701.7 (* 1 = 11701.7 loss)
I0316 11:26:42.892580 29479 solver.cpp:610] Iteration 73420, lr = 6.62524e-09
I0316 11:26:42.892592 29479 solver.cpp:613] Iteration 73420, avg_grad_norm = 496996
I0316 11:27:49.264781 29479 solver.cpp:214] Iteration 73440, loss = 6129.33
I0316 11:27:49.265007 29479 solver.cpp:229]     Train net output #0: loss = 9112.5 (* 1 = 9112.5 loss)
I0316 11:27:49.369977 29479 solver.cpp:610] Iteration 73440, lr = 6.6243e-09
I0316 11:27:49.369992 29479 solver.cpp:613] Iteration 73440, avg_grad_norm = 529602
I0316 11:28:38.190099 29479 solver.cpp:214] Iteration 73460, loss = 5935.8
I0316 11:28:38.190234 29479 solver.cpp:229]     Train net output #0: loss = 5891.29 (* 1 = 5891.29 loss)
I0316 11:28:38.534085 29479 solver.cpp:610] Iteration 73460, lr = 6.62336e-09
I0316 11:28:38.534101 29479 solver.cpp:613] Iteration 73460, avg_grad_norm = 555646
I0316 11:29:46.723176 29479 solver.cpp:214] Iteration 73480, loss = 5951.54
I0316 11:29:46.723294 29479 solver.cpp:229]     Train net output #0: loss = 2802.35 (* 1 = 2802.35 loss)
I0316 11:29:47.084167 29479 solver.cpp:610] Iteration 73480, lr = 6.62241e-09
I0316 11:29:47.084182 29479 solver.cpp:613] Iteration 73480, avg_grad_norm = 596205
I0316 11:30:55.391585 29479 solver.cpp:214] Iteration 73500, loss = 5682.77
I0316 11:30:55.391707 29479 solver.cpp:229]     Train net output #0: loss = 6268.52 (* 1 = 6268.52 loss)
I0316 11:30:55.761723 29479 solver.cpp:610] Iteration 73500, lr = 6.62147e-09
I0316 11:30:55.761737 29479 solver.cpp:613] Iteration 73500, avg_grad_norm = 495846
I0316 11:32:03.121438 29479 solver.cpp:214] Iteration 73520, loss = 5762.38
I0316 11:32:03.121551 29479 solver.cpp:229]     Train net output #0: loss = 9455.55 (* 1 = 9455.55 loss)
I0316 11:32:03.491258 29479 solver.cpp:610] Iteration 73520, lr = 6.62053e-09
I0316 11:32:03.491271 29479 solver.cpp:613] Iteration 73520, avg_grad_norm = 485439
I0316 11:33:27.631336 29479 solver.cpp:214] Iteration 73540, loss = 5559.77
I0316 11:33:27.631439 29479 solver.cpp:229]     Train net output #0: loss = 2284.46 (* 1 = 2284.46 loss)
I0316 11:33:28.003188 29479 solver.cpp:610] Iteration 73540, lr = 6.61959e-09
I0316 11:33:28.003202 29479 solver.cpp:613] Iteration 73540, avg_grad_norm = 563526
I0316 11:34:36.275959 29479 solver.cpp:214] Iteration 73560, loss = 5682.24
I0316 11:34:36.276142 29479 solver.cpp:229]     Train net output #0: loss = 6080.56 (* 1 = 6080.56 loss)
I0316 11:34:36.642976 29479 solver.cpp:610] Iteration 73560, lr = 6.61864e-09
I0316 11:34:36.642988 29479 solver.cpp:613] Iteration 73560, avg_grad_norm = 592204
I0316 11:35:29.407537 29479 solver.cpp:214] Iteration 73580, loss = 5862.48
I0316 11:35:29.407686 29479 solver.cpp:229]     Train net output #0: loss = 4898.55 (* 1 = 4898.55 loss)
I0316 11:35:29.522290 29479 solver.cpp:610] Iteration 73580, lr = 6.6177e-09
I0316 11:35:29.522315 29479 solver.cpp:613] Iteration 73580, avg_grad_norm = 527637
I0316 11:36:29.214021 29479 solver.cpp:214] Iteration 73600, loss = 5428.28
I0316 11:36:29.214174 29479 solver.cpp:229]     Train net output #0: loss = 4925.09 (* 1 = 4925.09 loss)
I0316 11:36:29.597167 29479 solver.cpp:610] Iteration 73600, lr = 6.61676e-09
I0316 11:36:29.597180 29479 solver.cpp:613] Iteration 73600, avg_grad_norm = 484921
I0316 11:37:37.788107 29479 solver.cpp:214] Iteration 73620, loss = 6006.49
I0316 11:37:37.788204 29479 solver.cpp:229]     Train net output #0: loss = 5127.8 (* 1 = 5127.8 loss)
I0316 11:37:38.151680 29479 solver.cpp:610] Iteration 73620, lr = 6.61582e-09
I0316 11:37:38.151693 29479 solver.cpp:613] Iteration 73620, avg_grad_norm = 567517
I0316 11:38:45.398416 29479 solver.cpp:214] Iteration 73640, loss = 5860.94
I0316 11:38:45.398591 29479 solver.cpp:229]     Train net output #0: loss = 4450.69 (* 1 = 4450.69 loss)
I0316 11:38:45.761842 29479 solver.cpp:610] Iteration 73640, lr = 6.61488e-09
I0316 11:38:45.761857 29479 solver.cpp:613] Iteration 73640, avg_grad_norm = 563996
I0316 11:40:06.388692 29479 solver.cpp:214] Iteration 73660, loss = 5985.71
I0316 11:40:06.388838 29479 solver.cpp:229]     Train net output #0: loss = 3615.86 (* 1 = 3615.86 loss)
I0316 11:40:06.757122 29479 solver.cpp:610] Iteration 73660, lr = 6.61393e-09
I0316 11:40:06.757134 29479 solver.cpp:613] Iteration 73660, avg_grad_norm = 498044
I0316 11:41:13.749388 29479 solver.cpp:214] Iteration 73680, loss = 5684.45
I0316 11:41:13.749523 29479 solver.cpp:229]     Train net output #0: loss = 6349.03 (* 1 = 6349.03 loss)
I0316 11:41:14.138376 29479 solver.cpp:610] Iteration 73680, lr = 6.61299e-09
I0316 11:41:14.138389 29479 solver.cpp:613] Iteration 73680, avg_grad_norm = 585966
I0316 11:42:22.010151 29479 solver.cpp:214] Iteration 73700, loss = 5762.24
I0316 11:42:22.010284 29479 solver.cpp:229]     Train net output #0: loss = 3949.25 (* 1 = 3949.25 loss)
I0316 11:42:22.216598 29479 solver.cpp:610] Iteration 73700, lr = 6.61205e-09
I0316 11:42:22.216611 29479 solver.cpp:613] Iteration 73700, avg_grad_norm = 489922
I0316 11:43:09.525007 29479 solver.cpp:214] Iteration 73720, loss = 5437.61
I0316 11:43:09.525166 29479 solver.cpp:229]     Train net output #0: loss = 5637.03 (* 1 = 5637.03 loss)
I0316 11:43:09.641193 29479 solver.cpp:610] Iteration 73720, lr = 6.61111e-09
I0316 11:43:09.641207 29479 solver.cpp:613] Iteration 73720, avg_grad_norm = 490992
I0316 11:44:16.018043 29479 solver.cpp:214] Iteration 73740, loss = 5548.98
I0316 11:44:16.018179 29479 solver.cpp:229]     Train net output #0: loss = 3880.66 (* 1 = 3880.66 loss)
I0316 11:44:16.234457 29479 solver.cpp:610] Iteration 73740, lr = 6.61016e-09
I0316 11:44:16.234470 29479 solver.cpp:613] Iteration 73740, avg_grad_norm = 504423
I0316 11:45:23.993320 29479 solver.cpp:214] Iteration 73760, loss = 5593.46
I0316 11:45:23.993451 29479 solver.cpp:229]     Train net output #0: loss = 5431.39 (* 1 = 5431.39 loss)
I0316 11:45:24.371345 29479 solver.cpp:610] Iteration 73760, lr = 6.60922e-09
I0316 11:45:24.371358 29479 solver.cpp:613] Iteration 73760, avg_grad_norm = 553905
I0316 11:46:32.524344 29479 solver.cpp:214] Iteration 73780, loss = 5763.18
I0316 11:46:32.524495 29479 solver.cpp:229]     Train net output #0: loss = 3587.68 (* 1 = 3587.68 loss)
I0316 11:46:32.889758 29479 solver.cpp:610] Iteration 73780, lr = 6.60828e-09
I0316 11:46:32.889775 29479 solver.cpp:613] Iteration 73780, avg_grad_norm = 503703
I0316 11:48:10.993446 29479 solver.cpp:214] Iteration 73800, loss = 5625.73
I0316 11:48:10.993569 29479 solver.cpp:229]     Train net output #0: loss = 7842.21 (* 1 = 7842.21 loss)
I0316 11:48:11.337528 29479 solver.cpp:610] Iteration 73800, lr = 6.60734e-09
I0316 11:48:11.337541 29479 solver.cpp:613] Iteration 73800, avg_grad_norm = 539405
I0316 11:49:18.792419 29479 solver.cpp:214] Iteration 73820, loss = 5652.61
I0316 11:49:18.792537 29479 solver.cpp:229]     Train net output #0: loss = 12244.9 (* 1 = 12244.9 loss)
I0316 11:49:19.182669 29479 solver.cpp:610] Iteration 73820, lr = 6.60639e-09
I0316 11:49:19.182683 29479 solver.cpp:613] Iteration 73820, avg_grad_norm = 578377
I0316 11:50:24.349979 29479 solver.cpp:214] Iteration 73840, loss = 5733.7
I0316 11:50:24.350178 29479 solver.cpp:229]     Train net output #0: loss = 6433.61 (* 1 = 6433.61 loss)
I0316 11:50:24.457820 29479 solver.cpp:610] Iteration 73840, lr = 6.60545e-09
I0316 11:50:24.457834 29479 solver.cpp:613] Iteration 73840, avg_grad_norm = 536416
I0316 11:51:13.403280 29479 solver.cpp:214] Iteration 73860, loss = 5778.34
I0316 11:51:13.403419 29479 solver.cpp:229]     Train net output #0: loss = 8241.87 (* 1 = 8241.87 loss)
I0316 11:51:13.768054 29479 solver.cpp:610] Iteration 73860, lr = 6.60451e-09
I0316 11:51:13.768067 29479 solver.cpp:613] Iteration 73860, avg_grad_norm = 524125
I0316 11:52:21.550458 29479 solver.cpp:214] Iteration 73880, loss = 5346.02
I0316 11:52:21.550650 29479 solver.cpp:229]     Train net output #0: loss = 4182.25 (* 1 = 4182.25 loss)
I0316 11:52:21.910754 29479 solver.cpp:610] Iteration 73880, lr = 6.60357e-09
I0316 11:52:21.910804 29479 solver.cpp:613] Iteration 73880, avg_grad_norm = 540341
I0316 11:53:30.291337 29479 solver.cpp:214] Iteration 73900, loss = 5805.32
I0316 11:53:30.291463 29479 solver.cpp:229]     Train net output #0: loss = 2725.87 (* 1 = 2725.87 loss)
I0316 11:53:30.680819 29479 solver.cpp:610] Iteration 73900, lr = 6.60262e-09
I0316 11:53:30.680835 29479 solver.cpp:613] Iteration 73900, avg_grad_norm = 546550
I0316 11:54:52.212230 29479 solver.cpp:214] Iteration 73920, loss = 5845.78
I0316 11:54:52.212354 29479 solver.cpp:229]     Train net output #0: loss = 9877.72 (* 1 = 9877.72 loss)
I0316 11:54:52.601415 29479 solver.cpp:610] Iteration 73920, lr = 6.60168e-09
I0316 11:54:52.601428 29479 solver.cpp:613] Iteration 73920, avg_grad_norm = 499346
I0316 11:55:59.958029 29479 solver.cpp:214] Iteration 73940, loss = 5798.93
I0316 11:55:59.958220 29479 solver.cpp:229]     Train net output #0: loss = 4191.18 (* 1 = 4191.18 loss)
I0316 11:56:00.301197 29479 solver.cpp:610] Iteration 73940, lr = 6.60074e-09
I0316 11:56:00.301230 29479 solver.cpp:613] Iteration 73940, avg_grad_norm = 508743
I0316 11:57:07.580667 29479 solver.cpp:214] Iteration 73960, loss = 5692.27
I0316 11:57:07.580890 29479 solver.cpp:229]     Train net output #0: loss = 5093.93 (* 1 = 5093.93 loss)
I0316 11:57:07.797214 29479 solver.cpp:610] Iteration 73960, lr = 6.5998e-09
I0316 11:57:07.797237 29479 solver.cpp:613] Iteration 73960, avg_grad_norm = 533270
I0316 11:58:04.693784 29479 solver.cpp:214] Iteration 73980, loss = 5680.6
I0316 11:58:04.693922 29479 solver.cpp:229]     Train net output #0: loss = 3091.3 (* 1 = 3091.3 loss)
I0316 11:58:04.808480 29479 solver.cpp:610] Iteration 73980, lr = 6.59885e-09
I0316 11:58:04.808493 29479 solver.cpp:613] Iteration 73980, avg_grad_norm = 671601
I0316 11:59:01.617663 29479 solver.cpp:214] Iteration 74000, loss = 5926.02
I0316 11:59:01.617780 29479 solver.cpp:229]     Train net output #0: loss = 4654.9 (* 1 = 4654.9 loss)
I0316 11:59:01.986232 29479 solver.cpp:610] Iteration 74000, lr = 6.59791e-09
I0316 11:59:01.986245 29479 solver.cpp:613] Iteration 74000, avg_grad_norm = 598401
I0316 12:00:08.953091 29479 solver.cpp:214] Iteration 74020, loss = 6125.31
I0316 12:00:08.953217 29479 solver.cpp:229]     Train net output #0: loss = 3563.05 (* 1 = 3563.05 loss)
I0316 12:00:09.155920 29479 solver.cpp:610] Iteration 74020, lr = 6.59697e-09
I0316 12:00:09.155932 29479 solver.cpp:613] Iteration 74020, avg_grad_norm = 512476
I0316 12:01:39.879940 29479 solver.cpp:214] Iteration 74040, loss = 5843.88
I0316 12:01:39.880049 29479 solver.cpp:229]     Train net output #0: loss = 1881.83 (* 1 = 1881.83 loss)
I0316 12:01:40.245944 29479 solver.cpp:610] Iteration 74040, lr = 6.59603e-09
I0316 12:01:40.245957 29479 solver.cpp:613] Iteration 74040, avg_grad_norm = 494733
I0316 12:02:48.672376 29479 solver.cpp:214] Iteration 74060, loss = 5672.96
I0316 12:02:48.672505 29479 solver.cpp:229]     Train net output #0: loss = 8163.39 (* 1 = 8163.39 loss)
I0316 12:02:48.881250 29479 solver.cpp:610] Iteration 74060, lr = 6.59508e-09
I0316 12:02:48.881265 29479 solver.cpp:613] Iteration 74060, avg_grad_norm = 579656
I0316 12:03:57.150898 29479 solver.cpp:214] Iteration 74080, loss = 5761.52
I0316 12:03:57.151026 29479 solver.cpp:229]     Train net output #0: loss = 4757.22 (* 1 = 4757.22 loss)
I0316 12:03:57.494817 29479 solver.cpp:610] Iteration 74080, lr = 6.59414e-09
I0316 12:03:57.494832 29479 solver.cpp:613] Iteration 74080, avg_grad_norm = 592343
I0316 12:05:05.404444 29479 solver.cpp:214] Iteration 74100, loss = 5761.83
I0316 12:05:05.404582 29479 solver.cpp:229]     Train net output #0: loss = 3700.28 (* 1 = 3700.28 loss)
I0316 12:05:05.793059 29479 solver.cpp:610] Iteration 74100, lr = 6.5932e-09
I0316 12:05:05.793072 29479 solver.cpp:613] Iteration 74100, avg_grad_norm = 657062
I0316 12:05:52.004068 29479 solver.cpp:214] Iteration 74120, loss = 5628.94
I0316 12:05:52.004307 29479 solver.cpp:229]     Train net output #0: loss = 4858.48 (* 1 = 4858.48 loss)
I0316 12:05:52.370543 29479 solver.cpp:610] Iteration 74120, lr = 6.59226e-09
I0316 12:05:52.370556 29479 solver.cpp:613] Iteration 74120, avg_grad_norm = 602159
I0316 12:07:00.477654 29479 solver.cpp:214] Iteration 74140, loss = 5718.3
I0316 12:07:00.477855 29479 solver.cpp:229]     Train net output #0: loss = 8259.77 (* 1 = 8259.77 loss)
I0316 12:07:00.848412 29479 solver.cpp:610] Iteration 74140, lr = 6.59131e-09
I0316 12:07:00.848434 29479 solver.cpp:613] Iteration 74140, avg_grad_norm = 523797
I0316 12:08:09.099067 29479 solver.cpp:214] Iteration 74160, loss = 5667.28
I0316 12:08:09.099205 29479 solver.cpp:229]     Train net output #0: loss = 7783.46 (* 1 = 7783.46 loss)
I0316 12:08:09.468812 29479 solver.cpp:610] Iteration 74160, lr = 6.59037e-09
I0316 12:08:09.468827 29479 solver.cpp:613] Iteration 74160, avg_grad_norm = 518389
I0316 12:09:26.585037 29479 solver.cpp:214] Iteration 74180, loss = 5761.69
I0316 12:09:26.585240 29479 solver.cpp:229]     Train net output #0: loss = 5338.7 (* 1 = 5338.7 loss)
I0316 12:09:26.959272 29479 solver.cpp:610] Iteration 74180, lr = 6.58943e-09
I0316 12:09:26.959287 29479 solver.cpp:613] Iteration 74180, avg_grad_norm = 537395
I0316 12:10:32.612584 29479 solver.cpp:214] Iteration 74200, loss = 5612.71
I0316 12:10:32.612754 29479 solver.cpp:229]     Train net output #0: loss = 5316.8 (* 1 = 5316.8 loss)
I0316 12:10:32.950059 29479 solver.cpp:610] Iteration 74200, lr = 6.58849e-09
I0316 12:10:32.950073 29479 solver.cpp:613] Iteration 74200, avg_grad_norm = 511245
I0316 12:11:40.450922 29479 solver.cpp:214] Iteration 74220, loss = 5526.69
I0316 12:11:40.451114 29479 solver.cpp:229]     Train net output #0: loss = 3913.63 (* 1 = 3913.63 loss)
I0316 12:11:40.817186 29479 solver.cpp:610] Iteration 74220, lr = 6.58754e-09
I0316 12:11:40.817199 29479 solver.cpp:613] Iteration 74220, avg_grad_norm = 611426
I0316 12:12:48.458335 29479 solver.cpp:214] Iteration 74240, loss = 5558.22
I0316 12:12:48.458452 29479 solver.cpp:229]     Train net output #0: loss = 4557.47 (* 1 = 4557.47 loss)
I0316 12:12:48.820809 29479 solver.cpp:610] Iteration 74240, lr = 6.5866e-09
I0316 12:12:48.820823 29479 solver.cpp:613] Iteration 74240, avg_grad_norm = 549197
I0316 12:13:35.108098 29479 solver.cpp:214] Iteration 74260, loss = 5708.4
I0316 12:13:35.108237 29479 solver.cpp:229]     Train net output #0: loss = 6855.08 (* 1 = 6855.08 loss)
I0316 12:13:35.468241 29479 solver.cpp:610] Iteration 74260, lr = 6.58566e-09
I0316 12:13:35.468255 29479 solver.cpp:613] Iteration 74260, avg_grad_norm = 462612
I0316 12:14:42.620633 29479 solver.cpp:214] Iteration 74280, loss = 5777.73
I0316 12:14:42.620750 29479 solver.cpp:229]     Train net output #0: loss = 2244.07 (* 1 = 2244.07 loss)
I0316 12:14:42.980940 29479 solver.cpp:610] Iteration 74280, lr = 6.58471e-09
I0316 12:14:42.980954 29479 solver.cpp:613] Iteration 74280, avg_grad_norm = 493613
I0316 12:16:06.603700 29479 solver.cpp:214] Iteration 74300, loss = 5721.31
I0316 12:16:06.603898 29479 solver.cpp:229]     Train net output #0: loss = 4537.61 (* 1 = 4537.61 loss)
I0316 12:16:06.820161 29479 solver.cpp:610] Iteration 74300, lr = 6.58377e-09
I0316 12:16:06.820176 29479 solver.cpp:613] Iteration 74300, avg_grad_norm = 532539
I0316 12:17:14.082885 29479 solver.cpp:214] Iteration 74320, loss = 5929.96
I0316 12:17:14.083055 29479 solver.cpp:229]     Train net output #0: loss = 11302 (* 1 = 11302 loss)
I0316 12:17:14.450505 29479 solver.cpp:610] Iteration 74320, lr = 6.58283e-09
I0316 12:17:14.450518 29479 solver.cpp:613] Iteration 74320, avg_grad_norm = 533339
I0316 12:18:22.834573 29479 solver.cpp:214] Iteration 74340, loss = 5726.74
I0316 12:18:22.834707 29479 solver.cpp:229]     Train net output #0: loss = 9324.76 (* 1 = 9324.76 loss)
I0316 12:18:23.199638 29479 solver.cpp:610] Iteration 74340, lr = 6.58189e-09
I0316 12:18:23.199651 29479 solver.cpp:613] Iteration 74340, avg_grad_norm = 515769
I0316 12:19:30.566339 29479 solver.cpp:214] Iteration 74360, loss = 5453.12
I0316 12:19:30.566506 29479 solver.cpp:229]     Train net output #0: loss = 11593.4 (* 1 = 11593.4 loss)
I0316 12:19:30.935930 29479 solver.cpp:610] Iteration 74360, lr = 6.58094e-09
I0316 12:19:30.935943 29479 solver.cpp:613] Iteration 74360, avg_grad_norm = 460518
I0316 12:20:38.701385 29479 solver.cpp:214] Iteration 74380, loss = 5895.29
I0316 12:20:38.701578 29479 solver.cpp:229]     Train net output #0: loss = 7312.46 (* 1 = 7312.46 loss)
I0316 12:20:39.063674 29479 solver.cpp:610] Iteration 74380, lr = 6.58e-09
I0316 12:20:39.063688 29479 solver.cpp:613] Iteration 74380, avg_grad_norm = 525562
I0316 12:21:25.850317 29479 solver.cpp:214] Iteration 74400, loss = 5580.1
I0316 12:21:25.850461 29479 solver.cpp:229]     Train net output #0: loss = 7297.04 (* 1 = 7297.04 loss)
I0316 12:21:26.220160 29479 solver.cpp:610] Iteration 74400, lr = 6.57906e-09
I0316 12:21:26.220175 29479 solver.cpp:613] Iteration 74400, avg_grad_norm = 488920
I0316 12:22:47.537698 29479 solver.cpp:214] Iteration 74420, loss = 5727.73
I0316 12:22:47.537827 29479 solver.cpp:229]     Train net output #0: loss = 2993.2 (* 1 = 2993.2 loss)
I0316 12:22:47.865936 29479 solver.cpp:610] Iteration 74420, lr = 6.57811e-09
I0316 12:22:47.865949 29479 solver.cpp:613] Iteration 74420, avg_grad_norm = 483872
I0316 12:23:55.991330 29479 solver.cpp:214] Iteration 74440, loss = 5595.59
I0316 12:23:55.991472 29479 solver.cpp:229]     Train net output #0: loss = 10184.2 (* 1 = 10184.2 loss)
I0316 12:23:56.357082 29479 solver.cpp:610] Iteration 74440, lr = 6.57717e-09
I0316 12:23:56.357096 29479 solver.cpp:613] Iteration 74440, avg_grad_norm = 551793
I0316 12:25:04.665630 29479 solver.cpp:214] Iteration 74460, loss = 5708.2
I0316 12:25:04.665737 29479 solver.cpp:229]     Train net output #0: loss = 8225.31 (* 1 = 8225.31 loss)
I0316 12:25:05.025872 29479 solver.cpp:610] Iteration 74460, lr = 6.57623e-09
I0316 12:25:05.025885 29479 solver.cpp:613] Iteration 74460, avg_grad_norm = 532436
I0316 12:26:12.308641 29479 solver.cpp:214] Iteration 74480, loss = 5918.57
I0316 12:26:12.308763 29479 solver.cpp:229]     Train net output #0: loss = 5976.33 (* 1 = 5976.33 loss)
I0316 12:26:12.677142 29479 solver.cpp:610] Iteration 74480, lr = 6.57529e-09
I0316 12:26:12.677155 29479 solver.cpp:613] Iteration 74480, avg_grad_norm = 553328
I0316 12:27:21.173398 29479 solver.cpp:214] Iteration 74500, loss = 5743.22
I0316 12:27:21.173588 29479 solver.cpp:229]     Train net output #0: loss = 4226.53 (* 1 = 4226.53 loss)
I0316 12:27:21.540200 29479 solver.cpp:610] Iteration 74500, lr = 6.57434e-09
I0316 12:27:21.540221 29479 solver.cpp:613] Iteration 74500, avg_grad_norm = 501927
I0316 12:28:20.206759 29479 solver.cpp:214] Iteration 74520, loss = 5945.85
I0316 12:28:20.206897 29479 solver.cpp:229]     Train net output #0: loss = 10746.7 (* 1 = 10746.7 loss)
I0316 12:28:20.319870 29479 solver.cpp:610] Iteration 74520, lr = 6.5734e-09
I0316 12:28:20.319919 29479 solver.cpp:613] Iteration 74520, avg_grad_norm = 487168
I0316 12:29:16.459733 29479 solver.cpp:214] Iteration 74540, loss = 5793.19
I0316 12:29:16.459877 29479 solver.cpp:229]     Train net output #0: loss = 3565.99 (* 1 = 3565.99 loss)
I0316 12:29:16.824023 29479 solver.cpp:610] Iteration 74540, lr = 6.57246e-09
I0316 12:29:16.824038 29479 solver.cpp:613] Iteration 74540, avg_grad_norm = 539005
I0316 12:30:36.994433 29479 solver.cpp:214] Iteration 74560, loss = 6073.44
I0316 12:30:36.994637 29479 solver.cpp:229]     Train net output #0: loss = 7151.29 (* 1 = 7151.29 loss)
I0316 12:30:37.359624 29479 solver.cpp:610] Iteration 74560, lr = 6.57151e-09
I0316 12:30:37.359637 29479 solver.cpp:613] Iteration 74560, avg_grad_norm = 564522
I0316 12:31:44.515597 29479 solver.cpp:214] Iteration 74580, loss = 5696.55
I0316 12:31:44.515789 29479 solver.cpp:229]     Train net output #0: loss = 4957.36 (* 1 = 4957.36 loss)
I0316 12:31:44.882128 29479 solver.cpp:610] Iteration 74580, lr = 6.57057e-09
I0316 12:31:44.882141 29479 solver.cpp:613] Iteration 74580, avg_grad_norm = 496448
I0316 12:32:52.662369 29479 solver.cpp:214] Iteration 74600, loss = 5705.1
I0316 12:32:52.662602 29479 solver.cpp:229]     Train net output #0: loss = 4118.24 (* 1 = 4118.24 loss)
I0316 12:32:53.034664 29479 solver.cpp:610] Iteration 74600, lr = 6.56963e-09
I0316 12:32:53.034677 29479 solver.cpp:613] Iteration 74600, avg_grad_norm = 544777
I0316 12:34:00.348649 29479 solver.cpp:214] Iteration 74620, loss = 5647.61
I0316 12:34:00.348778 29479 solver.cpp:229]     Train net output #0: loss = 4119.76 (* 1 = 4119.76 loss)
I0316 12:34:00.724422 29479 solver.cpp:610] Iteration 74620, lr = 6.56868e-09
I0316 12:34:00.724436 29479 solver.cpp:613] Iteration 74620, avg_grad_norm = 530951
I0316 12:35:08.338484 29479 solver.cpp:214] Iteration 74640, loss = 6030.46
I0316 12:35:08.338618 29479 solver.cpp:229]     Train net output #0: loss = 2147.97 (* 1 = 2147.97 loss)
I0316 12:35:08.706377 29479 solver.cpp:610] Iteration 74640, lr = 6.56774e-09
I0316 12:35:08.706389 29479 solver.cpp:613] Iteration 74640, avg_grad_norm = 493732
I0316 12:36:00.327613 29479 solver.cpp:214] Iteration 74660, loss = 5958.49
I0316 12:36:00.328800 29479 solver.cpp:229]     Train net output #0: loss = 4119.61 (* 1 = 4119.61 loss)
I0316 12:36:00.443629 29479 solver.cpp:610] Iteration 74660, lr = 6.5668e-09
I0316 12:36:00.443647 29479 solver.cpp:613] Iteration 74660, avg_grad_norm = 492646
I0316 12:37:15.740581 29479 solver.cpp:214] Iteration 74680, loss = 5859.15
I0316 12:37:15.740715 29479 solver.cpp:229]     Train net output #0: loss = 5488.25 (* 1 = 5488.25 loss)
I0316 12:37:16.107632 29479 solver.cpp:610] Iteration 74680, lr = 6.56586e-09
I0316 12:37:16.107646 29479 solver.cpp:613] Iteration 74680, avg_grad_norm = 499416
I0316 12:38:23.998309 29479 solver.cpp:214] Iteration 74700, loss = 5686.72
I0316 12:38:23.998440 29479 solver.cpp:229]     Train net output #0: loss = 2894.14 (* 1 = 2894.14 loss)
I0316 12:38:24.388130 29479 solver.cpp:610] Iteration 74700, lr = 6.56491e-09
I0316 12:38:24.388144 29479 solver.cpp:613] Iteration 74700, avg_grad_norm = 509757
I0316 12:39:31.483417 29479 solver.cpp:214] Iteration 74720, loss = 5708.63
I0316 12:39:31.483551 29479 solver.cpp:229]     Train net output #0: loss = 4189.47 (* 1 = 4189.47 loss)
I0316 12:39:31.846022 29479 solver.cpp:610] Iteration 74720, lr = 6.56397e-09
I0316 12:39:31.846036 29479 solver.cpp:613] Iteration 74720, avg_grad_norm = 536825
I0316 12:40:39.641201 29479 solver.cpp:214] Iteration 74740, loss = 5970.56
I0316 12:40:39.641299 29479 solver.cpp:229]     Train net output #0: loss = 5037.09 (* 1 = 5037.09 loss)
I0316 12:40:40.030632 29479 solver.cpp:610] Iteration 74740, lr = 6.56303e-09
I0316 12:40:40.030647 29479 solver.cpp:613] Iteration 74740, avg_grad_norm = 491776
I0316 12:41:47.483109 29479 solver.cpp:214] Iteration 74760, loss = 5373.01
I0316 12:41:47.483261 29479 solver.cpp:229]     Train net output #0: loss = 4437.79 (* 1 = 4437.79 loss)
I0316 12:41:47.845264 29479 solver.cpp:610] Iteration 74760, lr = 6.56208e-09
I0316 12:41:47.845278 29479 solver.cpp:613] Iteration 74760, avg_grad_norm = 504648
I0316 12:42:55.742097 29479 solver.cpp:214] Iteration 74780, loss = 5860.27
I0316 12:42:55.742208 29479 solver.cpp:229]     Train net output #0: loss = 6673.62 (* 1 = 6673.62 loss)
I0316 12:42:56.104878 29479 solver.cpp:610] Iteration 74780, lr = 6.56114e-09
I0316 12:42:56.104892 29479 solver.cpp:613] Iteration 74780, avg_grad_norm = 531990
I0316 12:43:57.603730 29479 solver.cpp:214] Iteration 74800, loss = 5827.29
I0316 12:43:57.603829 29479 solver.cpp:229]     Train net output #0: loss = 4650.09 (* 1 = 4650.09 loss)
I0316 12:43:57.972929 29479 solver.cpp:610] Iteration 74800, lr = 6.5602e-09
I0316 12:43:57.972944 29479 solver.cpp:613] Iteration 74800, avg_grad_norm = 521251
I0316 12:45:06.489311 29479 solver.cpp:214] Iteration 74820, loss = 5348.56
I0316 12:45:06.489509 29479 solver.cpp:229]     Train net output #0: loss = 4832.31 (* 1 = 4832.31 loss)
I0316 12:45:06.850790 29479 solver.cpp:610] Iteration 74820, lr = 6.55925e-09
I0316 12:45:06.850811 29479 solver.cpp:613] Iteration 74820, avg_grad_norm = 506374
I0316 12:46:14.812636 29479 solver.cpp:214] Iteration 74840, loss = 5606.04
I0316 12:46:14.812891 29479 solver.cpp:229]     Train net output #0: loss = 4538.76 (* 1 = 4538.76 loss)
I0316 12:46:15.174582 29479 solver.cpp:610] Iteration 74840, lr = 6.55831e-09
I0316 12:46:15.174615 29479 solver.cpp:613] Iteration 74840, avg_grad_norm = 477087
I0316 12:47:22.661603 29479 solver.cpp:214] Iteration 74860, loss = 5752.17
I0316 12:47:22.661749 29479 solver.cpp:229]     Train net output #0: loss = 4680.25 (* 1 = 4680.25 loss)
I0316 12:47:22.987414 29479 solver.cpp:610] Iteration 74860, lr = 6.55737e-09
I0316 12:47:22.987427 29479 solver.cpp:613] Iteration 74860, avg_grad_norm = 515283
I0316 12:48:30.699026 29479 solver.cpp:214] Iteration 74880, loss = 5874.77
I0316 12:48:30.699218 29479 solver.cpp:229]     Train net output #0: loss = 4554.04 (* 1 = 4554.04 loss)
I0316 12:48:31.062317 29479 solver.cpp:610] Iteration 74880, lr = 6.55642e-09
I0316 12:48:31.062330 29479 solver.cpp:613] Iteration 74880, avg_grad_norm = 492262
I0316 12:49:38.627993 29479 solver.cpp:214] Iteration 74900, loss = 5736.13
I0316 12:49:38.628114 29479 solver.cpp:229]     Train net output #0: loss = 4204.48 (* 1 = 4204.48 loss)
I0316 12:49:38.843673 29479 solver.cpp:610] Iteration 74900, lr = 6.55548e-09
I0316 12:49:38.843686 29479 solver.cpp:613] Iteration 74900, avg_grad_norm = 493880
I0316 12:50:47.068411 29479 solver.cpp:214] Iteration 74920, loss = 6056.85
I0316 12:50:47.068553 29479 solver.cpp:229]     Train net output #0: loss = 8058.56 (* 1 = 8058.56 loss)
I0316 12:50:47.434293 29479 solver.cpp:610] Iteration 74920, lr = 6.55454e-09
I0316 12:50:47.434306 29479 solver.cpp:613] Iteration 74920, avg_grad_norm = 484625
I0316 12:52:15.496222 29479 solver.cpp:214] Iteration 74940, loss = 5772.17
I0316 12:52:15.496422 29479 solver.cpp:229]     Train net output #0: loss = 3907.41 (* 1 = 3907.41 loss)
I0316 12:52:15.858278 29479 solver.cpp:610] Iteration 74940, lr = 6.55359e-09
I0316 12:52:15.858292 29479 solver.cpp:613] Iteration 74940, avg_grad_norm = 509397
I0316 12:53:23.156539 29479 solver.cpp:214] Iteration 74960, loss = 5685.53
I0316 12:53:23.156678 29479 solver.cpp:229]     Train net output #0: loss = 7138.55 (* 1 = 7138.55 loss)
I0316 12:53:23.520232 29479 solver.cpp:610] Iteration 74960, lr = 6.55265e-09
I0316 12:53:23.520248 29479 solver.cpp:613] Iteration 74960, avg_grad_norm = 535849
I0316 12:54:31.373035 29479 solver.cpp:214] Iteration 74980, loss = 5504.33
I0316 12:54:31.373150 29479 solver.cpp:229]     Train net output #0: loss = 5027.46 (* 1 = 5027.46 loss)
I0316 12:54:31.700145 29479 solver.cpp:610] Iteration 74980, lr = 6.55171e-09
I0316 12:54:31.700160 29479 solver.cpp:613] Iteration 74980, avg_grad_norm = 697345
I0316 12:55:39.317364 29479 solver.cpp:214] Iteration 75000, loss = 5340
I0316 12:55:39.317497 29479 solver.cpp:229]     Train net output #0: loss = 4542.4 (* 1 = 4542.4 loss)
I0316 12:55:39.679133 29479 solver.cpp:610] Iteration 75000, lr = 6.55076e-09
I0316 12:55:39.679147 29479 solver.cpp:613] Iteration 75000, avg_grad_norm = 580221
I0316 12:56:48.082182 29479 solver.cpp:214] Iteration 75020, loss = 5728.27
I0316 12:56:48.082315 29479 solver.cpp:229]     Train net output #0: loss = 8073.61 (* 1 = 8073.61 loss)
I0316 12:56:48.443337 29479 solver.cpp:610] Iteration 75020, lr = 6.54982e-09
I0316 12:56:48.443377 29479 solver.cpp:613] Iteration 75020, avg_grad_norm = 522718
I0316 12:57:56.331315 29479 solver.cpp:214] Iteration 75040, loss = 5661.33
I0316 12:57:56.331439 29479 solver.cpp:229]     Train net output #0: loss = 3033.95 (* 1 = 3033.95 loss)
I0316 12:57:56.700525 29479 solver.cpp:610] Iteration 75040, lr = 6.54888e-09
I0316 12:57:56.700539 29479 solver.cpp:613] Iteration 75040, avg_grad_norm = 511658
I0316 12:59:19.536218 29479 solver.cpp:214] Iteration 75060, loss = 5870.69
I0316 12:59:19.536347 29479 solver.cpp:229]     Train net output #0: loss = 4590.15 (* 1 = 4590.15 loss)
I0316 12:59:19.895303 29479 solver.cpp:610] Iteration 75060, lr = 6.54794e-09
I0316 12:59:19.895318 29479 solver.cpp:613] Iteration 75060, avg_grad_norm = 490255
I0316 13:00:27.098762 29479 solver.cpp:214] Iteration 75080, loss = 5885.6
I0316 13:00:27.098948 29479 solver.cpp:229]     Train net output #0: loss = 7613.24 (* 1 = 7613.24 loss)
I0316 13:00:27.425241 29479 solver.cpp:610] Iteration 75080, lr = 6.54699e-09
I0316 13:00:27.425254 29479 solver.cpp:613] Iteration 75080, avg_grad_norm = 509650
I0316 13:01:35.292414 29479 solver.cpp:214] Iteration 75100, loss = 5738.48
I0316 13:01:35.292556 29479 solver.cpp:229]     Train net output #0: loss = 9294.87 (* 1 = 9294.87 loss)
I0316 13:01:35.652674 29479 solver.cpp:610] Iteration 75100, lr = 6.54605e-09
I0316 13:01:35.652714 29479 solver.cpp:613] Iteration 75100, avg_grad_norm = 559818
I0316 13:02:42.884441 29479 solver.cpp:214] Iteration 75120, loss = 6135.64
I0316 13:02:42.884569 29479 solver.cpp:229]     Train net output #0: loss = 5865.85 (* 1 = 5865.85 loss)
I0316 13:02:43.245250 29479 solver.cpp:610] Iteration 75120, lr = 6.5451e-09
I0316 13:02:43.245263 29479 solver.cpp:613] Iteration 75120, avg_grad_norm = 541260
I0316 13:03:51.330777 29479 solver.cpp:214] Iteration 75140, loss = 5900.24
I0316 13:03:51.330904 29479 solver.cpp:229]     Train net output #0: loss = 4476.13 (* 1 = 4476.13 loss)
I0316 13:03:51.691612 29479 solver.cpp:610] Iteration 75140, lr = 6.54416e-09
I0316 13:03:51.691625 29479 solver.cpp:613] Iteration 75140, avg_grad_norm = 500686
I0316 13:04:59.254992 29479 solver.cpp:214] Iteration 75160, loss = 5905.26
I0316 13:04:59.255105 29479 solver.cpp:229]     Train net output #0: loss = 7414.55 (* 1 = 7414.55 loss)
I0316 13:04:59.617781 29479 solver.cpp:610] Iteration 75160, lr = 6.54322e-09
I0316 13:04:59.617795 29479 solver.cpp:613] Iteration 75160, avg_grad_norm = 546201
I0316 13:06:28.832365 29479 solver.cpp:214] Iteration 75180, loss = 5374.51
I0316 13:06:28.832509 29479 solver.cpp:229]     Train net output #0: loss = 4701.17 (* 1 = 4701.17 loss)
I0316 13:06:28.936765 29479 solver.cpp:610] Iteration 75180, lr = 6.54227e-09
I0316 13:06:28.936779 29479 solver.cpp:613] Iteration 75180, avg_grad_norm = 506570
I0316 13:07:07.967440 29479 solver.cpp:214] Iteration 75200, loss = 5804.29
I0316 13:07:07.967571 29479 solver.cpp:229]     Train net output #0: loss = 4804.21 (* 1 = 4804.21 loss)
I0316 13:07:08.331487 29479 solver.cpp:610] Iteration 75200, lr = 6.54133e-09
I0316 13:07:08.331501 29479 solver.cpp:613] Iteration 75200, avg_grad_norm = 500121
I0316 13:08:16.447353 29479 solver.cpp:214] Iteration 75220, loss = 5726.44
I0316 13:08:16.447465 29479 solver.cpp:229]     Train net output #0: loss = 3229.24 (* 1 = 3229.24 loss)
I0316 13:08:16.805912 29479 solver.cpp:610] Iteration 75220, lr = 6.54039e-09
I0316 13:08:16.805925 29479 solver.cpp:613] Iteration 75220, avg_grad_norm = 497756
I0316 13:09:24.182579 29479 solver.cpp:214] Iteration 75240, loss = 5837.37
I0316 13:09:24.182708 29479 solver.cpp:229]     Train net output #0: loss = 5058.29 (* 1 = 5058.29 loss)
I0316 13:09:24.562553 29479 solver.cpp:610] Iteration 75240, lr = 6.53944e-09
I0316 13:09:24.562566 29479 solver.cpp:613] Iteration 75240, avg_grad_norm = 518988
I0316 13:10:32.346303 29479 solver.cpp:214] Iteration 75260, loss = 5328.19
I0316 13:10:32.346427 29479 solver.cpp:229]     Train net output #0: loss = 5900.27 (* 1 = 5900.27 loss)
I0316 13:10:32.689504 29479 solver.cpp:610] Iteration 75260, lr = 6.5385e-09
I0316 13:10:32.689517 29479 solver.cpp:613] Iteration 75260, avg_grad_norm = 565103
I0316 13:11:40.064923 29479 solver.cpp:214] Iteration 75280, loss = 5700.23
I0316 13:11:40.065114 29479 solver.cpp:229]     Train net output #0: loss = 5278.79 (* 1 = 5278.79 loss)
I0316 13:11:40.431176 29479 solver.cpp:610] Iteration 75280, lr = 6.53756e-09
I0316 13:11:40.431190 29479 solver.cpp:613] Iteration 75280, avg_grad_norm = 529740
I0316 13:12:47.784976 29479 solver.cpp:214] Iteration 75300, loss = 5766.17
I0316 13:12:47.785145 29479 solver.cpp:229]     Train net output #0: loss = 4577.47 (* 1 = 4577.47 loss)
I0316 13:12:48.144706 29479 solver.cpp:610] Iteration 75300, lr = 6.53661e-09
I0316 13:12:48.144728 29479 solver.cpp:613] Iteration 75300, avg_grad_norm = 597705
I0316 13:14:05.278142 29479 solver.cpp:214] Iteration 75320, loss = 5510.76
I0316 13:14:05.278332 29479 solver.cpp:229]     Train net output #0: loss = 4438.24 (* 1 = 4438.24 loss)
I0316 13:14:05.384776 29479 solver.cpp:610] Iteration 75320, lr = 6.53567e-09
I0316 13:14:05.384817 29479 solver.cpp:613] Iteration 75320, avg_grad_norm = 566690
I0316 13:14:55.140213 29479 solver.cpp:214] Iteration 75340, loss = 5526.94
I0316 13:14:55.140368 29479 solver.cpp:229]     Train net output #0: loss = 5528.65 (* 1 = 5528.65 loss)
I0316 13:14:55.483479 29479 solver.cpp:610] Iteration 75340, lr = 6.53473e-09
I0316 13:14:55.483491 29479 solver.cpp:613] Iteration 75340, avg_grad_norm = 544339
I0316 13:16:02.598115 29479 solver.cpp:214] Iteration 75360, loss = 5705.18
I0316 13:16:02.598248 29479 solver.cpp:229]     Train net output #0: loss = 8122.34 (* 1 = 8122.34 loss)
I0316 13:16:02.963986 29479 solver.cpp:610] Iteration 75360, lr = 6.53378e-09
I0316 13:16:02.964000 29479 solver.cpp:613] Iteration 75360, avg_grad_norm = 536794
I0316 13:17:10.225219 29479 solver.cpp:214] Iteration 75380, loss = 5618.76
I0316 13:17:10.225352 29479 solver.cpp:229]     Train net output #0: loss = 3010.39 (* 1 = 3010.39 loss)
I0316 13:17:10.590973 29479 solver.cpp:610] Iteration 75380, lr = 6.53284e-09
I0316 13:17:10.590987 29479 solver.cpp:613] Iteration 75380, avg_grad_norm = 480415
I0316 13:18:19.043820 29479 solver.cpp:214] Iteration 75400, loss = 5691.48
I0316 13:18:19.043952 29479 solver.cpp:229]     Train net output #0: loss = 7269.58 (* 1 = 7269.58 loss)
I0316 13:18:19.405263 29479 solver.cpp:610] Iteration 75400, lr = 6.5319e-09
I0316 13:18:19.405277 29479 solver.cpp:613] Iteration 75400, avg_grad_norm = 519177
I0316 13:19:27.857203 29479 solver.cpp:214] Iteration 75420, loss = 5701.35
I0316 13:19:27.857409 29479 solver.cpp:229]     Train net output #0: loss = 5215.52 (* 1 = 5215.52 loss)
I0316 13:19:28.220471 29479 solver.cpp:610] Iteration 75420, lr = 6.53095e-09
I0316 13:19:28.220485 29479 solver.cpp:613] Iteration 75420, avg_grad_norm = 489617
I0316 13:20:47.823534 29479 solver.cpp:214] Iteration 75440, loss = 5818.92
I0316 13:20:47.823670 29479 solver.cpp:229]     Train net output #0: loss = 5630.71 (* 1 = 5630.71 loss)
I0316 13:20:48.194133 29479 solver.cpp:610] Iteration 75440, lr = 6.53001e-09
I0316 13:20:48.194149 29479 solver.cpp:613] Iteration 75440, avg_grad_norm = 498955
I0316 13:21:44.957733 29479 solver.cpp:214] Iteration 75460, loss = 5638.16
I0316 13:21:44.957871 29479 solver.cpp:229]     Train net output #0: loss = 7483.57 (* 1 = 7483.57 loss)
I0316 13:21:45.073896 29479 solver.cpp:610] Iteration 75460, lr = 6.52906e-09
I0316 13:21:45.073910 29479 solver.cpp:613] Iteration 75460, avg_grad_norm = 512860
I0316 13:22:43.433681 29479 solver.cpp:214] Iteration 75480, loss = 5956.54
I0316 13:22:43.433792 29479 solver.cpp:229]     Train net output #0: loss = 3652.31 (* 1 = 3652.31 loss)
I0316 13:22:43.805392 29479 solver.cpp:610] Iteration 75480, lr = 6.52812e-09
I0316 13:22:43.805405 29479 solver.cpp:613] Iteration 75480, avg_grad_norm = 523247
I0316 13:23:51.699604 29479 solver.cpp:214] Iteration 75500, loss = 5471.59
I0316 13:23:51.699792 29479 solver.cpp:229]     Train net output #0: loss = 6751.65 (* 1 = 6751.65 loss)
I0316 13:23:52.045969 29479 solver.cpp:610] Iteration 75500, lr = 6.52718e-09
I0316 13:23:52.045981 29479 solver.cpp:613] Iteration 75500, avg_grad_norm = 512401
I0316 13:24:56.205420 29479 solver.cpp:214] Iteration 75520, loss = 5691.96
I0316 13:24:56.205622 29479 solver.cpp:229]     Train net output #0: loss = 5439.94 (* 1 = 5439.94 loss)
I0316 13:24:56.568079 29479 solver.cpp:610] Iteration 75520, lr = 6.52623e-09
I0316 13:24:56.568092 29479 solver.cpp:613] Iteration 75520, avg_grad_norm = 575222
I0316 13:26:04.792518 29479 solver.cpp:214] Iteration 75540, loss = 5613.66
I0316 13:26:04.792773 29479 solver.cpp:229]     Train net output #0: loss = 5168.36 (* 1 = 5168.36 loss)
I0316 13:26:05.130888 29479 solver.cpp:610] Iteration 75540, lr = 6.52529e-09
I0316 13:26:05.130903 29479 solver.cpp:613] Iteration 75540, avg_grad_norm = 518846
I0316 13:27:13.801734 29479 solver.cpp:214] Iteration 75560, loss = 5676.42
I0316 13:27:13.801877 29479 solver.cpp:229]     Train net output #0: loss = 4552.13 (* 1 = 4552.13 loss)
I0316 13:27:14.160997 29479 solver.cpp:610] Iteration 75560, lr = 6.52435e-09
I0316 13:27:14.161012 29479 solver.cpp:613] Iteration 75560, avg_grad_norm = 539507
I0316 13:28:34.650957 29479 solver.cpp:214] Iteration 75580, loss = 5609.33
I0316 13:28:34.651092 29479 solver.cpp:229]     Train net output #0: loss = 3442.3 (* 1 = 3442.3 loss)
I0316 13:28:35.019794 29479 solver.cpp:610] Iteration 75580, lr = 6.5234e-09
I0316 13:28:35.019807 29479 solver.cpp:613] Iteration 75580, avg_grad_norm = 500737
I0316 13:29:25.041136 29479 solver.cpp:214] Iteration 75600, loss = 5827.5
I0316 13:29:25.041261 29479 solver.cpp:229]     Train net output #0: loss = 9345.2 (* 1 = 9345.2 loss)
I0316 13:29:25.157295 29479 solver.cpp:610] Iteration 75600, lr = 6.52246e-09
I0316 13:29:25.157310 29479 solver.cpp:613] Iteration 75600, avg_grad_norm = 488347
I0316 13:30:28.178022 29479 solver.cpp:214] Iteration 75620, loss = 5880.46
I0316 13:30:28.178139 29479 solver.cpp:229]     Train net output #0: loss = 3728.73 (* 1 = 3728.73 loss)
I0316 13:30:28.521881 29479 solver.cpp:610] Iteration 75620, lr = 6.52151e-09
I0316 13:30:28.521894 29479 solver.cpp:613] Iteration 75620, avg_grad_norm = 551177
I0316 13:31:36.276027 29479 solver.cpp:214] Iteration 75640, loss = 5784.95
I0316 13:31:36.276149 29479 solver.cpp:229]     Train net output #0: loss = 8618.54 (* 1 = 8618.54 loss)
I0316 13:31:36.645632 29479 solver.cpp:610] Iteration 75640, lr = 6.52057e-09
I0316 13:31:36.645645 29479 solver.cpp:613] Iteration 75640, avg_grad_norm = 535591
I0316 13:32:44.564654 29479 solver.cpp:214] Iteration 75660, loss = 5693.49
I0316 13:32:44.564846 29479 solver.cpp:229]     Train net output #0: loss = 3589.4 (* 1 = 3589.4 loss)
I0316 13:32:44.910053 29479 solver.cpp:610] Iteration 75660, lr = 6.51963e-09
I0316 13:32:44.910068 29479 solver.cpp:613] Iteration 75660, avg_grad_norm = 544852
I0316 13:33:52.306298 29479 solver.cpp:214] Iteration 75680, loss = 5920.46
I0316 13:33:52.306404 29479 solver.cpp:229]     Train net output #0: loss = 5406.33 (* 1 = 5406.33 loss)
I0316 13:33:52.669189 29479 solver.cpp:610] Iteration 75680, lr = 6.51868e-09
I0316 13:33:52.669203 29479 solver.cpp:613] Iteration 75680, avg_grad_norm = 611370
I0316 13:35:13.310891 29479 solver.cpp:214] Iteration 75700, loss = 5868.08
I0316 13:35:13.311091 29479 solver.cpp:229]     Train net output #0: loss = 10010.6 (* 1 = 10010.6 loss)
I0316 13:35:13.655419 29479 solver.cpp:610] Iteration 75700, lr = 6.51774e-09
I0316 13:35:13.655433 29479 solver.cpp:613] Iteration 75700, avg_grad_norm = 577377
I0316 13:36:21.657683 29479 solver.cpp:214] Iteration 75720, loss = 5862.51
I0316 13:36:21.657819 29479 solver.cpp:229]     Train net output #0: loss = 4440.4 (* 1 = 4440.4 loss)
I0316 13:36:22.027405 29479 solver.cpp:610] Iteration 75720, lr = 6.5168e-09
I0316 13:36:22.027454 29479 solver.cpp:613] Iteration 75720, avg_grad_norm = 612207
I0316 13:37:06.289561 29479 solver.cpp:214] Iteration 75740, loss = 5833.74
I0316 13:37:06.289680 29479 solver.cpp:229]     Train net output #0: loss = 4817.02 (* 1 = 4817.02 loss)
I0316 13:37:06.697756 29479 solver.cpp:610] Iteration 75740, lr = 6.51585e-09
I0316 13:37:06.697769 29479 solver.cpp:613] Iteration 75740, avg_grad_norm = 487688
I0316 13:38:14.281944 29479 solver.cpp:214] Iteration 75760, loss = 5703.31
I0316 13:38:14.282086 29479 solver.cpp:229]     Train net output #0: loss = 5837.95 (* 1 = 5837.95 loss)
I0316 13:38:14.649896 29479 solver.cpp:610] Iteration 75760, lr = 6.51491e-09
I0316 13:38:14.649910 29479 solver.cpp:613] Iteration 75760, avg_grad_norm = 499645
I0316 13:39:22.073410 29479 solver.cpp:214] Iteration 75780, loss = 5640.41
I0316 13:39:22.073601 29479 solver.cpp:229]     Train net output #0: loss = 4961.93 (* 1 = 4961.93 loss)
I0316 13:39:22.287127 29479 solver.cpp:610] Iteration 75780, lr = 6.51396e-09
I0316 13:39:22.287139 29479 solver.cpp:613] Iteration 75780, avg_grad_norm = 523263
I0316 13:40:29.861063 29479 solver.cpp:214] Iteration 75800, loss = 5778.46
I0316 13:40:29.861265 29479 solver.cpp:229]     Train net output #0: loss = 4313.61 (* 1 = 4313.61 loss)
I0316 13:40:30.224387 29479 solver.cpp:610] Iteration 75800, lr = 6.51302e-09
I0316 13:40:30.224409 29479 solver.cpp:613] Iteration 75800, avg_grad_norm = 520334
I0316 13:41:56.856402 29479 solver.cpp:214] Iteration 75820, loss = 5589.83
I0316 13:41:56.856509 29479 solver.cpp:229]     Train net output #0: loss = 4972.93 (* 1 = 4972.93 loss)
I0316 13:41:57.225332 29479 solver.cpp:610] Iteration 75820, lr = 6.51208e-09
I0316 13:41:57.225344 29479 solver.cpp:613] Iteration 75820, avg_grad_norm = 574355
I0316 13:43:06.051573 29479 solver.cpp:214] Iteration 75840, loss = 5622.13
I0316 13:43:06.051698 29479 solver.cpp:229]     Train net output #0: loss = 3381.76 (* 1 = 3381.76 loss)
I0316 13:43:06.417439 29479 solver.cpp:610] Iteration 75840, lr = 6.51113e-09
I0316 13:43:06.417456 29479 solver.cpp:613] Iteration 75840, avg_grad_norm = 494554
I0316 13:44:15.078336 29479 solver.cpp:214] Iteration 75860, loss = 5595.88
I0316 13:44:15.078459 29479 solver.cpp:229]     Train net output #0: loss = 8998.25 (* 1 = 8998.25 loss)
I0316 13:44:15.438601 29479 solver.cpp:610] Iteration 75860, lr = 6.51019e-09
I0316 13:44:15.438616 29479 solver.cpp:613] Iteration 75860, avg_grad_norm = 480474
I0316 13:45:01.965812 29479 solver.cpp:214] Iteration 75880, loss = 5729.94
I0316 13:45:01.965950 29479 solver.cpp:229]     Train net output #0: loss = 7065.55 (* 1 = 7065.55 loss)
I0316 13:45:02.326328 29479 solver.cpp:610] Iteration 75880, lr = 6.50924e-09
I0316 13:45:02.326341 29479 solver.cpp:613] Iteration 75880, avg_grad_norm = 491645
I0316 13:46:09.884213 29479 solver.cpp:214] Iteration 75900, loss = 5800.19
I0316 13:46:09.884356 29479 solver.cpp:229]     Train net output #0: loss = 4544.39 (* 1 = 4544.39 loss)
I0316 13:46:10.254150 29479 solver.cpp:610] Iteration 75900, lr = 6.5083e-09
I0316 13:46:10.254164 29479 solver.cpp:613] Iteration 75900, avg_grad_norm = 494179
I0316 13:47:18.773082 29479 solver.cpp:214] Iteration 75920, loss = 5993.13
I0316 13:47:18.773191 29479 solver.cpp:229]     Train net output #0: loss = 2966.84 (* 1 = 2966.84 loss)
I0316 13:47:19.128468 29479 solver.cpp:610] Iteration 75920, lr = 6.50736e-09
I0316 13:47:19.128482 29479 solver.cpp:613] Iteration 75920, avg_grad_norm = 486962
I0316 13:48:28.033390 29479 solver.cpp:214] Iteration 75940, loss = 5624.63
I0316 13:48:28.033514 29479 solver.cpp:229]     Train net output #0: loss = 5226.48 (* 1 = 5226.48 loss)
I0316 13:48:28.399868 29479 solver.cpp:610] Iteration 75940, lr = 6.50641e-09
I0316 13:48:28.399883 29479 solver.cpp:613] Iteration 75940, avg_grad_norm = 484248
I0316 13:49:49.935143 29479 solver.cpp:214] Iteration 75960, loss = 5859.35
I0316 13:49:49.935287 29479 solver.cpp:229]     Train net output #0: loss = 3340.66 (* 1 = 3340.66 loss)
I0316 13:49:50.281958 29479 solver.cpp:610] Iteration 75960, lr = 6.50547e-09
I0316 13:49:50.281975 29479 solver.cpp:613] Iteration 75960, avg_grad_norm = 501807
I0316 13:50:57.038676 29479 solver.cpp:214] Iteration 75980, loss = 5775.22
I0316 13:50:57.038771 29479 solver.cpp:229]     Train net output #0: loss = 3758.3 (* 1 = 3758.3 loss)
I0316 13:50:57.402758 29479 solver.cpp:610] Iteration 75980, lr = 6.50452e-09
I0316 13:50:57.402772 29479 solver.cpp:613] Iteration 75980, avg_grad_norm = 503799
I0316 13:52:01.054555 29479 solver.cpp:214] Iteration 76000, loss = 5765.69
I0316 13:52:01.054687 29479 solver.cpp:229]     Train net output #0: loss = 6859.51 (* 1 = 6859.51 loss)
I0316 13:52:01.165093 29479 solver.cpp:610] Iteration 76000, lr = 6.50358e-09
I0316 13:52:01.165128 29479 solver.cpp:613] Iteration 76000, avg_grad_norm = 486890
I0316 13:52:53.119354 29479 solver.cpp:214] Iteration 76020, loss = 5693.01
I0316 13:52:53.119524 29479 solver.cpp:229]     Train net output #0: loss = 5385.95 (* 1 = 5385.95 loss)
I0316 13:52:53.460046 29479 solver.cpp:610] Iteration 76020, lr = 6.50264e-09
I0316 13:52:53.460059 29479 solver.cpp:613] Iteration 76020, avg_grad_norm = 488383
I0316 13:54:00.019244 29479 solver.cpp:214] Iteration 76040, loss = 5615.8
I0316 13:54:00.019387 29479 solver.cpp:229]     Train net output #0: loss = 6805.08 (* 1 = 6805.08 loss)
I0316 13:54:00.388550 29479 solver.cpp:610] Iteration 76040, lr = 6.50169e-09
I0316 13:54:00.388563 29479 solver.cpp:613] Iteration 76040, avg_grad_norm = 500917
I0316 13:55:08.196285 29479 solver.cpp:214] Iteration 76060, loss = 5834.19
I0316 13:55:08.196405 29479 solver.cpp:229]     Train net output #0: loss = 6887.09 (* 1 = 6887.09 loss)
I0316 13:55:08.559739 29479 solver.cpp:610] Iteration 76060, lr = 6.50075e-09
I0316 13:55:08.559752 29479 solver.cpp:613] Iteration 76060, avg_grad_norm = 550021
I0316 13:56:29.685189 29479 solver.cpp:214] Iteration 76080, loss = 5482.75
I0316 13:56:29.685358 29479 solver.cpp:229]     Train net output #0: loss = 6737.61 (* 1 = 6737.61 loss)
I0316 13:56:30.047971 29479 solver.cpp:610] Iteration 76080, lr = 6.4998e-09
I0316 13:56:30.047984 29479 solver.cpp:613] Iteration 76080, avg_grad_norm = 511377
I0316 13:57:37.435449 29479 solver.cpp:214] Iteration 76100, loss = 5786.48
I0316 13:57:37.435571 29479 solver.cpp:229]     Train net output #0: loss = 4347.25 (* 1 = 4347.25 loss)
I0316 13:57:37.825456 29479 solver.cpp:610] Iteration 76100, lr = 6.49886e-09
I0316 13:57:37.825469 29479 solver.cpp:613] Iteration 76100, avg_grad_norm = 483745
I0316 13:58:45.984797 29479 solver.cpp:214] Iteration 76120, loss = 6026.43
I0316 13:58:45.984956 29479 solver.cpp:229]     Train net output #0: loss = 4257.64 (* 1 = 4257.64 loss)
I0316 13:58:46.183732 29479 solver.cpp:610] Iteration 76120, lr = 6.49792e-09
I0316 13:58:46.183766 29479 solver.cpp:613] Iteration 76120, avg_grad_norm = 508933
I0316 13:59:41.577782 29479 solver.cpp:214] Iteration 76140, loss = 5573.23
I0316 13:59:41.577930 29479 solver.cpp:229]     Train net output #0: loss = 5287 (* 1 = 5287 loss)
I0316 13:59:41.693938 29479 solver.cpp:610] Iteration 76140, lr = 6.49697e-09
I0316 13:59:41.693953 29479 solver.cpp:613] Iteration 76140, avg_grad_norm = 572871
I0316 14:00:41.328694 29479 solver.cpp:214] Iteration 76160, loss = 5875.81
I0316 14:00:41.328837 29479 solver.cpp:229]     Train net output #0: loss = 6727.8 (* 1 = 6727.8 loss)
I0316 14:00:41.688406 29479 solver.cpp:610] Iteration 76160, lr = 6.49603e-09
I0316 14:00:41.688421 29479 solver.cpp:613] Iteration 76160, avg_grad_norm = 613092
I0316 14:01:49.056429 29479 solver.cpp:214] Iteration 76180, loss = 5697.61
I0316 14:01:49.056612 29479 solver.cpp:229]     Train net output #0: loss = 4605.73 (* 1 = 4605.73 loss)
I0316 14:01:49.427665 29479 solver.cpp:610] Iteration 76180, lr = 6.49508e-09
I0316 14:01:49.427680 29479 solver.cpp:613] Iteration 76180, avg_grad_norm = 561820
I0316 14:03:16.317910 29479 solver.cpp:214] Iteration 76200, loss = 5729.68
I0316 14:03:16.318033 29479 solver.cpp:229]     Train net output #0: loss = 4724.12 (* 1 = 4724.12 loss)
I0316 14:03:16.656424 29479 solver.cpp:610] Iteration 76200, lr = 6.49414e-09
I0316 14:03:16.656436 29479 solver.cpp:613] Iteration 76200, avg_grad_norm = 515705
I0316 14:04:24.137621 29479 solver.cpp:214] Iteration 76220, loss = 5603.89
I0316 14:04:24.137753 29479 solver.cpp:229]     Train net output #0: loss = 11201.2 (* 1 = 11201.2 loss)
I0316 14:04:24.503917 29479 solver.cpp:610] Iteration 76220, lr = 6.49319e-09
I0316 14:04:24.503931 29479 solver.cpp:613] Iteration 76220, avg_grad_norm = 494570
I0316 14:05:32.759019 29479 solver.cpp:214] Iteration 76240, loss = 5950.33
I0316 14:05:32.759150 29479 solver.cpp:229]     Train net output #0: loss = 10876.3 (* 1 = 10876.3 loss)
I0316 14:05:33.121634 29479 solver.cpp:610] Iteration 76240, lr = 6.49225e-09
I0316 14:05:33.121651 29479 solver.cpp:613] Iteration 76240, avg_grad_norm = 490786
I0316 14:06:40.754696 29479 solver.cpp:214] Iteration 76260, loss = 5939
I0316 14:06:40.754875 29479 solver.cpp:229]     Train net output #0: loss = 5936.52 (* 1 = 5936.52 loss)
I0316 14:06:41.124243 29479 solver.cpp:610] Iteration 76260, lr = 6.49131e-09
I0316 14:06:41.124256 29479 solver.cpp:613] Iteration 76260, avg_grad_norm = 515928
I0316 14:07:27.473142 29479 solver.cpp:214] Iteration 76280, loss = 6111.61
I0316 14:07:27.473264 29479 solver.cpp:229]     Train net output #0: loss = 9697.85 (* 1 = 9697.85 loss)
I0316 14:07:27.866811 29479 solver.cpp:610] Iteration 76280, lr = 6.49036e-09
I0316 14:07:27.866824 29479 solver.cpp:613] Iteration 76280, avg_grad_norm = 528772
I0316 14:08:35.876292 29479 solver.cpp:214] Iteration 76300, loss = 5806.58
I0316 14:08:35.876423 29479 solver.cpp:229]     Train net output #0: loss = 5798.25 (* 1 = 5798.25 loss)
I0316 14:08:36.244983 29479 solver.cpp:610] Iteration 76300, lr = 6.48942e-09
I0316 14:08:36.245008 29479 solver.cpp:613] Iteration 76300, avg_grad_norm = 480807
I0316 14:09:44.270661 29479 solver.cpp:214] Iteration 76320, loss = 5920.96
I0316 14:09:44.270799 29479 solver.cpp:229]     Train net output #0: loss = 9471.25 (* 1 = 9471.25 loss)
I0316 14:09:44.635921 29479 solver.cpp:610] Iteration 76320, lr = 6.48847e-09
I0316 14:09:44.635960 29479 solver.cpp:613] Iteration 76320, avg_grad_norm = 483101
I0316 14:11:05.581687 29479 solver.cpp:214] Iteration 76340, loss = 5804.58
I0316 14:11:05.581806 29479 solver.cpp:229]     Train net output #0: loss = 8165.48 (* 1 = 8165.48 loss)
I0316 14:11:05.781662 29479 solver.cpp:610] Iteration 76340, lr = 6.48753e-09
I0316 14:11:05.781677 29479 solver.cpp:613] Iteration 76340, avg_grad_norm = 512691
I0316 14:12:13.017237 29479 solver.cpp:214] Iteration 76360, loss = 5842.7
I0316 14:12:13.017369 29479 solver.cpp:229]     Train net output #0: loss = 3841.34 (* 1 = 3841.34 loss)
I0316 14:12:13.353596 29479 solver.cpp:610] Iteration 76360, lr = 6.48659e-09
I0316 14:12:13.353610 29479 solver.cpp:613] Iteration 76360, avg_grad_norm = 535846
I0316 14:13:20.071732 29479 solver.cpp:214] Iteration 76380, loss = 5841.15
I0316 14:13:20.071871 29479 solver.cpp:229]     Train net output #0: loss = 11734.9 (* 1 = 11734.9 loss)
I0316 14:13:20.440593 29479 solver.cpp:610] Iteration 76380, lr = 6.48564e-09
I0316 14:13:20.440608 29479 solver.cpp:613] Iteration 76380, avg_grad_norm = 527473
I0316 14:14:29.083614 29479 solver.cpp:214] Iteration 76400, loss = 5645.7
I0316 14:14:29.083739 29479 solver.cpp:229]     Train net output #0: loss = 4193.23 (* 1 = 4193.23 loss)
I0316 14:14:29.442976 29479 solver.cpp:610] Iteration 76400, lr = 6.4847e-09
I0316 14:14:29.442989 29479 solver.cpp:613] Iteration 76400, avg_grad_norm = 549453
I0316 14:15:16.096125 29479 solver.cpp:214] Iteration 76420, loss = 6063.41
I0316 14:15:16.096245 29479 solver.cpp:229]     Train net output #0: loss = 3930.11 (* 1 = 3930.11 loss)
I0316 14:15:16.458974 29479 solver.cpp:610] Iteration 76420, lr = 6.48375e-09
I0316 14:15:16.458988 29479 solver.cpp:613] Iteration 76420, avg_grad_norm = 653383
I0316 14:16:24.445772 29479 solver.cpp:214] Iteration 76440, loss = 5624.48
I0316 14:16:24.445900 29479 solver.cpp:229]     Train net output #0: loss = 5076.7 (* 1 = 5076.7 loss)
I0316 14:16:24.836287 29479 solver.cpp:610] Iteration 76440, lr = 6.48281e-09
I0316 14:16:24.836299 29479 solver.cpp:613] Iteration 76440, avg_grad_norm = 564370
I0316 14:17:53.917484 29479 solver.cpp:214] Iteration 76460, loss = 5776.55
I0316 14:17:53.917616 29479 solver.cpp:229]     Train net output #0: loss = 9176.4 (* 1 = 9176.4 loss)
I0316 14:17:54.297451 29479 solver.cpp:610] Iteration 76460, lr = 6.48186e-09
I0316 14:17:54.297466 29479 solver.cpp:613] Iteration 76460, avg_grad_norm = 489694
I0316 14:19:01.376617 29479 solver.cpp:214] Iteration 76480, loss = 5634.7
I0316 14:19:01.376791 29479 solver.cpp:229]     Train net output #0: loss = 4744.01 (* 1 = 4744.01 loss)
I0316 14:19:01.563643 29479 solver.cpp:610] Iteration 76480, lr = 6.48092e-09
I0316 14:19:01.563657 29479 solver.cpp:613] Iteration 76480, avg_grad_norm = 479365
I0316 14:20:08.891206 29479 solver.cpp:214] Iteration 76500, loss = 5525.91
I0316 14:20:08.891402 29479 solver.cpp:229]     Train net output #0: loss = 3915.98 (* 1 = 3915.98 loss)
I0316 14:20:09.254631 29479 solver.cpp:610] Iteration 76500, lr = 6.47997e-09
I0316 14:20:09.254645 29479 solver.cpp:613] Iteration 76500, avg_grad_norm = 471918
I0316 14:21:16.332978 29479 solver.cpp:214] Iteration 76520, loss = 5861.43
I0316 14:21:16.333107 29479 solver.cpp:229]     Train net output #0: loss = 4211.73 (* 1 = 4211.73 loss)
I0316 14:21:16.677778 29479 solver.cpp:610] Iteration 76520, lr = 6.47903e-09
I0316 14:21:16.677790 29479 solver.cpp:613] Iteration 76520, avg_grad_norm = 474679
I0316 14:22:17.165465 29479 solver.cpp:214] Iteration 76540, loss = 5814.99
I0316 14:22:17.165616 29479 solver.cpp:229]     Train net output #0: loss = 4000 (* 1 = 4000 loss)
I0316 14:22:17.278606 29479 solver.cpp:610] Iteration 76540, lr = 6.47809e-09
I0316 14:22:17.278620 29479 solver.cpp:613] Iteration 76540, avg_grad_norm = 497871
I0316 14:23:10.425671 29479 solver.cpp:214] Iteration 76560, loss = 5976.92
I0316 14:23:10.425812 29479 solver.cpp:229]     Train net output #0: loss = 4251.62 (* 1 = 4251.62 loss)
I0316 14:23:10.771376 29479 solver.cpp:610] Iteration 76560, lr = 6.47714e-09
I0316 14:23:10.771389 29479 solver.cpp:613] Iteration 76560, avg_grad_norm = 537506
I0316 14:24:32.009361 29479 solver.cpp:214] Iteration 76580, loss = 5947.65
I0316 14:24:32.009485 29479 solver.cpp:229]     Train net output #0: loss = 6305.63 (* 1 = 6305.63 loss)
I0316 14:24:32.372759 29479 solver.cpp:610] Iteration 76580, lr = 6.4762e-09
I0316 14:24:32.372772 29479 solver.cpp:613] Iteration 76580, avg_grad_norm = 516982
I0316 14:25:39.981314 29479 solver.cpp:214] Iteration 76600, loss = 5892.38
I0316 14:25:39.981457 29479 solver.cpp:229]     Train net output #0: loss = 9764.86 (* 1 = 9764.86 loss)
I0316 14:25:40.347746 29479 solver.cpp:610] Iteration 76600, lr = 6.47525e-09
I0316 14:25:40.347760 29479 solver.cpp:613] Iteration 76600, avg_grad_norm = 499652
I0316 14:26:48.653964 29479 solver.cpp:214] Iteration 76620, loss = 5695.29
I0316 14:26:48.654075 29479 solver.cpp:229]     Train net output #0: loss = 4237.95 (* 1 = 4237.95 loss)
I0316 14:26:49.021199 29479 solver.cpp:610] Iteration 76620, lr = 6.47431e-09
I0316 14:26:49.021215 29479 solver.cpp:613] Iteration 76620, avg_grad_norm = 478746
I0316 14:27:57.036772 29479 solver.cpp:214] Iteration 76640, loss = 5775.19
I0316 14:27:57.036909 29479 solver.cpp:229]     Train net output #0: loss = 7808.24 (* 1 = 7808.24 loss)
I0316 14:27:57.406024 29479 solver.cpp:610] Iteration 76640, lr = 6.47336e-09
I0316 14:27:57.406038 29479 solver.cpp:613] Iteration 76640, avg_grad_norm = 484788
I0316 14:29:05.019255 29479 solver.cpp:214] Iteration 76660, loss = 5738.6
I0316 14:29:05.019390 29479 solver.cpp:229]     Train net output #0: loss = 8887.45 (* 1 = 8887.45 loss)
I0316 14:29:05.361922 29479 solver.cpp:610] Iteration 76660, lr = 6.47242e-09
I0316 14:29:05.361937 29479 solver.cpp:613] Iteration 76660, avg_grad_norm = 494818
I0316 14:29:57.535845 29479 solver.cpp:214] Iteration 76680, loss = 5805.9
I0316 14:29:57.535977 29479 solver.cpp:229]     Train net output #0: loss = 8690.29 (* 1 = 8690.29 loss)
I0316 14:29:57.650614 29479 solver.cpp:610] Iteration 76680, lr = 6.47147e-09
I0316 14:29:57.650629 29479 solver.cpp:613] Iteration 76680, avg_grad_norm = 566124
I0316 14:30:58.902081 29479 solver.cpp:214] Iteration 76700, loss = 5721.3
I0316 14:30:58.902204 29479 solver.cpp:229]     Train net output #0: loss = 4748.69 (* 1 = 4748.69 loss)
I0316 14:30:59.263121 29479 solver.cpp:610] Iteration 76700, lr = 6.47053e-09
I0316 14:30:59.263135 29479 solver.cpp:613] Iteration 76700, avg_grad_norm = 509589
I0316 14:32:22.002295 29479 solver.cpp:214] Iteration 76720, loss = 6173.56
I0316 14:32:22.002501 29479 solver.cpp:229]     Train net output #0: loss = 4673.07 (* 1 = 4673.07 loss)
I0316 14:32:22.371219 29479 solver.cpp:610] Iteration 76720, lr = 6.46958e-09
I0316 14:32:22.371233 29479 solver.cpp:613] Iteration 76720, avg_grad_norm = 514903
I0316 14:33:30.235415 29479 solver.cpp:214] Iteration 76740, loss = 5785.31
I0316 14:33:30.235571 29479 solver.cpp:229]     Train net output #0: loss = 6327.84 (* 1 = 6327.84 loss)
I0316 14:33:30.628407 29479 solver.cpp:610] Iteration 76740, lr = 6.46864e-09
I0316 14:33:30.628420 29479 solver.cpp:613] Iteration 76740, avg_grad_norm = 519702
I0316 14:34:38.478075 29479 solver.cpp:214] Iteration 76760, loss = 5532.54
I0316 14:34:38.478225 29479 solver.cpp:229]     Train net output #0: loss = 4733.01 (* 1 = 4733.01 loss)
I0316 14:34:38.677054 29479 solver.cpp:610] Iteration 76760, lr = 6.46769e-09
I0316 14:34:38.677068 29479 solver.cpp:613] Iteration 76760, avg_grad_norm = 504175
I0316 14:35:46.341168 29479 solver.cpp:214] Iteration 76780, loss = 5541.64
I0316 14:35:46.341284 29479 solver.cpp:229]     Train net output #0: loss = 2845.4 (* 1 = 2845.4 loss)
I0316 14:35:46.707409 29479 solver.cpp:610] Iteration 76780, lr = 6.46675e-09
I0316 14:35:46.707422 29479 solver.cpp:613] Iteration 76780, avg_grad_norm = 506430
I0316 14:36:54.332866 29479 solver.cpp:214] Iteration 76800, loss = 5783.23
I0316 14:36:54.332986 29479 solver.cpp:229]     Train net output #0: loss = 5310.13 (* 1 = 5310.13 loss)
I0316 14:36:54.695983 29479 solver.cpp:610] Iteration 76800, lr = 6.46581e-09
I0316 14:36:54.695997 29479 solver.cpp:613] Iteration 76800, avg_grad_norm = 544353
I0316 14:37:41.649679 29479 solver.cpp:214] Iteration 76820, loss = 5696.55
I0316 14:37:41.649796 29479 solver.cpp:229]     Train net output #0: loss = 5212.4 (* 1 = 5212.4 loss)
I0316 14:37:42.020159 29479 solver.cpp:610] Iteration 76820, lr = 6.46486e-09
I0316 14:37:42.020172 29479 solver.cpp:613] Iteration 76820, avg_grad_norm = 494734
I0316 14:39:20.863087 29479 solver.cpp:214] Iteration 76840, loss = 5814.49
I0316 14:39:20.863234 29479 solver.cpp:229]     Train net output #0: loss = 6600.02 (* 1 = 6600.02 loss)
I0316 14:39:21.221113 29479 solver.cpp:610] Iteration 76840, lr = 6.46392e-09
I0316 14:39:21.221127 29479 solver.cpp:613] Iteration 76840, avg_grad_norm = 506555
I0316 14:40:29.588390 29479 solver.cpp:214] Iteration 76860, loss = 5863.71
I0316 14:40:29.588512 29479 solver.cpp:229]     Train net output #0: loss = 2732.15 (* 1 = 2732.15 loss)
I0316 14:40:29.954923 29479 solver.cpp:610] Iteration 76860, lr = 6.46297e-09
I0316 14:40:29.954937 29479 solver.cpp:613] Iteration 76860, avg_grad_norm = 517148
I0316 14:41:37.236587 29479 solver.cpp:214] Iteration 76880, loss = 5886.43
I0316 14:41:37.236699 29479 solver.cpp:229]     Train net output #0: loss = 4486.87 (* 1 = 4486.87 loss)
I0316 14:41:37.597936 29479 solver.cpp:610] Iteration 76880, lr = 6.46203e-09
I0316 14:41:37.597950 29479 solver.cpp:613] Iteration 76880, avg_grad_norm = 499573
I0316 14:42:44.792202 29479 solver.cpp:214] Iteration 76900, loss = 6156.74
I0316 14:42:44.792311 29479 solver.cpp:229]     Train net output #0: loss = 8732.61 (* 1 = 8732.61 loss)
I0316 14:42:45.163673 29479 solver.cpp:610] Iteration 76900, lr = 6.46108e-09
I0316 14:42:45.163686 29479 solver.cpp:613] Iteration 76900, avg_grad_norm = 523967
I0316 14:43:52.763370 29479 solver.cpp:214] Iteration 76920, loss = 5595.13
I0316 14:43:52.763496 29479 solver.cpp:229]     Train net output #0: loss = 3980.03 (* 1 = 3980.03 loss)
I0316 14:43:53.103967 29479 solver.cpp:610] Iteration 76920, lr = 6.46014e-09
I0316 14:43:53.103981 29479 solver.cpp:613] Iteration 76920, avg_grad_norm = 478615
I0316 14:44:58.863580 29479 solver.cpp:214] Iteration 76940, loss = 5919.81
I0316 14:44:58.863787 29479 solver.cpp:229]     Train net output #0: loss = 4068.22 (* 1 = 4068.22 loss)
I0316 14:44:58.967703 29479 solver.cpp:610] Iteration 76940, lr = 6.45919e-09
I0316 14:44:58.967718 29479 solver.cpp:613] Iteration 76940, avg_grad_norm = 564559
I0316 14:46:08.626351 29479 solver.cpp:214] Iteration 76960, loss = 5797.87
I0316 14:46:08.626497 29479 solver.cpp:229]     Train net output #0: loss = 7845.77 (* 1 = 7845.77 loss)
I0316 14:46:08.985474 29479 solver.cpp:610] Iteration 76960, lr = 6.45825e-09
I0316 14:46:08.985489 29479 solver.cpp:613] Iteration 76960, avg_grad_norm = 500003
I0316 14:47:18.466264 29479 solver.cpp:214] Iteration 76980, loss = 5677.67
I0316 14:47:18.466459 29479 solver.cpp:229]     Train net output #0: loss = 1947.17 (* 1 = 1947.17 loss)
I0316 14:47:18.832633 29479 solver.cpp:610] Iteration 76980, lr = 6.4573e-09
I0316 14:47:18.832648 29479 solver.cpp:613] Iteration 76980, avg_grad_norm = 571410
I0316 14:48:27.163331 29479 solver.cpp:214] Iteration 77000, loss = 5583.44
I0316 14:48:27.163523 29479 solver.cpp:229]     Train net output #0: loss = 6206 (* 1 = 6206 loss)
I0316 14:48:27.524211 29479 solver.cpp:610] Iteration 77000, lr = 6.45636e-09
I0316 14:48:27.524225 29479 solver.cpp:613] Iteration 77000, avg_grad_norm = 600431
I0316 14:49:36.496141 29479 solver.cpp:214] Iteration 77020, loss = 5597.12
I0316 14:49:36.496255 29479 solver.cpp:229]     Train net output #0: loss = 5095.79 (* 1 = 5095.79 loss)
I0316 14:49:36.864794 29479 solver.cpp:610] Iteration 77020, lr = 6.45541e-09
I0316 14:49:36.864807 29479 solver.cpp:613] Iteration 77020, avg_grad_norm = 517071
I0316 14:50:45.706799 29479 solver.cpp:214] Iteration 77040, loss = 5393.58
I0316 14:50:45.707001 29479 solver.cpp:229]     Train net output #0: loss = 4970.98 (* 1 = 4970.98 loss)
I0316 14:50:46.045701 29479 solver.cpp:610] Iteration 77040, lr = 6.45447e-09
I0316 14:50:46.045720 29479 solver.cpp:613] Iteration 77040, avg_grad_norm = 485281
I0316 14:51:54.358435 29479 solver.cpp:214] Iteration 77060, loss = 5813.13
I0316 14:51:54.358554 29479 solver.cpp:229]     Train net output #0: loss = 12460.2 (* 1 = 12460.2 loss)
I0316 14:51:54.719045 29479 solver.cpp:610] Iteration 77060, lr = 6.45352e-09
I0316 14:51:54.719059 29479 solver.cpp:613] Iteration 77060, avg_grad_norm = 483125
I0316 14:52:41.005316 29479 solver.cpp:214] Iteration 77080, loss = 5687.56
I0316 14:52:41.005437 29479 solver.cpp:229]     Train net output #0: loss = 4507.2 (* 1 = 4507.2 loss)
I0316 14:52:41.243644 29479 solver.cpp:610] Iteration 77080, lr = 6.45258e-09
I0316 14:52:41.243659 29479 solver.cpp:613] Iteration 77080, avg_grad_norm = 505809
I0316 14:54:02.061235 29479 solver.cpp:214] Iteration 77100, loss = 5854.71
I0316 14:54:02.061350 29479 solver.cpp:229]     Train net output #0: loss = 7974.05 (* 1 = 7974.05 loss)
I0316 14:54:02.422348 29479 solver.cpp:610] Iteration 77100, lr = 6.45163e-09
I0316 14:54:02.422361 29479 solver.cpp:613] Iteration 77100, avg_grad_norm = 574258
I0316 14:55:10.902838 29479 solver.cpp:214] Iteration 77120, loss = 5908.14
I0316 14:55:10.902957 29479 solver.cpp:229]     Train net output #0: loss = 3862.86 (* 1 = 3862.86 loss)
I0316 14:55:11.246949 29479 solver.cpp:610] Iteration 77120, lr = 6.45069e-09
I0316 14:55:11.246963 29479 solver.cpp:613] Iteration 77120, avg_grad_norm = 543054
I0316 14:56:19.889596 29479 solver.cpp:214] Iteration 77140, loss = 5730.47
I0316 14:56:19.889725 29479 solver.cpp:229]     Train net output #0: loss = 5548.92 (* 1 = 5548.92 loss)
I0316 14:56:20.250632 29479 solver.cpp:610] Iteration 77140, lr = 6.44974e-09
I0316 14:56:20.250644 29479 solver.cpp:613] Iteration 77140, avg_grad_norm = 584631
I0316 14:57:27.408058 29479 solver.cpp:214] Iteration 77160, loss = 5911.86
I0316 14:57:27.408190 29479 solver.cpp:229]     Train net output #0: loss = 7780.01 (* 1 = 7780.01 loss)
I0316 14:57:27.771303 29479 solver.cpp:610] Iteration 77160, lr = 6.4488e-09
I0316 14:57:27.771317 29479 solver.cpp:613] Iteration 77160, avg_grad_norm = 512810
I0316 14:58:35.238087 29479 solver.cpp:214] Iteration 77180, loss = 5689.58
I0316 14:58:35.238210 29479 solver.cpp:229]     Train net output #0: loss = 6835.98 (* 1 = 6835.98 loss)
I0316 14:58:35.607959 29479 solver.cpp:610] Iteration 77180, lr = 6.44785e-09
I0316 14:58:35.607971 29479 solver.cpp:613] Iteration 77180, avg_grad_norm = 508995
I0316 14:59:43.655937 29479 solver.cpp:214] Iteration 77200, loss = 5868.72
I0316 14:59:43.656067 29479 solver.cpp:229]     Train net output #0: loss = 6015.46 (* 1 = 6015.46 loss)
I0316 14:59:44.019162 29479 solver.cpp:610] Iteration 77200, lr = 6.44691e-09
I0316 14:59:44.019176 29479 solver.cpp:613] Iteration 77200, avg_grad_norm = 532059
I0316 15:01:01.879422 29479 solver.cpp:214] Iteration 77220, loss = 5635.93
I0316 15:01:01.879607 29479 solver.cpp:229]     Train net output #0: loss = 3962.08 (* 1 = 3962.08 loss)
I0316 15:01:02.192566 29479 solver.cpp:610] Iteration 77220, lr = 6.44596e-09
I0316 15:01:02.192580 29479 solver.cpp:613] Iteration 77220, avg_grad_norm = 513604
I0316 15:02:09.714041 29479 solver.cpp:214] Iteration 77240, loss = 5753.93
I0316 15:02:09.714149 29479 solver.cpp:229]     Train net output #0: loss = 3656.04 (* 1 = 3656.04 loss)
I0316 15:02:10.074059 29479 solver.cpp:610] Iteration 77240, lr = 6.44502e-09
I0316 15:02:10.074072 29479 solver.cpp:613] Iteration 77240, avg_grad_norm = 633468
I0316 15:03:17.850971 29479 solver.cpp:214] Iteration 77260, loss = 5885.64
I0316 15:03:17.851161 29479 solver.cpp:229]     Train net output #0: loss = 7396.35 (* 1 = 7396.35 loss)
I0316 15:03:18.234719 29479 solver.cpp:610] Iteration 77260, lr = 6.44407e-09
I0316 15:03:18.234733 29479 solver.cpp:613] Iteration 77260, avg_grad_norm = 550146
I0316 15:04:26.034024 29479 solver.cpp:214] Iteration 77280, loss = 5862.96
I0316 15:04:26.034143 29479 solver.cpp:229]     Train net output #0: loss = 4401.36 (* 1 = 4401.36 loss)
I0316 15:04:26.394088 29479 solver.cpp:610] Iteration 77280, lr = 6.44313e-09
I0316 15:04:26.394101 29479 solver.cpp:613] Iteration 77280, avg_grad_norm = 560636
I0316 15:05:33.852144 29479 solver.cpp:214] Iteration 77300, loss = 5689.06
I0316 15:05:33.852282 29479 solver.cpp:229]     Train net output #0: loss = 8973.67 (* 1 = 8973.67 loss)
I0316 15:05:34.191965 29479 solver.cpp:610] Iteration 77300, lr = 6.44218e-09
I0316 15:05:34.191979 29479 solver.cpp:613] Iteration 77300, avg_grad_norm = 510065
I0316 15:06:41.854353 29479 solver.cpp:214] Iteration 77320, loss = 5518.99
I0316 15:06:41.854475 29479 solver.cpp:229]     Train net output #0: loss = 10049.6 (* 1 = 10049.6 loss)
I0316 15:06:42.186200 29479 solver.cpp:610] Iteration 77320, lr = 6.44124e-09
I0316 15:06:42.186214 29479 solver.cpp:613] Iteration 77320, avg_grad_norm = 475844
I0316 15:08:09.601685 29479 solver.cpp:214] Iteration 77340, loss = 5395.51
I0316 15:08:09.601894 29479 solver.cpp:229]     Train net output #0: loss = 5340.87 (* 1 = 5340.87 loss)
I0316 15:08:09.960010 29479 solver.cpp:610] Iteration 77340, lr = 6.44029e-09
I0316 15:08:09.960024 29479 solver.cpp:613] Iteration 77340, avg_grad_norm = 525495
I0316 15:09:16.688061 29479 solver.cpp:214] Iteration 77360, loss = 5609.71
I0316 15:09:16.688179 29479 solver.cpp:229]     Train net output #0: loss = 7583.3 (* 1 = 7583.3 loss)
I0316 15:09:17.051743 29479 solver.cpp:610] Iteration 77360, lr = 6.43935e-09
I0316 15:09:17.051756 29479 solver.cpp:613] Iteration 77360, avg_grad_norm = 473628
I0316 15:10:24.521595 29479 solver.cpp:214] Iteration 77380, loss = 5669.9
I0316 15:10:24.521730 29479 solver.cpp:229]     Train net output #0: loss = 6283.61 (* 1 = 6283.61 loss)
I0316 15:10:24.900424 29479 solver.cpp:610] Iteration 77380, lr = 6.4384e-09
I0316 15:10:24.900439 29479 solver.cpp:613] Iteration 77380, avg_grad_norm = 556213
I0316 15:11:32.437067 29479 solver.cpp:214] Iteration 77400, loss = 5642.56
I0316 15:11:32.437252 29479 solver.cpp:229]     Train net output #0: loss = 4546.69 (* 1 = 4546.69 loss)
I0316 15:11:32.797430 29479 solver.cpp:610] Iteration 77400, lr = 6.43746e-09
I0316 15:11:32.797443 29479 solver.cpp:613] Iteration 77400, avg_grad_norm = 535371
I0316 15:12:40.831938 29479 solver.cpp:214] Iteration 77420, loss = 5600.54
I0316 15:12:40.832064 29479 solver.cpp:229]     Train net output #0: loss = 11487.7 (* 1 = 11487.7 loss)
I0316 15:12:41.192502 29479 solver.cpp:610] Iteration 77420, lr = 6.43651e-09
I0316 15:12:41.192515 29479 solver.cpp:613] Iteration 77420, avg_grad_norm = 511783
I0316 15:13:48.660104 29479 solver.cpp:214] Iteration 77440, loss = 5554.19
I0316 15:13:48.660224 29479 solver.cpp:229]     Train net output #0: loss = 12257 (* 1 = 12257 loss)
I0316 15:13:48.985074 29479 solver.cpp:610] Iteration 77440, lr = 6.43557e-09
I0316 15:13:48.985088 29479 solver.cpp:613] Iteration 77440, avg_grad_norm = 522904
I0316 15:14:56.711421 29479 solver.cpp:214] Iteration 77460, loss = 5521.23
I0316 15:14:56.711596 29479 solver.cpp:229]     Train net output #0: loss = 6707.77 (* 1 = 6707.77 loss)
I0316 15:14:57.055044 29479 solver.cpp:610] Iteration 77460, lr = 6.43462e-09
I0316 15:14:57.055058 29479 solver.cpp:613] Iteration 77460, avg_grad_norm = 498238
I0316 15:16:19.816309 29479 solver.cpp:214] Iteration 77480, loss = 5758.67
I0316 15:16:19.816443 29479 solver.cpp:229]     Train net output #0: loss = 4051.32 (* 1 = 4051.32 loss)
I0316 15:16:20.153403 29479 solver.cpp:610] Iteration 77480, lr = 6.43368e-09
I0316 15:16:20.153416 29479 solver.cpp:613] Iteration 77480, avg_grad_norm = 531743
I0316 15:17:27.581343 29479 solver.cpp:214] Iteration 77500, loss = 5713.44
I0316 15:17:27.581594 29479 solver.cpp:229]     Train net output #0: loss = 8320.56 (* 1 = 8320.56 loss)
I0316 15:17:27.941180 29479 solver.cpp:610] Iteration 77500, lr = 6.43273e-09
I0316 15:17:27.941195 29479 solver.cpp:613] Iteration 77500, avg_grad_norm = 547838
I0316 15:18:35.720480 29479 solver.cpp:214] Iteration 77520, loss = 5576.58
I0316 15:18:35.720618 29479 solver.cpp:229]     Train net output #0: loss = 2747.42 (* 1 = 2747.42 loss)
I0316 15:18:36.083109 29479 solver.cpp:610] Iteration 77520, lr = 6.43179e-09
I0316 15:18:36.083124 29479 solver.cpp:613] Iteration 77520, avg_grad_norm = 586224
I0316 15:19:43.849901 29479 solver.cpp:214] Iteration 77540, loss = 5752.23
I0316 15:19:43.850046 29479 solver.cpp:229]     Train net output #0: loss = 3626.99 (* 1 = 3626.99 loss)
I0316 15:19:44.214316 29479 solver.cpp:610] Iteration 77540, lr = 6.43084e-09
I0316 15:19:44.214329 29479 solver.cpp:613] Iteration 77540, avg_grad_norm = 510569
I0316 15:20:52.300705 29479 solver.cpp:214] Iteration 77560, loss = 5503.75
I0316 15:20:52.300832 29479 solver.cpp:229]     Train net output #0: loss = 10690.9 (* 1 = 10690.9 loss)
I0316 15:20:52.664115 29479 solver.cpp:610] Iteration 77560, lr = 6.4299e-09
I0316 15:20:52.664129 29479 solver.cpp:613] Iteration 77560, avg_grad_norm = 488761
I0316 15:22:00.194679 29479 solver.cpp:214] Iteration 77580, loss = 5561.13
I0316 15:22:00.194792 29479 solver.cpp:229]     Train net output #0: loss = 5928.06 (* 1 = 5928.06 loss)
I0316 15:22:00.559029 29479 solver.cpp:610] Iteration 77580, lr = 6.42895e-09
I0316 15:22:00.559043 29479 solver.cpp:613] Iteration 77580, avg_grad_norm = 486968
I0316 15:23:05.604440 29479 solver.cpp:214] Iteration 77600, loss = 5560.76
I0316 15:23:05.604585 29479 solver.cpp:229]     Train net output #0: loss = 3872.64 (* 1 = 3872.64 loss)
I0316 15:23:05.717504 29479 solver.cpp:610] Iteration 77600, lr = 6.42801e-09
I0316 15:23:05.717519 29479 solver.cpp:613] Iteration 77600, avg_grad_norm = 580260
I0316 15:24:06.778744 29479 solver.cpp:214] Iteration 77620, loss = 5691.5
I0316 15:24:06.778861 29479 solver.cpp:229]     Train net output #0: loss = 6480.47 (* 1 = 6480.47 loss)
I0316 15:24:07.144556 29479 solver.cpp:610] Iteration 77620, lr = 6.42706e-09
I0316 15:24:07.144570 29479 solver.cpp:613] Iteration 77620, avg_grad_norm = 582658
I0316 15:25:15.841912 29479 solver.cpp:214] Iteration 77640, loss = 6078.18
I0316 15:25:15.842044 29479 solver.cpp:229]     Train net output #0: loss = 3823.81 (* 1 = 3823.81 loss)
I0316 15:25:16.207059 29479 solver.cpp:610] Iteration 77640, lr = 6.42612e-09
I0316 15:25:16.207073 29479 solver.cpp:613] Iteration 77640, avg_grad_norm = 580789
I0316 15:26:24.973222 29479 solver.cpp:214] Iteration 77660, loss = 5460.46
I0316 15:26:24.973430 29479 solver.cpp:229]     Train net output #0: loss = 7340.95 (* 1 = 7340.95 loss)
I0316 15:26:25.353174 29479 solver.cpp:610] Iteration 77660, lr = 6.42517e-09
I0316 15:26:25.353196 29479 solver.cpp:613] Iteration 77660, avg_grad_norm = 529351
I0316 15:27:33.871422 29479 solver.cpp:214] Iteration 77680, loss = 5623.24
I0316 15:27:33.871620 29479 solver.cpp:229]     Train net output #0: loss = 4698.86 (* 1 = 4698.86 loss)
I0316 15:27:34.077340 29479 solver.cpp:610] Iteration 77680, lr = 6.42423e-09
I0316 15:27:34.077353 29479 solver.cpp:613] Iteration 77680, avg_grad_norm = 517456
I0316 15:28:41.354290 29479 solver.cpp:214] Iteration 77700, loss = 6043.52
I0316 15:28:41.354449 29479 solver.cpp:229]     Train net output #0: loss = 8273.9 (* 1 = 8273.9 loss)
I0316 15:28:41.717667 29479 solver.cpp:610] Iteration 77700, lr = 6.42328e-09
I0316 15:28:41.717681 29479 solver.cpp:613] Iteration 77700, avg_grad_norm = 547679
I0316 15:30:02.664911 29479 solver.cpp:214] Iteration 77720, loss = 5797.91
I0316 15:30:02.665024 29479 solver.cpp:229]     Train net output #0: loss = 3559.99 (* 1 = 3559.99 loss)
I0316 15:30:03.025992 29479 solver.cpp:610] Iteration 77720, lr = 6.42233e-09
I0316 15:30:03.026007 29479 solver.cpp:613] Iteration 77720, avg_grad_norm = 573455
I0316 15:30:45.148356 29479 solver.cpp:214] Iteration 77740, loss = 5734.53
I0316 15:30:45.148499 29479 solver.cpp:229]     Train net output #0: loss = 6321.77 (* 1 = 6321.77 loss)
I0316 15:30:45.589571 29479 solver.cpp:610] Iteration 77740, lr = 6.42139e-09
I0316 15:30:45.589588 29479 solver.cpp:613] Iteration 77740, avg_grad_norm = 562162
I0316 15:31:53.090788 29479 solver.cpp:214] Iteration 77760, loss = 5595.47
I0316 15:31:53.090903 29479 solver.cpp:229]     Train net output #0: loss = 4501.71 (* 1 = 4501.71 loss)
I0316 15:31:53.452028 29479 solver.cpp:610] Iteration 77760, lr = 6.42044e-09
I0316 15:31:53.452042 29479 solver.cpp:613] Iteration 77760, avg_grad_norm = 504184
I0316 15:33:01.448019 29479 solver.cpp:214] Iteration 77780, loss = 5744.18
I0316 15:33:01.448117 29479 solver.cpp:229]     Train net output #0: loss = 4091.85 (* 1 = 4091.85 loss)
I0316 15:33:01.642760 29479 solver.cpp:610] Iteration 77780, lr = 6.4195e-09
I0316 15:33:01.642772 29479 solver.cpp:613] Iteration 77780, avg_grad_norm = 536635
I0316 15:34:09.535003 29479 solver.cpp:214] Iteration 77800, loss = 5789.3
I0316 15:34:09.535130 29479 solver.cpp:229]     Train net output #0: loss = 4995.79 (* 1 = 4995.79 loss)
I0316 15:34:09.926172 29479 solver.cpp:610] Iteration 77800, lr = 6.41855e-09
I0316 15:34:09.926187 29479 solver.cpp:613] Iteration 77800, avg_grad_norm = 477272
I0316 15:35:16.640808 29479 solver.cpp:214] Iteration 77820, loss = 5565.01
I0316 15:35:16.640918 29479 solver.cpp:229]     Train net output #0: loss = 3765.13 (* 1 = 3765.13 loss)
I0316 15:35:16.968477 29479 solver.cpp:610] Iteration 77820, lr = 6.41761e-09
I0316 15:35:16.968490 29479 solver.cpp:613] Iteration 77820, avg_grad_norm = 488374
I0316 15:36:24.674530 29479 solver.cpp:214] Iteration 77840, loss = 5798.68
I0316 15:36:24.674664 29479 solver.cpp:229]     Train net output #0: loss = 5440.94 (* 1 = 5440.94 loss)
I0316 15:36:25.037582 29479 solver.cpp:610] Iteration 77840, lr = 6.41666e-09
I0316 15:36:25.037596 29479 solver.cpp:613] Iteration 77840, avg_grad_norm = 529655
I0316 15:37:45.565542 29479 solver.cpp:214] Iteration 77860, loss = 5822.63
I0316 15:37:45.565661 29479 solver.cpp:229]     Train net output #0: loss = 3438.52 (* 1 = 3438.52 loss)
I0316 15:37:45.926803 29479 solver.cpp:610] Iteration 77860, lr = 6.41572e-09
I0316 15:37:45.926817 29479 solver.cpp:613] Iteration 77860, avg_grad_norm = 502697
I0316 15:38:31.846921 29479 solver.cpp:214] Iteration 77880, loss = 5696.45
I0316 15:38:31.847064 29479 solver.cpp:229]     Train net output #0: loss = 3404.77 (* 1 = 3404.77 loss)
I0316 15:38:32.210880 29479 solver.cpp:610] Iteration 77880, lr = 6.41477e-09
I0316 15:38:32.210897 29479 solver.cpp:613] Iteration 77880, avg_grad_norm = 535252
I0316 15:39:39.152935 29479 solver.cpp:214] Iteration 77900, loss = 5763.23
I0316 15:39:39.153211 29479 solver.cpp:229]     Train net output #0: loss = 4877.96 (* 1 = 4877.96 loss)
I0316 15:39:39.521595 29479 solver.cpp:610] Iteration 77900, lr = 6.41382e-09
I0316 15:39:39.521608 29479 solver.cpp:613] Iteration 77900, avg_grad_norm = 551849
I0316 15:40:47.055443 29479 solver.cpp:214] Iteration 77920, loss = 6098.74
I0316 15:40:47.055569 29479 solver.cpp:229]     Train net output #0: loss = 6018.89 (* 1 = 6018.89 loss)
I0316 15:40:47.440637 29479 solver.cpp:610] Iteration 77920, lr = 6.41288e-09
I0316 15:40:47.440651 29479 solver.cpp:613] Iteration 77920, avg_grad_norm = 571725
I0316 15:41:55.239078 29479 solver.cpp:214] Iteration 77940, loss = 5736.35
I0316 15:41:55.239251 29479 solver.cpp:229]     Train net output #0: loss = 5239.75 (* 1 = 5239.75 loss)
I0316 15:41:55.607552 29479 solver.cpp:610] Iteration 77940, lr = 6.41193e-09
I0316 15:41:55.607565 29479 solver.cpp:613] Iteration 77940, avg_grad_norm = 666618
I0316 15:43:02.898680 29479 solver.cpp:214] Iteration 77960, loss = 5734.92
I0316 15:43:02.898818 29479 solver.cpp:229]     Train net output #0: loss = 8086.65 (* 1 = 8086.65 loss)
I0316 15:43:03.269481 29479 solver.cpp:610] Iteration 77960, lr = 6.41099e-09
I0316 15:43:03.269495 29479 solver.cpp:613] Iteration 77960, avg_grad_norm = 540713
I0316 15:44:24.791262 29479 solver.cpp:214] Iteration 77980, loss = 6098.47
I0316 15:44:24.791406 29479 solver.cpp:229]     Train net output #0: loss = 3991.43 (* 1 = 3991.43 loss)
I0316 15:44:24.994073 29479 solver.cpp:610] Iteration 77980, lr = 6.41004e-09
I0316 15:44:24.994087 29479 solver.cpp:613] Iteration 77980, avg_grad_norm = 651103
I0316 15:45:32.028528 29479 solver.cpp:214] Iteration 78000, loss = 5458.58
I0316 15:45:32.028640 29479 solver.cpp:229]     Train net output #0: loss = 7313.58 (* 1 = 7313.58 loss)
I0316 15:45:32.373349 29479 solver.cpp:610] Iteration 78000, lr = 6.4091e-09
I0316 15:45:32.373363 29479 solver.cpp:613] Iteration 78000, avg_grad_norm = 570208
I0316 15:46:05.815737 29479 solver.cpp:214] Iteration 78020, loss = 5505.47
I0316 15:46:05.815883 29479 solver.cpp:229]     Train net output #0: loss = 4024.84 (* 1 = 4024.84 loss)
I0316 15:46:05.933876 29479 solver.cpp:610] Iteration 78020, lr = 6.40815e-09
I0316 15:46:05.933912 29479 solver.cpp:613] Iteration 78020, avg_grad_norm = 562580
I0316 15:47:07.991339 29479 solver.cpp:214] Iteration 78040, loss = 5894.18
I0316 15:47:07.991483 29479 solver.cpp:229]     Train net output #0: loss = 9249.72 (* 1 = 9249.72 loss)
I0316 15:47:08.336017 29479 solver.cpp:610] Iteration 78040, lr = 6.40721e-09
I0316 15:47:08.336031 29479 solver.cpp:613] Iteration 78040, avg_grad_norm = 505708
I0316 15:48:15.731276 29479 solver.cpp:214] Iteration 78060, loss = 6040.96
I0316 15:48:15.731387 29479 solver.cpp:229]     Train net output #0: loss = 3838.59 (* 1 = 3838.59 loss)
I0316 15:48:16.094841 29479 solver.cpp:610] Iteration 78060, lr = 6.40626e-09
I0316 15:48:16.094854 29479 solver.cpp:613] Iteration 78060, avg_grad_norm = 518214
I0316 15:49:24.182005 29479 solver.cpp:214] Iteration 78080, loss = 5864.01
I0316 15:49:24.182129 29479 solver.cpp:229]     Train net output #0: loss = 10067 (* 1 = 10067 loss)
I0316 15:49:24.547978 29479 solver.cpp:610] Iteration 78080, lr = 6.40531e-09
I0316 15:49:24.547992 29479 solver.cpp:613] Iteration 78080, avg_grad_norm = 485300
I0316 15:50:32.937290 29479 solver.cpp:214] Iteration 78100, loss = 5524.9
I0316 15:50:32.937419 29479 solver.cpp:229]     Train net output #0: loss = 4902.63 (* 1 = 4902.63 loss)
I0316 15:50:33.301794 29479 solver.cpp:610] Iteration 78100, lr = 6.40437e-09
I0316 15:50:33.301806 29479 solver.cpp:613] Iteration 78100, avg_grad_norm = 529994
I0316 15:51:53.335032 29479 solver.cpp:214] Iteration 78120, loss = 5548.94
I0316 15:51:53.335146 29479 solver.cpp:229]     Train net output #0: loss = 3669.85 (* 1 = 3669.85 loss)
I0316 15:51:53.676658 29479 solver.cpp:610] Iteration 78120, lr = 6.40342e-09
I0316 15:51:53.676671 29479 solver.cpp:613] Iteration 78120, avg_grad_norm = 516074
I0316 15:53:01.770511 29479 solver.cpp:214] Iteration 78140, loss = 5692.05
I0316 15:53:01.770643 29479 solver.cpp:229]     Train net output #0: loss = 4897.18 (* 1 = 4897.18 loss)
I0316 15:53:02.131362 29479 solver.cpp:610] Iteration 78140, lr = 6.40248e-09
I0316 15:53:02.131376 29479 solver.cpp:613] Iteration 78140, avg_grad_norm = 471806
I0316 15:53:45.709697 29479 solver.cpp:214] Iteration 78160, loss = 5517.64
I0316 15:53:45.709823 29479 solver.cpp:229]     Train net output #0: loss = 5862.86 (* 1 = 5862.86 loss)
I0316 15:53:45.825914 29479 solver.cpp:610] Iteration 78160, lr = 6.40153e-09
I0316 15:53:45.825927 29479 solver.cpp:613] Iteration 78160, avg_grad_norm = 473777
I0316 15:54:50.152310 29479 solver.cpp:214] Iteration 78180, loss = 5937.56
I0316 15:54:50.152495 29479 solver.cpp:229]     Train net output #0: loss = 4680.25 (* 1 = 4680.25 loss)
I0316 15:54:50.521332 29479 solver.cpp:610] Iteration 78180, lr = 6.40059e-09
I0316 15:54:50.521369 29479 solver.cpp:613] Iteration 78180, avg_grad_norm = 574982
I0316 15:55:58.807253 29479 solver.cpp:214] Iteration 78200, loss = 5716.97
I0316 15:55:58.807384 29479 solver.cpp:229]     Train net output #0: loss = 4606.67 (* 1 = 4606.67 loss)
I0316 15:55:59.167747 29479 solver.cpp:610] Iteration 78200, lr = 6.39964e-09
I0316 15:55:59.167760 29479 solver.cpp:613] Iteration 78200, avg_grad_norm = 529151
I0316 15:57:07.368831 29479 solver.cpp:214] Iteration 78220, loss = 5780.38
I0316 15:57:07.369011 29479 solver.cpp:229]     Train net output #0: loss = 4888.8 (* 1 = 4888.8 loss)
I0316 15:57:07.729444 29479 solver.cpp:610] Iteration 78220, lr = 6.39869e-09
I0316 15:57:07.729460 29479 solver.cpp:613] Iteration 78220, avg_grad_norm = 495308
I0316 15:58:29.038347 29479 solver.cpp:214] Iteration 78240, loss = 5781.19
I0316 15:58:29.038480 29479 solver.cpp:229]     Train net output #0: loss = 4356.38 (* 1 = 4356.38 loss)
I0316 15:58:29.400631 29479 solver.cpp:610] Iteration 78240, lr = 6.39775e-09
I0316 15:58:29.400646 29479 solver.cpp:613] Iteration 78240, avg_grad_norm = 502340
I0316 15:59:36.461874 29479 solver.cpp:214] Iteration 78260, loss = 5589.01
I0316 15:59:36.462014 29479 solver.cpp:229]     Train net output #0: loss = 3686.63 (* 1 = 3686.63 loss)
I0316 15:59:36.834111 29479 solver.cpp:610] Iteration 78260, lr = 6.3968e-09
I0316 15:59:36.834125 29479 solver.cpp:613] Iteration 78260, avg_grad_norm = 511740
I0316 16:00:44.213387 29479 solver.cpp:214] Iteration 78280, loss = 5733.7
I0316 16:00:44.213562 29479 solver.cpp:229]     Train net output #0: loss = 7459.38 (* 1 = 7459.38 loss)
I0316 16:00:44.604928 29479 solver.cpp:610] Iteration 78280, lr = 6.39586e-09
I0316 16:00:44.604940 29479 solver.cpp:613] Iteration 78280, avg_grad_norm = 504754
I0316 16:01:25.457944 29479 solver.cpp:214] Iteration 78300, loss = 5814.68
I0316 16:01:25.458086 29479 solver.cpp:229]     Train net output #0: loss = 3591.01 (* 1 = 3591.01 loss)
I0316 16:01:25.575927 29479 solver.cpp:610] Iteration 78300, lr = 6.39491e-09
I0316 16:01:25.575942 29479 solver.cpp:613] Iteration 78300, avg_grad_norm = 587896
I0316 16:02:32.896013 29479 solver.cpp:214] Iteration 78320, loss = 5881.69
I0316 16:02:32.896149 29479 solver.cpp:229]     Train net output #0: loss = 5659.53 (* 1 = 5659.53 loss)
I0316 16:02:33.256778 29479 solver.cpp:610] Iteration 78320, lr = 6.39397e-09
I0316 16:02:33.256791 29479 solver.cpp:613] Iteration 78320, avg_grad_norm = 572546
I0316 16:03:40.611224 29479 solver.cpp:214] Iteration 78340, loss = 5609.97
I0316 16:03:40.611368 29479 solver.cpp:229]     Train net output #0: loss = 3802.14 (* 1 = 3802.14 loss)
I0316 16:03:40.955109 29479 solver.cpp:610] Iteration 78340, lr = 6.39302e-09
I0316 16:03:40.955123 29479 solver.cpp:613] Iteration 78340, avg_grad_norm = 539248
I0316 16:05:07.981488 29479 solver.cpp:214] Iteration 78360, loss = 5583.3
I0316 16:05:07.981612 29479 solver.cpp:229]     Train net output #0: loss = 5155.29 (* 1 = 5155.29 loss)
I0316 16:05:08.344621 29479 solver.cpp:610] Iteration 78360, lr = 6.39207e-09
I0316 16:05:08.344635 29479 solver.cpp:613] Iteration 78360, avg_grad_norm = 520458
I0316 16:06:16.269960 29479 solver.cpp:214] Iteration 78380, loss = 5727.8
I0316 16:06:16.270093 29479 solver.cpp:229]     Train net output #0: loss = 3916.36 (* 1 = 3916.36 loss)
I0316 16:06:16.660344 29479 solver.cpp:610] Iteration 78380, lr = 6.39113e-09
I0316 16:06:16.660358 29479 solver.cpp:613] Iteration 78380, avg_grad_norm = 468521
I0316 16:07:24.923955 29479 solver.cpp:214] Iteration 78400, loss = 5492.35
I0316 16:07:24.924064 29479 solver.cpp:229]     Train net output #0: loss = 2745.12 (* 1 = 2745.12 loss)
I0316 16:07:25.247208 29479 solver.cpp:610] Iteration 78400, lr = 6.39018e-09
I0316 16:07:25.247221 29479 solver.cpp:613] Iteration 78400, avg_grad_norm = 527665
I0316 16:08:32.393291 29479 solver.cpp:214] Iteration 78420, loss = 5777.11
I0316 16:08:32.393481 29479 solver.cpp:229]     Train net output #0: loss = 8169.18 (* 1 = 8169.18 loss)
I0316 16:08:32.783833 29479 solver.cpp:610] Iteration 78420, lr = 6.38924e-09
I0316 16:08:32.783848 29479 solver.cpp:613] Iteration 78420, avg_grad_norm = 481578
I0316 16:09:15.207358 29479 solver.cpp:214] Iteration 78440, loss = 5791.99
I0316 16:09:15.207509 29479 solver.cpp:229]     Train net output #0: loss = 5367.1 (* 1 = 5367.1 loss)
I0316 16:09:15.567013 29479 solver.cpp:610] Iteration 78440, lr = 6.38829e-09
I0316 16:09:15.567026 29479 solver.cpp:613] Iteration 78440, avg_grad_norm = 506696
I0316 16:10:23.127118 29479 solver.cpp:214] Iteration 78460, loss = 5612.15
I0316 16:10:23.127261 29479 solver.cpp:229]     Train net output #0: loss = 6746.9 (* 1 = 6746.9 loss)
I0316 16:10:23.496206 29479 solver.cpp:610] Iteration 78460, lr = 6.38734e-09
I0316 16:10:23.496219 29479 solver.cpp:613] Iteration 78460, avg_grad_norm = 554497
I0316 16:11:32.052613 29479 solver.cpp:214] Iteration 78480, loss = 5789.17
I0316 16:11:32.052767 29479 solver.cpp:229]     Train net output #0: loss = 4605.61 (* 1 = 4605.61 loss)
I0316 16:11:32.419256 29479 solver.cpp:610] Iteration 78480, lr = 6.3864e-09
I0316 16:11:32.419270 29479 solver.cpp:613] Iteration 78480, avg_grad_norm = 514950
I0316 16:12:53.606091 29479 solver.cpp:214] Iteration 78500, loss = 6071.4
I0316 16:12:53.606226 29479 solver.cpp:229]     Train net output #0: loss = 6959.61 (* 1 = 6959.61 loss)
I0316 16:12:53.975934 29479 solver.cpp:610] Iteration 78500, lr = 6.38545e-09
I0316 16:12:53.975953 29479 solver.cpp:613] Iteration 78500, avg_grad_norm = 485016
I0316 16:14:02.670299 29479 solver.cpp:214] Iteration 78520, loss = 5795.15
I0316 16:14:02.670423 29479 solver.cpp:229]     Train net output #0: loss = 9147.78 (* 1 = 9147.78 loss)
I0316 16:14:03.039422 29479 solver.cpp:610] Iteration 78520, lr = 6.38451e-09
I0316 16:14:03.039434 29479 solver.cpp:613] Iteration 78520, avg_grad_norm = 513455
I0316 16:15:10.368963 29479 solver.cpp:214] Iteration 78540, loss = 5906.15
I0316 16:15:10.369088 29479 solver.cpp:229]     Train net output #0: loss = 4471.12 (* 1 = 4471.12 loss)
I0316 16:15:10.732244 29479 solver.cpp:610] Iteration 78540, lr = 6.38356e-09
I0316 16:15:10.732257 29479 solver.cpp:613] Iteration 78540, avg_grad_norm = 578795
I0316 16:16:18.166235 29479 solver.cpp:214] Iteration 78560, loss = 5901.07
I0316 16:16:18.166353 29479 solver.cpp:229]     Train net output #0: loss = 3304.15 (* 1 = 3304.15 loss)
I0316 16:16:18.548661 29479 solver.cpp:610] Iteration 78560, lr = 6.38261e-09
I0316 16:16:18.548674 29479 solver.cpp:613] Iteration 78560, avg_grad_norm = 611782
I0316 16:16:45.237016 29479 solver.cpp:214] Iteration 78580, loss = 5506.06
I0316 16:16:45.237073 29479 solver.cpp:229]     Train net output #0: loss = 7994.46 (* 1 = 7994.46 loss)
I0316 16:16:45.356593 29479 solver.cpp:610] Iteration 78580, lr = 6.38167e-09
I0316 16:16:45.356607 29479 solver.cpp:613] Iteration 78580, avg_grad_norm = 509425
I0316 16:17:42.211846 29479 solver.cpp:214] Iteration 78600, loss = 5907.01
I0316 16:17:42.211980 29479 solver.cpp:229]     Train net output #0: loss = 9307.05 (* 1 = 9307.05 loss)
I0316 16:17:42.573268 29479 solver.cpp:610] Iteration 78600, lr = 6.38072e-09
I0316 16:17:42.573282 29479 solver.cpp:613] Iteration 78600, avg_grad_norm = 471087
I0316 16:19:15.333328 29479 solver.cpp:214] Iteration 78620, loss = 5714.56
I0316 16:19:15.333454 29479 solver.cpp:229]     Train net output #0: loss = 4838.77 (* 1 = 4838.77 loss)
I0316 16:19:15.699487 29479 solver.cpp:610] Iteration 78620, lr = 6.37978e-09
I0316 16:19:15.699501 29479 solver.cpp:613] Iteration 78620, avg_grad_norm = 505312
I0316 16:20:23.426460 29479 solver.cpp:214] Iteration 78640, loss = 5653.88
I0316 16:20:23.426570 29479 solver.cpp:229]     Train net output #0: loss = 4744.52 (* 1 = 4744.52 loss)
I0316 16:20:23.789412 29479 solver.cpp:610] Iteration 78640, lr = 6.37883e-09
I0316 16:20:23.789425 29479 solver.cpp:613] Iteration 78640, avg_grad_norm = 540650
I0316 16:21:31.778102 29479 solver.cpp:214] Iteration 78660, loss = 5965.27
I0316 16:21:31.778270 29479 solver.cpp:229]     Train net output #0: loss = 5248.35 (* 1 = 5248.35 loss)
I0316 16:21:31.980506 29479 solver.cpp:610] Iteration 78660, lr = 6.37788e-09
I0316 16:21:31.980520 29479 solver.cpp:613] Iteration 78660, avg_grad_norm = 482102
I0316 16:22:39.634537 29479 solver.cpp:214] Iteration 78680, loss = 5637.74
I0316 16:22:39.634675 29479 solver.cpp:229]     Train net output #0: loss = 5029.34 (* 1 = 5029.34 loss)
I0316 16:22:39.960422 29479 solver.cpp:610] Iteration 78680, lr = 6.37694e-09
I0316 16:22:39.960436 29479 solver.cpp:613] Iteration 78680, avg_grad_norm = 467492
I0316 16:23:47.949301 29479 solver.cpp:214] Iteration 78700, loss = 5631.6
I0316 16:23:47.949496 29479 solver.cpp:229]     Train net output #0: loss = 3193.12 (* 1 = 3193.12 loss)
I0316 16:23:48.293437 29479 solver.cpp:610] Iteration 78700, lr = 6.37599e-09
I0316 16:23:48.293457 29479 solver.cpp:613] Iteration 78700, avg_grad_norm = 478245
I0316 16:24:35.037339 29479 solver.cpp:214] Iteration 78720, loss = 5598.29
I0316 16:24:35.037458 29479 solver.cpp:229]     Train net output #0: loss = 8606.21 (* 1 = 8606.21 loss)
I0316 16:24:35.398226 29479 solver.cpp:610] Iteration 78720, lr = 6.37505e-09
I0316 16:24:35.398239 29479 solver.cpp:613] Iteration 78720, avg_grad_norm = 561264
I0316 16:25:56.350273 29479 solver.cpp:214] Iteration 78740, loss = 5569.77
I0316 16:25:56.350422 29479 solver.cpp:229]     Train net output #0: loss = 5268.62 (* 1 = 5268.62 loss)
I0316 16:25:56.713635 29479 solver.cpp:610] Iteration 78740, lr = 6.3741e-09
I0316 16:25:56.713649 29479 solver.cpp:613] Iteration 78740, avg_grad_norm = 529912
I0316 16:27:03.599915 29479 solver.cpp:214] Iteration 78760, loss = 5490.54
I0316 16:27:03.600028 29479 solver.cpp:229]     Train net output #0: loss = 5731.74 (* 1 = 5731.74 loss)
I0316 16:27:03.990207 29479 solver.cpp:610] Iteration 78760, lr = 6.37315e-09
I0316 16:27:03.990221 29479 solver.cpp:613] Iteration 78760, avg_grad_norm = 495753
I0316 16:28:11.865578 29479 solver.cpp:214] Iteration 78780, loss = 5656.23
I0316 16:28:11.865694 29479 solver.cpp:229]     Train net output #0: loss = 5240.4 (* 1 = 5240.4 loss)
I0316 16:28:12.208497 29479 solver.cpp:610] Iteration 78780, lr = 6.37221e-09
I0316 16:28:12.208510 29479 solver.cpp:613] Iteration 78780, avg_grad_norm = 492239
I0316 16:29:20.175796 29479 solver.cpp:214] Iteration 78800, loss = 5624.56
I0316 16:29:20.175930 29479 solver.cpp:229]     Train net output #0: loss = 3539.6 (* 1 = 3539.6 loss)
I0316 16:29:20.541688 29479 solver.cpp:610] Iteration 78800, lr = 6.37126e-09
I0316 16:29:20.541726 29479 solver.cpp:613] Iteration 78800, avg_grad_norm = 545599
I0316 16:30:29.160302 29479 solver.cpp:214] Iteration 78820, loss = 5692.09
I0316 16:30:29.160436 29479 solver.cpp:229]     Train net output #0: loss = 3903.36 (* 1 = 3903.36 loss)
I0316 16:30:29.522094 29479 solver.cpp:610] Iteration 78820, lr = 6.37031e-09
I0316 16:30:29.522107 29479 solver.cpp:613] Iteration 78820, avg_grad_norm = 519071
I0316 16:31:38.230433 29479 solver.cpp:214] Iteration 78840, loss = 5490.42
I0316 16:31:38.230618 29479 solver.cpp:229]     Train net output #0: loss = 3453.89 (* 1 = 3453.89 loss)
I0316 16:31:38.591071 29479 solver.cpp:610] Iteration 78840, lr = 6.36937e-09
I0316 16:31:38.591115 29479 solver.cpp:613] Iteration 78840, avg_grad_norm = 490822
I0316 16:32:16.158844 29479 solver.cpp:214] Iteration 78860, loss = 5602.22
I0316 16:32:16.158983 29479 solver.cpp:229]     Train net output #0: loss = 4811.67 (* 1 = 4811.67 loss)
I0316 16:32:16.519587 29479 solver.cpp:610] Iteration 78860, lr = 6.36842e-09
I0316 16:32:16.519600 29479 solver.cpp:613] Iteration 78860, avg_grad_norm = 497279
I0316 16:33:44.205539 29479 solver.cpp:214] Iteration 78880, loss = 5596.36
I0316 16:33:44.205744 29479 solver.cpp:229]     Train net output #0: loss = 10757 (* 1 = 10757 loss)
I0316 16:33:44.568852 29479 solver.cpp:610] Iteration 78880, lr = 6.36748e-09
I0316 16:33:44.568886 29479 solver.cpp:613] Iteration 78880, avg_grad_norm = 525624
I0316 16:34:53.050304 29479 solver.cpp:214] Iteration 78900, loss = 5647.25
I0316 16:34:53.050477 29479 solver.cpp:229]     Train net output #0: loss = 6304.62 (* 1 = 6304.62 loss)
I0316 16:34:53.386742 29479 solver.cpp:610] Iteration 78900, lr = 6.36653e-09
I0316 16:34:53.386756 29479 solver.cpp:613] Iteration 78900, avg_grad_norm = 514559
I0316 16:36:02.281105 29479 solver.cpp:214] Iteration 78920, loss = 5511.35
I0316 16:36:02.281230 29479 solver.cpp:229]     Train net output #0: loss = 9707.12 (* 1 = 9707.12 loss)
I0316 16:36:02.646502 29479 solver.cpp:610] Iteration 78920, lr = 6.36558e-09
I0316 16:36:02.646517 29479 solver.cpp:613] Iteration 78920, avg_grad_norm = 486883
I0316 16:37:10.816561 29479 solver.cpp:214] Iteration 78940, loss = 5596.3
I0316 16:37:10.816702 29479 solver.cpp:229]     Train net output #0: loss = 5310.34 (* 1 = 5310.34 loss)
I0316 16:37:11.178808 29479 solver.cpp:610] Iteration 78940, lr = 6.36464e-09
I0316 16:37:11.178822 29479 solver.cpp:613] Iteration 78940, avg_grad_norm = 480558
I0316 16:38:19.229298 29479 solver.cpp:214] Iteration 78960, loss = 5858.24
I0316 16:38:19.229449 29479 solver.cpp:229]     Train net output #0: loss = 8752.36 (* 1 = 8752.36 loss)
I0316 16:38:19.434602 29479 solver.cpp:610] Iteration 78960, lr = 6.36369e-09
I0316 16:38:19.434615 29479 solver.cpp:613] Iteration 78960, avg_grad_norm = 484238
I0316 16:39:17.953507 29479 solver.cpp:214] Iteration 78980, loss = 5792.38
I0316 16:39:17.953654 29479 solver.cpp:229]     Train net output #0: loss = 2990.1 (* 1 = 2990.1 loss)
I0316 16:39:18.068214 29479 solver.cpp:610] Iteration 78980, lr = 6.36274e-09
I0316 16:39:18.068228 29479 solver.cpp:613] Iteration 78980, avg_grad_norm = 500093
I0316 16:40:27.636065 29479 solver.cpp:214] Iteration 79000, loss = 5661.62
I0316 16:40:27.636196 29479 solver.cpp:229]     Train net output #0: loss = 6624.87 (* 1 = 6624.87 loss)
I0316 16:40:28.000424 29479 solver.cpp:610] Iteration 79000, lr = 6.3618e-09
I0316 16:40:28.000438 29479 solver.cpp:613] Iteration 79000, avg_grad_norm = 522655
I0316 16:41:35.306418 29479 solver.cpp:214] Iteration 79020, loss = 5465.99
I0316 16:41:35.306546 29479 solver.cpp:229]     Train net output #0: loss = 8560.71 (* 1 = 8560.71 loss)
I0316 16:41:35.653131 29479 solver.cpp:610] Iteration 79020, lr = 6.36085e-09
I0316 16:41:35.653143 29479 solver.cpp:613] Iteration 79020, avg_grad_norm = 516998
I0316 16:42:43.337491 29479 solver.cpp:214] Iteration 79040, loss = 6152.26
I0316 16:42:43.337690 29479 solver.cpp:229]     Train net output #0: loss = 4554.81 (* 1 = 4554.81 loss)
I0316 16:42:43.698596 29479 solver.cpp:610] Iteration 79040, lr = 6.3599e-09
I0316 16:42:43.698609 29479 solver.cpp:613] Iteration 79040, avg_grad_norm = 579872
I0316 16:43:50.576318 29479 solver.cpp:214] Iteration 79060, loss = 5794.45
I0316 16:43:50.576444 29479 solver.cpp:229]     Train net output #0: loss = 5054.23 (* 1 = 5054.23 loss)
I0316 16:43:50.942035 29479 solver.cpp:610] Iteration 79060, lr = 6.35896e-09
I0316 16:43:50.942049 29479 solver.cpp:613] Iteration 79060, avg_grad_norm = 493430
I0316 16:44:58.227023 29479 solver.cpp:214] Iteration 79080, loss = 5435.89
I0316 16:44:58.227133 29479 solver.cpp:229]     Train net output #0: loss = 6696.01 (* 1 = 6696.01 loss)
I0316 16:44:58.590488 29479 solver.cpp:610] Iteration 79080, lr = 6.35801e-09
I0316 16:44:58.590502 29479 solver.cpp:613] Iteration 79080, avg_grad_norm = 495890
I0316 16:46:06.437602 29479 solver.cpp:214] Iteration 79100, loss = 5762.5
I0316 16:46:06.437793 29479 solver.cpp:229]     Train net output #0: loss = 4597.2 (* 1 = 4597.2 loss)
I0316 16:46:06.821092 29479 solver.cpp:610] Iteration 79100, lr = 6.35707e-09
I0316 16:46:06.821105 29479 solver.cpp:613] Iteration 79100, avg_grad_norm = 557250
I0316 16:47:40.782500 29479 solver.cpp:214] Iteration 79120, loss = 5432.87
I0316 16:47:40.782620 29479 solver.cpp:229]     Train net output #0: loss = 3338.72 (* 1 = 3338.72 loss)
I0316 16:47:41.144191 29479 solver.cpp:610] Iteration 79120, lr = 6.35612e-09
I0316 16:47:41.144204 29479 solver.cpp:613] Iteration 79120, avg_grad_norm = 534044
I0316 16:48:47.004613 29479 solver.cpp:214] Iteration 79140, loss = 5941.22
I0316 16:48:47.004806 29479 solver.cpp:229]     Train net output #0: loss = 8195.56 (* 1 = 8195.56 loss)
I0316 16:48:47.362977 29479 solver.cpp:610] Iteration 79140, lr = 6.35517e-09
I0316 16:48:47.362992 29479 solver.cpp:613] Iteration 79140, avg_grad_norm = 529071
I0316 16:49:54.997769 29479 solver.cpp:214] Iteration 79160, loss = 5561.11
I0316 16:49:54.997886 29479 solver.cpp:229]     Train net output #0: loss = 4804.73 (* 1 = 4804.73 loss)
I0316 16:49:55.376499 29479 solver.cpp:610] Iteration 79160, lr = 6.35423e-09
I0316 16:49:55.376513 29479 solver.cpp:613] Iteration 79160, avg_grad_norm = 511165
I0316 16:51:03.368485 29479 solver.cpp:214] Iteration 79180, loss = 5455.56
I0316 16:51:03.368613 29479 solver.cpp:229]     Train net output #0: loss = 7960.98 (* 1 = 7960.98 loss)
I0316 16:51:03.732034 29479 solver.cpp:610] Iteration 79180, lr = 6.35328e-09
I0316 16:51:03.732048 29479 solver.cpp:613] Iteration 79180, avg_grad_norm = 518334
I0316 16:52:11.822891 29479 solver.cpp:214] Iteration 79200, loss = 5547.82
I0316 16:52:11.823027 29479 solver.cpp:229]     Train net output #0: loss = 6921.84 (* 1 = 6921.84 loss)
I0316 16:52:12.182926 29479 solver.cpp:610] Iteration 79200, lr = 6.35233e-09
I0316 16:52:12.182940 29479 solver.cpp:613] Iteration 79200, avg_grad_norm = 491438
I0316 16:53:19.628769 29479 solver.cpp:214] Iteration 79220, loss = 5579.8
I0316 16:53:19.628962 29479 solver.cpp:229]     Train net output #0: loss = 4489.47 (* 1 = 4489.47 loss)
I0316 16:53:19.954141 29479 solver.cpp:610] Iteration 79220, lr = 6.35139e-09
I0316 16:53:19.954164 29479 solver.cpp:613] Iteration 79220, avg_grad_norm = 465586
I0316 16:54:27.569629 29479 solver.cpp:214] Iteration 79240, loss = 5485.03
I0316 16:54:27.569746 29479 solver.cpp:229]     Train net output #0: loss = 7937.13 (* 1 = 7937.13 loss)
I0316 16:54:27.924949 29479 solver.cpp:610] Iteration 79240, lr = 6.35044e-09
I0316 16:54:27.924962 29479 solver.cpp:613] Iteration 79240, avg_grad_norm = 483122
I0316 16:56:06.063436 29479 solver.cpp:214] Iteration 79260, loss = 5706.47
I0316 16:56:06.063540 29479 solver.cpp:229]     Train net output #0: loss = 4496.75 (* 1 = 4496.75 loss)
I0316 16:56:06.416106 29479 solver.cpp:610] Iteration 79260, lr = 6.34949e-09
I0316 16:56:06.416120 29479 solver.cpp:613] Iteration 79260, avg_grad_norm = 516271
I0316 16:57:13.427745 29479 solver.cpp:214] Iteration 79280, loss = 5562.68
I0316 16:57:13.427877 29479 solver.cpp:229]     Train net output #0: loss = 4201.89 (* 1 = 4201.89 loss)
I0316 16:57:13.790745 29479 solver.cpp:610] Iteration 79280, lr = 6.34855e-09
I0316 16:57:13.790758 29479 solver.cpp:613] Iteration 79280, avg_grad_norm = 528622
I0316 16:58:21.685037 29479 solver.cpp:214] Iteration 79300, loss = 5598.09
I0316 16:58:21.685180 29479 solver.cpp:229]     Train net output #0: loss = 6504.08 (* 1 = 6504.08 loss)
I0316 16:58:22.049064 29479 solver.cpp:610] Iteration 79300, lr = 6.3476e-09
I0316 16:58:22.049082 29479 solver.cpp:613] Iteration 79300, avg_grad_norm = 535709
I0316 16:59:29.254935 29479 solver.cpp:214] Iteration 79320, loss = 5820.31
I0316 16:59:29.255019 29479 solver.cpp:229]     Train net output #0: loss = 10190.5 (* 1 = 10190.5 loss)
I0316 16:59:29.617564 29479 solver.cpp:610] Iteration 79320, lr = 6.34665e-09
I0316 16:59:29.617578 29479 solver.cpp:613] Iteration 79320, avg_grad_norm = 579916
I0316 17:00:37.605087 29479 solver.cpp:214] Iteration 79340, loss = 5660.34
I0316 17:00:37.605229 29479 solver.cpp:229]     Train net output #0: loss = 5400.48 (* 1 = 5400.48 loss)
I0316 17:00:37.968087 29479 solver.cpp:610] Iteration 79340, lr = 6.34571e-09
I0316 17:00:37.968101 29479 solver.cpp:613] Iteration 79340, avg_grad_norm = 556240
I0316 17:01:45.426262 29479 solver.cpp:214] Iteration 79360, loss = 5817.99
I0316 17:01:45.426343 29479 solver.cpp:229]     Train net output #0: loss = 8014.96 (* 1 = 8014.96 loss)
I0316 17:01:45.786945 29479 solver.cpp:610] Iteration 79360, lr = 6.34476e-09
I0316 17:01:45.786959 29479 solver.cpp:613] Iteration 79360, avg_grad_norm = 595087
I0316 17:03:14.785634 29479 solver.cpp:214] Iteration 79380, loss = 5557.01
I0316 17:03:14.785835 29479 solver.cpp:229]     Train net output #0: loss = 3404.5 (* 1 = 3404.5 loss)
I0316 17:03:15.146611 29479 solver.cpp:610] Iteration 79380, lr = 6.34381e-09
I0316 17:03:15.146625 29479 solver.cpp:613] Iteration 79380, avg_grad_norm = 496588
I0316 17:04:22.133743 29479 solver.cpp:214] Iteration 79400, loss = 5901.96
I0316 17:04:22.133893 29479 solver.cpp:229]     Train net output #0: loss = 7577.91 (* 1 = 7577.91 loss)
I0316 17:04:22.487272 29479 solver.cpp:610] Iteration 79400, lr = 6.34287e-09
I0316 17:04:22.487284 29479 solver.cpp:613] Iteration 79400, avg_grad_norm = 475785
I0316 17:05:29.601485 29479 solver.cpp:214] Iteration 79420, loss = 5636.04
I0316 17:05:29.601675 29479 solver.cpp:229]     Train net output #0: loss = 5219.7 (* 1 = 5219.7 loss)
I0316 17:05:29.958163 29479 solver.cpp:610] Iteration 79420, lr = 6.34192e-09
I0316 17:05:29.958176 29479 solver.cpp:613] Iteration 79420, avg_grad_norm = 481420
I0316 17:06:37.619817 29479 solver.cpp:214] Iteration 79440, loss = 5595.71
I0316 17:06:37.619948 29479 solver.cpp:229]     Train net output #0: loss = 4707.78 (* 1 = 4707.78 loss)
I0316 17:06:37.981652 29479 solver.cpp:610] Iteration 79440, lr = 6.34097e-09
I0316 17:06:37.981665 29479 solver.cpp:613] Iteration 79440, avg_grad_norm = 482465
I0316 17:07:46.272356 29479 solver.cpp:214] Iteration 79460, loss = 5973.03
I0316 17:07:46.272487 29479 solver.cpp:229]     Train net output #0: loss = 3586.67 (* 1 = 3586.67 loss)
I0316 17:07:46.634842 29479 solver.cpp:610] Iteration 79460, lr = 6.34003e-09
I0316 17:07:46.634855 29479 solver.cpp:613] Iteration 79460, avg_grad_norm = 490792
I0316 17:08:54.651587 29479 solver.cpp:214] Iteration 79480, loss = 5722.23
I0316 17:08:54.651721 29479 solver.cpp:229]     Train net output #0: loss = 4229.32 (* 1 = 4229.32 loss)
I0316 17:08:55.009220 29479 solver.cpp:610] Iteration 79480, lr = 6.33908e-09
I0316 17:08:55.009234 29479 solver.cpp:613] Iteration 79480, avg_grad_norm = 510633
I0316 17:10:07.732522 29479 solver.cpp:214] Iteration 79500, loss = 5632.59
I0316 17:10:07.732735 29479 solver.cpp:229]     Train net output #0: loss = 4891.17 (* 1 = 4891.17 loss)
I0316 17:10:07.838085 29479 solver.cpp:610] Iteration 79500, lr = 6.33813e-09
I0316 17:10:07.838099 29479 solver.cpp:613] Iteration 79500, avg_grad_norm = 489218
I0316 17:10:56.520783 29479 solver.cpp:214] Iteration 79520, loss = 5944.89
I0316 17:10:56.520966 29479 solver.cpp:229]     Train net output #0: loss = 7173.48 (* 1 = 7173.48 loss)
I0316 17:10:56.845108 29479 solver.cpp:610] Iteration 79520, lr = 6.33719e-09
I0316 17:10:56.845121 29479 solver.cpp:613] Iteration 79520, avg_grad_norm = 526477
I0316 17:12:03.746193 29479 solver.cpp:214] Iteration 79540, loss = 5669.79
I0316 17:12:03.746330 29479 solver.cpp:229]     Train net output #0: loss = 8596.92 (* 1 = 8596.92 loss)
I0316 17:12:03.941599 29479 solver.cpp:610] Iteration 79540, lr = 6.33624e-09
I0316 17:12:03.941613 29479 solver.cpp:613] Iteration 79540, avg_grad_norm = 500491
I0316 17:13:12.077253 29479 solver.cpp:214] Iteration 79560, loss = 5625.23
I0316 17:13:12.077373 29479 solver.cpp:229]     Train net output #0: loss = 3932.87 (* 1 = 3932.87 loss)
I0316 17:13:12.439697 29479 solver.cpp:610] Iteration 79560, lr = 6.33529e-09
I0316 17:13:12.439710 29479 solver.cpp:613] Iteration 79560, avg_grad_norm = 489840
I0316 17:14:19.796262 29479 solver.cpp:214] Iteration 79580, loss = 5774.94
I0316 17:14:19.796383 29479 solver.cpp:229]     Train net output #0: loss = 1942.49 (* 1 = 1942.49 loss)
I0316 17:14:20.139694 29479 solver.cpp:610] Iteration 79580, lr = 6.33435e-09
I0316 17:14:20.139708 29479 solver.cpp:613] Iteration 79580, avg_grad_norm = 504672
I0316 17:15:26.807879 29479 solver.cpp:214] Iteration 79600, loss = 5848.74
I0316 17:15:26.808017 29479 solver.cpp:229]     Train net output #0: loss = 7814.83 (* 1 = 7814.83 loss)
I0316 17:15:27.198326 29479 solver.cpp:610] Iteration 79600, lr = 6.3334e-09
I0316 17:15:27.198340 29479 solver.cpp:613] Iteration 79600, avg_grad_norm = 531625
I0316 17:16:34.896466 29479 solver.cpp:214] Iteration 79620, loss = 5711.67
I0316 17:16:34.896626 29479 solver.cpp:229]     Train net output #0: loss = 4660.77 (* 1 = 4660.77 loss)
I0316 17:16:35.111830 29479 solver.cpp:610] Iteration 79620, lr = 6.33245e-09
I0316 17:16:35.111845 29479 solver.cpp:613] Iteration 79620, avg_grad_norm = 505925
I0316 17:17:45.260638 29479 solver.cpp:214] Iteration 79640, loss = 5516.54
I0316 17:17:45.260897 29479 solver.cpp:229]     Train net output #0: loss = 4313.87 (* 1 = 4313.87 loss)
I0316 17:17:45.375327 29479 solver.cpp:610] Iteration 79640, lr = 6.3315e-09
I0316 17:17:45.375365 29479 solver.cpp:613] Iteration 79640, avg_grad_norm = 530000
I0316 17:18:42.235622 29479 solver.cpp:214] Iteration 79660, loss = 5221.83
I0316 17:18:42.235772 29479 solver.cpp:229]     Train net output #0: loss = 5781.51 (* 1 = 5781.51 loss)
I0316 17:18:42.615087 29479 solver.cpp:610] Iteration 79660, lr = 6.33056e-09
I0316 17:18:42.615100 29479 solver.cpp:613] Iteration 79660, avg_grad_norm = 572541
I0316 17:19:50.282089 29479 solver.cpp:214] Iteration 79680, loss = 5589.46
I0316 17:19:50.282233 29479 solver.cpp:229]     Train net output #0: loss = 4578.52 (* 1 = 4578.52 loss)
I0316 17:19:50.604815 29479 solver.cpp:610] Iteration 79680, lr = 6.32961e-09
I0316 17:19:50.604827 29479 solver.cpp:613] Iteration 79680, avg_grad_norm = 492672
I0316 17:20:58.313946 29479 solver.cpp:214] Iteration 79700, loss = 5878.51
I0316 17:20:58.314076 29479 solver.cpp:229]     Train net output #0: loss = 4375.77 (* 1 = 4375.77 loss)
I0316 17:20:58.657742 29479 solver.cpp:610] Iteration 79700, lr = 6.32866e-09
I0316 17:20:58.657754 29479 solver.cpp:613] Iteration 79700, avg_grad_norm = 548655
I0316 17:22:05.715543 29479 solver.cpp:214] Iteration 79720, loss = 5640.84
I0316 17:22:05.715642 29479 solver.cpp:229]     Train net output #0: loss = 3540.12 (* 1 = 3540.12 loss)
I0316 17:22:06.078102 29479 solver.cpp:610] Iteration 79720, lr = 6.32772e-09
I0316 17:22:06.078115 29479 solver.cpp:613] Iteration 79720, avg_grad_norm = 528092
I0316 17:23:13.164857 29479 solver.cpp:214] Iteration 79740, loss = 5737.65
I0316 17:23:13.165040 29479 solver.cpp:229]     Train net output #0: loss = 4971.25 (* 1 = 4971.25 loss)
I0316 17:23:13.532119 29479 solver.cpp:610] Iteration 79740, lr = 6.32677e-09
I0316 17:23:13.532143 29479 solver.cpp:613] Iteration 79740, avg_grad_norm = 497795
I0316 17:24:33.856765 29479 solver.cpp:214] Iteration 79760, loss = 5881.51
I0316 17:24:33.856856 29479 solver.cpp:229]     Train net output #0: loss = 4007.52 (* 1 = 4007.52 loss)
I0316 17:24:34.199621 29479 solver.cpp:610] Iteration 79760, lr = 6.32582e-09
I0316 17:24:34.199635 29479 solver.cpp:613] Iteration 79760, avg_grad_norm = 527517
I0316 17:25:24.859998 29479 solver.cpp:214] Iteration 79780, loss = 5772.87
I0316 17:25:24.860151 29479 solver.cpp:229]     Train net output #0: loss = 9247.91 (* 1 = 9247.91 loss)
I0316 17:25:24.974920 29479 solver.cpp:610] Iteration 79780, lr = 6.32488e-09
I0316 17:25:24.974934 29479 solver.cpp:613] Iteration 79780, avg_grad_norm = 619203
I0316 17:26:28.282471 29479 solver.cpp:214] Iteration 79800, loss = 5673.02
I0316 17:26:28.282594 29479 solver.cpp:229]     Train net output #0: loss = 4719.34 (* 1 = 4719.34 loss)
I0316 17:26:28.652055 29479 solver.cpp:610] Iteration 79800, lr = 6.32393e-09
I0316 17:26:28.652068 29479 solver.cpp:613] Iteration 79800, avg_grad_norm = 565558
I0316 17:27:36.070013 29479 solver.cpp:214] Iteration 79820, loss = 5597.17
I0316 17:27:36.070215 29479 solver.cpp:229]     Train net output #0: loss = 11083.5 (* 1 = 11083.5 loss)
I0316 17:27:36.463418 29479 solver.cpp:610] Iteration 79820, lr = 6.32298e-09
I0316 17:27:36.463431 29479 solver.cpp:613] Iteration 79820, avg_grad_norm = 490211
I0316 17:28:45.491832 29479 solver.cpp:214] Iteration 79840, loss = 5687.51
I0316 17:28:45.492033 29479 solver.cpp:229]     Train net output #0: loss = 3665.91 (* 1 = 3665.91 loss)
I0316 17:28:45.852418 29479 solver.cpp:610] Iteration 79840, lr = 6.32204e-09
I0316 17:28:45.852432 29479 solver.cpp:613] Iteration 79840, avg_grad_norm = 555371
I0316 17:29:53.867419 29479 solver.cpp:214] Iteration 79860, loss = 5730.44
I0316 17:29:53.867604 29479 solver.cpp:229]     Train net output #0: loss = 4277.58 (* 1 = 4277.58 loss)
I0316 17:29:54.237802 29479 solver.cpp:610] Iteration 79860, lr = 6.32109e-09
I0316 17:29:54.237815 29479 solver.cpp:613] Iteration 79860, avg_grad_norm = 589501
I0316 17:31:20.353150 29479 solver.cpp:214] Iteration 79880, loss = 5825.15
I0316 17:31:20.353241 29479 solver.cpp:229]     Train net output #0: loss = 3631.67 (* 1 = 3631.67 loss)
I0316 17:31:20.715807 29479 solver.cpp:610] Iteration 79880, lr = 6.32014e-09
I0316 17:31:20.715821 29479 solver.cpp:613] Iteration 79880, avg_grad_norm = 484853
I0316 17:32:27.923010 29479 solver.cpp:214] Iteration 79900, loss = 5561.05
I0316 17:32:27.923135 29479 solver.cpp:229]     Train net output #0: loss = 4858.33 (* 1 = 4858.33 loss)
I0316 17:32:28.288527 29479 solver.cpp:610] Iteration 79900, lr = 6.31919e-09
I0316 17:32:28.288540 29479 solver.cpp:613] Iteration 79900, avg_grad_norm = 466129
I0316 17:33:08.682925 29479 solver.cpp:214] Iteration 79920, loss = 5597.69
I0316 17:33:08.683058 29479 solver.cpp:229]     Train net output #0: loss = 4952.7 (* 1 = 4952.7 loss)
I0316 17:33:09.064635 29479 solver.cpp:610] Iteration 79920, lr = 6.31825e-09
I0316 17:33:09.064647 29479 solver.cpp:613] Iteration 79920, avg_grad_norm = 476563
I0316 17:34:16.241884 29479 solver.cpp:214] Iteration 79940, loss = 5578.95
I0316 17:34:16.241986 29479 solver.cpp:229]     Train net output #0: loss = 4416.43 (* 1 = 4416.43 loss)
I0316 17:34:16.602151 29479 solver.cpp:610] Iteration 79940, lr = 6.3173e-09
I0316 17:34:16.602164 29479 solver.cpp:613] Iteration 79940, avg_grad_norm = 582851
I0316 17:35:24.466723 29479 solver.cpp:214] Iteration 79960, loss = 6071.16
I0316 17:35:24.466833 29479 solver.cpp:229]     Train net output #0: loss = 3915.6 (* 1 = 3915.6 loss)
I0316 17:35:24.834578 29479 solver.cpp:610] Iteration 79960, lr = 6.31635e-09
I0316 17:35:24.834592 29479 solver.cpp:613] Iteration 79960, avg_grad_norm = 538265
I0316 17:36:32.071208 29479 solver.cpp:214] Iteration 79980, loss = 5424.68
I0316 17:36:32.071333 29479 solver.cpp:229]     Train net output #0: loss = 11517.3 (* 1 = 11517.3 loss)
I0316 17:36:32.460502 29479 solver.cpp:610] Iteration 79980, lr = 6.31541e-09
I0316 17:36:32.460515 29479 solver.cpp:613] Iteration 79980, avg_grad_norm = 479547
I0316 17:37:37.391851 29479 solver.cpp:458] Snapshotting to models/pnet/VGG_VOC2012ext_iter_80000.caffemodel
I0316 17:37:38.633047 29479 solver.cpp:466] Snapshotting solver state to models/pnet/VGG_VOC2012ext_iter_80000.solverstate
I0316 17:37:42.372273 29479 solver.cpp:214] Iteration 80000, loss = 5877.21
I0316 17:37:42.372323 29479 solver.cpp:229]     Train net output #0: loss = 3136.27 (* 1 = 3136.27 loss)
I0316 17:37:42.732929 29479 solver.cpp:610] Iteration 80000, lr = 6.31446e-09
I0316 17:37:42.732942 29479 solver.cpp:613] Iteration 80000, avg_grad_norm = 542445
I0316 17:39:03.909414 29479 solver.cpp:214] Iteration 80020, loss = 5691.16
I0316 17:39:03.909517 29479 solver.cpp:229]     Train net output #0: loss = 5762.26 (* 1 = 5762.26 loss)
I0316 17:39:04.252449 29479 solver.cpp:610] Iteration 80020, lr = 6.31351e-09
I0316 17:39:04.252463 29479 solver.cpp:613] Iteration 80020, avg_grad_norm = 556420
I0316 17:40:11.522773 29479 solver.cpp:214] Iteration 80040, loss = 5402.01
I0316 17:40:11.522886 29479 solver.cpp:229]     Train net output #0: loss = 3654.52 (* 1 = 3654.52 loss)
I0316 17:40:11.883882 29479 solver.cpp:610] Iteration 80040, lr = 6.31256e-09
I0316 17:40:11.883895 29479 solver.cpp:613] Iteration 80040, avg_grad_norm = 519715
I0316 17:40:58.383654 29479 solver.cpp:214] Iteration 80060, loss = 5754.21
I0316 17:40:58.383801 29479 solver.cpp:229]     Train net output #0: loss = 3572.66 (* 1 = 3572.66 loss)
I0316 17:40:58.737491 29479 solver.cpp:610] Iteration 80060, lr = 6.31162e-09
I0316 17:40:58.737504 29479 solver.cpp:613] Iteration 80060, avg_grad_norm = 515014
I0316 17:42:06.218209 29479 solver.cpp:214] Iteration 80080, loss = 5834.33
I0316 17:42:06.218400 29479 solver.cpp:229]     Train net output #0: loss = 3914.85 (* 1 = 3914.85 loss)
I0316 17:42:06.587889 29479 solver.cpp:610] Iteration 80080, lr = 6.31067e-09
I0316 17:42:06.587903 29479 solver.cpp:613] Iteration 80080, avg_grad_norm = 518844
I0316 17:43:14.171092 29479 solver.cpp:214] Iteration 80100, loss = 5673.8
I0316 17:43:14.171236 29479 solver.cpp:229]     Train net output #0: loss = 7324.16 (* 1 = 7324.16 loss)
I0316 17:43:14.496157 29479 solver.cpp:610] Iteration 80100, lr = 6.30972e-09
I0316 17:43:14.496171 29479 solver.cpp:613] Iteration 80100, avg_grad_norm = 554601
I0316 17:44:22.205287 29479 solver.cpp:214] Iteration 80120, loss = 5775.31
I0316 17:44:22.205464 29479 solver.cpp:229]     Train net output #0: loss = 6253.88 (* 1 = 6253.88 loss)
I0316 17:44:22.585762 29479 solver.cpp:610] Iteration 80120, lr = 6.30878e-09
I0316 17:44:22.585774 29479 solver.cpp:613] Iteration 80120, avg_grad_norm = 514329
I0316 17:45:46.805871 29479 solver.cpp:214] Iteration 80140, loss = 5729.81
I0316 17:45:46.806016 29479 solver.cpp:229]     Train net output #0: loss = 4929.69 (* 1 = 4929.69 loss)
I0316 17:45:47.177909 29479 solver.cpp:610] Iteration 80140, lr = 6.30783e-09
I0316 17:45:47.177923 29479 solver.cpp:613] Iteration 80140, avg_grad_norm = 539552
I0316 17:46:54.628417 29479 solver.cpp:214] Iteration 80160, loss = 5615.45
I0316 17:46:54.628542 29479 solver.cpp:229]     Train net output #0: loss = 7323.27 (* 1 = 7323.27 loss)
I0316 17:46:54.987785 29479 solver.cpp:610] Iteration 80160, lr = 6.30688e-09
I0316 17:46:54.987798 29479 solver.cpp:613] Iteration 80160, avg_grad_norm = 545663
I0316 17:47:58.168617 29479 solver.cpp:214] Iteration 80180, loss = 5802
I0316 17:47:58.168757 29479 solver.cpp:229]     Train net output #0: loss = 6824.61 (* 1 = 6824.61 loss)
I0316 17:47:58.277565 29479 solver.cpp:610] Iteration 80180, lr = 6.30593e-09
I0316 17:47:58.277577 29479 solver.cpp:613] Iteration 80180, avg_grad_norm = 560201
I0316 17:48:40.747973 29479 solver.cpp:214] Iteration 80200, loss = 5891.26
I0316 17:48:40.748102 29479 solver.cpp:229]     Train net output #0: loss = 6038.85 (* 1 = 6038.85 loss)
I0316 17:48:41.136675 29479 solver.cpp:610] Iteration 80200, lr = 6.30499e-09
I0316 17:48:41.136689 29479 solver.cpp:613] Iteration 80200, avg_grad_norm = 576005
I0316 17:49:49.203011 29479 solver.cpp:214] Iteration 80220, loss = 5489.62
I0316 17:49:49.203214 29479 solver.cpp:229]     Train net output #0: loss = 5314.68 (* 1 = 5314.68 loss)
I0316 17:49:49.562939 29479 solver.cpp:610] Iteration 80220, lr = 6.30404e-09
I0316 17:49:49.562953 29479 solver.cpp:613] Iteration 80220, avg_grad_norm = 524619
I0316 17:50:57.148309 29479 solver.cpp:214] Iteration 80240, loss = 5730.14
I0316 17:50:57.148423 29479 solver.cpp:229]     Train net output #0: loss = 5674.02 (* 1 = 5674.02 loss)
I0316 17:50:57.336298 29479 solver.cpp:610] Iteration 80240, lr = 6.30309e-09
I0316 17:50:57.336311 29479 solver.cpp:613] Iteration 80240, avg_grad_norm = 510144
I0316 17:52:18.328488 29479 solver.cpp:214] Iteration 80260, loss = 5904.45
I0316 17:52:18.328596 29479 solver.cpp:229]     Train net output #0: loss = 10423.8 (* 1 = 10423.8 loss)
I0316 17:52:18.684875 29479 solver.cpp:610] Iteration 80260, lr = 6.30214e-09
I0316 17:52:18.684888 29479 solver.cpp:613] Iteration 80260, avg_grad_norm = 563951
I0316 17:53:26.000771 29479 solver.cpp:214] Iteration 80280, loss = 5442.92
I0316 17:53:26.000885 29479 solver.cpp:229]     Train net output #0: loss = 3510.06 (* 1 = 3510.06 loss)
I0316 17:53:26.339262 29479 solver.cpp:610] Iteration 80280, lr = 6.3012e-09
I0316 17:53:26.339274 29479 solver.cpp:613] Iteration 80280, avg_grad_norm = 520639
I0316 17:54:33.844472 29479 solver.cpp:214] Iteration 80300, loss = 5859.45
I0316 17:54:33.844599 29479 solver.cpp:229]     Train net output #0: loss = 3540.73 (* 1 = 3540.73 loss)
I0316 17:54:34.038691 29479 solver.cpp:610] Iteration 80300, lr = 6.30025e-09
I0316 17:54:34.038704 29479 solver.cpp:613] Iteration 80300, avg_grad_norm = 488820
I0316 17:55:38.001824 29479 solver.cpp:214] Iteration 80320, loss = 5603.02
I0316 17:55:38.002044 29479 solver.cpp:229]     Train net output #0: loss = 7341.62 (* 1 = 7341.62 loss)
I0316 17:55:38.107293 29479 solver.cpp:610] Iteration 80320, lr = 6.2993e-09
I0316 17:55:38.107333 29479 solver.cpp:613] Iteration 80320, avg_grad_norm = 454071
I0316 17:56:27.901731 29479 solver.cpp:214] Iteration 80340, loss = 5600.44
I0316 17:56:27.901859 29479 solver.cpp:229]     Train net output #0: loss = 3605.21 (* 1 = 3605.21 loss)
I0316 17:56:28.271244 29479 solver.cpp:610] Iteration 80340, lr = 6.29835e-09
I0316 17:56:28.271257 29479 solver.cpp:613] Iteration 80340, avg_grad_norm = 548677
I0316 17:57:35.795008 29479 solver.cpp:214] Iteration 80360, loss = 5791.68
I0316 17:57:35.795181 29479 solver.cpp:229]     Train net output #0: loss = 9265.18 (* 1 = 9265.18 loss)
I0316 17:57:36.158355 29479 solver.cpp:610] Iteration 80360, lr = 6.29741e-09
I0316 17:57:36.158370 29479 solver.cpp:613] Iteration 80360, avg_grad_norm = 496444
I0316 17:58:44.770467 29479 solver.cpp:214] Iteration 80380, loss = 5476.94
I0316 17:58:44.770567 29479 solver.cpp:229]     Train net output #0: loss = 7995.32 (* 1 = 7995.32 loss)
I0316 17:58:45.160251 29479 solver.cpp:610] Iteration 80380, lr = 6.29646e-09
I0316 17:58:45.160264 29479 solver.cpp:613] Iteration 80380, avg_grad_norm = 462423
I0316 18:00:06.275764 29479 solver.cpp:214] Iteration 80400, loss = 5624.48
I0316 18:00:06.275903 29479 solver.cpp:229]     Train net output #0: loss = 4888.47 (* 1 = 4888.47 loss)
I0316 18:00:06.656412 29479 solver.cpp:610] Iteration 80400, lr = 6.29551e-09
I0316 18:00:06.656427 29479 solver.cpp:613] Iteration 80400, avg_grad_norm = 494453
I0316 18:01:14.222941 29479 solver.cpp:214] Iteration 80420, loss = 5775.22
I0316 18:01:14.223125 29479 solver.cpp:229]     Train net output #0: loss = 5379.88 (* 1 = 5379.88 loss)
I0316 18:01:14.586246 29479 solver.cpp:610] Iteration 80420, lr = 6.29456e-09
I0316 18:01:14.586258 29479 solver.cpp:613] Iteration 80420, avg_grad_norm = 506116
I0316 18:02:23.031800 29479 solver.cpp:214] Iteration 80440, loss = 5954.77
I0316 18:02:23.031931 29479 solver.cpp:229]     Train net output #0: loss = 6561.69 (* 1 = 6561.69 loss)
I0316 18:02:23.394881 29479 solver.cpp:610] Iteration 80440, lr = 6.29362e-09
I0316 18:02:23.394894 29479 solver.cpp:613] Iteration 80440, avg_grad_norm = 495374
I0316 18:03:17.223942 29479 solver.cpp:214] Iteration 80460, loss = 5563.97
I0316 18:03:17.224086 29479 solver.cpp:229]     Train net output #0: loss = 5702.56 (* 1 = 5702.56 loss)
I0316 18:03:17.341948 29479 solver.cpp:610] Iteration 80460, lr = 6.29267e-09
I0316 18:03:17.341961 29479 solver.cpp:613] Iteration 80460, avg_grad_norm = 489335
I0316 18:03:59.759814 29479 solver.cpp:214] Iteration 80480, loss = 5905.03
I0316 18:03:59.759937 29479 solver.cpp:229]     Train net output #0: loss = 2872.57 (* 1 = 2872.57 loss)
I0316 18:04:00.129209 29479 solver.cpp:610] Iteration 80480, lr = 6.29172e-09
I0316 18:04:00.129222 29479 solver.cpp:613] Iteration 80480, avg_grad_norm = 497376
I0316 18:05:08.425552 29479 solver.cpp:214] Iteration 80500, loss = 5410.22
I0316 18:05:08.425662 29479 solver.cpp:229]     Train net output #0: loss = 6639.07 (* 1 = 6639.07 loss)
I0316 18:05:08.788370 29479 solver.cpp:610] Iteration 80500, lr = 6.29077e-09
I0316 18:05:08.788383 29479 solver.cpp:613] Iteration 80500, avg_grad_norm = 510413
I0316 18:06:29.757190 29479 solver.cpp:214] Iteration 80520, loss = 5886.46
I0316 18:06:29.757309 29479 solver.cpp:229]     Train net output #0: loss = 4104.49 (* 1 = 4104.49 loss)
I0316 18:06:29.947129 29479 solver.cpp:610] Iteration 80520, lr = 6.28983e-09
I0316 18:06:29.947144 29479 solver.cpp:613] Iteration 80520, avg_grad_norm = 481678
I0316 18:07:37.919852 29479 solver.cpp:214] Iteration 80540, loss = 5766.73
I0316 18:07:37.919981 29479 solver.cpp:229]     Train net output #0: loss = 6294.35 (* 1 = 6294.35 loss)
I0316 18:07:38.279484 29479 solver.cpp:610] Iteration 80540, lr = 6.28888e-09
I0316 18:07:38.279498 29479 solver.cpp:613] Iteration 80540, avg_grad_norm = 496747
I0316 18:08:45.591961 29479 solver.cpp:214] Iteration 80560, loss = 6024.39
I0316 18:08:45.592134 29479 solver.cpp:229]     Train net output #0: loss = 7366.43 (* 1 = 7366.43 loss)
I0316 18:08:45.960739 29479 solver.cpp:610] Iteration 80560, lr = 6.28793e-09
I0316 18:08:45.960753 29479 solver.cpp:613] Iteration 80560, avg_grad_norm = 499937
I0316 18:09:53.839210 29479 solver.cpp:214] Iteration 80580, loss = 5721.45
I0316 18:09:53.839341 29479 solver.cpp:229]     Train net output #0: loss = 3829.04 (* 1 = 3829.04 loss)
I0316 18:09:54.199666 29479 solver.cpp:610] Iteration 80580, lr = 6.28698e-09
I0316 18:09:54.199681 29479 solver.cpp:613] Iteration 80580, avg_grad_norm = 557864
I0316 18:10:56.766752 29479 solver.cpp:214] Iteration 80600, loss = 5926.36
I0316 18:10:56.766896 29479 solver.cpp:229]     Train net output #0: loss = 5428.63 (* 1 = 5428.63 loss)
I0316 18:10:56.874598 29479 solver.cpp:610] Iteration 80600, lr = 6.28604e-09
I0316 18:10:56.874611 29479 solver.cpp:613] Iteration 80600, avg_grad_norm = 528510
I0316 18:11:48.457365 29479 solver.cpp:214] Iteration 80620, loss = 6048.38
I0316 18:11:48.457486 29479 solver.cpp:229]     Train net output #0: loss = 9350.57 (* 1 = 9350.57 loss)
I0316 18:11:48.794745 29479 solver.cpp:610] Iteration 80620, lr = 6.28509e-09
I0316 18:11:48.794759 29479 solver.cpp:613] Iteration 80620, avg_grad_norm = 542544
I0316 18:12:56.749995 29479 solver.cpp:214] Iteration 80640, loss = 5553.73
I0316 18:12:56.750185 29479 solver.cpp:229]     Train net output #0: loss = 6464.93 (* 1 = 6464.93 loss)
I0316 18:12:57.114130 29479 solver.cpp:610] Iteration 80640, lr = 6.28414e-09
I0316 18:12:57.114143 29479 solver.cpp:613] Iteration 80640, avg_grad_norm = 529785
I0316 18:14:28.680485 29479 solver.cpp:214] Iteration 80660, loss = 5855.55
I0316 18:14:28.680686 29479 solver.cpp:229]     Train net output #0: loss = 4043.49 (* 1 = 4043.49 loss)
I0316 18:14:29.053802 29479 solver.cpp:610] Iteration 80660, lr = 6.28319e-09
I0316 18:14:29.053815 29479 solver.cpp:613] Iteration 80660, avg_grad_norm = 485814
I0316 18:15:36.977761 29479 solver.cpp:214] Iteration 80680, loss = 5581.03
I0316 18:15:36.977888 29479 solver.cpp:229]     Train net output #0: loss = 4816.94 (* 1 = 4816.94 loss)
I0316 18:15:37.340710 29479 solver.cpp:610] Iteration 80680, lr = 6.28225e-09
I0316 18:15:37.340740 29479 solver.cpp:613] Iteration 80680, avg_grad_norm = 486860
I0316 18:16:44.880630 29479 solver.cpp:214] Iteration 80700, loss = 5439.13
I0316 18:16:44.880774 29479 solver.cpp:229]     Train net output #0: loss = 3873.29 (* 1 = 3873.29 loss)
I0316 18:16:45.241237 29479 solver.cpp:610] Iteration 80700, lr = 6.2813e-09
I0316 18:16:45.241250 29479 solver.cpp:613] Iteration 80700, avg_grad_norm = 502901
I0316 18:17:52.724414 29479 solver.cpp:214] Iteration 80720, loss = 5620.38
I0316 18:17:52.724529 29479 solver.cpp:229]     Train net output #0: loss = 6574.77 (* 1 = 6574.77 loss)
I0316 18:17:53.095796 29479 solver.cpp:610] Iteration 80720, lr = 6.28035e-09
I0316 18:17:53.095810 29479 solver.cpp:613] Iteration 80720, avg_grad_norm = 496081
I0316 18:18:36.164290 29479 solver.cpp:214] Iteration 80740, loss = 5573.44
I0316 18:18:36.164427 29479 solver.cpp:229]     Train net output #0: loss = 4770.33 (* 1 = 4770.33 loss)
I0316 18:18:36.282264 29479 solver.cpp:610] Iteration 80740, lr = 6.2794e-09
I0316 18:18:36.282279 29479 solver.cpp:613] Iteration 80740, avg_grad_norm = 473914
I0316 18:19:41.910915 29479 solver.cpp:214] Iteration 80760, loss = 5375.24
I0316 18:19:41.911027 29479 solver.cpp:229]     Train net output #0: loss = 6069.89 (* 1 = 6069.89 loss)
I0316 18:19:42.270880 29479 solver.cpp:610] Iteration 80760, lr = 6.27845e-09
I0316 18:19:42.270894 29479 solver.cpp:613] Iteration 80760, avg_grad_norm = 497152
I0316 18:21:03.910287 29479 solver.cpp:214] Iteration 80780, loss = 5789.81
I0316 18:21:03.910405 29479 solver.cpp:229]     Train net output #0: loss = 5337.08 (* 1 = 5337.08 loss)
I0316 18:21:04.270021 29479 solver.cpp:610] Iteration 80780, lr = 6.27751e-09
I0316 18:21:04.270035 29479 solver.cpp:613] Iteration 80780, avg_grad_norm = 505031
I0316 18:22:12.284695 29479 solver.cpp:214] Iteration 80800, loss = 5575.54
I0316 18:22:12.284890 29479 solver.cpp:229]     Train net output #0: loss = 5616.08 (* 1 = 5616.08 loss)
I0316 18:22:12.644477 29479 solver.cpp:610] Iteration 80800, lr = 6.27656e-09
I0316 18:22:12.644491 29479 solver.cpp:613] Iteration 80800, avg_grad_norm = 568802
I0316 18:23:20.520153 29479 solver.cpp:214] Iteration 80820, loss = 5735.52
I0316 18:23:20.520339 29479 solver.cpp:229]     Train net output #0: loss = 3668.17 (* 1 = 3668.17 loss)
I0316 18:23:20.711146 29479 solver.cpp:610] Iteration 80820, lr = 6.27561e-09
I0316 18:23:20.711159 29479 solver.cpp:613] Iteration 80820, avg_grad_norm = 592507
I0316 18:24:24.481812 29479 solver.cpp:214] Iteration 80840, loss = 5771.18
I0316 18:24:24.481917 29479 solver.cpp:229]     Train net output #0: loss = 5537.56 (* 1 = 5537.56 loss)
I0316 18:24:24.827400 29479 solver.cpp:610] Iteration 80840, lr = 6.27466e-09
I0316 18:24:24.827414 29479 solver.cpp:613] Iteration 80840, avg_grad_norm = 460736
I0316 18:25:32.207363 29479 solver.cpp:214] Iteration 80860, loss = 5662.27
I0316 18:25:32.207496 29479 solver.cpp:229]     Train net output #0: loss = 4108.85 (* 1 = 4108.85 loss)
I0316 18:25:32.567299 29479 solver.cpp:610] Iteration 80860, lr = 6.27372e-09
I0316 18:25:32.567313 29479 solver.cpp:613] Iteration 80860, avg_grad_norm = 527699
I0316 18:26:18.313933 29479 solver.cpp:214] Iteration 80880, loss = 5963.42
I0316 18:26:18.314059 29479 solver.cpp:229]     Train net output #0: loss = 6404.21 (* 1 = 6404.21 loss)
I0316 18:26:18.510293 29479 solver.cpp:610] Iteration 80880, lr = 6.27277e-09
I0316 18:26:18.510305 29479 solver.cpp:613] Iteration 80880, avg_grad_norm = 519284
I0316 18:27:39.137717 29479 solver.cpp:214] Iteration 80900, loss = 5863.08
I0316 18:27:39.137836 29479 solver.cpp:229]     Train net output #0: loss = 2745.95 (* 1 = 2745.95 loss)
I0316 18:27:39.498049 29479 solver.cpp:610] Iteration 80900, lr = 6.27182e-09
I0316 18:27:39.498064 29479 solver.cpp:613] Iteration 80900, avg_grad_norm = 612009
I0316 18:28:48.080395 29479 solver.cpp:214] Iteration 80920, loss = 5454.54
I0316 18:28:48.080523 29479 solver.cpp:229]     Train net output #0: loss = 6176.62 (* 1 = 6176.62 loss)
I0316 18:28:48.455838 29479 solver.cpp:610] Iteration 80920, lr = 6.27087e-09
I0316 18:28:48.455854 29479 solver.cpp:613] Iteration 80920, avg_grad_norm = 584497
I0316 18:29:57.213083 29479 solver.cpp:214] Iteration 80940, loss = 5701.4
I0316 18:29:57.213196 29479 solver.cpp:229]     Train net output #0: loss = 4310.38 (* 1 = 4310.38 loss)
I0316 18:29:57.576409 29479 solver.cpp:610] Iteration 80940, lr = 6.26992e-09
I0316 18:29:57.576422 29479 solver.cpp:613] Iteration 80940, avg_grad_norm = 555809
I0316 18:31:05.801796 29479 solver.cpp:214] Iteration 80960, loss = 5746.46
I0316 18:31:05.801926 29479 solver.cpp:229]     Train net output #0: loss = 4589.32 (* 1 = 4589.32 loss)
I0316 18:31:06.138424 29479 solver.cpp:610] Iteration 80960, lr = 6.26898e-09
I0316 18:31:06.138438 29479 solver.cpp:613] Iteration 80960, avg_grad_norm = 580330
I0316 18:32:14.132387 29479 solver.cpp:214] Iteration 80980, loss = 5732.1
I0316 18:32:14.132531 29479 solver.cpp:229]     Train net output #0: loss = 4314.59 (* 1 = 4314.59 loss)
I0316 18:32:14.495137 29479 solver.cpp:610] Iteration 80980, lr = 6.26803e-09
I0316 18:32:14.495151 29479 solver.cpp:613] Iteration 80980, avg_grad_norm = 584483
I0316 18:33:22.484587 29479 solver.cpp:214] Iteration 81000, loss = 5908.24
I0316 18:33:22.484727 29479 solver.cpp:229]     Train net output #0: loss = 9126.22 (* 1 = 9126.22 loss)
I0316 18:33:22.852882 29479 solver.cpp:610] Iteration 81000, lr = 6.26708e-09
I0316 18:33:22.852907 29479 solver.cpp:613] Iteration 81000, avg_grad_norm = 576547
I0316 18:34:04.604181 29479 solver.cpp:214] Iteration 81020, loss = 5779.98
I0316 18:34:04.604290 29479 solver.cpp:229]     Train net output #0: loss = 5253.33 (* 1 = 5253.33 loss)
I0316 18:34:04.967635 29479 solver.cpp:610] Iteration 81020, lr = 6.26613e-09
I0316 18:34:04.967649 29479 solver.cpp:613] Iteration 81020, avg_grad_norm = 642088
I0316 18:35:25.806725 29479 solver.cpp:214] Iteration 81040, loss = 5739.29
I0316 18:35:25.806918 29479 solver.cpp:229]     Train net output #0: loss = 9764.61 (* 1 = 9764.61 loss)
I0316 18:35:26.173511 29479 solver.cpp:610] Iteration 81040, lr = 6.26518e-09
I0316 18:35:26.173527 29479 solver.cpp:613] Iteration 81040, avg_grad_norm = 540351
I0316 18:36:34.706181 29479 solver.cpp:214] Iteration 81060, loss = 6029.19
I0316 18:36:34.706315 29479 solver.cpp:229]     Train net output #0: loss = 4694.02 (* 1 = 4694.02 loss)
I0316 18:36:35.049562 29479 solver.cpp:610] Iteration 81060, lr = 6.26424e-09
I0316 18:36:35.049576 29479 solver.cpp:613] Iteration 81060, avg_grad_norm = 541626
I0316 18:37:42.957705 29479 solver.cpp:214] Iteration 81080, loss = 5874.17
I0316 18:37:42.957825 29479 solver.cpp:229]     Train net output #0: loss = 5642.36 (* 1 = 5642.36 loss)
I0316 18:37:43.320935 29479 solver.cpp:610] Iteration 81080, lr = 6.26329e-09
I0316 18:37:43.320948 29479 solver.cpp:613] Iteration 81080, avg_grad_norm = 523625
I0316 18:38:51.562680 29479 solver.cpp:214] Iteration 81100, loss = 5909.38
I0316 18:38:51.562798 29479 solver.cpp:229]     Train net output #0: loss = 5352.21 (* 1 = 5352.21 loss)
I0316 18:38:51.928220 29479 solver.cpp:610] Iteration 81100, lr = 6.26234e-09
I0316 18:38:51.928236 29479 solver.cpp:613] Iteration 81100, avg_grad_norm = 507704
I0316 18:39:59.664502 29479 solver.cpp:214] Iteration 81120, loss = 5618.61
I0316 18:39:59.664633 29479 solver.cpp:229]     Train net output #0: loss = 5575.32 (* 1 = 5575.32 loss)
I0316 18:40:00.027642 29479 solver.cpp:610] Iteration 81120, lr = 6.26139e-09
I0316 18:40:00.027655 29479 solver.cpp:613] Iteration 81120, avg_grad_norm = 551952
I0316 18:41:02.091142 29479 solver.cpp:214] Iteration 81140, loss = 5698.1
I0316 18:41:02.091260 29479 solver.cpp:229]     Train net output #0: loss = 5230.7 (* 1 = 5230.7 loss)
I0316 18:41:02.197474 29479 solver.cpp:610] Iteration 81140, lr = 6.26044e-09
I0316 18:41:02.197487 29479 solver.cpp:613] Iteration 81140, avg_grad_norm = 516860
I0316 18:42:06.242561 29479 solver.cpp:214] Iteration 81160, loss = 5501.98
I0316 18:42:06.242696 29479 solver.cpp:229]     Train net output #0: loss = 4050.41 (* 1 = 4050.41 loss)
I0316 18:42:06.603219 29479 solver.cpp:610] Iteration 81160, lr = 6.2595e-09
I0316 18:42:06.603232 29479 solver.cpp:613] Iteration 81160, avg_grad_norm = 543613
I0316 18:43:14.334311 29479 solver.cpp:214] Iteration 81180, loss = 5559.86
I0316 18:43:14.334430 29479 solver.cpp:229]     Train net output #0: loss = 2899.62 (* 1 = 2899.62 loss)
I0316 18:43:14.677990 29479 solver.cpp:610] Iteration 81180, lr = 6.25855e-09
I0316 18:43:14.678004 29479 solver.cpp:613] Iteration 81180, avg_grad_norm = 537068
I0316 18:44:22.108161 29479 solver.cpp:214] Iteration 81200, loss = 5846.15
I0316 18:44:22.108290 29479 solver.cpp:229]     Train net output #0: loss = 3734.35 (* 1 = 3734.35 loss)
I0316 18:44:22.470505 29479 solver.cpp:610] Iteration 81200, lr = 6.2576e-09
I0316 18:44:22.470520 29479 solver.cpp:613] Iteration 81200, avg_grad_norm = 521456
I0316 18:45:30.700206 29479 solver.cpp:214] Iteration 81220, loss = 5309.07
I0316 18:45:30.700357 29479 solver.cpp:229]     Train net output #0: loss = 4949.8 (* 1 = 4949.8 loss)
I0316 18:45:31.059223 29479 solver.cpp:610] Iteration 81220, lr = 6.25665e-09
I0316 18:45:31.059237 29479 solver.cpp:613] Iteration 81220, avg_grad_norm = 463839
I0316 18:46:38.418200 29479 solver.cpp:214] Iteration 81240, loss = 5970.97
I0316 18:46:38.418390 29479 solver.cpp:229]     Train net output #0: loss = 2023.46 (* 1 = 2023.46 loss)
I0316 18:46:38.778241 29479 solver.cpp:610] Iteration 81240, lr = 6.2557e-09
I0316 18:46:38.778254 29479 solver.cpp:613] Iteration 81240, avg_grad_norm = 490213
I0316 18:47:46.563864 29479 solver.cpp:214] Iteration 81260, loss = 5801.81
I0316 18:47:46.564000 29479 solver.cpp:229]     Train net output #0: loss = 5243.46 (* 1 = 5243.46 loss)
I0316 18:47:46.924276 29479 solver.cpp:610] Iteration 81260, lr = 6.25476e-09
I0316 18:47:46.924327 29479 solver.cpp:613] Iteration 81260, avg_grad_norm = 539303
I0316 18:49:17.078631 29479 solver.cpp:214] Iteration 81280, loss = 5952.12
I0316 18:49:17.078837 29479 solver.cpp:229]     Train net output #0: loss = 7078.79 (* 1 = 7078.79 loss)
I0316 18:49:17.254016 29479 solver.cpp:610] Iteration 81280, lr = 6.25381e-09
I0316 18:49:17.254030 29479 solver.cpp:613] Iteration 81280, avg_grad_norm = 517370
I0316 18:50:23.651491 29479 solver.cpp:214] Iteration 81300, loss = 5592.16
I0316 18:50:23.651608 29479 solver.cpp:229]     Train net output #0: loss = 9518.39 (* 1 = 9518.39 loss)
I0316 18:50:24.009045 29479 solver.cpp:610] Iteration 81300, lr = 6.25286e-09
I0316 18:50:24.009059 29479 solver.cpp:613] Iteration 81300, avg_grad_norm = 580316
I0316 18:51:31.423229 29479 solver.cpp:214] Iteration 81320, loss = 5678.4
I0316 18:51:31.423439 29479 solver.cpp:229]     Train net output #0: loss = 3857.69 (* 1 = 3857.69 loss)
I0316 18:51:31.781536 29479 solver.cpp:610] Iteration 81320, lr = 6.25191e-09
I0316 18:51:31.781550 29479 solver.cpp:613] Iteration 81320, avg_grad_norm = 530278
I0316 18:52:37.875280 29479 solver.cpp:214] Iteration 81340, loss = 5424.45
I0316 18:52:37.875411 29479 solver.cpp:229]     Train net output #0: loss = 5180.27 (* 1 = 5180.27 loss)
I0316 18:52:38.237977 29479 solver.cpp:610] Iteration 81340, lr = 6.25096e-09
I0316 18:52:38.237992 29479 solver.cpp:613] Iteration 81340, avg_grad_norm = 519400
I0316 18:53:45.472290 29479 solver.cpp:214] Iteration 81360, loss = 5471.39
I0316 18:53:45.472415 29479 solver.cpp:229]     Train net output #0: loss = 4136.89 (* 1 = 4136.89 loss)
I0316 18:53:45.834512 29479 solver.cpp:610] Iteration 81360, lr = 6.25001e-09
I0316 18:53:45.834527 29479 solver.cpp:613] Iteration 81360, avg_grad_norm = 467434
I0316 18:54:52.557018 29479 solver.cpp:214] Iteration 81380, loss = 5546.27
I0316 18:54:52.557235 29479 solver.cpp:229]     Train net output #0: loss = 5232.87 (* 1 = 5232.87 loss)
I0316 18:54:52.916326 29479 solver.cpp:610] Iteration 81380, lr = 6.24907e-09
I0316 18:54:52.916340 29479 solver.cpp:613] Iteration 81380, avg_grad_norm = 507779
I0316 18:55:59.891973 29479 solver.cpp:214] Iteration 81400, loss = 5668.9
I0316 18:55:59.892115 29479 solver.cpp:229]     Train net output #0: loss = 5779.27 (* 1 = 5779.27 loss)
I0316 18:56:00.217870 29479 solver.cpp:610] Iteration 81400, lr = 6.24812e-09
I0316 18:56:00.217893 29479 solver.cpp:613] Iteration 81400, avg_grad_norm = 508201
I0316 18:57:08.214501 29479 solver.cpp:214] Iteration 81420, loss = 5580.78
I0316 18:57:08.214630 29479 solver.cpp:229]     Train net output #0: loss = 8543.13 (* 1 = 8543.13 loss)
I0316 18:57:08.568859 29479 solver.cpp:610] Iteration 81420, lr = 6.24717e-09
I0316 18:57:08.568873 29479 solver.cpp:613] Iteration 81420, avg_grad_norm = 532327
I0316 18:58:15.855921 29479 solver.cpp:214] Iteration 81440, loss = 5582.49
I0316 18:58:15.856029 29479 solver.cpp:229]     Train net output #0: loss = 4724.95 (* 1 = 4724.95 loss)
I0316 18:58:16.192514 29479 solver.cpp:610] Iteration 81440, lr = 6.24622e-09
I0316 18:58:16.192528 29479 solver.cpp:613] Iteration 81440, avg_grad_norm = 608632
I0316 18:59:23.058179 29479 solver.cpp:214] Iteration 81460, loss = 5678.89
I0316 18:59:23.058368 29479 solver.cpp:229]     Train net output #0: loss = 3205.7 (* 1 = 3205.7 loss)
I0316 18:59:23.418861 29479 solver.cpp:610] Iteration 81460, lr = 6.24527e-09
I0316 18:59:23.418875 29479 solver.cpp:613] Iteration 81460, avg_grad_norm = 543604
I0316 19:00:30.494035 29479 solver.cpp:214] Iteration 81480, loss = 5754.45
I0316 19:00:30.494168 29479 solver.cpp:229]     Train net output #0: loss = 6119.27 (* 1 = 6119.27 loss)
I0316 19:00:30.830520 29479 solver.cpp:610] Iteration 81480, lr = 6.24432e-09
I0316 19:00:30.830533 29479 solver.cpp:613] Iteration 81480, avg_grad_norm = 489225
I0316 19:01:37.890363 29479 solver.cpp:214] Iteration 81500, loss = 5237.42
I0316 19:01:37.890471 29479 solver.cpp:229]     Train net output #0: loss = 3989.17 (* 1 = 3989.17 loss)
I0316 19:01:38.254062 29479 solver.cpp:610] Iteration 81500, lr = 6.24338e-09
I0316 19:01:38.254076 29479 solver.cpp:613] Iteration 81500, avg_grad_norm = 484335
I0316 19:02:46.357967 29479 solver.cpp:214] Iteration 81520, loss = 5771.85
I0316 19:02:46.358146 29479 solver.cpp:229]     Train net output #0: loss = 3709.26 (* 1 = 3709.26 loss)
I0316 19:02:46.718581 29479 solver.cpp:610] Iteration 81520, lr = 6.24243e-09
I0316 19:02:46.718595 29479 solver.cpp:613] Iteration 81520, avg_grad_norm = 494128
I0316 19:03:54.002501 29479 solver.cpp:214] Iteration 81540, loss = 5764.25
I0316 19:03:54.002641 29479 solver.cpp:229]     Train net output #0: loss = 6412.2 (* 1 = 6412.2 loss)
I0316 19:03:54.118530 29479 solver.cpp:610] Iteration 81540, lr = 6.24148e-09
I0316 19:03:54.118544 29479 solver.cpp:613] Iteration 81540, avg_grad_norm = 555294
I0316 19:04:58.788101 29479 solver.cpp:214] Iteration 81560, loss = 5777.86
I0316 19:04:58.788231 29479 solver.cpp:229]     Train net output #0: loss = 7094.2 (* 1 = 7094.2 loss)
I0316 19:04:59.148828 29479 solver.cpp:610] Iteration 81560, lr = 6.24053e-09
I0316 19:04:59.148843 29479 solver.cpp:613] Iteration 81560, avg_grad_norm = 585291
I0316 19:06:06.627181 29479 solver.cpp:214] Iteration 81580, loss = 5561.92
I0316 19:06:06.627310 29479 solver.cpp:229]     Train net output #0: loss = 3690.77 (* 1 = 3690.77 loss)
I0316 19:06:06.987536 29479 solver.cpp:610] Iteration 81580, lr = 6.23958e-09
I0316 19:06:06.987551 29479 solver.cpp:613] Iteration 81580, avg_grad_norm = 520234
I0316 19:07:14.896198 29479 solver.cpp:214] Iteration 81600, loss = 5622.2
I0316 19:07:14.896379 29479 solver.cpp:229]     Train net output #0: loss = 4846.3 (* 1 = 4846.3 loss)
I0316 19:07:15.256003 29479 solver.cpp:610] Iteration 81600, lr = 6.23863e-09
I0316 19:07:15.256017 29479 solver.cpp:613] Iteration 81600, avg_grad_norm = 589805
I0316 19:08:22.161042 29479 solver.cpp:214] Iteration 81620, loss = 5876.21
I0316 19:08:22.161252 29479 solver.cpp:229]     Train net output #0: loss = 5252.75 (* 1 = 5252.75 loss)
I0316 19:08:22.521510 29479 solver.cpp:610] Iteration 81620, lr = 6.23769e-09
I0316 19:08:22.521533 29479 solver.cpp:613] Iteration 81620, avg_grad_norm = 527652
I0316 19:09:30.065749 29479 solver.cpp:214] Iteration 81640, loss = 6031.94
I0316 19:09:30.065881 29479 solver.cpp:229]     Train net output #0: loss = 4728.05 (* 1 = 4728.05 loss)
I0316 19:09:30.426381 29479 solver.cpp:610] Iteration 81640, lr = 6.23674e-09
I0316 19:09:30.426434 29479 solver.cpp:613] Iteration 81640, avg_grad_norm = 480499
I0316 19:10:54.187345 29479 solver.cpp:214] Iteration 81660, loss = 5810.63
I0316 19:10:54.187489 29479 solver.cpp:229]     Train net output #0: loss = 4674.53 (* 1 = 4674.53 loss)
I0316 19:10:54.550581 29479 solver.cpp:610] Iteration 81660, lr = 6.23579e-09
I0316 19:10:54.550595 29479 solver.cpp:613] Iteration 81660, avg_grad_norm = 551846
I0316 19:11:33.266271 29479 solver.cpp:214] Iteration 81680, loss = 5609.95
I0316 19:11:33.266401 29479 solver.cpp:229]     Train net output #0: loss = 4264.94 (* 1 = 4264.94 loss)
I0316 19:11:33.679610 29479 solver.cpp:610] Iteration 81680, lr = 6.23484e-09
I0316 19:11:33.679622 29479 solver.cpp:613] Iteration 81680, avg_grad_norm = 582420
I0316 19:12:41.418278 29479 solver.cpp:214] Iteration 81700, loss = 5683.6
I0316 19:12:41.418383 29479 solver.cpp:229]     Train net output #0: loss = 6935.88 (* 1 = 6935.88 loss)
I0316 19:12:41.797830 29479 solver.cpp:610] Iteration 81700, lr = 6.23389e-09
I0316 19:12:41.797843 29479 solver.cpp:613] Iteration 81700, avg_grad_norm = 571029
I0316 19:13:49.696637 29479 solver.cpp:214] Iteration 81720, loss = 5664.24
I0316 19:13:49.696756 29479 solver.cpp:229]     Train net output #0: loss = 4736.5 (* 1 = 4736.5 loss)
I0316 19:13:50.059825 29479 solver.cpp:610] Iteration 81720, lr = 6.23294e-09
I0316 19:13:50.059839 29479 solver.cpp:613] Iteration 81720, avg_grad_norm = 570549
I0316 19:14:57.689972 29479 solver.cpp:214] Iteration 81740, loss = 5572.66
I0316 19:14:57.690165 29479 solver.cpp:229]     Train net output #0: loss = 5152.08 (* 1 = 5152.08 loss)
I0316 19:14:58.033401 29479 solver.cpp:610] Iteration 81740, lr = 6.23199e-09
I0316 19:14:58.033416 29479 solver.cpp:613] Iteration 81740, avg_grad_norm = 515962
I0316 19:16:06.027287 29479 solver.cpp:214] Iteration 81760, loss = 5623.29
I0316 19:16:06.027470 29479 solver.cpp:229]     Train net output #0: loss = 4762.57 (* 1 = 4762.57 loss)
I0316 19:16:06.387127 29479 solver.cpp:610] Iteration 81760, lr = 6.23105e-09
I0316 19:16:06.387141 29479 solver.cpp:613] Iteration 81760, avg_grad_norm = 520618
I0316 19:17:14.838804 29479 solver.cpp:214] Iteration 81780, loss = 5610.83
I0316 19:17:14.838938 29479 solver.cpp:229]     Train net output #0: loss = 4635.96 (* 1 = 4635.96 loss)
I0316 19:17:15.201576 29479 solver.cpp:610] Iteration 81780, lr = 6.2301e-09
I0316 19:17:15.201591 29479 solver.cpp:613] Iteration 81780, avg_grad_norm = 525670
I0316 19:18:41.585070 29479 solver.cpp:214] Iteration 81800, loss = 5696.01
I0316 19:18:41.585209 29479 solver.cpp:229]     Train net output #0: loss = 3376.98 (* 1 = 3376.98 loss)
I0316 19:18:41.947481 29479 solver.cpp:610] Iteration 81800, lr = 6.22915e-09
I0316 19:18:41.947495 29479 solver.cpp:613] Iteration 81800, avg_grad_norm = 507335
I0316 19:19:20.429172 29479 solver.cpp:214] Iteration 81820, loss = 5591.05
I0316 19:19:20.429328 29479 solver.cpp:229]     Train net output #0: loss = 8468.19 (* 1 = 8468.19 loss)
I0316 19:19:20.792560 29479 solver.cpp:610] Iteration 81820, lr = 6.2282e-09
I0316 19:19:20.792575 29479 solver.cpp:613] Iteration 81820, avg_grad_norm = 489145
I0316 19:20:27.397662 29479 solver.cpp:214] Iteration 81840, loss = 5404.57
I0316 19:20:27.397801 29479 solver.cpp:229]     Train net output #0: loss = 4072.2 (* 1 = 4072.2 loss)
I0316 19:20:27.760874 29479 solver.cpp:610] Iteration 81840, lr = 6.22725e-09
I0316 19:20:27.760887 29479 solver.cpp:613] Iteration 81840, avg_grad_norm = 545100
I0316 19:21:35.663339 29479 solver.cpp:214] Iteration 81860, loss = 5516.08
I0316 19:21:35.663456 29479 solver.cpp:229]     Train net output #0: loss = 5293.16 (* 1 = 5293.16 loss)
I0316 19:21:36.026368 29479 solver.cpp:610] Iteration 81860, lr = 6.2263e-09
I0316 19:21:36.026381 29479 solver.cpp:613] Iteration 81860, avg_grad_norm = 464374
I0316 19:22:43.915494 29479 solver.cpp:214] Iteration 81880, loss = 5702.91
I0316 19:22:43.915632 29479 solver.cpp:229]     Train net output #0: loss = 6356.83 (* 1 = 6356.83 loss)
I0316 19:22:44.275847 29479 solver.cpp:610] Iteration 81880, lr = 6.22535e-09
I0316 19:22:44.275887 29479 solver.cpp:613] Iteration 81880, avg_grad_norm = 510561
I0316 19:23:52.885450 29479 solver.cpp:214] Iteration 81900, loss = 5677.1
I0316 19:23:52.885619 29479 solver.cpp:229]     Train net output #0: loss = 7454.15 (* 1 = 7454.15 loss)
I0316 19:23:53.245667 29479 solver.cpp:610] Iteration 81900, lr = 6.22441e-09
I0316 19:23:53.245690 29479 solver.cpp:613] Iteration 81900, avg_grad_norm = 471347
I0316 19:25:14.399718 29479 solver.cpp:214] Iteration 81920, loss = 5622.02
I0316 19:25:14.399857 29479 solver.cpp:229]     Train net output #0: loss = 4334.4 (* 1 = 4334.4 loss)
I0316 19:25:14.759714 29479 solver.cpp:610] Iteration 81920, lr = 6.22346e-09
I0316 19:25:14.759728 29479 solver.cpp:613] Iteration 81920, avg_grad_norm = 444726
I0316 19:26:18.619314 29479 solver.cpp:214] Iteration 81940, loss = 5867.27
I0316 19:26:18.619453 29479 solver.cpp:229]     Train net output #0: loss = 5892.84 (* 1 = 5892.84 loss)
I0316 19:26:18.728350 29479 solver.cpp:610] Iteration 81940, lr = 6.22251e-09
I0316 19:26:18.728364 29479 solver.cpp:613] Iteration 81940, avg_grad_norm = 534245
I0316 19:27:09.142153 29479 solver.cpp:214] Iteration 81960, loss = 5692.23
I0316 19:27:09.142282 29479 solver.cpp:229]     Train net output #0: loss = 7446.27 (* 1 = 7446.27 loss)
I0316 19:27:09.514442 29479 solver.cpp:610] Iteration 81960, lr = 6.22156e-09
I0316 19:27:09.514456 29479 solver.cpp:613] Iteration 81960, avg_grad_norm = 523221
I0316 19:28:16.572787 29479 solver.cpp:214] Iteration 81980, loss = 5414.42
I0316 19:28:16.572906 29479 solver.cpp:229]     Train net output #0: loss = 10592.1 (* 1 = 10592.1 loss)
I0316 19:28:16.913075 29479 solver.cpp:610] Iteration 81980, lr = 6.22061e-09
I0316 19:28:16.913089 29479 solver.cpp:613] Iteration 81980, avg_grad_norm = 498121
I0316 19:29:24.765683 29479 solver.cpp:214] Iteration 82000, loss = 5762.87
I0316 19:29:24.765864 29479 solver.cpp:229]     Train net output #0: loss = 3065.64 (* 1 = 3065.64 loss)
I0316 19:29:25.129204 29479 solver.cpp:610] Iteration 82000, lr = 6.21966e-09
I0316 19:29:25.129217 29479 solver.cpp:613] Iteration 82000, avg_grad_norm = 492750
I0316 19:30:32.423384 29479 solver.cpp:214] Iteration 82020, loss = 5563.09
I0316 19:30:32.423506 29479 solver.cpp:229]     Train net output #0: loss = 5302.06 (* 1 = 5302.06 loss)
I0316 19:30:32.789091 29479 solver.cpp:610] Iteration 82020, lr = 6.21871e-09
I0316 19:30:32.789104 29479 solver.cpp:613] Iteration 82020, avg_grad_norm = 524773
I0316 19:31:56.302156 29479 solver.cpp:214] Iteration 82040, loss = 5661.18
I0316 19:31:56.302263 29479 solver.cpp:229]     Train net output #0: loss = 8255.57 (* 1 = 8255.57 loss)
I0316 19:31:56.662117 29479 solver.cpp:610] Iteration 82040, lr = 6.21776e-09
I0316 19:31:56.662130 29479 solver.cpp:613] Iteration 82040, avg_grad_norm = 478697
I0316 19:33:04.776563 29479 solver.cpp:214] Iteration 82060, loss = 5533.27
I0316 19:33:04.776674 29479 solver.cpp:229]     Train net output #0: loss = 3158.07 (* 1 = 3158.07 loss)
I0316 19:33:05.139555 29479 solver.cpp:610] Iteration 82060, lr = 6.21682e-09
I0316 19:33:05.139569 29479 solver.cpp:613] Iteration 82060, avg_grad_norm = 512776
I0316 19:33:56.722362 29479 solver.cpp:214] Iteration 82080, loss = 5646.31
I0316 19:33:56.722507 29479 solver.cpp:229]     Train net output #0: loss = 5266.07 (* 1 = 5266.07 loss)
I0316 19:33:56.837288 29479 solver.cpp:610] Iteration 82080, lr = 6.21587e-09
I0316 19:33:56.837302 29479 solver.cpp:613] Iteration 82080, avg_grad_norm = 514461
I0316 19:34:59.527031 29479 solver.cpp:214] Iteration 82100, loss = 5855.79
I0316 19:34:59.527146 29479 solver.cpp:229]     Train net output #0: loss = 3568.33 (* 1 = 3568.33 loss)
I0316 19:34:59.886750 29479 solver.cpp:610] Iteration 82100, lr = 6.21492e-09
I0316 19:34:59.886765 29479 solver.cpp:613] Iteration 82100, avg_grad_norm = 574392
I0316 19:36:07.972023 29479 solver.cpp:214] Iteration 82120, loss = 5693.27
I0316 19:36:07.972152 29479 solver.cpp:229]     Train net output #0: loss = 4409.1 (* 1 = 4409.1 loss)
I0316 19:36:08.332358 29479 solver.cpp:610] Iteration 82120, lr = 6.21397e-09
I0316 19:36:08.332372 29479 solver.cpp:613] Iteration 82120, avg_grad_norm = 523118
I0316 19:37:17.030916 29479 solver.cpp:214] Iteration 82140, loss = 5932.6
I0316 19:37:17.031044 29479 solver.cpp:229]     Train net output #0: loss = 5406.56 (* 1 = 5406.56 loss)
I0316 19:37:17.390839 29479 solver.cpp:610] Iteration 82140, lr = 6.21302e-09
I0316 19:37:17.390853 29479 solver.cpp:613] Iteration 82140, avg_grad_norm = 523027
I0316 19:38:20.979316 29479 solver.cpp:214] Iteration 82160, loss = 5710.6
I0316 19:38:20.979434 29479 solver.cpp:229]     Train net output #0: loss = 4782.71 (* 1 = 4782.71 loss)
I0316 19:38:21.340204 29479 solver.cpp:610] Iteration 82160, lr = 6.21207e-09
I0316 19:38:21.340217 29479 solver.cpp:613] Iteration 82160, avg_grad_norm = 494238
I0316 19:39:41.003945 29479 solver.cpp:214] Iteration 82180, loss = 5975.84
I0316 19:39:41.004065 29479 solver.cpp:229]     Train net output #0: loss = 6485.96 (* 1 = 6485.96 loss)
I0316 19:39:41.364003 29479 solver.cpp:610] Iteration 82180, lr = 6.21112e-09
I0316 19:39:41.364017 29479 solver.cpp:613] Iteration 82180, avg_grad_norm = 560681
I0316 19:40:48.632709 29479 solver.cpp:214] Iteration 82200, loss = 5652.54
I0316 19:40:48.632881 29479 solver.cpp:229]     Train net output #0: loss = 7079.13 (* 1 = 7079.13 loss)
I0316 19:40:49.000555 29479 solver.cpp:610] Iteration 82200, lr = 6.21017e-09
I0316 19:40:49.000568 29479 solver.cpp:613] Iteration 82200, avg_grad_norm = 490184
I0316 19:41:34.405187 29479 solver.cpp:214] Iteration 82220, loss = 5671.96
I0316 19:41:34.405306 29479 solver.cpp:229]     Train net output #0: loss = 4839.4 (* 1 = 4839.4 loss)
I0316 19:41:34.599242 29479 solver.cpp:610] Iteration 82220, lr = 6.20922e-09
I0316 19:41:34.599256 29479 solver.cpp:613] Iteration 82220, avg_grad_norm = 521497
I0316 19:42:42.455500 29479 solver.cpp:214] Iteration 82240, loss = 5552.98
I0316 19:42:42.455725 29479 solver.cpp:229]     Train net output #0: loss = 4272 (* 1 = 4272 loss)
I0316 19:42:42.818703 29479 solver.cpp:610] Iteration 82240, lr = 6.20828e-09
I0316 19:42:42.818717 29479 solver.cpp:613] Iteration 82240, avg_grad_norm = 480970
I0316 19:43:50.394814 29479 solver.cpp:214] Iteration 82260, loss = 5971.73
I0316 19:43:50.394932 29479 solver.cpp:229]     Train net output #0: loss = 11343.3 (* 1 = 11343.3 loss)
I0316 19:43:50.757441 29479 solver.cpp:610] Iteration 82260, lr = 6.20733e-09
I0316 19:43:50.757454 29479 solver.cpp:613] Iteration 82260, avg_grad_norm = 485160
I0316 19:44:58.837996 29479 solver.cpp:214] Iteration 82280, loss = 5904.62
I0316 19:44:58.838120 29479 solver.cpp:229]     Train net output #0: loss = 6492.35 (* 1 = 6492.35 loss)
I0316 19:44:59.197942 29479 solver.cpp:610] Iteration 82280, lr = 6.20638e-09
I0316 19:44:59.197957 29479 solver.cpp:613] Iteration 82280, avg_grad_norm = 499512
I0316 19:46:25.359824 29479 solver.cpp:214] Iteration 82300, loss = 5763.19
I0316 19:46:25.359951 29479 solver.cpp:229]     Train net output #0: loss = 4205.94 (* 1 = 4205.94 loss)
I0316 19:46:25.721190 29479 solver.cpp:610] Iteration 82300, lr = 6.20543e-09
I0316 19:46:25.721204 29479 solver.cpp:613] Iteration 82300, avg_grad_norm = 485735
I0316 19:47:32.946940 29479 solver.cpp:214] Iteration 82320, loss = 5674.3
I0316 19:47:32.947059 29479 solver.cpp:229]     Train net output #0: loss = 10785.5 (* 1 = 10785.5 loss)
I0316 19:47:33.310238 29479 solver.cpp:610] Iteration 82320, lr = 6.20448e-09
I0316 19:47:33.310253 29479 solver.cpp:613] Iteration 82320, avg_grad_norm = 507675
I0316 19:48:40.798627 29479 solver.cpp:214] Iteration 82340, loss = 5636.31
I0316 19:48:40.798835 29479 solver.cpp:229]     Train net output #0: loss = 7413.92 (* 1 = 7413.92 loss)
I0316 19:48:41.160171 29479 solver.cpp:610] Iteration 82340, lr = 6.20353e-09
I0316 19:48:41.160184 29479 solver.cpp:613] Iteration 82340, avg_grad_norm = 515214
I0316 19:49:24.880039 29479 solver.cpp:214] Iteration 82360, loss = 5936.59
I0316 19:49:24.880247 29479 solver.cpp:229]     Train net output #0: loss = 11030.1 (* 1 = 11030.1 loss)
I0316 19:49:25.239265 29479 solver.cpp:610] Iteration 82360, lr = 6.20258e-09
I0316 19:49:25.239279 29479 solver.cpp:613] Iteration 82360, avg_grad_norm = 562009
I0316 19:50:32.509850 29479 solver.cpp:214] Iteration 82380, loss = 5281.46
I0316 19:50:32.509932 29479 solver.cpp:229]     Train net output #0: loss = 4756.34 (* 1 = 4756.34 loss)
I0316 19:50:32.873327 29479 solver.cpp:610] Iteration 82380, lr = 6.20163e-09
I0316 19:50:32.873342 29479 solver.cpp:613] Iteration 82380, avg_grad_norm = 488251
I0316 19:51:41.047683 29479 solver.cpp:214] Iteration 82400, loss = 5762.47
I0316 19:51:41.047811 29479 solver.cpp:229]     Train net output #0: loss = 3613.5 (* 1 = 3613.5 loss)
I0316 19:51:41.407897 29479 solver.cpp:610] Iteration 82400, lr = 6.20068e-09
I0316 19:51:41.407912 29479 solver.cpp:613] Iteration 82400, avg_grad_norm = 477970
I0316 19:53:03.099439 29479 solver.cpp:214] Iteration 82420, loss = 5765
I0316 19:53:03.099578 29479 solver.cpp:229]     Train net output #0: loss = 2926.35 (* 1 = 2926.35 loss)
I0316 19:53:03.454890 29479 solver.cpp:610] Iteration 82420, lr = 6.19974e-09
I0316 19:53:03.454905 29479 solver.cpp:613] Iteration 82420, avg_grad_norm = 480154
I0316 19:54:11.704087 29479 solver.cpp:214] Iteration 82440, loss = 5292.38
I0316 19:54:11.704202 29479 solver.cpp:229]     Train net output #0: loss = 6965.3 (* 1 = 6965.3 loss)
I0316 19:54:12.039422 29479 solver.cpp:610] Iteration 82440, lr = 6.19879e-09
I0316 19:54:12.039435 29479 solver.cpp:613] Iteration 82440, avg_grad_norm = 491060
I0316 19:55:19.950292 29479 solver.cpp:214] Iteration 82460, loss = 5545.74
I0316 19:55:19.950408 29479 solver.cpp:229]     Train net output #0: loss = 3863.5 (* 1 = 3863.5 loss)
I0316 19:55:20.286820 29479 solver.cpp:610] Iteration 82460, lr = 6.19784e-09
I0316 19:55:20.286834 29479 solver.cpp:613] Iteration 82460, avg_grad_norm = 527249
I0316 19:56:19.807472 29479 solver.cpp:214] Iteration 82480, loss = 5723.71
I0316 19:56:19.807662 29479 solver.cpp:229]     Train net output #0: loss = 8965.3 (* 1 = 8965.3 loss)
I0316 19:56:19.920709 29479 solver.cpp:610] Iteration 82480, lr = 6.19689e-09
I0316 19:56:19.920728 29479 solver.cpp:613] Iteration 82480, avg_grad_norm = 456318
I0316 19:57:14.439460 29479 solver.cpp:214] Iteration 82500, loss = 5814.78
I0316 19:57:14.439589 29479 solver.cpp:229]     Train net output #0: loss = 7736.96 (* 1 = 7736.96 loss)
I0316 19:57:14.794541 29479 solver.cpp:610] Iteration 82500, lr = 6.19594e-09
I0316 19:57:14.794580 29479 solver.cpp:613] Iteration 82500, avg_grad_norm = 495892
I0316 19:58:22.865443 29479 solver.cpp:214] Iteration 82520, loss = 5653.98
I0316 19:58:22.865567 29479 solver.cpp:229]     Train net output #0: loss = 3740.17 (* 1 = 3740.17 loss)
I0316 19:58:23.230124 29479 solver.cpp:610] Iteration 82520, lr = 6.19499e-09
I0316 19:58:23.230139 29479 solver.cpp:613] Iteration 82520, avg_grad_norm = 478286
I0316 19:59:30.663008 29479 solver.cpp:214] Iteration 82540, loss = 6032.82
I0316 19:59:30.663182 29479 solver.cpp:229]     Train net output #0: loss = 4065.44 (* 1 = 4065.44 loss)
I0316 19:59:31.025836 29479 solver.cpp:610] Iteration 82540, lr = 6.19404e-09
I0316 19:59:31.025852 29479 solver.cpp:613] Iteration 82540, avg_grad_norm = 559842
I0316 20:00:51.819243 29479 solver.cpp:214] Iteration 82560, loss = 5720.14
I0316 20:00:51.819372 29479 solver.cpp:229]     Train net output #0: loss = 7360.68 (* 1 = 7360.68 loss)
I0316 20:00:52.199694 29479 solver.cpp:610] Iteration 82560, lr = 6.19309e-09
I0316 20:00:52.199708 29479 solver.cpp:613] Iteration 82560, avg_grad_norm = 516971
I0316 20:01:59.751065 29479 solver.cpp:214] Iteration 82580, loss = 5622.4
I0316 20:01:59.751199 29479 solver.cpp:229]     Train net output #0: loss = 6983.55 (* 1 = 6983.55 loss)
I0316 20:02:00.114295 29479 solver.cpp:610] Iteration 82580, lr = 6.19214e-09
I0316 20:02:00.114310 29479 solver.cpp:613] Iteration 82580, avg_grad_norm = 483715
I0316 20:03:06.532040 29479 solver.cpp:214] Iteration 82600, loss = 5378.7
I0316 20:03:06.532225 29479 solver.cpp:229]     Train net output #0: loss = 4770.37 (* 1 = 4770.37 loss)
I0316 20:03:06.894459 29479 solver.cpp:610] Iteration 82600, lr = 6.19119e-09
I0316 20:03:06.894471 29479 solver.cpp:613] Iteration 82600, avg_grad_norm = 487018
I0316 20:03:55.593413 29479 solver.cpp:214] Iteration 82620, loss = 5284.81
I0316 20:03:55.593525 29479 solver.cpp:229]     Train net output #0: loss = 4789.54 (* 1 = 4789.54 loss)
I0316 20:03:55.708107 29479 solver.cpp:610] Iteration 82620, lr = 6.19024e-09
I0316 20:03:55.708122 29479 solver.cpp:613] Iteration 82620, avg_grad_norm = 530758
I0316 20:04:59.897351 29479 solver.cpp:214] Iteration 82640, loss = 5653.55
I0316 20:04:59.897475 29479 solver.cpp:229]     Train net output #0: loss = 4897.73 (* 1 = 4897.73 loss)
I0316 20:05:00.259397 29479 solver.cpp:610] Iteration 82640, lr = 6.18929e-09
I0316 20:05:00.259412 29479 solver.cpp:613] Iteration 82640, avg_grad_norm = 490739
I0316 20:06:07.806819 29479 solver.cpp:214] Iteration 82660, loss = 5560.74
I0316 20:06:07.806944 29479 solver.cpp:229]     Train net output #0: loss = 2396.12 (* 1 = 2396.12 loss)
I0316 20:06:08.169832 29479 solver.cpp:610] Iteration 82660, lr = 6.18834e-09
I0316 20:06:08.169847 29479 solver.cpp:613] Iteration 82660, avg_grad_norm = 487136
I0316 20:07:28.908516 29479 solver.cpp:214] Iteration 82680, loss = 5847.57
I0316 20:07:28.908671 29479 solver.cpp:229]     Train net output #0: loss = 7494.97 (* 1 = 7494.97 loss)
I0316 20:07:29.269795 29479 solver.cpp:610] Iteration 82680, lr = 6.1874e-09
I0316 20:07:29.269809 29479 solver.cpp:613] Iteration 82680, avg_grad_norm = 504427
I0316 20:08:36.600772 29479 solver.cpp:214] Iteration 82700, loss = 5806.23
I0316 20:08:36.600867 29479 solver.cpp:229]     Train net output #0: loss = 2647.53 (* 1 = 2647.53 loss)
I0316 20:08:36.961882 29479 solver.cpp:610] Iteration 82700, lr = 6.18645e-09
I0316 20:08:36.961895 29479 solver.cpp:613] Iteration 82700, avg_grad_norm = 593073
I0316 20:09:44.680796 29479 solver.cpp:214] Iteration 82720, loss = 5716.42
I0316 20:09:44.680970 29479 solver.cpp:229]     Train net output #0: loss = 3542.95 (* 1 = 3542.95 loss)
I0316 20:09:45.064522 29479 solver.cpp:610] Iteration 82720, lr = 6.1855e-09
I0316 20:09:45.064538 29479 solver.cpp:613] Iteration 82720, avg_grad_norm = 577573
I0316 20:10:52.568214 29479 solver.cpp:214] Iteration 82740, loss = 6034.1
I0316 20:10:52.568408 29479 solver.cpp:229]     Train net output #0: loss = 4744.41 (* 1 = 4744.41 loss)
I0316 20:10:52.933979 29479 solver.cpp:610] Iteration 82740, lr = 6.18455e-09
I0316 20:10:52.933993 29479 solver.cpp:613] Iteration 82740, avg_grad_norm = 531813
I0316 20:11:39.412843 29479 solver.cpp:214] Iteration 82760, loss = 5841.84
I0316 20:11:39.412972 29479 solver.cpp:229]     Train net output #0: loss = 8097.21 (* 1 = 8097.21 loss)
I0316 20:11:39.772938 29479 solver.cpp:610] Iteration 82760, lr = 6.1836e-09
I0316 20:11:39.772951 29479 solver.cpp:613] Iteration 82760, avg_grad_norm = 491622
I0316 20:12:46.076189 29479 solver.cpp:214] Iteration 82780, loss = 5813.3
I0316 20:12:46.076305 29479 solver.cpp:229]     Train net output #0: loss = 3998.28 (* 1 = 3998.28 loss)
I0316 20:12:46.442428 29479 solver.cpp:610] Iteration 82780, lr = 6.18265e-09
I0316 20:12:46.442441 29479 solver.cpp:613] Iteration 82780, avg_grad_norm = 512781
I0316 20:14:07.717777 29479 solver.cpp:214] Iteration 82800, loss = 5336.38
I0316 20:14:07.717922 29479 solver.cpp:229]     Train net output #0: loss = 10483.1 (* 1 = 10483.1 loss)
I0316 20:14:08.076511 29479 solver.cpp:610] Iteration 82800, lr = 6.1817e-09
I0316 20:14:08.076525 29479 solver.cpp:613] Iteration 82800, avg_grad_norm = 513271
I0316 20:15:15.591579 29479 solver.cpp:214] Iteration 82820, loss = 5780.1
I0316 20:15:15.591686 29479 solver.cpp:229]     Train net output #0: loss = 6637.13 (* 1 = 6637.13 loss)
I0316 20:15:15.952489 29479 solver.cpp:610] Iteration 82820, lr = 6.18075e-09
I0316 20:15:15.952503 29479 solver.cpp:613] Iteration 82820, avg_grad_norm = 523934
I0316 20:16:24.424003 29479 solver.cpp:214] Iteration 82840, loss = 5653.34
I0316 20:16:24.424132 29479 solver.cpp:229]     Train net output #0: loss = 3420.11 (* 1 = 3420.11 loss)
I0316 20:16:24.784220 29479 solver.cpp:610] Iteration 82840, lr = 6.1798e-09
I0316 20:16:24.784235 29479 solver.cpp:613] Iteration 82840, avg_grad_norm = 533052
I0316 20:17:33.232134 29479 solver.cpp:214] Iteration 82860, loss = 5852.1
I0316 20:17:33.232261 29479 solver.cpp:229]     Train net output #0: loss = 5376.07 (* 1 = 5376.07 loss)
I0316 20:17:33.593046 29479 solver.cpp:610] Iteration 82860, lr = 6.17885e-09
I0316 20:17:33.593060 29479 solver.cpp:613] Iteration 82860, avg_grad_norm = 674272
I0316 20:18:40.887470 29479 solver.cpp:214] Iteration 82880, loss = 5222.25
I0316 20:18:40.887590 29479 solver.cpp:229]     Train net output #0: loss = 6803.61 (* 1 = 6803.61 loss)
I0316 20:18:41.250160 29479 solver.cpp:610] Iteration 82880, lr = 6.1779e-09
I0316 20:18:41.250175 29479 solver.cpp:613] Iteration 82880, avg_grad_norm = 521611
I0316 20:19:26.193709 29479 solver.cpp:214] Iteration 82900, loss = 5656.05
I0316 20:19:26.193837 29479 solver.cpp:229]     Train net output #0: loss = 3577.14 (* 1 = 3577.14 loss)
I0316 20:19:26.554409 29479 solver.cpp:610] Iteration 82900, lr = 6.17695e-09
I0316 20:19:26.554424 29479 solver.cpp:613] Iteration 82900, avg_grad_norm = 476895
I0316 20:20:34.990231 29479 solver.cpp:214] Iteration 82920, loss = 5671.65
I0316 20:20:34.990348 29479 solver.cpp:229]     Train net output #0: loss = 3686.1 (* 1 = 3686.1 loss)
I0316 20:20:35.350334 29479 solver.cpp:610] Iteration 82920, lr = 6.176e-09
I0316 20:20:35.350347 29479 solver.cpp:613] Iteration 82920, avg_grad_norm = 520438
I0316 20:21:55.878772 29479 solver.cpp:214] Iteration 82940, loss = 5449.16
I0316 20:21:55.878890 29479 solver.cpp:229]     Train net output #0: loss = 4696.46 (* 1 = 4696.46 loss)
I0316 20:21:56.243562 29479 solver.cpp:610] Iteration 82940, lr = 6.17505e-09
I0316 20:21:56.243576 29479 solver.cpp:613] Iteration 82940, avg_grad_norm = 529143
I0316 20:23:04.089515 29479 solver.cpp:214] Iteration 82960, loss = 5446.71
I0316 20:23:04.089690 29479 solver.cpp:229]     Train net output #0: loss = 3603.08 (* 1 = 3603.08 loss)
I0316 20:23:04.449841 29479 solver.cpp:610] Iteration 82960, lr = 6.1741e-09
I0316 20:23:04.449854 29479 solver.cpp:613] Iteration 82960, avg_grad_norm = 500364
I0316 20:24:11.777490 29479 solver.cpp:214] Iteration 82980, loss = 5654.37
I0316 20:24:11.777676 29479 solver.cpp:229]     Train net output #0: loss = 5785.72 (* 1 = 5785.72 loss)
I0316 20:24:12.161337 29479 solver.cpp:610] Iteration 82980, lr = 6.17315e-09
I0316 20:24:12.161350 29479 solver.cpp:613] Iteration 82980, avg_grad_norm = 530395
I0316 20:25:19.415730 29479 solver.cpp:214] Iteration 83000, loss = 5625.03
I0316 20:25:19.415858 29479 solver.cpp:229]     Train net output #0: loss = 8610.65 (* 1 = 8610.65 loss)
I0316 20:25:19.779340 29479 solver.cpp:610] Iteration 83000, lr = 6.1722e-09
I0316 20:25:19.779352 29479 solver.cpp:613] Iteration 83000, avg_grad_norm = 483230
I0316 20:26:16.964064 29479 solver.cpp:214] Iteration 83020, loss = 5541.63
I0316 20:26:16.964200 29479 solver.cpp:229]     Train net output #0: loss = 5388.03 (* 1 = 5388.03 loss)
I0316 20:26:17.077121 29479 solver.cpp:610] Iteration 83020, lr = 6.17125e-09
I0316 20:26:17.077134 29479 solver.cpp:613] Iteration 83020, avg_grad_norm = 486910
I0316 20:27:14.113908 29479 solver.cpp:214] Iteration 83040, loss = 5712.58
I0316 20:27:14.114012 29479 solver.cpp:229]     Train net output #0: loss = 6698.33 (* 1 = 6698.33 loss)
I0316 20:27:14.475617 29479 solver.cpp:610] Iteration 83040, lr = 6.17031e-09
I0316 20:27:14.475630 29479 solver.cpp:613] Iteration 83040, avg_grad_norm = 543237
I0316 20:28:34.625972 29479 solver.cpp:214] Iteration 83060, loss = 5777.92
I0316 20:28:34.626116 29479 solver.cpp:229]     Train net output #0: loss = 9991.06 (* 1 = 9991.06 loss)
I0316 20:28:34.965386 29479 solver.cpp:610] Iteration 83060, lr = 6.16936e-09
I0316 20:28:34.965400 29479 solver.cpp:613] Iteration 83060, avg_grad_norm = 517464
I0316 20:29:42.233253 29479 solver.cpp:214] Iteration 83080, loss = 5539.07
I0316 20:29:42.233381 29479 solver.cpp:229]     Train net output #0: loss = 7281.45 (* 1 = 7281.45 loss)
I0316 20:29:42.598511 29479 solver.cpp:610] Iteration 83080, lr = 6.16841e-09
I0316 20:29:42.598525 29479 solver.cpp:613] Iteration 83080, avg_grad_norm = 550360
I0316 20:30:50.398056 29479 solver.cpp:214] Iteration 83100, loss = 5928.84
I0316 20:30:50.398190 29479 solver.cpp:229]     Train net output #0: loss = 9730.97 (* 1 = 9730.97 loss)
I0316 20:30:50.759171 29479 solver.cpp:610] Iteration 83100, lr = 6.16746e-09
I0316 20:30:50.759183 29479 solver.cpp:613] Iteration 83100, avg_grad_norm = 543368
I0316 20:31:59.188050 29479 solver.cpp:214] Iteration 83120, loss = 5362.34
I0316 20:31:59.188158 29479 solver.cpp:229]     Train net output #0: loss = 2138.48 (* 1 = 2138.48 loss)
I0316 20:31:59.548003 29479 solver.cpp:610] Iteration 83120, lr = 6.16651e-09
I0316 20:31:59.548050 29479 solver.cpp:613] Iteration 83120, avg_grad_norm = 487726
I0316 20:33:07.584650 29479 solver.cpp:214] Iteration 83140, loss = 5626.33
I0316 20:33:07.584774 29479 solver.cpp:229]     Train net output #0: loss = 7401.87 (* 1 = 7401.87 loss)
I0316 20:33:07.947636 29479 solver.cpp:610] Iteration 83140, lr = 6.16556e-09
I0316 20:33:07.947650 29479 solver.cpp:613] Iteration 83140, avg_grad_norm = 518258
I0316 20:33:54.403378 29479 solver.cpp:214] Iteration 83160, loss = 5563.32
I0316 20:33:54.403504 29479 solver.cpp:229]     Train net output #0: loss = 7487.07 (* 1 = 7487.07 loss)
I0316 20:33:54.518301 29479 solver.cpp:610] Iteration 83160, lr = 6.16461e-09
I0316 20:33:54.518314 29479 solver.cpp:613] Iteration 83160, avg_grad_norm = 496448
I0316 20:35:00.047194 29479 solver.cpp:214] Iteration 83180, loss = 5602.59
I0316 20:35:00.047348 29479 solver.cpp:229]     Train net output #0: loss = 3247.68 (* 1 = 3247.68 loss)
I0316 20:35:00.418304 29479 solver.cpp:610] Iteration 83180, lr = 6.16366e-09
I0316 20:35:00.418318 29479 solver.cpp:613] Iteration 83180, avg_grad_norm = 508019
I0316 20:36:20.632963 29479 solver.cpp:214] Iteration 83200, loss = 5534.81
I0316 20:36:20.633172 29479 solver.cpp:229]     Train net output #0: loss = 4458.9 (* 1 = 4458.9 loss)
I0316 20:36:20.993088 29479 solver.cpp:610] Iteration 83200, lr = 6.16271e-09
I0316 20:36:20.993103 29479 solver.cpp:613] Iteration 83200, avg_grad_norm = 514586
I0316 20:37:28.777014 29479 solver.cpp:214] Iteration 83220, loss = 5796.92
I0316 20:37:28.777204 29479 solver.cpp:229]     Train net output #0: loss = 3107.9 (* 1 = 3107.9 loss)
I0316 20:37:29.142448 29479 solver.cpp:610] Iteration 83220, lr = 6.16176e-09
I0316 20:37:29.142462 29479 solver.cpp:613] Iteration 83220, avg_grad_norm = 528496
I0316 20:38:36.723562 29479 solver.cpp:214] Iteration 83240, loss = 5818.87
I0316 20:38:36.723701 29479 solver.cpp:229]     Train net output #0: loss = 6692.04 (* 1 = 6692.04 loss)
I0316 20:38:37.091719 29479 solver.cpp:610] Iteration 83240, lr = 6.16081e-09
I0316 20:38:37.091733 29479 solver.cpp:613] Iteration 83240, avg_grad_norm = 498721
I0316 20:39:45.088866 29479 solver.cpp:214] Iteration 83260, loss = 5693.55
I0316 20:39:45.088974 29479 solver.cpp:229]     Train net output #0: loss = 3204.3 (* 1 = 3204.3 loss)
I0316 20:39:45.457978 29479 solver.cpp:610] Iteration 83260, lr = 6.15986e-09
I0316 20:39:45.457993 29479 solver.cpp:613] Iteration 83260, avg_grad_norm = 487153
I0316 20:40:52.166332 29479 solver.cpp:214] Iteration 83280, loss = 5603.12
I0316 20:40:52.166473 29479 solver.cpp:229]     Train net output #0: loss = 3097.97 (* 1 = 3097.97 loss)
I0316 20:40:52.495465 29479 solver.cpp:610] Iteration 83280, lr = 6.15891e-09
I0316 20:40:52.495478 29479 solver.cpp:613] Iteration 83280, avg_grad_norm = 489458
I0316 20:41:38.315690 29479 solver.cpp:214] Iteration 83300, loss = 5881.49
I0316 20:41:38.315829 29479 solver.cpp:229]     Train net output #0: loss = 6168.02 (* 1 = 6168.02 loss)
I0316 20:41:38.678164 29479 solver.cpp:610] Iteration 83300, lr = 6.15796e-09
I0316 20:41:38.678179 29479 solver.cpp:613] Iteration 83300, avg_grad_norm = 488320
I0316 20:42:57.131400 29479 solver.cpp:214] Iteration 83320, loss = 5843.26
I0316 20:42:57.131547 29479 solver.cpp:229]     Train net output #0: loss = 4962.76 (* 1 = 4962.76 loss)
I0316 20:42:57.494910 29479 solver.cpp:610] Iteration 83320, lr = 6.15701e-09
I0316 20:42:57.494923 29479 solver.cpp:613] Iteration 83320, avg_grad_norm = 551277
I0316 20:44:04.306481 29479 solver.cpp:214] Iteration 83340, loss = 5775.42
I0316 20:44:04.306613 29479 solver.cpp:229]     Train net output #0: loss = 8689.34 (* 1 = 8689.34 loss)
I0316 20:44:04.667268 29479 solver.cpp:610] Iteration 83340, lr = 6.15606e-09
I0316 20:44:04.667281 29479 solver.cpp:613] Iteration 83340, avg_grad_norm = 541789
I0316 20:45:12.438271 29479 solver.cpp:214] Iteration 83360, loss = 5756.03
I0316 20:45:12.438398 29479 solver.cpp:229]     Train net output #0: loss = 5296.18 (* 1 = 5296.18 loss)
I0316 20:45:12.798919 29479 solver.cpp:610] Iteration 83360, lr = 6.15511e-09
I0316 20:45:12.798933 29479 solver.cpp:613] Iteration 83360, avg_grad_norm = 498025
I0316 20:46:20.437345 29479 solver.cpp:214] Iteration 83380, loss = 5636.51
I0316 20:46:20.437553 29479 solver.cpp:229]     Train net output #0: loss = 5205.6 (* 1 = 5205.6 loss)
I0316 20:46:20.820137 29479 solver.cpp:610] Iteration 83380, lr = 6.15416e-09
I0316 20:46:20.820150 29479 solver.cpp:613] Iteration 83380, avg_grad_norm = 514019
I0316 20:47:28.069259 29479 solver.cpp:214] Iteration 83400, loss = 5599.89
I0316 20:47:28.069375 29479 solver.cpp:229]     Train net output #0: loss = 4784.39 (* 1 = 4784.39 loss)
I0316 20:47:28.434058 29479 solver.cpp:610] Iteration 83400, lr = 6.15321e-09
I0316 20:47:28.434072 29479 solver.cpp:613] Iteration 83400, avg_grad_norm = 495377
I0316 20:48:35.830135 29479 solver.cpp:214] Iteration 83420, loss = 5712.54
I0316 20:48:35.830324 29479 solver.cpp:229]     Train net output #0: loss = 5335.42 (* 1 = 5335.42 loss)
I0316 20:48:36.192817 29479 solver.cpp:610] Iteration 83420, lr = 6.15226e-09
I0316 20:48:36.192831 29479 solver.cpp:613] Iteration 83420, avg_grad_norm = 536118
I0316 20:49:35.970293 29479 solver.cpp:214] Iteration 83440, loss = 5575.5
I0316 20:49:35.970433 29479 solver.cpp:229]     Train net output #0: loss = 3179.1 (* 1 = 3179.1 loss)
I0316 20:49:36.331022 29479 solver.cpp:610] Iteration 83440, lr = 6.15131e-09
I0316 20:49:36.331037 29479 solver.cpp:613] Iteration 83440, avg_grad_norm = 496753
I0316 20:50:43.670617 29479 solver.cpp:214] Iteration 83460, loss = 5502.49
I0316 20:50:43.670804 29479 solver.cpp:229]     Train net output #0: loss = 3978.5 (* 1 = 3978.5 loss)
I0316 20:50:44.061347 29479 solver.cpp:610] Iteration 83460, lr = 6.15036e-09
I0316 20:50:44.061360 29479 solver.cpp:613] Iteration 83460, avg_grad_norm = 490449
I0316 20:51:48.225111 29479 solver.cpp:214] Iteration 83480, loss = 5537.74
I0316 20:51:48.225226 29479 solver.cpp:229]     Train net output #0: loss = 4883.96 (* 1 = 4883.96 loss)
I0316 20:51:48.602599 29479 solver.cpp:610] Iteration 83480, lr = 6.14941e-09
I0316 20:51:48.602613 29479 solver.cpp:613] Iteration 83480, avg_grad_norm = 510674
I0316 20:52:55.436404 29479 solver.cpp:214] Iteration 83500, loss = 5701.84
I0316 20:52:55.436533 29479 solver.cpp:229]     Train net output #0: loss = 3173.38 (* 1 = 3173.38 loss)
I0316 20:52:55.802321 29479 solver.cpp:610] Iteration 83500, lr = 6.14846e-09
I0316 20:52:55.802335 29479 solver.cpp:613] Iteration 83500, avg_grad_norm = 460543
I0316 20:54:03.158368 29479 solver.cpp:214] Iteration 83520, loss = 5746.06
I0316 20:54:03.158488 29479 solver.cpp:229]     Train net output #0: loss = 3506.69 (* 1 = 3506.69 loss)
I0316 20:54:03.520803 29479 solver.cpp:610] Iteration 83520, lr = 6.14751e-09
I0316 20:54:03.520817 29479 solver.cpp:613] Iteration 83520, avg_grad_norm = 463221
I0316 20:55:10.592005 29479 solver.cpp:214] Iteration 83540, loss = 5890.21
I0316 20:55:10.592120 29479 solver.cpp:229]     Train net output #0: loss = 3070.48 (* 1 = 3070.48 loss)
I0316 20:55:10.954743 29479 solver.cpp:610] Iteration 83540, lr = 6.14656e-09
I0316 20:55:10.954756 29479 solver.cpp:613] Iteration 83540, avg_grad_norm = 489447
I0316 20:56:19.063367 29479 solver.cpp:214] Iteration 83560, loss = 5575.41
I0316 20:56:19.063524 29479 solver.cpp:229]     Train net output #0: loss = 5116.45 (* 1 = 5116.45 loss)
I0316 20:56:19.167680 29479 solver.cpp:610] Iteration 83560, lr = 6.14561e-09
I0316 20:56:19.167721 29479 solver.cpp:613] Iteration 83560, avg_grad_norm = 520376
I0316 20:57:47.737439 29479 solver.cpp:214] Iteration 83580, loss = 5804.14
I0316 20:57:47.737635 29479 solver.cpp:229]     Train net output #0: loss = 3397.99 (* 1 = 3397.99 loss)
I0316 20:57:48.096544 29479 solver.cpp:610] Iteration 83580, lr = 6.14466e-09
I0316 20:57:48.096559 29479 solver.cpp:613] Iteration 83580, avg_grad_norm = 564821
I0316 20:58:55.469604 29479 solver.cpp:214] Iteration 83600, loss = 5731.65
I0316 20:58:55.469810 29479 solver.cpp:229]     Train net output #0: loss = 3749.72 (* 1 = 3749.72 loss)
I0316 20:58:55.828969 29479 solver.cpp:610] Iteration 83600, lr = 6.14371e-09
I0316 20:58:55.828990 29479 solver.cpp:613] Iteration 83600, avg_grad_norm = 510277
I0316 21:00:03.402104 29479 solver.cpp:214] Iteration 83620, loss = 5746.03
I0316 21:00:03.402240 29479 solver.cpp:229]     Train net output #0: loss = 9576.88 (* 1 = 9576.88 loss)
I0316 21:00:03.760936 29479 solver.cpp:610] Iteration 83620, lr = 6.14276e-09
I0316 21:00:03.760949 29479 solver.cpp:613] Iteration 83620, avg_grad_norm = 498496
I0316 21:01:10.828440 29479 solver.cpp:214] Iteration 83640, loss = 5588.05
I0316 21:01:10.828654 29479 solver.cpp:229]     Train net output #0: loss = 4570.82 (* 1 = 4570.82 loss)
I0316 21:01:11.191807 29479 solver.cpp:610] Iteration 83640, lr = 6.14181e-09
I0316 21:01:11.191822 29479 solver.cpp:613] Iteration 83640, avg_grad_norm = 482540
I0316 21:02:18.436233 29479 solver.cpp:214] Iteration 83660, loss = 5583.31
I0316 21:02:18.436419 29479 solver.cpp:229]     Train net output #0: loss = 5353.65 (* 1 = 5353.65 loss)
I0316 21:02:18.799669 29479 solver.cpp:610] Iteration 83660, lr = 6.14086e-09
I0316 21:02:18.799684 29479 solver.cpp:613] Iteration 83660, avg_grad_norm = 487678
I0316 21:03:26.176755 29479 solver.cpp:214] Iteration 83680, loss = 5791.76
I0316 21:03:26.176923 29479 solver.cpp:229]     Train net output #0: loss = 3699.99 (* 1 = 3699.99 loss)
I0316 21:03:26.539768 29479 solver.cpp:610] Iteration 83680, lr = 6.13991e-09
I0316 21:03:26.539783 29479 solver.cpp:613] Iteration 83680, avg_grad_norm = 566476
I0316 21:04:37.994756 29479 solver.cpp:214] Iteration 83700, loss = 5422.67
I0316 21:04:37.994897 29479 solver.cpp:229]     Train net output #0: loss = 4971.29 (* 1 = 4971.29 loss)
I0316 21:04:38.348853 29479 solver.cpp:610] Iteration 83700, lr = 6.13896e-09
I0316 21:04:38.348866 29479 solver.cpp:613] Iteration 83700, avg_grad_norm = 547845
I0316 21:05:45.382302 29479 solver.cpp:214] Iteration 83720, loss = 5731.05
I0316 21:05:45.382396 29479 solver.cpp:229]     Train net output #0: loss = 4357.42 (* 1 = 4357.42 loss)
I0316 21:05:45.740600 29479 solver.cpp:610] Iteration 83720, lr = 6.13801e-09
I0316 21:05:45.740613 29479 solver.cpp:613] Iteration 83720, avg_grad_norm = 514929
I0316 21:06:54.084031 29479 solver.cpp:214] Iteration 83740, loss = 5962.02
I0316 21:06:54.084131 29479 solver.cpp:229]     Train net output #0: loss = 5733.4 (* 1 = 5733.4 loss)
I0316 21:06:54.444087 29479 solver.cpp:610] Iteration 83740, lr = 6.13706e-09
I0316 21:06:54.444100 29479 solver.cpp:613] Iteration 83740, avg_grad_norm = 511816
I0316 21:08:03.044939 29479 solver.cpp:214] Iteration 83760, loss = 5547.56
I0316 21:08:03.045060 29479 solver.cpp:229]     Train net output #0: loss = 4716.56 (* 1 = 4716.56 loss)
I0316 21:08:03.404960 29479 solver.cpp:610] Iteration 83760, lr = 6.13611e-09
I0316 21:08:03.404973 29479 solver.cpp:613] Iteration 83760, avg_grad_norm = 617003
I0316 21:09:10.935762 29479 solver.cpp:214] Iteration 83780, loss = 5770.9
I0316 21:09:10.935842 29479 solver.cpp:229]     Train net output #0: loss = 7024.15 (* 1 = 7024.15 loss)
I0316 21:09:11.300016 29479 solver.cpp:610] Iteration 83780, lr = 6.13516e-09
I0316 21:09:11.300029 29479 solver.cpp:613] Iteration 83780, avg_grad_norm = 494620
I0316 21:10:19.398555 29479 solver.cpp:214] Iteration 83800, loss = 5604.45
I0316 21:10:19.398694 29479 solver.cpp:229]     Train net output #0: loss = 4334.37 (* 1 = 4334.37 loss)
I0316 21:10:19.758183 29479 solver.cpp:610] Iteration 83800, lr = 6.13421e-09
I0316 21:10:19.758198 29479 solver.cpp:613] Iteration 83800, avg_grad_norm = 501421
I0316 21:11:33.510342 29479 solver.cpp:214] Iteration 83820, loss = 5663.12
I0316 21:11:33.510486 29479 solver.cpp:229]     Train net output #0: loss = 4914.8 (* 1 = 4914.8 loss)
I0316 21:11:33.619365 29479 solver.cpp:610] Iteration 83820, lr = 6.13326e-09
I0316 21:11:33.619381 29479 solver.cpp:613] Iteration 83820, avg_grad_norm = 526034
I0316 21:12:26.292047 29479 solver.cpp:214] Iteration 83840, loss = 5576.66
I0316 21:12:26.292179 29479 solver.cpp:229]     Train net output #0: loss = 4920.64 (* 1 = 4920.64 loss)
I0316 21:12:26.652696 29479 solver.cpp:610] Iteration 83840, lr = 6.13231e-09
I0316 21:12:26.652710 29479 solver.cpp:613] Iteration 83840, avg_grad_norm = 497563
I0316 21:13:34.743047 29479 solver.cpp:214] Iteration 83860, loss = 5901.24
I0316 21:13:34.743162 29479 solver.cpp:229]     Train net output #0: loss = 6646.15 (* 1 = 6646.15 loss)
I0316 21:13:35.105829 29479 solver.cpp:610] Iteration 83860, lr = 6.13136e-09
I0316 21:13:35.105844 29479 solver.cpp:613] Iteration 83860, avg_grad_norm = 493320
I0316 21:14:43.158895 29479 solver.cpp:214] Iteration 83880, loss = 5877.73
I0316 21:14:43.159037 29479 solver.cpp:229]     Train net output #0: loss = 7340.83 (* 1 = 7340.83 loss)
I0316 21:14:43.484275 29479 solver.cpp:610] Iteration 83880, lr = 6.13041e-09
I0316 21:14:43.484289 29479 solver.cpp:613] Iteration 83880, avg_grad_norm = 553770
I0316 21:15:50.219887 29479 solver.cpp:214] Iteration 83900, loss = 6020.23
I0316 21:15:50.220062 29479 solver.cpp:229]     Train net output #0: loss = 7994.13 (* 1 = 7994.13 loss)
I0316 21:15:50.584067 29479 solver.cpp:610] Iteration 83900, lr = 6.12946e-09
I0316 21:15:50.584081 29479 solver.cpp:613] Iteration 83900, avg_grad_norm = 572251
I0316 21:16:58.452234 29479 solver.cpp:214] Iteration 83920, loss = 5748.55
I0316 21:16:58.452364 29479 solver.cpp:229]     Train net output #0: loss = 8020.45 (* 1 = 8020.45 loss)
I0316 21:16:58.812681 29479 solver.cpp:610] Iteration 83920, lr = 6.12851e-09
I0316 21:16:58.812695 29479 solver.cpp:613] Iteration 83920, avg_grad_norm = 531355
I0316 21:18:06.947691 29479 solver.cpp:214] Iteration 83940, loss = 5888.73
I0316 21:18:06.947813 29479 solver.cpp:229]     Train net output #0: loss = 8625.32 (* 1 = 8625.32 loss)
I0316 21:18:07.308028 29479 solver.cpp:610] Iteration 83940, lr = 6.12756e-09
I0316 21:18:07.308043 29479 solver.cpp:613] Iteration 83940, avg_grad_norm = 486815
I0316 21:19:11.977121 29479 solver.cpp:214] Iteration 83960, loss = 5775.59
I0316 21:19:11.977246 29479 solver.cpp:229]     Train net output #0: loss = 6316.07 (* 1 = 6316.07 loss)
I0316 21:19:12.356701 29479 solver.cpp:610] Iteration 83960, lr = 6.12661e-09
I0316 21:19:12.356715 29479 solver.cpp:613] Iteration 83960, avg_grad_norm = 482583
I0316 21:20:20.776031 29479 solver.cpp:214] Iteration 83980, loss = 5715.18
I0316 21:20:20.776162 29479 solver.cpp:229]     Train net output #0: loss = 3248.79 (* 1 = 3248.79 loss)
I0316 21:20:21.139422 29479 solver.cpp:610] Iteration 83980, lr = 6.12566e-09
I0316 21:20:21.139436 29479 solver.cpp:613] Iteration 83980, avg_grad_norm = 511371
I0316 21:21:29.489356 29479 solver.cpp:214] Iteration 84000, loss = 5779.56
I0316 21:21:29.489475 29479 solver.cpp:229]     Train net output #0: loss = 7008.8 (* 1 = 7008.8 loss)
I0316 21:21:29.828320 29479 solver.cpp:610] Iteration 84000, lr = 6.12471e-09
I0316 21:21:29.828335 29479 solver.cpp:613] Iteration 84000, avg_grad_norm = 499700
I0316 21:22:38.017330 29479 solver.cpp:214] Iteration 84020, loss = 5567.99
I0316 21:22:38.017441 29479 solver.cpp:229]     Train net output #0: loss = 5467.59 (* 1 = 5467.59 loss)
I0316 21:22:38.378353 29479 solver.cpp:610] Iteration 84020, lr = 6.12376e-09
I0316 21:22:38.378366 29479 solver.cpp:613] Iteration 84020, avg_grad_norm = 524120
I0316 21:23:45.497977 29479 solver.cpp:214] Iteration 84040, loss = 5994.06
I0316 21:23:45.498088 29479 solver.cpp:229]     Train net output #0: loss = 6128.16 (* 1 = 6128.16 loss)
I0316 21:23:45.883875 29479 solver.cpp:610] Iteration 84040, lr = 6.1228e-09
I0316 21:23:45.883889 29479 solver.cpp:613] Iteration 84040, avg_grad_norm = 586411
I0316 21:24:54.002701 29479 solver.cpp:214] Iteration 84060, loss = 5619.15
I0316 21:24:54.002800 29479 solver.cpp:229]     Train net output #0: loss = 7066.13 (* 1 = 7066.13 loss)
I0316 21:24:54.372398 29479 solver.cpp:610] Iteration 84060, lr = 6.12185e-09
I0316 21:24:54.372412 29479 solver.cpp:613] Iteration 84060, avg_grad_norm = 537798
I0316 21:26:14.865710 29479 solver.cpp:214] Iteration 84080, loss = 5689.51
I0316 21:26:14.865851 29479 solver.cpp:229]     Train net output #0: loss = 4746.33 (* 1 = 4746.33 loss)
I0316 21:26:15.231242 29479 solver.cpp:610] Iteration 84080, lr = 6.1209e-09
I0316 21:26:15.231256 29479 solver.cpp:613] Iteration 84080, avg_grad_norm = 490968
I0316 21:27:00.359902 29479 solver.cpp:214] Iteration 84100, loss = 5534.29
I0316 21:27:00.360038 29479 solver.cpp:229]     Train net output #0: loss = 8385.46 (* 1 = 8385.46 loss)
I0316 21:27:00.722580 29479 solver.cpp:610] Iteration 84100, lr = 6.11995e-09
I0316 21:27:00.722594 29479 solver.cpp:613] Iteration 84100, avg_grad_norm = 488682
I0316 21:28:08.173349 29479 solver.cpp:214] Iteration 84120, loss = 5512.53
I0316 21:28:08.173465 29479 solver.cpp:229]     Train net output #0: loss = 3660.76 (* 1 = 3660.76 loss)
I0316 21:28:08.533259 29479 solver.cpp:610] Iteration 84120, lr = 6.119e-09
I0316 21:28:08.533272 29479 solver.cpp:613] Iteration 84120, avg_grad_norm = 537755
I0316 21:29:16.319614 29479 solver.cpp:214] Iteration 84140, loss = 5787.41
I0316 21:29:16.319859 29479 solver.cpp:229]     Train net output #0: loss = 8062.65 (* 1 = 8062.65 loss)
I0316 21:29:16.710115 29479 solver.cpp:610] Iteration 84140, lr = 6.11805e-09
I0316 21:29:16.710129 29479 solver.cpp:613] Iteration 84140, avg_grad_norm = 497224
I0316 21:30:23.945010 29479 solver.cpp:214] Iteration 84160, loss = 5736.22
I0316 21:30:23.945310 29479 solver.cpp:229]     Train net output #0: loss = 4114.92 (* 1 = 4114.92 loss)
I0316 21:30:24.305264 29479 solver.cpp:610] Iteration 84160, lr = 6.1171e-09
I0316 21:30:24.305299 29479 solver.cpp:613] Iteration 84160, avg_grad_norm = 483502
I0316 21:31:32.556090 29479 solver.cpp:214] Iteration 84180, loss = 5899.23
I0316 21:31:32.556282 29479 solver.cpp:229]     Train net output #0: loss = 5611.15 (* 1 = 5611.15 loss)
I0316 21:31:32.917744 29479 solver.cpp:610] Iteration 84180, lr = 6.11615e-09
I0316 21:31:32.917757 29479 solver.cpp:613] Iteration 84180, avg_grad_norm = 562259
I0316 21:32:56.473935 29479 solver.cpp:214] Iteration 84200, loss = 5867.29
I0316 21:32:56.474056 29479 solver.cpp:229]     Train net output #0: loss = 4948.11 (* 1 = 4948.11 loss)
I0316 21:32:56.833976 29479 solver.cpp:610] Iteration 84200, lr = 6.1152e-09
I0316 21:32:56.833988 29479 solver.cpp:613] Iteration 84200, avg_grad_norm = 551968
I0316 21:33:57.697584 29479 solver.cpp:214] Iteration 84220, loss = 5903.4
I0316 21:33:57.697733 29479 solver.cpp:229]     Train net output #0: loss = 6906.81 (* 1 = 6906.81 loss)
I0316 21:33:57.807905 29479 solver.cpp:610] Iteration 84220, lr = 6.11425e-09
I0316 21:33:57.807919 29479 solver.cpp:613] Iteration 84220, avg_grad_norm = 574465
I0316 21:34:49.477828 29479 solver.cpp:214] Iteration 84240, loss = 5630.83
I0316 21:34:49.477957 29479 solver.cpp:229]     Train net output #0: loss = 10776 (* 1 = 10776 loss)
I0316 21:34:49.840237 29479 solver.cpp:610] Iteration 84240, lr = 6.1133e-09
I0316 21:34:49.840251 29479 solver.cpp:613] Iteration 84240, avg_grad_norm = 508544
I0316 21:35:57.341471 29479 solver.cpp:214] Iteration 84260, loss = 5681.68
I0316 21:35:57.341593 29479 solver.cpp:229]     Train net output #0: loss = 3093.87 (* 1 = 3093.87 loss)
I0316 21:35:57.704215 29479 solver.cpp:610] Iteration 84260, lr = 6.11235e-09
I0316 21:35:57.704229 29479 solver.cpp:613] Iteration 84260, avg_grad_norm = 488655
I0316 21:37:05.310739 29479 solver.cpp:214] Iteration 84280, loss = 5683.98
I0316 21:37:05.310876 29479 solver.cpp:229]     Train net output #0: loss = 3797.37 (* 1 = 3797.37 loss)
I0316 21:37:05.637707 29479 solver.cpp:610] Iteration 84280, lr = 6.1114e-09
I0316 21:37:05.637720 29479 solver.cpp:613] Iteration 84280, avg_grad_norm = 514794
I0316 21:38:13.320677 29479 solver.cpp:214] Iteration 84300, loss = 5751.03
I0316 21:38:13.320854 29479 solver.cpp:229]     Train net output #0: loss = 3830.91 (* 1 = 3830.91 loss)
I0316 21:38:13.681366 29479 solver.cpp:610] Iteration 84300, lr = 6.11045e-09
I0316 21:38:13.681380 29479 solver.cpp:613] Iteration 84300, avg_grad_norm = 489178
I0316 21:39:22.101296 29479 solver.cpp:214] Iteration 84320, loss = 5678.43
I0316 21:39:22.101485 29479 solver.cpp:229]     Train net output #0: loss = 5080.05 (* 1 = 5080.05 loss)
I0316 21:39:22.462021 29479 solver.cpp:610] Iteration 84320, lr = 6.1095e-09
I0316 21:39:22.462044 29479 solver.cpp:613] Iteration 84320, avg_grad_norm = 472825
I0316 21:40:41.566720 29479 solver.cpp:214] Iteration 84340, loss = 6082.84
I0316 21:40:41.566858 29479 solver.cpp:229]     Train net output #0: loss = 3781.72 (* 1 = 3781.72 loss)
I0316 21:40:41.929651 29479 solver.cpp:610] Iteration 84340, lr = 6.10855e-09
I0316 21:40:41.929666 29479 solver.cpp:613] Iteration 84340, avg_grad_norm = 516068
I0316 21:41:35.196437 29479 solver.cpp:214] Iteration 84360, loss = 5749.3
I0316 21:41:35.196584 29479 solver.cpp:229]     Train net output #0: loss = 4075.76 (* 1 = 4075.76 loss)
I0316 21:41:35.312714 29479 solver.cpp:610] Iteration 84360, lr = 6.1076e-09
I0316 21:41:35.312744 29479 solver.cpp:613] Iteration 84360, avg_grad_norm = 528748
I0316 21:42:35.782882 29479 solver.cpp:214] Iteration 84380, loss = 5534.44
I0316 21:42:35.783072 29479 solver.cpp:229]     Train net output #0: loss = 10076.1 (* 1 = 10076.1 loss)
I0316 21:42:36.162176 29479 solver.cpp:610] Iteration 84380, lr = 6.10664e-09
I0316 21:42:36.162190 29479 solver.cpp:613] Iteration 84380, avg_grad_norm = 493323
I0316 21:43:43.310878 29479 solver.cpp:214] Iteration 84400, loss = 5432.56
I0316 21:43:43.311069 29479 solver.cpp:229]     Train net output #0: loss = 8460.99 (* 1 = 8460.99 loss)
I0316 21:43:43.682278 29479 solver.cpp:610] Iteration 84400, lr = 6.10569e-09
I0316 21:43:43.682301 29479 solver.cpp:613] Iteration 84400, avg_grad_norm = 478375
I0316 21:44:51.994338 29479 solver.cpp:214] Iteration 84420, loss = 5698.19
I0316 21:44:51.994470 29479 solver.cpp:229]     Train net output #0: loss = 5173.2 (* 1 = 5173.2 loss)
I0316 21:44:52.354703 29479 solver.cpp:610] Iteration 84420, lr = 6.10474e-09
I0316 21:44:52.354717 29479 solver.cpp:613] Iteration 84420, avg_grad_norm = 549450
I0316 21:46:01.396718 29479 solver.cpp:214] Iteration 84440, loss = 5656.22
I0316 21:46:01.396857 29479 solver.cpp:229]     Train net output #0: loss = 5065.25 (* 1 = 5065.25 loss)
I0316 21:46:01.760087 29479 solver.cpp:610] Iteration 84440, lr = 6.10379e-09
I0316 21:46:01.760100 29479 solver.cpp:613] Iteration 84440, avg_grad_norm = 510872
I0316 21:47:26.436092 29479 solver.cpp:214] Iteration 84460, loss = 5778.3
I0316 21:47:26.436233 29479 solver.cpp:229]     Train net output #0: loss = 7287.64 (* 1 = 7287.64 loss)
I0316 21:47:26.801497 29479 solver.cpp:610] Iteration 84460, lr = 6.10284e-09
I0316 21:47:26.801532 29479 solver.cpp:613] Iteration 84460, avg_grad_norm = 536335
I0316 21:48:33.674736 29479 solver.cpp:214] Iteration 84480, loss = 5728.97
I0316 21:48:33.674943 29479 solver.cpp:229]     Train net output #0: loss = 3813.14 (* 1 = 3813.14 loss)
I0316 21:48:34.043942 29479 solver.cpp:610] Iteration 84480, lr = 6.10189e-09
I0316 21:48:34.043957 29479 solver.cpp:613] Iteration 84480, avg_grad_norm = 499835
I0316 21:49:18.779882 29479 solver.cpp:214] Iteration 84500, loss = 5831.92
I0316 21:49:18.780020 29479 solver.cpp:229]     Train net output #0: loss = 2994.4 (* 1 = 2994.4 loss)
I0316 21:49:19.116889 29479 solver.cpp:610] Iteration 84500, lr = 6.10094e-09
I0316 21:49:19.116904 29479 solver.cpp:613] Iteration 84500, avg_grad_norm = 487378
I0316 21:50:27.322265 29479 solver.cpp:214] Iteration 84520, loss = 6133.35
I0316 21:50:27.322374 29479 solver.cpp:229]     Train net output #0: loss = 6823.18 (* 1 = 6823.18 loss)
I0316 21:50:27.682700 29479 solver.cpp:610] Iteration 84520, lr = 6.09999e-09
I0316 21:50:27.682713 29479 solver.cpp:613] Iteration 84520, avg_grad_norm = 491827
I0316 21:51:34.843719 29479 solver.cpp:214] Iteration 84540, loss = 5525.9
I0316 21:51:34.843849 29479 solver.cpp:229]     Train net output #0: loss = 7048.9 (* 1 = 7048.9 loss)
I0316 21:51:35.204423 29479 solver.cpp:610] Iteration 84540, lr = 6.09904e-09
I0316 21:51:35.204437 29479 solver.cpp:613] Iteration 84540, avg_grad_norm = 511763
I0316 21:52:42.998916 29479 solver.cpp:214] Iteration 84560, loss = 5832.29
I0316 21:52:42.999049 29479 solver.cpp:229]     Train net output #0: loss = 3624.86 (* 1 = 3624.86 loss)
I0316 21:52:43.323787 29479 solver.cpp:610] Iteration 84560, lr = 6.09809e-09
I0316 21:52:43.323801 29479 solver.cpp:613] Iteration 84560, avg_grad_norm = 540876
I0316 21:54:11.912472 29479 solver.cpp:214] Iteration 84580, loss = 5807.37
I0316 21:54:11.912657 29479 solver.cpp:229]     Train net output #0: loss = 7580.44 (* 1 = 7580.44 loss)
I0316 21:54:12.266331 29479 solver.cpp:610] Iteration 84580, lr = 6.09714e-09
I0316 21:54:12.266345 29479 solver.cpp:613] Iteration 84580, avg_grad_norm = 577882
I0316 21:55:20.130980 29479 solver.cpp:214] Iteration 84600, loss = 5612.92
I0316 21:55:20.131096 29479 solver.cpp:229]     Train net output #0: loss = 8352.98 (* 1 = 8352.98 loss)
I0316 21:55:20.493618 29479 solver.cpp:610] Iteration 84600, lr = 6.09619e-09
I0316 21:55:20.493630 29479 solver.cpp:613] Iteration 84600, avg_grad_norm = 563294
I0316 21:56:23.511575 29479 solver.cpp:214] Iteration 84620, loss = 5455.88
I0316 21:56:23.511762 29479 solver.cpp:229]     Train net output #0: loss = 2756.75 (* 1 = 2756.75 loss)
I0316 21:56:23.616901 29479 solver.cpp:610] Iteration 84620, lr = 6.09524e-09
I0316 21:56:23.616916 29479 solver.cpp:613] Iteration 84620, avg_grad_norm = 596030
I0316 21:57:12.725991 29479 solver.cpp:214] Iteration 84640, loss = 5612.36
I0316 21:57:12.726128 29479 solver.cpp:229]     Train net output #0: loss = 10593.2 (* 1 = 10593.2 loss)
I0316 21:57:13.088502 29479 solver.cpp:610] Iteration 84640, lr = 6.09428e-09
I0316 21:57:13.088515 29479 solver.cpp:613] Iteration 84640, avg_grad_norm = 539363
I0316 21:58:20.508713 29479 solver.cpp:214] Iteration 84660, loss = 5273.36
I0316 21:58:20.508832 29479 solver.cpp:229]     Train net output #0: loss = 3020.88 (* 1 = 3020.88 loss)
I0316 21:58:20.878056 29479 solver.cpp:610] Iteration 84660, lr = 6.09333e-09
I0316 21:58:20.878068 29479 solver.cpp:613] Iteration 84660, avg_grad_norm = 492600
I0316 21:59:29.224125 29479 solver.cpp:214] Iteration 84680, loss = 5803.35
I0316 21:59:29.224267 29479 solver.cpp:229]     Train net output #0: loss = 5174.95 (* 1 = 5174.95 loss)
I0316 21:59:29.410284 29479 solver.cpp:610] Iteration 84680, lr = 6.09238e-09
I0316 21:59:29.410296 29479 solver.cpp:613] Iteration 84680, avg_grad_norm = 489278
I0316 22:00:38.101959 29479 solver.cpp:214] Iteration 84700, loss = 5662.86
I0316 22:00:38.102085 29479 solver.cpp:229]     Train net output #0: loss = 10665.5 (* 1 = 10665.5 loss)
I0316 22:00:38.462673 29479 solver.cpp:610] Iteration 84700, lr = 6.09143e-09
I0316 22:00:38.462687 29479 solver.cpp:613] Iteration 84700, avg_grad_norm = 501052
I0316 22:02:05.464906 29479 solver.cpp:214] Iteration 84720, loss = 5714.01
I0316 22:02:05.465066 29479 solver.cpp:229]     Train net output #0: loss = 3237 (* 1 = 3237 loss)
I0316 22:02:05.828271 29479 solver.cpp:610] Iteration 84720, lr = 6.09048e-09
I0316 22:02:05.828285 29479 solver.cpp:613] Iteration 84720, avg_grad_norm = 522272
I0316 22:03:13.199534 29479 solver.cpp:214] Iteration 84740, loss = 5813.4
I0316 22:03:13.199651 29479 solver.cpp:229]     Train net output #0: loss = 3487.09 (* 1 = 3487.09 loss)
I0316 22:03:13.560307 29479 solver.cpp:610] Iteration 84740, lr = 6.08953e-09
I0316 22:03:13.560322 29479 solver.cpp:613] Iteration 84740, avg_grad_norm = 531628
I0316 22:04:00.948410 29479 solver.cpp:214] Iteration 84760, loss = 5698.06
I0316 22:04:00.948619 29479 solver.cpp:229]     Train net output #0: loss = 7131.31 (* 1 = 7131.31 loss)
I0316 22:04:01.064851 29479 solver.cpp:610] Iteration 84760, lr = 6.08858e-09
I0316 22:04:01.064865 29479 solver.cpp:613] Iteration 84760, avg_grad_norm = 557680
I0316 22:05:08.279012 29479 solver.cpp:214] Iteration 84780, loss = 5842.41
I0316 22:05:08.279155 29479 solver.cpp:229]     Train net output #0: loss = 5016.49 (* 1 = 5016.49 loss)
I0316 22:05:08.642204 29479 solver.cpp:610] Iteration 84780, lr = 6.08763e-09
I0316 22:05:08.642218 29479 solver.cpp:613] Iteration 84780, avg_grad_norm = 535505
I0316 22:06:13.601357 29479 solver.cpp:214] Iteration 84800, loss = 5610.53
I0316 22:06:13.601482 29479 solver.cpp:229]     Train net output #0: loss = 3911.21 (* 1 = 3911.21 loss)
I0316 22:06:13.963395 29479 solver.cpp:610] Iteration 84800, lr = 6.08668e-09
I0316 22:06:13.963408 29479 solver.cpp:613] Iteration 84800, avg_grad_norm = 506708
I0316 22:07:22.290468 29479 solver.cpp:214] Iteration 84820, loss = 5852.61
I0316 22:07:22.290597 29479 solver.cpp:229]     Train net output #0: loss = 3067.67 (* 1 = 3067.67 loss)
I0316 22:07:22.660172 29479 solver.cpp:610] Iteration 84820, lr = 6.08573e-09
I0316 22:07:22.660186 29479 solver.cpp:613] Iteration 84820, avg_grad_norm = 518786
I0316 22:08:42.544337 29479 solver.cpp:214] Iteration 84840, loss = 5628.74
I0316 22:08:42.544442 29479 solver.cpp:229]     Train net output #0: loss = 6139.44 (* 1 = 6139.44 loss)
I0316 22:08:42.905094 29479 solver.cpp:610] Iteration 84840, lr = 6.08477e-09
I0316 22:08:42.905108 29479 solver.cpp:613] Iteration 84840, avg_grad_norm = 488325
I0316 22:09:50.196460 29479 solver.cpp:214] Iteration 84860, loss = 5627.53
I0316 22:09:50.196655 29479 solver.cpp:229]     Train net output #0: loss = 7853.92 (* 1 = 7853.92 loss)
I0316 22:09:50.560003 29479 solver.cpp:610] Iteration 84860, lr = 6.08382e-09
I0316 22:09:50.560016 29479 solver.cpp:613] Iteration 84860, avg_grad_norm = 561670
I0316 22:10:57.162003 29479 solver.cpp:214] Iteration 84880, loss = 5825.44
I0316 22:10:57.162118 29479 solver.cpp:229]     Train net output #0: loss = 4954.34 (* 1 = 4954.34 loss)
I0316 22:10:57.488946 29479 solver.cpp:610] Iteration 84880, lr = 6.08287e-09
I0316 22:10:57.488971 29479 solver.cpp:613] Iteration 84880, avg_grad_norm = 566083
I0316 22:11:37.987417 29479 solver.cpp:214] Iteration 84900, loss = 5842.02
I0316 22:11:37.987562 29479 solver.cpp:229]     Train net output #0: loss = 4260.92 (* 1 = 4260.92 loss)
I0316 22:11:38.102210 29479 solver.cpp:610] Iteration 84900, lr = 6.08192e-09
I0316 22:11:38.102224 29479 solver.cpp:613] Iteration 84900, avg_grad_norm = 532723
I0316 22:12:36.901854 29479 solver.cpp:214] Iteration 84920, loss = 5577.19
I0316 22:12:36.901979 29479 solver.cpp:229]     Train net output #0: loss = 3876.15 (* 1 = 3876.15 loss)
I0316 22:12:37.286098 29479 solver.cpp:610] Iteration 84920, lr = 6.08097e-09
I0316 22:12:37.286111 29479 solver.cpp:613] Iteration 84920, avg_grad_norm = 484042
I0316 22:13:45.085754 29479 solver.cpp:214] Iteration 84940, loss = 5459.74
I0316 22:13:45.085867 29479 solver.cpp:229]     Train net output #0: loss = 3522.18 (* 1 = 3522.18 loss)
I0316 22:13:45.410295 29479 solver.cpp:610] Iteration 84940, lr = 6.08002e-09
I0316 22:13:45.410310 29479 solver.cpp:613] Iteration 84940, avg_grad_norm = 467733
I0316 22:15:05.628399 29479 solver.cpp:214] Iteration 84960, loss = 5356.8
I0316 22:15:05.628538 29479 solver.cpp:229]     Train net output #0: loss = 4924.28 (* 1 = 4924.28 loss)
I0316 22:15:05.962261 29479 solver.cpp:610] Iteration 84960, lr = 6.07907e-09
I0316 22:15:05.962275 29479 solver.cpp:613] Iteration 84960, avg_grad_norm = 451854
I0316 22:16:14.050699 29479 solver.cpp:214] Iteration 84980, loss = 5549.01
I0316 22:16:14.050809 29479 solver.cpp:229]     Train net output #0: loss = 8237.84 (* 1 = 8237.84 loss)
I0316 22:16:14.415763 29479 solver.cpp:610] Iteration 84980, lr = 6.07812e-09
I0316 22:16:14.415776 29479 solver.cpp:613] Iteration 84980, avg_grad_norm = 486837
I0316 22:17:22.778717 29479 solver.cpp:214] Iteration 85000, loss = 5607.26
I0316 22:17:22.778911 29479 solver.cpp:229]     Train net output #0: loss = 5964.17 (* 1 = 5964.17 loss)
I0316 22:17:23.142107 29479 solver.cpp:610] Iteration 85000, lr = 6.07717e-09
I0316 22:17:23.142122 29479 solver.cpp:613] Iteration 85000, avg_grad_norm = 518227
I0316 22:18:30.484233 29479 solver.cpp:214] Iteration 85020, loss = 5571.18
I0316 22:18:30.484349 29479 solver.cpp:229]     Train net output #0: loss = 5652.9 (* 1 = 5652.9 loss)
I0316 22:18:30.682801 29479 solver.cpp:610] Iteration 85020, lr = 6.07621e-09
I0316 22:18:30.682814 29479 solver.cpp:613] Iteration 85020, avg_grad_norm = 497802
I0316 22:19:14.939311 29479 solver.cpp:214] Iteration 85040, loss = 5577.8
I0316 22:19:14.939457 29479 solver.cpp:229]     Train net output #0: loss = 10209 (* 1 = 10209 loss)
I0316 22:19:15.363276 29479 solver.cpp:610] Iteration 85040, lr = 6.07526e-09
I0316 22:19:15.363288 29479 solver.cpp:613] Iteration 85040, avg_grad_norm = 567706
I0316 22:20:23.425691 29479 solver.cpp:214] Iteration 85060, loss = 5454.92
I0316 22:20:23.425827 29479 solver.cpp:229]     Train net output #0: loss = 3979.66 (* 1 = 3979.66 loss)
I0316 22:20:23.786512 29479 solver.cpp:610] Iteration 85060, lr = 6.07431e-09
I0316 22:20:23.786525 29479 solver.cpp:613] Iteration 85060, avg_grad_norm = 507356
I0316 22:21:32.492070 29479 solver.cpp:214] Iteration 85080, loss = 5485.93
I0316 22:21:32.492175 29479 solver.cpp:229]     Train net output #0: loss = 5037.98 (* 1 = 5037.98 loss)
I0316 22:21:32.851907 29479 solver.cpp:610] Iteration 85080, lr = 6.07336e-09
I0316 22:21:32.851922 29479 solver.cpp:613] Iteration 85080, avg_grad_norm = 472712
I0316 22:22:52.524164 29479 solver.cpp:214] Iteration 85100, loss = 5661.67
I0316 22:22:52.524353 29479 solver.cpp:229]     Train net output #0: loss = 2761.48 (* 1 = 2761.48 loss)
I0316 22:22:52.884449 29479 solver.cpp:610] Iteration 85100, lr = 6.07241e-09
I0316 22:22:52.884461 29479 solver.cpp:613] Iteration 85100, avg_grad_norm = 502923
I0316 22:24:00.749744 29479 solver.cpp:214] Iteration 85120, loss = 5656.81
I0316 22:24:00.749871 29479 solver.cpp:229]     Train net output #0: loss = 3350.34 (* 1 = 3350.34 loss)
I0316 22:24:01.138669 29479 solver.cpp:610] Iteration 85120, lr = 6.07146e-09
I0316 22:24:01.138684 29479 solver.cpp:613] Iteration 85120, avg_grad_norm = 547965
I0316 22:25:08.813282 29479 solver.cpp:214] Iteration 85140, loss = 5522.84
I0316 22:25:08.813478 29479 solver.cpp:229]     Train net output #0: loss = 6134.96 (* 1 = 6134.96 loss)
I0316 22:25:09.155467 29479 solver.cpp:610] Iteration 85140, lr = 6.07051e-09
I0316 22:25:09.155501 29479 solver.cpp:613] Iteration 85140, avg_grad_norm = 484545
I0316 22:26:17.060133 29479 solver.cpp:214] Iteration 85160, loss = 5711.9
I0316 22:26:17.060262 29479 solver.cpp:229]     Train net output #0: loss = 9395.85 (* 1 = 9395.85 loss)
I0316 22:26:17.420197 29479 solver.cpp:610] Iteration 85160, lr = 6.06956e-09
I0316 22:26:17.420213 29479 solver.cpp:613] Iteration 85160, avg_grad_norm = 480262
I0316 22:27:03.158342 29479 solver.cpp:214] Iteration 85180, loss = 5415.4
I0316 22:27:03.158551 29479 solver.cpp:229]     Train net output #0: loss = 4291.59 (* 1 = 4291.59 loss)
I0316 22:27:03.519811 29479 solver.cpp:610] Iteration 85180, lr = 6.0686e-09
I0316 22:27:03.519826 29479 solver.cpp:613] Iteration 85180, avg_grad_norm = 470517
I0316 22:28:11.980751 29479 solver.cpp:214] Iteration 85200, loss = 5512.06
I0316 22:28:11.980860 29479 solver.cpp:229]     Train net output #0: loss = 7736.54 (* 1 = 7736.54 loss)
I0316 22:28:12.340471 29479 solver.cpp:610] Iteration 85200, lr = 6.06765e-09
I0316 22:28:12.340484 29479 solver.cpp:613] Iteration 85200, avg_grad_norm = 534712
I0316 22:29:42.000607 29479 solver.cpp:214] Iteration 85220, loss = 5500.44
I0316 22:29:42.000759 29479 solver.cpp:229]     Train net output #0: loss = 4571.85 (* 1 = 4571.85 loss)
I0316 22:29:42.213572 29479 solver.cpp:610] Iteration 85220, lr = 6.0667e-09
I0316 22:29:42.213585 29479 solver.cpp:613] Iteration 85220, avg_grad_norm = 519841
I0316 22:30:49.901600 29479 solver.cpp:214] Iteration 85240, loss = 5597.48
I0316 22:30:49.901738 29479 solver.cpp:229]     Train net output #0: loss = 3268.89 (* 1 = 3268.89 loss)
I0316 22:30:50.262416 29479 solver.cpp:610] Iteration 85240, lr = 6.06575e-09
I0316 22:30:50.262430 29479 solver.cpp:613] Iteration 85240, avg_grad_norm = 534309
I0316 22:31:58.312335 29479 solver.cpp:214] Iteration 85260, loss = 6007.51
I0316 22:31:58.312471 29479 solver.cpp:229]     Train net output #0: loss = 1954.46 (* 1 = 1954.46 loss)
I0316 22:31:58.698631 29479 solver.cpp:610] Iteration 85260, lr = 6.0648e-09
I0316 22:31:58.698644 29479 solver.cpp:613] Iteration 85260, avg_grad_norm = 528158
I0316 22:33:06.969540 29479 solver.cpp:214] Iteration 85280, loss = 5427.21
I0316 22:33:06.969652 29479 solver.cpp:229]     Train net output #0: loss = 4913.35 (* 1 = 4913.35 loss)
I0316 22:33:07.354339 29479 solver.cpp:610] Iteration 85280, lr = 6.06385e-09
I0316 22:33:07.354353 29479 solver.cpp:613] Iteration 85280, avg_grad_norm = 504784
I0316 22:34:03.448846 29479 solver.cpp:214] Iteration 85300, loss = 5582.37
I0316 22:34:03.448956 29479 solver.cpp:229]     Train net output #0: loss = 2678.42 (* 1 = 2678.42 loss)
I0316 22:34:03.563740 29479 solver.cpp:610] Iteration 85300, lr = 6.0629e-09
I0316 22:34:03.563778 29479 solver.cpp:613] Iteration 85300, avg_grad_norm = 525961
I0316 22:35:00.706856 29479 solver.cpp:214] Iteration 85320, loss = 6007.3
I0316 22:35:00.706972 29479 solver.cpp:229]     Train net output #0: loss = 4935.29 (* 1 = 4935.29 loss)
I0316 22:35:01.074429 29479 solver.cpp:610] Iteration 85320, lr = 6.06194e-09
I0316 22:35:01.074442 29479 solver.cpp:613] Iteration 85320, avg_grad_norm = 559837
I0316 22:36:21.776787 29479 solver.cpp:214] Iteration 85340, loss = 5772.9
I0316 22:36:21.776937 29479 solver.cpp:229]     Train net output #0: loss = 9872.81 (* 1 = 9872.81 loss)
I0316 22:36:22.134876 29479 solver.cpp:610] Iteration 85340, lr = 6.06099e-09
I0316 22:36:22.134891 29479 solver.cpp:613] Iteration 85340, avg_grad_norm = 548122
I0316 22:37:30.163830 29479 solver.cpp:214] Iteration 85360, loss = 5622.78
I0316 22:37:30.163928 29479 solver.cpp:229]     Train net output #0: loss = 8102.8 (* 1 = 8102.8 loss)
I0316 22:37:30.509083 29479 solver.cpp:610] Iteration 85360, lr = 6.06004e-09
I0316 22:37:30.509095 29479 solver.cpp:613] Iteration 85360, avg_grad_norm = 607963
I0316 22:38:38.077087 29479 solver.cpp:214] Iteration 85380, loss = 5536.14
I0316 22:38:38.077280 29479 solver.cpp:229]     Train net output #0: loss = 2617.29 (* 1 = 2617.29 loss)
I0316 22:38:38.439431 29479 solver.cpp:610] Iteration 85380, lr = 6.05909e-09
I0316 22:38:38.439446 29479 solver.cpp:613] Iteration 85380, avg_grad_norm = 515576
I0316 22:39:45.474074 29479 solver.cpp:214] Iteration 85400, loss = 5663.8
I0316 22:39:45.474220 29479 solver.cpp:229]     Train net output #0: loss = 4052.71 (* 1 = 4052.71 loss)
I0316 22:39:45.838371 29479 solver.cpp:610] Iteration 85400, lr = 6.05814e-09
I0316 22:39:45.838384 29479 solver.cpp:613] Iteration 85400, avg_grad_norm = 518391
I0316 22:40:52.977756 29479 solver.cpp:214] Iteration 85420, loss = 5733.25
I0316 22:40:52.977886 29479 solver.cpp:229]     Train net output #0: loss = 2805.1 (* 1 = 2805.1 loss)
I0316 22:40:53.341315 29479 solver.cpp:610] Iteration 85420, lr = 6.05719e-09
I0316 22:40:53.341330 29479 solver.cpp:613] Iteration 85420, avg_grad_norm = 491588
I0316 22:41:41.530486 29479 solver.cpp:214] Iteration 85440, loss = 5506.29
I0316 22:41:41.530625 29479 solver.cpp:229]     Train net output #0: loss = 6517.91 (* 1 = 6517.91 loss)
I0316 22:41:41.645284 29479 solver.cpp:610] Iteration 85440, lr = 6.05624e-09
I0316 22:41:41.645299 29479 solver.cpp:613] Iteration 85440, avg_grad_norm = 470018
I0316 22:42:47.234638 29479 solver.cpp:214] Iteration 85460, loss = 5787.59
I0316 22:42:47.234774 29479 solver.cpp:229]     Train net output #0: loss = 3573.91 (* 1 = 3573.91 loss)
I0316 22:42:47.595163 29479 solver.cpp:610] Iteration 85460, lr = 6.05528e-09
I0316 22:42:47.595177 29479 solver.cpp:613] Iteration 85460, avg_grad_norm = 497840
I0316 22:44:08.174890 29479 solver.cpp:214] Iteration 85480, loss = 5732.17
I0316 22:44:08.175045 29479 solver.cpp:229]     Train net output #0: loss = 3350.58 (* 1 = 3350.58 loss)
I0316 22:44:08.538599 29479 solver.cpp:610] Iteration 85480, lr = 6.05433e-09
I0316 22:44:08.538611 29479 solver.cpp:613] Iteration 85480, avg_grad_norm = 513604
I0316 22:45:15.984227 29479 solver.cpp:214] Iteration 85500, loss = 5632.58
I0316 22:45:15.984340 29479 solver.cpp:229]     Train net output #0: loss = 4569.67 (* 1 = 4569.67 loss)
I0316 22:45:16.347537 29479 solver.cpp:610] Iteration 85500, lr = 6.05338e-09
I0316 22:45:16.347550 29479 solver.cpp:613] Iteration 85500, avg_grad_norm = 508238
I0316 22:46:23.624644 29479 solver.cpp:214] Iteration 85520, loss = 5704.67
I0316 22:46:23.624841 29479 solver.cpp:229]     Train net output #0: loss = 4555.75 (* 1 = 4555.75 loss)
I0316 22:46:23.985508 29479 solver.cpp:610] Iteration 85520, lr = 6.05243e-09
I0316 22:46:23.985523 29479 solver.cpp:613] Iteration 85520, avg_grad_norm = 492199
I0316 22:47:31.351676 29479 solver.cpp:214] Iteration 85540, loss = 6073.82
I0316 22:47:31.351802 29479 solver.cpp:229]     Train net output #0: loss = 9451.47 (* 1 = 9451.47 loss)
I0316 22:47:31.718505 29479 solver.cpp:610] Iteration 85540, lr = 6.05148e-09
I0316 22:47:31.718519 29479 solver.cpp:613] Iteration 85540, avg_grad_norm = 535283
I0316 22:48:38.587620 29479 solver.cpp:214] Iteration 85560, loss = 5667.54
I0316 22:48:38.587759 29479 solver.cpp:229]     Train net output #0: loss = 5286.06 (* 1 = 5286.06 loss)
I0316 22:48:38.913240 29479 solver.cpp:610] Iteration 85560, lr = 6.05052e-09
I0316 22:48:38.913254 29479 solver.cpp:613] Iteration 85560, avg_grad_norm = 553218
I0316 22:49:23.681279 29479 solver.cpp:214] Iteration 85580, loss = 5704.14
I0316 22:49:23.681443 29479 solver.cpp:229]     Train net output #0: loss = 12935.4 (* 1 = 12935.4 loss)
I0316 22:49:24.041587 29479 solver.cpp:610] Iteration 85580, lr = 6.04957e-09
I0316 22:49:24.041601 29479 solver.cpp:613] Iteration 85580, avg_grad_norm = 526495
I0316 22:50:48.847419 29479 solver.cpp:214] Iteration 85600, loss = 5961.09
I0316 22:50:48.847564 29479 solver.cpp:229]     Train net output #0: loss = 4876.09 (* 1 = 4876.09 loss)
I0316 22:50:49.190937 29479 solver.cpp:610] Iteration 85600, lr = 6.04862e-09
I0316 22:50:49.190949 29479 solver.cpp:613] Iteration 85600, avg_grad_norm = 563613
I0316 22:51:56.874722 29479 solver.cpp:214] Iteration 85620, loss = 5427.91
I0316 22:51:56.874857 29479 solver.cpp:229]     Train net output #0: loss = 3629.61 (* 1 = 3629.61 loss)
I0316 22:51:57.235286 29479 solver.cpp:610] Iteration 85620, lr = 6.04767e-09
I0316 22:51:57.235299 29479 solver.cpp:613] Iteration 85620, avg_grad_norm = 484273
I0316 22:53:04.378216 29479 solver.cpp:214] Iteration 85640, loss = 5445.2
I0316 22:53:04.378330 29479 solver.cpp:229]     Train net output #0: loss = 5107.48 (* 1 = 5107.48 loss)
I0316 22:53:04.745384 29479 solver.cpp:610] Iteration 85640, lr = 6.04672e-09
I0316 22:53:04.745398 29479 solver.cpp:613] Iteration 85640, avg_grad_norm = 506615
I0316 22:54:12.287904 29479 solver.cpp:214] Iteration 85660, loss = 5854.63
I0316 22:54:12.288035 29479 solver.cpp:229]     Train net output #0: loss = 8092.64 (* 1 = 8092.64 loss)
I0316 22:54:12.492004 29479 solver.cpp:610] Iteration 85660, lr = 6.04577e-09
I0316 22:54:12.492017 29479 solver.cpp:613] Iteration 85660, avg_grad_norm = 546376
I0316 22:55:20.235137 29479 solver.cpp:214] Iteration 85680, loss = 5994.7
I0316 22:55:20.235271 29479 solver.cpp:229]     Train net output #0: loss = 8913.98 (* 1 = 8913.98 loss)
I0316 22:55:20.595048 29479 solver.cpp:610] Iteration 85680, lr = 6.04481e-09
I0316 22:55:20.595062 29479 solver.cpp:613] Iteration 85680, avg_grad_norm = 519128
I0316 22:56:28.635160 29479 solver.cpp:214] Iteration 85700, loss = 5789.53
I0316 22:56:28.635278 29479 solver.cpp:229]     Train net output #0: loss = 8349.2 (* 1 = 8349.2 loss)
I0316 22:56:28.996022 29479 solver.cpp:610] Iteration 85700, lr = 6.04386e-09
I0316 22:56:28.996036 29479 solver.cpp:613] Iteration 85700, avg_grad_norm = 466907
I0316 22:57:25.334449 29479 solver.cpp:214] Iteration 85720, loss = 5474.16
I0316 22:57:25.334602 29479 solver.cpp:229]     Train net output #0: loss = 8913.44 (* 1 = 8913.44 loss)
I0316 22:57:25.646819 29479 solver.cpp:610] Iteration 85720, lr = 6.04291e-09
I0316 22:57:25.646833 29479 solver.cpp:613] Iteration 85720, avg_grad_norm = 528923
I0316 22:58:33.462009 29479 solver.cpp:214] Iteration 85740, loss = 5453.82
I0316 22:58:33.462143 29479 solver.cpp:229]     Train net output #0: loss = 5908.45 (* 1 = 5908.45 loss)
I0316 22:58:33.825451 29479 solver.cpp:610] Iteration 85740, lr = 6.04196e-09
I0316 22:58:33.825465 29479 solver.cpp:613] Iteration 85740, avg_grad_norm = 519158
I0316 22:59:41.317142 29479 solver.cpp:214] Iteration 85760, loss = 5652.76
I0316 22:59:41.317284 29479 solver.cpp:229]     Train net output #0: loss = 5257.07 (* 1 = 5257.07 loss)
I0316 22:59:41.705845 29479 solver.cpp:610] Iteration 85760, lr = 6.04101e-09
I0316 22:59:41.705859 29479 solver.cpp:613] Iteration 85760, avg_grad_norm = 483164
I0316 23:00:49.895366 29479 solver.cpp:214] Iteration 85780, loss = 5458.1
I0316 23:00:49.895500 29479 solver.cpp:229]     Train net output #0: loss = 5493.07 (* 1 = 5493.07 loss)
I0316 23:00:50.256008 29479 solver.cpp:610] Iteration 85780, lr = 6.04006e-09
I0316 23:00:50.256022 29479 solver.cpp:613] Iteration 85780, avg_grad_norm = 485703
I0316 23:01:57.692548 29479 solver.cpp:214] Iteration 85800, loss = 5843.55
I0316 23:01:57.692658 29479 solver.cpp:229]     Train net output #0: loss = 5351.23 (* 1 = 5351.23 loss)
I0316 23:01:58.062674 29479 solver.cpp:610] Iteration 85800, lr = 6.0391e-09
I0316 23:01:58.062687 29479 solver.cpp:613] Iteration 85800, avg_grad_norm = 552289
I0316 23:03:06.005350 29479 solver.cpp:214] Iteration 85820, loss = 5671.49
I0316 23:03:06.005609 29479 solver.cpp:229]     Train net output #0: loss = 3399.03 (* 1 = 3399.03 loss)
I0316 23:03:06.365661 29479 solver.cpp:610] Iteration 85820, lr = 6.03815e-09
I0316 23:03:06.365682 29479 solver.cpp:613] Iteration 85820, avg_grad_norm = 533362
I0316 23:04:08.202090 29479 solver.cpp:214] Iteration 85840, loss = 5733.78
I0316 23:04:08.202224 29479 solver.cpp:229]     Train net output #0: loss = 8280.2 (* 1 = 8280.2 loss)
I0316 23:04:08.312340 29479 solver.cpp:610] Iteration 85840, lr = 6.0372e-09
I0316 23:04:08.312355 29479 solver.cpp:613] Iteration 85840, avg_grad_norm = 470124
I0316 23:05:25.972478 29479 solver.cpp:214] Iteration 85860, loss = 5716.66
I0316 23:05:25.972594 29479 solver.cpp:229]     Train net output #0: loss = 4262.03 (* 1 = 4262.03 loss)
I0316 23:05:26.327848 29479 solver.cpp:610] Iteration 85860, lr = 6.03625e-09
I0316 23:05:26.327862 29479 solver.cpp:613] Iteration 85860, avg_grad_norm = 465380
I0316 23:06:33.058357 29479 solver.cpp:214] Iteration 85880, loss = 5591.2
I0316 23:06:33.058552 29479 solver.cpp:229]     Train net output #0: loss = 10523.5 (* 1 = 10523.5 loss)
I0316 23:06:33.257076 29479 solver.cpp:610] Iteration 85880, lr = 6.0353e-09
I0316 23:06:33.257089 29479 solver.cpp:613] Iteration 85880, avg_grad_norm = 498198
I0316 23:07:40.918967 29479 solver.cpp:214] Iteration 85900, loss = 5610.48
I0316 23:07:40.919085 29479 solver.cpp:229]     Train net output #0: loss = 3171.07 (* 1 = 3171.07 loss)
I0316 23:07:41.281791 29479 solver.cpp:610] Iteration 85900, lr = 6.03434e-09
I0316 23:07:41.281805 29479 solver.cpp:613] Iteration 85900, avg_grad_norm = 476044
I0316 23:08:48.721063 29479 solver.cpp:214] Iteration 85920, loss = 5737.85
I0316 23:08:48.721206 29479 solver.cpp:229]     Train net output #0: loss = 6696.36 (* 1 = 6696.36 loss)
I0316 23:08:49.080610 29479 solver.cpp:610] Iteration 85920, lr = 6.03339e-09
I0316 23:08:49.080624 29479 solver.cpp:613] Iteration 85920, avg_grad_norm = 559434
I0316 23:09:56.631489 29479 solver.cpp:214] Iteration 85940, loss = 5798.8
I0316 23:09:56.631621 29479 solver.cpp:229]     Train net output #0: loss = 3534.7 (* 1 = 3534.7 loss)
I0316 23:09:56.995087 29479 solver.cpp:610] Iteration 85940, lr = 6.03244e-09
I0316 23:09:56.995101 29479 solver.cpp:613] Iteration 85940, avg_grad_norm = 528636
I0316 23:11:04.821663 29479 solver.cpp:214] Iteration 85960, loss = 5601.19
I0316 23:11:04.821792 29479 solver.cpp:229]     Train net output #0: loss = 9789.44 (* 1 = 9789.44 loss)
I0316 23:11:05.182027 29479 solver.cpp:610] Iteration 85960, lr = 6.03149e-09
I0316 23:11:05.182041 29479 solver.cpp:613] Iteration 85960, avg_grad_norm = 509764
I0316 23:12:28.203320 29479 solver.cpp:214] Iteration 85980, loss = 5511.13
I0316 23:12:28.203464 29479 solver.cpp:229]     Train net output #0: loss = 5360.92 (* 1 = 5360.92 loss)
I0316 23:12:28.565340 29479 solver.cpp:610] Iteration 85980, lr = 6.03054e-09
I0316 23:12:28.565353 29479 solver.cpp:613] Iteration 85980, avg_grad_norm = 501936
I0316 23:13:36.116186 29479 solver.cpp:214] Iteration 86000, loss = 5714.54
I0316 23:13:36.116317 29479 solver.cpp:229]     Train net output #0: loss = 8662.73 (* 1 = 8662.73 loss)
I0316 23:13:36.477983 29479 solver.cpp:610] Iteration 86000, lr = 6.02958e-09
I0316 23:13:36.477998 29479 solver.cpp:613] Iteration 86000, avg_grad_norm = 505667
I0316 23:14:43.894894 29479 solver.cpp:214] Iteration 86020, loss = 5427.9
I0316 23:14:43.895009 29479 solver.cpp:229]     Train net output #0: loss = 4687.38 (* 1 = 4687.38 loss)
I0316 23:14:44.253172 29479 solver.cpp:610] Iteration 86020, lr = 6.02863e-09
I0316 23:14:44.253186 29479 solver.cpp:613] Iteration 86020, avg_grad_norm = 518677
I0316 23:15:51.120586 29479 solver.cpp:214] Iteration 86040, loss = 5778.83
I0316 23:15:51.120718 29479 solver.cpp:229]     Train net output #0: loss = 7891.11 (* 1 = 7891.11 loss)
I0316 23:15:51.483889 29479 solver.cpp:610] Iteration 86040, lr = 6.02768e-09
I0316 23:15:51.483903 29479 solver.cpp:613] Iteration 86040, avg_grad_norm = 497518
I0316 23:16:59.223589 29479 solver.cpp:214] Iteration 86060, loss = 5694.49
I0316 23:16:59.223784 29479 solver.cpp:229]     Train net output #0: loss = 3569.11 (* 1 = 3569.11 loss)
I0316 23:16:59.584777 29479 solver.cpp:610] Iteration 86060, lr = 6.02673e-09
I0316 23:16:59.584791 29479 solver.cpp:613] Iteration 86060, avg_grad_norm = 474081
I0316 23:18:07.171938 29479 solver.cpp:214] Iteration 86080, loss = 5515.42
I0316 23:18:07.172085 29479 solver.cpp:229]     Train net output #0: loss = 3441.27 (* 1 = 3441.27 loss)
I0316 23:18:07.505204 29479 solver.cpp:610] Iteration 86080, lr = 6.02578e-09
I0316 23:18:07.505218 29479 solver.cpp:613] Iteration 86080, avg_grad_norm = 504698
I0316 23:19:15.619815 29479 solver.cpp:214] Iteration 86100, loss = 5770.66
I0316 23:19:15.619936 29479 solver.cpp:229]     Train net output #0: loss = 9015.45 (* 1 = 9015.45 loss)
I0316 23:19:15.980548 29479 solver.cpp:610] Iteration 86100, lr = 6.02482e-09
I0316 23:19:15.980562 29479 solver.cpp:613] Iteration 86100, avg_grad_norm = 532915
I0316 23:20:37.427939 29479 solver.cpp:214] Iteration 86120, loss = 5984.88
I0316 23:20:37.428063 29479 solver.cpp:229]     Train net output #0: loss = 5890.11 (* 1 = 5890.11 loss)
I0316 23:20:37.764333 29479 solver.cpp:610] Iteration 86120, lr = 6.02387e-09
I0316 23:20:37.764345 29479 solver.cpp:613] Iteration 86120, avg_grad_norm = 526178
I0316 23:21:43.948222 29479 solver.cpp:214] Iteration 86140, loss = 5796.31
I0316 23:21:43.948354 29479 solver.cpp:229]     Train net output #0: loss = 5486.41 (* 1 = 5486.41 loss)
I0316 23:21:44.309399 29479 solver.cpp:610] Iteration 86140, lr = 6.02292e-09
I0316 23:21:44.309413 29479 solver.cpp:613] Iteration 86140, avg_grad_norm = 541268
I0316 23:22:51.903085 29479 solver.cpp:214] Iteration 86160, loss = 5750.61
I0316 23:22:51.903216 29479 solver.cpp:229]     Train net output #0: loss = 4046.51 (* 1 = 4046.51 loss)
I0316 23:22:52.264837 29479 solver.cpp:610] Iteration 86160, lr = 6.02197e-09
I0316 23:22:52.264850 29479 solver.cpp:613] Iteration 86160, avg_grad_norm = 509256
I0316 23:23:59.658349 29479 solver.cpp:214] Iteration 86180, loss = 5854.52
I0316 23:23:59.658478 29479 solver.cpp:229]     Train net output #0: loss = 7230.76 (* 1 = 7230.76 loss)
I0316 23:24:00.021258 29479 solver.cpp:610] Iteration 86180, lr = 6.02102e-09
I0316 23:24:00.021272 29479 solver.cpp:613] Iteration 86180, avg_grad_norm = 491589
I0316 23:25:07.711050 29479 solver.cpp:214] Iteration 86200, loss = 5461.83
I0316 23:25:07.711191 29479 solver.cpp:229]     Train net output #0: loss = 5318.11 (* 1 = 5318.11 loss)
I0316 23:25:08.070787 29479 solver.cpp:610] Iteration 86200, lr = 6.02006e-09
I0316 23:25:08.070839 29479 solver.cpp:613] Iteration 86200, avg_grad_norm = 507160
I0316 23:26:16.341981 29479 solver.cpp:214] Iteration 86220, loss = 5880.26
I0316 23:26:16.342170 29479 solver.cpp:229]     Train net output #0: loss = 8508.35 (* 1 = 8508.35 loss)
I0316 23:26:16.702713 29479 solver.cpp:610] Iteration 86220, lr = 6.01911e-09
I0316 23:26:16.702726 29479 solver.cpp:613] Iteration 86220, avg_grad_norm = 515576
I0316 23:27:15.762862 29479 solver.cpp:214] Iteration 86240, loss = 5617.88
I0316 23:27:15.763005 29479 solver.cpp:229]     Train net output #0: loss = 5811.81 (* 1 = 5811.81 loss)
I0316 23:27:16.105885 29479 solver.cpp:610] Iteration 86240, lr = 6.01816e-09
I0316 23:27:16.105897 29479 solver.cpp:613] Iteration 86240, avg_grad_norm = 512063
I0316 23:28:24.216017 29479 solver.cpp:214] Iteration 86260, loss = 5620.46
I0316 23:28:24.216130 29479 solver.cpp:229]     Train net output #0: loss = 3606.68 (* 1 = 3606.68 loss)
I0316 23:28:24.575346 29479 solver.cpp:610] Iteration 86260, lr = 6.01721e-09
I0316 23:28:24.575359 29479 solver.cpp:613] Iteration 86260, avg_grad_norm = 550477
I0316 23:29:32.341593 29479 solver.cpp:214] Iteration 86280, loss = 5961.46
I0316 23:29:32.341730 29479 solver.cpp:229]     Train net output #0: loss = 10735.8 (* 1 = 10735.8 loss)
I0316 23:29:32.701887 29479 solver.cpp:610] Iteration 86280, lr = 6.01625e-09
I0316 23:29:32.701901 29479 solver.cpp:613] Iteration 86280, avg_grad_norm = 507588
I0316 23:30:40.142343 29479 solver.cpp:214] Iteration 86300, loss = 5583.2
I0316 23:30:40.142523 29479 solver.cpp:229]     Train net output #0: loss = 7496.73 (* 1 = 7496.73 loss)
I0316 23:30:40.504959 29479 solver.cpp:610] Iteration 86300, lr = 6.0153e-09
I0316 23:30:40.504973 29479 solver.cpp:613] Iteration 86300, avg_grad_norm = 507712
I0316 23:31:47.693639 29479 solver.cpp:214] Iteration 86320, loss = 5517.31
I0316 23:31:47.693843 29479 solver.cpp:229]     Train net output #0: loss = 6786.63 (* 1 = 6786.63 loss)
I0316 23:31:48.056859 29479 solver.cpp:610] Iteration 86320, lr = 6.01435e-09
I0316 23:31:48.056874 29479 solver.cpp:613] Iteration 86320, avg_grad_norm = 533316
I0316 23:32:55.860092 29479 solver.cpp:214] Iteration 86340, loss = 5545.58
I0316 23:32:55.860194 29479 solver.cpp:229]     Train net output #0: loss = 3364.14 (* 1 = 3364.14 loss)
I0316 23:32:56.220402 29479 solver.cpp:610] Iteration 86340, lr = 6.0134e-09
I0316 23:32:56.220415 29479 solver.cpp:613] Iteration 86340, avg_grad_norm = 520958
I0316 23:34:17.871071 29479 solver.cpp:214] Iteration 86360, loss = 5511.82
I0316 23:34:17.871204 29479 solver.cpp:229]     Train net output #0: loss = 8086.94 (* 1 = 8086.94 loss)
I0316 23:34:18.233526 29479 solver.cpp:610] Iteration 86360, lr = 6.01244e-09
I0316 23:34:18.233539 29479 solver.cpp:613] Iteration 86360, avg_grad_norm = 499114
I0316 23:35:02.794291 29479 solver.cpp:214] Iteration 86380, loss = 5434.88
I0316 23:35:02.794420 29479 solver.cpp:229]     Train net output #0: loss = 3549.18 (* 1 = 3549.18 loss)
I0316 23:35:03.157186 29479 solver.cpp:610] Iteration 86380, lr = 6.01149e-09
I0316 23:35:03.157198 29479 solver.cpp:613] Iteration 86380, avg_grad_norm = 497932
I0316 23:36:10.741920 29479 solver.cpp:214] Iteration 86400, loss = 5608.02
I0316 23:36:10.742044 29479 solver.cpp:229]     Train net output #0: loss = 5913.16 (* 1 = 5913.16 loss)
I0316 23:36:11.102316 29479 solver.cpp:610] Iteration 86400, lr = 6.01054e-09
I0316 23:36:11.102330 29479 solver.cpp:613] Iteration 86400, avg_grad_norm = 542025
I0316 23:37:18.839826 29479 solver.cpp:214] Iteration 86420, loss = 5543.87
I0316 23:37:18.840003 29479 solver.cpp:229]     Train net output #0: loss = 3788.48 (* 1 = 3788.48 loss)
I0316 23:37:19.218793 29479 solver.cpp:610] Iteration 86420, lr = 6.00959e-09
I0316 23:37:19.218806 29479 solver.cpp:613] Iteration 86420, avg_grad_norm = 516310
I0316 23:38:26.154829 29479 solver.cpp:214] Iteration 86440, loss = 5690.12
I0316 23:38:26.154999 29479 solver.cpp:229]     Train net output #0: loss = 6825.78 (* 1 = 6825.78 loss)
I0316 23:38:26.514540 29479 solver.cpp:610] Iteration 86440, lr = 6.00864e-09
I0316 23:38:26.514554 29479 solver.cpp:613] Iteration 86440, avg_grad_norm = 521737
I0316 23:39:34.217727 29479 solver.cpp:214] Iteration 86460, loss = 5369.58
I0316 23:39:34.217852 29479 solver.cpp:229]     Train net output #0: loss = 4057.49 (* 1 = 4057.49 loss)
I0316 23:39:34.580879 29479 solver.cpp:610] Iteration 86460, lr = 6.00768e-09
I0316 23:39:34.580893 29479 solver.cpp:613] Iteration 86460, avg_grad_norm = 514375
I0316 23:40:42.734246 29479 solver.cpp:214] Iteration 86480, loss = 5603.89
I0316 23:40:42.734351 29479 solver.cpp:229]     Train net output #0: loss = 4296.8 (* 1 = 4296.8 loss)
I0316 23:40:43.095338 29479 solver.cpp:610] Iteration 86480, lr = 6.00673e-09
I0316 23:40:43.095351 29479 solver.cpp:613] Iteration 86480, avg_grad_norm = 489123
I0316 23:41:57.900295 29479 solver.cpp:214] Iteration 86500, loss = 5473
I0316 23:41:57.900431 29479 solver.cpp:229]     Train net output #0: loss = 5107.31 (* 1 = 5107.31 loss)
I0316 23:41:58.009325 29479 solver.cpp:610] Iteration 86500, lr = 6.00578e-09
I0316 23:41:58.009340 29479 solver.cpp:613] Iteration 86500, avg_grad_norm = 467156
I0316 23:42:47.906816 29479 solver.cpp:214] Iteration 86520, loss = 5604.68
I0316 23:42:47.906954 29479 solver.cpp:229]     Train net output #0: loss = 5909.99 (* 1 = 5909.99 loss)
I0316 23:42:48.275429 29479 solver.cpp:610] Iteration 86520, lr = 6.00483e-09
I0316 23:42:48.275442 29479 solver.cpp:613] Iteration 86520, avg_grad_norm = 486200
I0316 23:43:55.353340 29479 solver.cpp:214] Iteration 86540, loss = 5491.51
I0316 23:43:55.353520 29479 solver.cpp:229]     Train net output #0: loss = 6042.8 (* 1 = 6042.8 loss)
I0316 23:43:55.718804 29479 solver.cpp:610] Iteration 86540, lr = 6.00387e-09
I0316 23:43:55.718817 29479 solver.cpp:613] Iteration 86540, avg_grad_norm = 578922
I0316 23:45:03.304509 29479 solver.cpp:214] Iteration 86560, loss = 5539.36
I0316 23:45:03.304633 29479 solver.cpp:229]     Train net output #0: loss = 7030.53 (* 1 = 7030.53 loss)
I0316 23:45:03.684942 29479 solver.cpp:610] Iteration 86560, lr = 6.00292e-09
I0316 23:45:03.684957 29479 solver.cpp:613] Iteration 86560, avg_grad_norm = 507454
I0316 23:46:12.049901 29479 solver.cpp:214] Iteration 86580, loss = 5810.17
I0316 23:46:12.049981 29479 solver.cpp:229]     Train net output #0: loss = 4382.5 (* 1 = 4382.5 loss)
I0316 23:46:12.410311 29479 solver.cpp:610] Iteration 86580, lr = 6.00197e-09
I0316 23:46:12.410325 29479 solver.cpp:613] Iteration 86580, avg_grad_norm = 494164
I0316 23:47:21.645160 29479 solver.cpp:214] Iteration 86600, loss = 5717.15
I0316 23:47:21.645293 29479 solver.cpp:229]     Train net output #0: loss = 6423.92 (* 1 = 6423.92 loss)
I0316 23:47:22.013245 29479 solver.cpp:610] Iteration 86600, lr = 6.00102e-09
I0316 23:47:22.013276 29479 solver.cpp:613] Iteration 86600, avg_grad_norm = 488487
I0316 23:48:46.387411 29479 solver.cpp:214] Iteration 86620, loss = 5588.46
I0316 23:48:46.387549 29479 solver.cpp:229]     Train net output #0: loss = 4315.51 (* 1 = 4315.51 loss)
I0316 23:48:46.713276 29479 solver.cpp:610] Iteration 86620, lr = 6.00006e-09
I0316 23:48:46.713290 29479 solver.cpp:613] Iteration 86620, avg_grad_norm = 478422
I0316 23:49:36.033979 29479 solver.cpp:214] Iteration 86640, loss = 5444.56
I0316 23:49:36.034126 29479 solver.cpp:229]     Train net output #0: loss = 8615.33 (* 1 = 8615.33 loss)
I0316 23:49:36.150301 29479 solver.cpp:610] Iteration 86640, lr = 5.99911e-09
I0316 23:49:36.150316 29479 solver.cpp:613] Iteration 86640, avg_grad_norm = 511482
I0316 23:50:40.716226 29479 solver.cpp:214] Iteration 86660, loss = 6060.15
I0316 23:50:40.716363 29479 solver.cpp:229]     Train net output #0: loss = 5154.19 (* 1 = 5154.19 loss)
I0316 23:50:41.077213 29479 solver.cpp:610] Iteration 86660, lr = 5.99816e-09
I0316 23:50:41.077225 29479 solver.cpp:613] Iteration 86660, avg_grad_norm = 616051
I0316 23:51:48.326742 29479 solver.cpp:214] Iteration 86680, loss = 5729.89
I0316 23:51:48.326889 29479 solver.cpp:229]     Train net output #0: loss = 2950.57 (* 1 = 2950.57 loss)
I0316 23:51:48.687674 29479 solver.cpp:610] Iteration 86680, lr = 5.9972e-09
I0316 23:51:48.687687 29479 solver.cpp:613] Iteration 86680, avg_grad_norm = 534713
I0316 23:52:56.744146 29479 solver.cpp:214] Iteration 86700, loss = 5408.51
I0316 23:52:56.744256 29479 solver.cpp:229]     Train net output #0: loss = 2850.59 (* 1 = 2850.59 loss)
I0316 23:52:57.104486 29479 solver.cpp:610] Iteration 86700, lr = 5.99625e-09
I0316 23:52:57.104501 29479 solver.cpp:613] Iteration 86700, avg_grad_norm = 517318
I0316 23:54:05.493476 29479 solver.cpp:214] Iteration 86720, loss = 5692.28
I0316 23:54:05.493584 29479 solver.cpp:229]     Train net output #0: loss = 3232.29 (* 1 = 3232.29 loss)
I0316 23:54:05.852238 29479 solver.cpp:610] Iteration 86720, lr = 5.9953e-09
I0316 23:54:05.852252 29479 solver.cpp:613] Iteration 86720, avg_grad_norm = 529624
I0316 23:55:27.342377 29479 solver.cpp:214] Iteration 86740, loss = 5420.87
I0316 23:55:27.342489 29479 solver.cpp:229]     Train net output #0: loss = 4416.57 (* 1 = 4416.57 loss)
I0316 23:55:27.711153 29479 solver.cpp:610] Iteration 86740, lr = 5.99435e-09
I0316 23:55:27.711166 29479 solver.cpp:613] Iteration 86740, avg_grad_norm = 526098
I0316 23:56:35.189422 29479 solver.cpp:214] Iteration 86760, loss = 5851.82
I0316 23:56:35.189630 29479 solver.cpp:229]     Train net output #0: loss = 4682.91 (* 1 = 4682.91 loss)
I0316 23:56:35.535620 29479 solver.cpp:610] Iteration 86760, lr = 5.9934e-09
I0316 23:56:35.535653 29479 solver.cpp:613] Iteration 86760, avg_grad_norm = 519183
I0316 23:57:15.192601 29479 solver.cpp:214] Iteration 86780, loss = 5537.47
I0316 23:57:15.192786 29479 solver.cpp:229]     Train net output #0: loss = 7808.04 (* 1 = 7808.04 loss)
I0316 23:57:15.600582 29479 solver.cpp:610] Iteration 86780, lr = 5.99244e-09
I0316 23:57:15.600600 29479 solver.cpp:613] Iteration 86780, avg_grad_norm = 491096
I0316 23:58:23.745347 29479 solver.cpp:214] Iteration 86800, loss = 5366.46
I0316 23:58:23.745507 29479 solver.cpp:229]     Train net output #0: loss = 7566.54 (* 1 = 7566.54 loss)
I0316 23:58:24.110786 29479 solver.cpp:610] Iteration 86800, lr = 5.99149e-09
I0316 23:58:24.110801 29479 solver.cpp:613] Iteration 86800, avg_grad_norm = 505114
I0316 23:59:32.586019 29479 solver.cpp:214] Iteration 86820, loss = 5472.07
I0316 23:59:32.586149 29479 solver.cpp:229]     Train net output #0: loss = 9691.28 (* 1 = 9691.28 loss)
I0316 23:59:32.946957 29479 solver.cpp:610] Iteration 86820, lr = 5.99054e-09
I0316 23:59:32.946995 29479 solver.cpp:613] Iteration 86820, avg_grad_norm = 463616
I0317 00:00:42.001075 29479 solver.cpp:214] Iteration 86840, loss = 5528.35
I0317 00:00:42.001188 29479 solver.cpp:229]     Train net output #0: loss = 7220.21 (* 1 = 7220.21 loss)
I0317 00:00:42.361807 29479 solver.cpp:610] Iteration 86840, lr = 5.98958e-09
I0317 00:00:42.361821 29479 solver.cpp:613] Iteration 86840, avg_grad_norm = 470578
I0317 00:01:51.271167 29479 solver.cpp:214] Iteration 86860, loss = 5408.45
I0317 00:01:51.271308 29479 solver.cpp:229]     Train net output #0: loss = 9860.19 (* 1 = 9860.19 loss)
I0317 00:01:51.636891 29479 solver.cpp:610] Iteration 86860, lr = 5.98863e-09
I0317 00:01:51.636907 29479 solver.cpp:613] Iteration 86860, avg_grad_norm = 474534
I0317 00:03:23.073508 29479 solver.cpp:214] Iteration 86880, loss = 5644.98
I0317 00:03:23.073639 29479 solver.cpp:229]     Train net output #0: loss = 6940.92 (* 1 = 6940.92 loss)
I0317 00:03:23.436291 29479 solver.cpp:610] Iteration 86880, lr = 5.98768e-09
I0317 00:03:23.436305 29479 solver.cpp:613] Iteration 86880, avg_grad_norm = 478136
I0317 00:04:25.981853 29479 solver.cpp:214] Iteration 86900, loss = 5470.44
I0317 00:04:25.981993 29479 solver.cpp:229]     Train net output #0: loss = 3601.62 (* 1 = 3601.62 loss)
I0317 00:04:26.092077 29479 solver.cpp:610] Iteration 86900, lr = 5.98673e-09
I0317 00:04:26.092092 29479 solver.cpp:613] Iteration 86900, avg_grad_norm = 529492
I0317 00:04:58.454982 29479 solver.cpp:214] Iteration 86920, loss = 5585.42
I0317 00:04:58.455106 29479 solver.cpp:229]     Train net output #0: loss = 6433.12 (* 1 = 6433.12 loss)
I0317 00:04:58.816385 29479 solver.cpp:610] Iteration 86920, lr = 5.98577e-09
I0317 00:04:58.816401 29479 solver.cpp:613] Iteration 86920, avg_grad_norm = 486837
I0317 00:06:05.567188 29479 solver.cpp:214] Iteration 86940, loss = 5728.64
I0317 00:06:05.567452 29479 solver.cpp:229]     Train net output #0: loss = 6187.81 (* 1 = 6187.81 loss)
I0317 00:06:05.932883 29479 solver.cpp:610] Iteration 86940, lr = 5.98482e-09
I0317 00:06:05.932898 29479 solver.cpp:613] Iteration 86940, avg_grad_norm = 498621
I0317 00:07:13.233644 29479 solver.cpp:214] Iteration 86960, loss = 5618.56
I0317 00:07:13.233844 29479 solver.cpp:229]     Train net output #0: loss = 9093.27 (* 1 = 9093.27 loss)
I0317 00:07:13.593765 29479 solver.cpp:610] Iteration 86960, lr = 5.98387e-09
I0317 00:07:13.593778 29479 solver.cpp:613] Iteration 86960, avg_grad_norm = 513365
I0317 00:08:21.935310 29479 solver.cpp:214] Iteration 86980, loss = 5714.16
I0317 00:08:21.935441 29479 solver.cpp:229]     Train net output #0: loss = 4563.55 (* 1 = 4563.55 loss)
I0317 00:08:22.296164 29479 solver.cpp:610] Iteration 86980, lr = 5.98291e-09
I0317 00:08:22.296176 29479 solver.cpp:613] Iteration 86980, avg_grad_norm = 516348
I0317 00:09:42.019369 29479 solver.cpp:214] Iteration 87000, loss = 5554.26
I0317 00:09:42.019497 29479 solver.cpp:229]     Train net output #0: loss = 5526.24 (* 1 = 5526.24 loss)
I0317 00:09:42.234935 29479 solver.cpp:610] Iteration 87000, lr = 5.98196e-09
I0317 00:09:42.234949 29479 solver.cpp:613] Iteration 87000, avg_grad_norm = 483313
I0317 00:10:49.401563 29479 solver.cpp:214] Iteration 87020, loss = 5841.83
I0317 00:10:49.401789 29479 solver.cpp:229]     Train net output #0: loss = 4224.4 (* 1 = 4224.4 loss)
I0317 00:10:49.764453 29479 solver.cpp:610] Iteration 87020, lr = 5.98101e-09
I0317 00:10:49.764467 29479 solver.cpp:613] Iteration 87020, avg_grad_norm = 617783
I0317 00:11:56.852583 29479 solver.cpp:214] Iteration 87040, loss = 5535.05
I0317 00:11:56.852727 29479 solver.cpp:229]     Train net output #0: loss = 3581.1 (* 1 = 3581.1 loss)
I0317 00:11:57.221833 29479 solver.cpp:610] Iteration 87040, lr = 5.98006e-09
I0317 00:11:57.221846 29479 solver.cpp:613] Iteration 87040, avg_grad_norm = 517139
I0317 00:12:40.738025 29479 solver.cpp:214] Iteration 87060, loss = 5626.65
I0317 00:12:40.738131 29479 solver.cpp:229]     Train net output #0: loss = 3705.7 (* 1 = 3705.7 loss)
I0317 00:12:41.101474 29479 solver.cpp:610] Iteration 87060, lr = 5.9791e-09
I0317 00:12:41.101485 29479 solver.cpp:613] Iteration 87060, avg_grad_norm = 559589
I0317 00:13:48.511512 29479 solver.cpp:214] Iteration 87080, loss = 5870.92
I0317 00:13:48.511647 29479 solver.cpp:229]     Train net output #0: loss = 3159.23 (* 1 = 3159.23 loss)
I0317 00:13:48.712647 29479 solver.cpp:610] Iteration 87080, lr = 5.97815e-09
I0317 00:13:48.712661 29479 solver.cpp:613] Iteration 87080, avg_grad_norm = 548791
I0317 00:14:57.502331 29479 solver.cpp:214] Iteration 87100, loss = 5767.45
I0317 00:14:57.502442 29479 solver.cpp:229]     Train net output #0: loss = 11834.5 (* 1 = 11834.5 loss)
I0317 00:14:57.871878 29479 solver.cpp:610] Iteration 87100, lr = 5.9772e-09
I0317 00:14:57.871892 29479 solver.cpp:613] Iteration 87100, avg_grad_norm = 513287
I0317 00:16:29.209291 29479 solver.cpp:214] Iteration 87120, loss = 5523.3
I0317 00:16:29.209419 29479 solver.cpp:229]     Train net output #0: loss = 6871.64 (* 1 = 6871.64 loss)
I0317 00:16:29.572372 29479 solver.cpp:610] Iteration 87120, lr = 5.97624e-09
I0317 00:16:29.572386 29479 solver.cpp:613] Iteration 87120, avg_grad_norm = 488156
I0317 00:17:37.208991 29479 solver.cpp:214] Iteration 87140, loss = 5910.91
I0317 00:17:37.209226 29479 solver.cpp:229]     Train net output #0: loss = 8491.31 (* 1 = 8491.31 loss)
I0317 00:17:37.572746 29479 solver.cpp:610] Iteration 87140, lr = 5.97529e-09
I0317 00:17:37.572762 29479 solver.cpp:613] Iteration 87140, avg_grad_norm = 486707
I0317 00:18:45.674166 29479 solver.cpp:214] Iteration 87160, loss = 5564.93
I0317 00:18:45.674295 29479 solver.cpp:229]     Train net output #0: loss = 4283.37 (* 1 = 4283.37 loss)
I0317 00:18:46.017623 29479 solver.cpp:610] Iteration 87160, lr = 5.97434e-09
I0317 00:18:46.017637 29479 solver.cpp:613] Iteration 87160, avg_grad_norm = 511499
I0317 00:19:40.896082 29479 solver.cpp:214] Iteration 87180, loss = 5608.23
I0317 00:19:40.896248 29479 solver.cpp:229]     Train net output #0: loss = 4485.6 (* 1 = 4485.6 loss)
I0317 00:19:41.006484 29479 solver.cpp:610] Iteration 87180, lr = 5.97338e-09
I0317 00:19:41.006520 29479 solver.cpp:613] Iteration 87180, avg_grad_norm = 519618
I0317 00:20:38.568689 29479 solver.cpp:214] Iteration 87200, loss = 5708.22
I0317 00:20:38.568856 29479 solver.cpp:229]     Train net output #0: loss = 8152.12 (* 1 = 8152.12 loss)
I0317 00:20:38.931324 29479 solver.cpp:610] Iteration 87200, lr = 5.97243e-09
I0317 00:20:38.931337 29479 solver.cpp:613] Iteration 87200, avg_grad_norm = 459176
I0317 00:21:46.956065 29479 solver.cpp:214] Iteration 87220, loss = 5741.49
I0317 00:21:46.956234 29479 solver.cpp:229]     Train net output #0: loss = 3283.69 (* 1 = 3283.69 loss)
I0317 00:21:47.314772 29479 solver.cpp:610] Iteration 87220, lr = 5.97148e-09
I0317 00:21:47.314791 29479 solver.cpp:613] Iteration 87220, avg_grad_norm = 476426
I0317 00:22:55.984189 29479 solver.cpp:214] Iteration 87240, loss = 5703.46
I0317 00:22:55.984297 29479 solver.cpp:229]     Train net output #0: loss = 8712.79 (* 1 = 8712.79 loss)
I0317 00:22:56.342026 29479 solver.cpp:610] Iteration 87240, lr = 5.97053e-09
I0317 00:22:56.342041 29479 solver.cpp:613] Iteration 87240, avg_grad_norm = 506570
I0317 00:24:16.878197 29479 solver.cpp:214] Iteration 87260, loss = 5480.52
I0317 00:24:16.878432 29479 solver.cpp:229]     Train net output #0: loss = 9322.71 (* 1 = 9322.71 loss)
I0317 00:24:17.241868 29479 solver.cpp:610] Iteration 87260, lr = 5.96957e-09
I0317 00:24:17.241881 29479 solver.cpp:613] Iteration 87260, avg_grad_norm = 536911
I0317 00:25:24.476552 29479 solver.cpp:214] Iteration 87280, loss = 5157.96
I0317 00:25:24.476696 29479 solver.cpp:229]     Train net output #0: loss = 8206.92 (* 1 = 8206.92 loss)
I0317 00:25:24.839306 29479 solver.cpp:610] Iteration 87280, lr = 5.96862e-09
I0317 00:25:24.839319 29479 solver.cpp:613] Iteration 87280, avg_grad_norm = 519394
I0317 00:26:32.714745 29479 solver.cpp:214] Iteration 87300, loss = 5544.84
I0317 00:26:32.714936 29479 solver.cpp:229]     Train net output #0: loss = 6222.13 (* 1 = 6222.13 loss)
I0317 00:26:33.043076 29479 solver.cpp:610] Iteration 87300, lr = 5.96767e-09
I0317 00:26:33.043089 29479 solver.cpp:613] Iteration 87300, avg_grad_norm = 551434
I0317 00:27:18.105978 29479 solver.cpp:214] Iteration 87320, loss = 5801.55
I0317 00:27:18.106109 29479 solver.cpp:229]     Train net output #0: loss = 6377.69 (* 1 = 6377.69 loss)
I0317 00:27:18.222090 29479 solver.cpp:610] Iteration 87320, lr = 5.96671e-09
I0317 00:27:18.222105 29479 solver.cpp:613] Iteration 87320, avg_grad_norm = 538949
I0317 00:28:23.167628 29479 solver.cpp:214] Iteration 87340, loss = 5585.98
I0317 00:28:23.167759 29479 solver.cpp:229]     Train net output #0: loss = 4721.42 (* 1 = 4721.42 loss)
I0317 00:28:23.548441 29479 solver.cpp:610] Iteration 87340, lr = 5.96576e-09
I0317 00:28:23.548455 29479 solver.cpp:613] Iteration 87340, avg_grad_norm = 522044
I0317 00:29:31.740598 29479 solver.cpp:214] Iteration 87360, loss = 5676.54
I0317 00:29:31.740716 29479 solver.cpp:229]     Train net output #0: loss = 5008.47 (* 1 = 5008.47 loss)
I0317 00:29:32.120967 29479 solver.cpp:610] Iteration 87360, lr = 5.96481e-09
I0317 00:29:32.120980 29479 solver.cpp:613] Iteration 87360, avg_grad_norm = 482138
I0317 00:30:56.422122 29479 solver.cpp:214] Iteration 87380, loss = 5817.63
I0317 00:30:56.422255 29479 solver.cpp:229]     Train net output #0: loss = 5706.48 (* 1 = 5706.48 loss)
I0317 00:30:56.782240 29479 solver.cpp:610] Iteration 87380, lr = 5.96385e-09
I0317 00:30:56.782253 29479 solver.cpp:613] Iteration 87380, avg_grad_norm = 547353
I0317 00:32:04.208299 29479 solver.cpp:214] Iteration 87400, loss = 5763.94
I0317 00:32:04.208487 29479 solver.cpp:229]     Train net output #0: loss = 9941.19 (* 1 = 9941.19 loss)
I0317 00:32:04.571197 29479 solver.cpp:610] Iteration 87400, lr = 5.9629e-09
I0317 00:32:04.571209 29479 solver.cpp:613] Iteration 87400, avg_grad_norm = 587727
I0317 00:33:11.794025 29479 solver.cpp:214] Iteration 87420, loss = 5582.1
I0317 00:33:11.794142 29479 solver.cpp:229]     Train net output #0: loss = 3226.5 (* 1 = 3226.5 loss)
I0317 00:33:12.158190 29479 solver.cpp:610] Iteration 87420, lr = 5.96195e-09
I0317 00:33:12.158203 29479 solver.cpp:613] Iteration 87420, avg_grad_norm = 558056
I0317 00:34:12.233690 29479 solver.cpp:214] Iteration 87440, loss = 5564.25
I0317 00:34:12.233808 29479 solver.cpp:229]     Train net output #0: loss = 9608.48 (* 1 = 9608.48 loss)
I0317 00:34:12.622666 29479 solver.cpp:610] Iteration 87440, lr = 5.96099e-09
I0317 00:34:12.622716 29479 solver.cpp:613] Iteration 87440, avg_grad_norm = 525443
I0317 00:34:59.052217 29479 solver.cpp:214] Iteration 87460, loss = 5606.14
I0317 00:34:59.052317 29479 solver.cpp:229]     Train net output #0: loss = 3325.99 (* 1 = 3325.99 loss)
I0317 00:34:59.424283 29479 solver.cpp:610] Iteration 87460, lr = 5.96004e-09
I0317 00:34:59.424298 29479 solver.cpp:613] Iteration 87460, avg_grad_norm = 578949
I0317 00:36:07.773561 29479 solver.cpp:214] Iteration 87480, loss = 5679.16
I0317 00:36:07.773749 29479 solver.cpp:229]     Train net output #0: loss = 5401.58 (* 1 = 5401.58 loss)
I0317 00:36:08.133376 29479 solver.cpp:610] Iteration 87480, lr = 5.95909e-09
I0317 00:36:08.133389 29479 solver.cpp:613] Iteration 87480, avg_grad_norm = 599611
I0317 00:37:30.947909 29479 solver.cpp:214] Iteration 87500, loss = 5774.46
I0317 00:37:30.948050 29479 solver.cpp:229]     Train net output #0: loss = 5569.53 (* 1 = 5569.53 loss)
I0317 00:37:31.276314 29479 solver.cpp:610] Iteration 87500, lr = 5.95813e-09
I0317 00:37:31.276329 29479 solver.cpp:613] Iteration 87500, avg_grad_norm = 499422
I0317 00:38:37.874828 29479 solver.cpp:214] Iteration 87520, loss = 5498.78
I0317 00:38:37.874968 29479 solver.cpp:229]     Train net output #0: loss = 7796.26 (* 1 = 7796.26 loss)
I0317 00:38:38.235350 29479 solver.cpp:610] Iteration 87520, lr = 5.95718e-09
I0317 00:38:38.235364 29479 solver.cpp:613] Iteration 87520, avg_grad_norm = 452193
I0317 00:39:45.415019 29479 solver.cpp:214] Iteration 87540, loss = 5554.71
I0317 00:39:45.415150 29479 solver.cpp:229]     Train net output #0: loss = 7337.01 (* 1 = 7337.01 loss)
I0317 00:39:45.800083 29479 solver.cpp:610] Iteration 87540, lr = 5.95623e-09
I0317 00:39:45.800099 29479 solver.cpp:613] Iteration 87540, avg_grad_norm = 480611
I0317 00:40:53.641789 29479 solver.cpp:214] Iteration 87560, loss = 5493.26
I0317 00:40:53.641916 29479 solver.cpp:229]     Train net output #0: loss = 5640.63 (* 1 = 5640.63 loss)
I0317 00:40:54.007010 29479 solver.cpp:610] Iteration 87560, lr = 5.95527e-09
I0317 00:40:54.007037 29479 solver.cpp:613] Iteration 87560, avg_grad_norm = 538693
I0317 00:42:01.510574 29479 solver.cpp:214] Iteration 87580, loss = 6044.59
I0317 00:42:01.510713 29479 solver.cpp:229]     Train net output #0: loss = 7344.44 (* 1 = 7344.44 loss)
I0317 00:42:01.873505 29479 solver.cpp:610] Iteration 87580, lr = 5.95432e-09
I0317 00:42:01.873518 29479 solver.cpp:613] Iteration 87580, avg_grad_norm = 518617
I0317 00:42:44.439692 29479 solver.cpp:214] Iteration 87600, loss = 5352.13
I0317 00:42:44.439812 29479 solver.cpp:229]     Train net output #0: loss = 5671.24 (* 1 = 5671.24 loss)
I0317 00:42:44.799587 29479 solver.cpp:610] Iteration 87600, lr = 5.95337e-09
I0317 00:42:44.799600 29479 solver.cpp:613] Iteration 87600, avg_grad_norm = 570255
I0317 00:43:52.961805 29479 solver.cpp:214] Iteration 87620, loss = 5863.52
I0317 00:43:52.961885 29479 solver.cpp:229]     Train net output #0: loss = 7433.75 (* 1 = 7433.75 loss)
I0317 00:43:53.324492 29479 solver.cpp:610] Iteration 87620, lr = 5.95241e-09
I0317 00:43:53.324506 29479 solver.cpp:613] Iteration 87620, avg_grad_norm = 527346
I0317 00:45:14.463884 29479 solver.cpp:214] Iteration 87640, loss = 5611.63
I0317 00:45:14.464000 29479 solver.cpp:229]     Train net output #0: loss = 3213.04 (* 1 = 3213.04 loss)
I0317 00:45:14.829380 29479 solver.cpp:610] Iteration 87640, lr = 5.95146e-09
I0317 00:45:14.829393 29479 solver.cpp:613] Iteration 87640, avg_grad_norm = 514157
I0317 00:46:22.415226 29479 solver.cpp:214] Iteration 87660, loss = 5376.06
I0317 00:46:22.415356 29479 solver.cpp:229]     Train net output #0: loss = 9171.07 (* 1 = 9171.07 loss)
I0317 00:46:22.778110 29479 solver.cpp:610] Iteration 87660, lr = 5.95051e-09
I0317 00:46:22.778122 29479 solver.cpp:613] Iteration 87660, avg_grad_norm = 470250
I0317 00:47:31.418213 29479 solver.cpp:214] Iteration 87680, loss = 5738.4
I0317 00:47:31.418413 29479 solver.cpp:229]     Train net output #0: loss = 7368.44 (* 1 = 7368.44 loss)
I0317 00:47:31.782374 29479 solver.cpp:610] Iteration 87680, lr = 5.94955e-09
I0317 00:47:31.782388 29479 solver.cpp:613] Iteration 87680, avg_grad_norm = 529233
I0317 00:48:39.688565 29479 solver.cpp:214] Iteration 87700, loss = 5728.27
I0317 00:48:39.688695 29479 solver.cpp:229]     Train net output #0: loss = 10496.2 (* 1 = 10496.2 loss)
I0317 00:48:40.051756 29479 solver.cpp:610] Iteration 87700, lr = 5.9486e-09
I0317 00:48:40.051770 29479 solver.cpp:613] Iteration 87700, avg_grad_norm = 514905
I0317 00:49:44.658305 29479 solver.cpp:214] Iteration 87720, loss = 5603.33
I0317 00:49:44.658506 29479 solver.cpp:229]     Train net output #0: loss = 3903.51 (* 1 = 3903.51 loss)
I0317 00:49:44.767398 29479 solver.cpp:610] Iteration 87720, lr = 5.94765e-09
I0317 00:49:44.767437 29479 solver.cpp:613] Iteration 87720, avg_grad_norm = 516855
I0317 00:50:26.801589 29479 solver.cpp:214] Iteration 87740, loss = 5730.19
I0317 00:50:26.801756 29479 solver.cpp:229]     Train net output #0: loss = 3492.06 (* 1 = 3492.06 loss)
I0317 00:50:27.162251 29479 solver.cpp:610] Iteration 87740, lr = 5.94669e-09
I0317 00:50:27.162266 29479 solver.cpp:613] Iteration 87740, avg_grad_norm = 511852
I0317 00:51:48.181646 29479 solver.cpp:214] Iteration 87760, loss = 5672.84
I0317 00:51:48.181735 29479 solver.cpp:229]     Train net output #0: loss = 4420.69 (* 1 = 4420.69 loss)
I0317 00:51:48.546892 29479 solver.cpp:610] Iteration 87760, lr = 5.94574e-09
I0317 00:51:48.546905 29479 solver.cpp:613] Iteration 87760, avg_grad_norm = 561162
I0317 00:52:55.983770 29479 solver.cpp:214] Iteration 87780, loss = 5523.39
I0317 00:52:55.983902 29479 solver.cpp:229]     Train net output #0: loss = 5370.7 (* 1 = 5370.7 loss)
I0317 00:52:56.349499 29479 solver.cpp:610] Iteration 87780, lr = 5.94479e-09
I0317 00:52:56.349514 29479 solver.cpp:613] Iteration 87780, avg_grad_norm = 551400
I0317 00:54:04.090858 29479 solver.cpp:214] Iteration 87800, loss = 5791
I0317 00:54:04.090957 29479 solver.cpp:229]     Train net output #0: loss = 7433.16 (* 1 = 7433.16 loss)
I0317 00:54:04.464298 29479 solver.cpp:610] Iteration 87800, lr = 5.94383e-09
I0317 00:54:04.464311 29479 solver.cpp:613] Iteration 87800, avg_grad_norm = 532135
I0317 00:55:12.313480 29479 solver.cpp:214] Iteration 87820, loss = 5831.93
I0317 00:55:12.313619 29479 solver.cpp:229]     Train net output #0: loss = 7068.91 (* 1 = 7068.91 loss)
I0317 00:55:12.515810 29479 solver.cpp:610] Iteration 87820, lr = 5.94288e-09
I0317 00:55:12.515825 29479 solver.cpp:613] Iteration 87820, avg_grad_norm = 657426
I0317 00:56:20.619480 29479 solver.cpp:214] Iteration 87840, loss = 5456.12
I0317 00:56:20.619591 29479 solver.cpp:229]     Train net output #0: loss = 11307.9 (* 1 = 11307.9 loss)
I0317 00:56:20.983932 29479 solver.cpp:610] Iteration 87840, lr = 5.94193e-09
I0317 00:56:20.983947 29479 solver.cpp:613] Iteration 87840, avg_grad_norm = 528293
I0317 00:57:23.028214 29479 solver.cpp:214] Iteration 87860, loss = 5641.39
I0317 00:57:23.028348 29479 solver.cpp:229]     Train net output #0: loss = 5132.01 (* 1 = 5132.01 loss)
I0317 00:57:23.141377 29479 solver.cpp:610] Iteration 87860, lr = 5.94097e-09
I0317 00:57:23.141391 29479 solver.cpp:613] Iteration 87860, avg_grad_norm = 550495
I0317 00:58:26.124696 29479 solver.cpp:214] Iteration 87880, loss = 5816.2
I0317 00:58:26.124815 29479 solver.cpp:229]     Train net output #0: loss = 4422.72 (* 1 = 4422.72 loss)
I0317 00:58:26.482576 29479 solver.cpp:610] Iteration 87880, lr = 5.94002e-09
I0317 00:58:26.482589 29479 solver.cpp:613] Iteration 87880, avg_grad_norm = 551696
I0317 00:59:33.784174 29479 solver.cpp:214] Iteration 87900, loss = 5368.12
I0317 00:59:33.784301 29479 solver.cpp:229]     Train net output #0: loss = 5100.77 (* 1 = 5100.77 loss)
I0317 00:59:34.153623 29479 solver.cpp:610] Iteration 87900, lr = 5.93906e-09
I0317 00:59:34.153640 29479 solver.cpp:613] Iteration 87900, avg_grad_norm = 514583
I0317 01:00:41.639947 29479 solver.cpp:214] Iteration 87920, loss = 5842.6
I0317 01:00:41.640076 29479 solver.cpp:229]     Train net output #0: loss = 9286.4 (* 1 = 9286.4 loss)
I0317 01:00:42.001561 29479 solver.cpp:610] Iteration 87920, lr = 5.93811e-09
I0317 01:00:42.001575 29479 solver.cpp:613] Iteration 87920, avg_grad_norm = 488587
I0317 01:01:50.362265 29479 solver.cpp:214] Iteration 87940, loss = 5527.58
I0317 01:01:50.362382 29479 solver.cpp:229]     Train net output #0: loss = 3506.05 (* 1 = 3506.05 loss)
I0317 01:01:50.725739 29479 solver.cpp:610] Iteration 87940, lr = 5.93716e-09
I0317 01:01:50.725751 29479 solver.cpp:613] Iteration 87940, avg_grad_norm = 477667
I0317 01:02:58.125663 29479 solver.cpp:214] Iteration 87960, loss = 5596.56
I0317 01:02:58.125792 29479 solver.cpp:229]     Train net output #0: loss = 9065.17 (* 1 = 9065.17 loss)
I0317 01:02:58.488734 29479 solver.cpp:610] Iteration 87960, lr = 5.9362e-09
I0317 01:02:58.488746 29479 solver.cpp:613] Iteration 87960, avg_grad_norm = 533945
I0317 01:04:06.289474 29479 solver.cpp:214] Iteration 87980, loss = 5713.49
I0317 01:04:06.289708 29479 solver.cpp:229]     Train net output #0: loss = 9116.38 (* 1 = 9116.38 loss)
I0317 01:04:06.653615 29479 solver.cpp:610] Iteration 87980, lr = 5.93525e-09
I0317 01:04:06.653628 29479 solver.cpp:613] Iteration 87980, avg_grad_norm = 527190
I0317 01:05:01.849620 29479 solver.cpp:214] Iteration 88000, loss = 5454.79
I0317 01:05:01.849750 29479 solver.cpp:229]     Train net output #0: loss = 4023.69 (* 1 = 4023.69 loss)
I0317 01:05:01.964390 29479 solver.cpp:610] Iteration 88000, lr = 5.9343e-09
I0317 01:05:01.964406 29479 solver.cpp:613] Iteration 88000, avg_grad_norm = 533477
I0317 01:06:14.325844 29479 solver.cpp:214] Iteration 88020, loss = 5565.52
I0317 01:06:14.325973 29479 solver.cpp:229]     Train net output #0: loss = 5768.32 (* 1 = 5768.32 loss)
I0317 01:06:14.663225 29479 solver.cpp:610] Iteration 88020, lr = 5.93334e-09
I0317 01:06:14.663239 29479 solver.cpp:613] Iteration 88020, avg_grad_norm = 475430
I0317 01:07:22.605818 29479 solver.cpp:214] Iteration 88040, loss = 5730.11
I0317 01:07:22.605928 29479 solver.cpp:229]     Train net output #0: loss = 11778.3 (* 1 = 11778.3 loss)
I0317 01:07:22.966809 29479 solver.cpp:610] Iteration 88040, lr = 5.93239e-09
I0317 01:07:22.966823 29479 solver.cpp:613] Iteration 88040, avg_grad_norm = 530163
I0317 01:08:30.530246 29479 solver.cpp:214] Iteration 88060, loss = 5887.13
I0317 01:08:30.530380 29479 solver.cpp:229]     Train net output #0: loss = 5523.52 (* 1 = 5523.52 loss)
I0317 01:08:30.890430 29479 solver.cpp:610] Iteration 88060, lr = 5.93144e-09
I0317 01:08:30.890470 29479 solver.cpp:613] Iteration 88060, avg_grad_norm = 567228
I0317 01:09:38.388454 29479 solver.cpp:214] Iteration 88080, loss = 5504.11
I0317 01:09:38.388584 29479 solver.cpp:229]     Train net output #0: loss = 4493.19 (* 1 = 4493.19 loss)
I0317 01:09:38.753337 29479 solver.cpp:610] Iteration 88080, lr = 5.93048e-09
I0317 01:09:38.753351 29479 solver.cpp:613] Iteration 88080, avg_grad_norm = 498019
I0317 01:10:46.943336 29479 solver.cpp:214] Iteration 88100, loss = 5847.35
I0317 01:10:46.943465 29479 solver.cpp:229]     Train net output #0: loss = 4722.45 (* 1 = 4722.45 loss)
I0317 01:10:47.306397 29479 solver.cpp:610] Iteration 88100, lr = 5.92953e-09
I0317 01:10:47.306411 29479 solver.cpp:613] Iteration 88100, avg_grad_norm = 507615
I0317 01:11:55.878077 29479 solver.cpp:214] Iteration 88120, loss = 5355.48
I0317 01:11:55.878206 29479 solver.cpp:229]     Train net output #0: loss = 8994.47 (* 1 = 8994.47 loss)
I0317 01:11:56.247051 29479 solver.cpp:610] Iteration 88120, lr = 5.92857e-09
I0317 01:11:56.247064 29479 solver.cpp:613] Iteration 88120, avg_grad_norm = 464030
I0317 01:13:13.536536 29479 solver.cpp:214] Iteration 88140, loss = 5859.43
I0317 01:13:13.536669 29479 solver.cpp:229]     Train net output #0: loss = 6998.59 (* 1 = 6998.59 loss)
I0317 01:13:13.747936 29479 solver.cpp:610] Iteration 88140, lr = 5.92762e-09
I0317 01:13:13.747974 29479 solver.cpp:613] Iteration 88140, avg_grad_norm = 496207
I0317 01:14:20.030539 29479 solver.cpp:214] Iteration 88160, loss = 5692.58
I0317 01:14:20.030659 29479 solver.cpp:229]     Train net output #0: loss = 5609.65 (* 1 = 5609.65 loss)
I0317 01:14:20.390419 29479 solver.cpp:610] Iteration 88160, lr = 5.92667e-09
I0317 01:14:20.390434 29479 solver.cpp:613] Iteration 88160, avg_grad_norm = 530276
I0317 01:15:27.211143 29479 solver.cpp:214] Iteration 88180, loss = 5929.44
I0317 01:15:27.211271 29479 solver.cpp:229]     Train net output #0: loss = 4891.55 (* 1 = 4891.55 loss)
I0317 01:15:27.573223 29479 solver.cpp:610] Iteration 88180, lr = 5.92571e-09
I0317 01:15:27.573236 29479 solver.cpp:613] Iteration 88180, avg_grad_norm = 515954
I0317 01:16:34.523624 29479 solver.cpp:214] Iteration 88200, loss = 5721.97
I0317 01:16:34.523747 29479 solver.cpp:229]     Train net output #0: loss = 7856.94 (* 1 = 7856.94 loss)
I0317 01:16:34.903436 29479 solver.cpp:610] Iteration 88200, lr = 5.92476e-09
I0317 01:16:34.903450 29479 solver.cpp:613] Iteration 88200, avg_grad_norm = 527271
I0317 01:17:43.223078 29479 solver.cpp:214] Iteration 88220, loss = 5826.04
I0317 01:17:43.223258 29479 solver.cpp:229]     Train net output #0: loss = 4113.97 (* 1 = 4113.97 loss)
I0317 01:17:43.549373 29479 solver.cpp:610] Iteration 88220, lr = 5.9238e-09
I0317 01:17:43.549386 29479 solver.cpp:613] Iteration 88220, avg_grad_norm = 485217
I0317 01:18:51.739958 29479 solver.cpp:214] Iteration 88240, loss = 6010.07
I0317 01:18:51.740113 29479 solver.cpp:229]     Train net output #0: loss = 8028.23 (* 1 = 8028.23 loss)
I0317 01:18:52.102748 29479 solver.cpp:610] Iteration 88240, lr = 5.92285e-09
I0317 01:18:52.102762 29479 solver.cpp:613] Iteration 88240, avg_grad_norm = 557332
I0317 01:20:24.897542 29479 solver.cpp:214] Iteration 88260, loss = 5530.41
I0317 01:20:24.897651 29479 solver.cpp:229]     Train net output #0: loss = 5968.15 (* 1 = 5968.15 loss)
I0317 01:20:25.105742 29479 solver.cpp:610] Iteration 88260, lr = 5.9219e-09
I0317 01:20:25.105756 29479 solver.cpp:613] Iteration 88260, avg_grad_norm = 532155
I0317 01:21:31.523391 29479 solver.cpp:214] Iteration 88280, loss = 5756.16
I0317 01:21:31.523488 29479 solver.cpp:229]     Train net output #0: loss = 3681.02 (* 1 = 3681.02 loss)
I0317 01:21:31.880895 29479 solver.cpp:610] Iteration 88280, lr = 5.92094e-09
I0317 01:21:31.880909 29479 solver.cpp:613] Iteration 88280, avg_grad_norm = 506116
I0317 01:22:39.643684 29479 solver.cpp:214] Iteration 88300, loss = 5543.3
I0317 01:22:39.643795 29479 solver.cpp:229]     Train net output #0: loss = 4880.69 (* 1 = 4880.69 loss)
I0317 01:22:40.002647 29479 solver.cpp:610] Iteration 88300, lr = 5.91999e-09
I0317 01:22:40.002661 29479 solver.cpp:613] Iteration 88300, avg_grad_norm = 468505
I0317 01:23:47.711355 29479 solver.cpp:214] Iteration 88320, loss = 5364.92
I0317 01:23:47.711470 29479 solver.cpp:229]     Train net output #0: loss = 3388.17 (* 1 = 3388.17 loss)
I0317 01:23:48.068946 29479 solver.cpp:610] Iteration 88320, lr = 5.91904e-09
I0317 01:23:48.068961 29479 solver.cpp:613] Iteration 88320, avg_grad_norm = 503237
I0317 01:24:55.548856 29479 solver.cpp:214] Iteration 88340, loss = 5607.09
I0317 01:24:55.549000 29479 solver.cpp:229]     Train net output #0: loss = 5057.24 (* 1 = 5057.24 loss)
I0317 01:24:55.911731 29479 solver.cpp:610] Iteration 88340, lr = 5.91808e-09
I0317 01:24:55.911744 29479 solver.cpp:613] Iteration 88340, avg_grad_norm = 560283
I0317 01:26:04.010414 29479 solver.cpp:214] Iteration 88360, loss = 5485.39
I0317 01:26:04.010547 29479 solver.cpp:229]     Train net output #0: loss = 5997.83 (* 1 = 5997.83 loss)
I0317 01:26:04.367537 29479 solver.cpp:610] Iteration 88360, lr = 5.91713e-09
I0317 01:26:04.367552 29479 solver.cpp:613] Iteration 88360, avg_grad_norm = 497919
I0317 01:27:12.447378 29479 solver.cpp:214] Iteration 88380, loss = 5334.48
I0317 01:27:12.447510 29479 solver.cpp:229]     Train net output #0: loss = 4990.76 (* 1 = 4990.76 loss)
I0317 01:27:12.805501 29479 solver.cpp:610] Iteration 88380, lr = 5.91617e-09
I0317 01:27:12.805515 29479 solver.cpp:613] Iteration 88380, avg_grad_norm = 478267
I0317 01:28:36.631037 29479 solver.cpp:214] Iteration 88400, loss = 5715.6
I0317 01:28:36.631171 29479 solver.cpp:229]     Train net output #0: loss = 5339.61 (* 1 = 5339.61 loss)
I0317 01:28:36.944347 29479 solver.cpp:610] Iteration 88400, lr = 5.91522e-09
I0317 01:28:36.944361 29479 solver.cpp:613] Iteration 88400, avg_grad_norm = 507970
I0317 01:29:43.780946 29479 solver.cpp:214] Iteration 88420, loss = 5551.46
I0317 01:29:43.781136 29479 solver.cpp:229]     Train net output #0: loss = 12030.2 (* 1 = 12030.2 loss)
I0317 01:29:44.137426 29479 solver.cpp:610] Iteration 88420, lr = 5.91426e-09
I0317 01:29:44.137439 29479 solver.cpp:613] Iteration 88420, avg_grad_norm = 526551
I0317 01:30:52.340083 29479 solver.cpp:214] Iteration 88440, loss = 5691.81
I0317 01:30:52.340194 29479 solver.cpp:229]     Train net output #0: loss = 3774.11 (* 1 = 3774.11 loss)
I0317 01:30:52.721343 29479 solver.cpp:610] Iteration 88440, lr = 5.91331e-09
I0317 01:30:52.721357 29479 solver.cpp:613] Iteration 88440, avg_grad_norm = 564681
I0317 01:32:00.776234 29479 solver.cpp:214] Iteration 88460, loss = 5701.92
I0317 01:32:00.776494 29479 solver.cpp:229]     Train net output #0: loss = 4892.4 (* 1 = 4892.4 loss)
I0317 01:32:01.113468 29479 solver.cpp:610] Iteration 88460, lr = 5.91236e-09
I0317 01:32:01.113481 29479 solver.cpp:613] Iteration 88460, avg_grad_norm = 490052
I0317 01:33:08.680188 29479 solver.cpp:214] Iteration 88480, loss = 5658.16
I0317 01:33:08.680335 29479 solver.cpp:229]     Train net output #0: loss = 5571.58 (* 1 = 5571.58 loss)
I0317 01:33:09.067345 29479 solver.cpp:610] Iteration 88480, lr = 5.9114e-09
I0317 01:33:09.067358 29479 solver.cpp:613] Iteration 88480, avg_grad_norm = 505510
I0317 01:34:17.184741 29479 solver.cpp:214] Iteration 88500, loss = 5851.04
I0317 01:34:17.184937 29479 solver.cpp:229]     Train net output #0: loss = 7965.51 (* 1 = 7965.51 loss)
I0317 01:34:17.543705 29479 solver.cpp:610] Iteration 88500, lr = 5.91045e-09
I0317 01:34:17.543720 29479 solver.cpp:613] Iteration 88500, avg_grad_norm = 528572
I0317 01:35:26.249310 29479 solver.cpp:214] Iteration 88520, loss = 5816.05
I0317 01:35:26.249470 29479 solver.cpp:229]     Train net output #0: loss = 7815.28 (* 1 = 7815.28 loss)
I0317 01:35:26.353099 29479 solver.cpp:610] Iteration 88520, lr = 5.90949e-09
I0317 01:35:26.353113 29479 solver.cpp:613] Iteration 88520, avg_grad_norm = 605692
I0317 01:36:25.838953 29479 solver.cpp:214] Iteration 88540, loss = 5434.11
I0317 01:36:25.839087 29479 solver.cpp:229]     Train net output #0: loss = 8436.07 (* 1 = 8436.07 loss)
I0317 01:36:26.197352 29479 solver.cpp:610] Iteration 88540, lr = 5.90854e-09
I0317 01:36:26.197366 29479 solver.cpp:613] Iteration 88540, avg_grad_norm = 552693
I0317 01:37:33.782999 29479 solver.cpp:214] Iteration 88560, loss = 5631.7
I0317 01:37:33.783146 29479 solver.cpp:229]     Train net output #0: loss = 6212.94 (* 1 = 6212.94 loss)
I0317 01:37:34.141659 29479 solver.cpp:610] Iteration 88560, lr = 5.90759e-09
I0317 01:37:34.141674 29479 solver.cpp:613] Iteration 88560, avg_grad_norm = 476504
I0317 01:38:40.932538 29479 solver.cpp:214] Iteration 88580, loss = 5655.78
I0317 01:38:40.932664 29479 solver.cpp:229]     Train net output #0: loss = 6695.12 (* 1 = 6695.12 loss)
I0317 01:38:41.288756 29479 solver.cpp:610] Iteration 88580, lr = 5.90663e-09
I0317 01:38:41.288769 29479 solver.cpp:613] Iteration 88580, avg_grad_norm = 509080
I0317 01:39:49.577790 29479 solver.cpp:214] Iteration 88600, loss = 5654.24
I0317 01:39:49.577929 29479 solver.cpp:229]     Train net output #0: loss = 9627.47 (* 1 = 9627.47 loss)
I0317 01:39:49.941001 29479 solver.cpp:610] Iteration 88600, lr = 5.90568e-09
I0317 01:39:49.941015 29479 solver.cpp:613] Iteration 88600, avg_grad_norm = 456683
I0317 01:40:58.658136 29479 solver.cpp:214] Iteration 88620, loss = 5819.85
I0317 01:40:58.658217 29479 solver.cpp:229]     Train net output #0: loss = 4708.26 (* 1 = 4708.26 loss)
I0317 01:40:59.018503 29479 solver.cpp:610] Iteration 88620, lr = 5.90472e-09
I0317 01:40:59.018517 29479 solver.cpp:613] Iteration 88620, avg_grad_norm = 513573
I0317 01:42:07.736107 29479 solver.cpp:214] Iteration 88640, loss = 5723.23
I0317 01:42:07.736230 29479 solver.cpp:229]     Train net output #0: loss = 3838.02 (* 1 = 3838.02 loss)
I0317 01:42:08.094414 29479 solver.cpp:610] Iteration 88640, lr = 5.90377e-09
I0317 01:42:08.094429 29479 solver.cpp:613] Iteration 88640, avg_grad_norm = 524195
I0317 01:43:02.474673 29479 solver.cpp:214] Iteration 88660, loss = 5710.66
I0317 01:43:02.474866 29479 solver.cpp:229]     Train net output #0: loss = 4221.64 (* 1 = 4221.64 loss)
I0317 01:43:02.846424 29479 solver.cpp:610] Iteration 88660, lr = 5.90281e-09
I0317 01:43:02.846441 29479 solver.cpp:613] Iteration 88660, avg_grad_norm = 526586
I0317 01:44:11.039469 29479 solver.cpp:214] Iteration 88680, loss = 5984.5
I0317 01:44:11.039587 29479 solver.cpp:229]     Train net output #0: loss = 6453.26 (* 1 = 6453.26 loss)
I0317 01:44:11.406496 29479 solver.cpp:610] Iteration 88680, lr = 5.90186e-09
I0317 01:44:11.406510 29479 solver.cpp:613] Iteration 88680, avg_grad_norm = 560976
I0317 01:45:19.105654 29479 solver.cpp:214] Iteration 88700, loss = 5759.42
I0317 01:45:19.105829 29479 solver.cpp:229]     Train net output #0: loss = 3843.93 (* 1 = 3843.93 loss)
I0317 01:45:19.438911 29479 solver.cpp:610] Iteration 88700, lr = 5.90091e-09
I0317 01:45:19.438925 29479 solver.cpp:613] Iteration 88700, avg_grad_norm = 563947
I0317 01:46:27.630523 29479 solver.cpp:214] Iteration 88720, loss = 5906.82
I0317 01:46:27.630621 29479 solver.cpp:229]     Train net output #0: loss = 3514.34 (* 1 = 3514.34 loss)
I0317 01:46:27.954984 29479 solver.cpp:610] Iteration 88720, lr = 5.89995e-09
I0317 01:46:27.954998 29479 solver.cpp:613] Iteration 88720, avg_grad_norm = 558635
I0317 01:47:35.282680 29479 solver.cpp:214] Iteration 88740, loss = 5534.12
I0317 01:47:35.282804 29479 solver.cpp:229]     Train net output #0: loss = 4911.53 (* 1 = 4911.53 loss)
I0317 01:47:35.668154 29479 solver.cpp:610] Iteration 88740, lr = 5.899e-09
I0317 01:47:35.668167 29479 solver.cpp:613] Iteration 88740, avg_grad_norm = 550224
I0317 01:48:39.443295 29479 solver.cpp:214] Iteration 88760, loss = 5661.93
I0317 01:48:39.443446 29479 solver.cpp:229]     Train net output #0: loss = 7868.59 (* 1 = 7868.59 loss)
I0317 01:48:39.642352 29479 solver.cpp:610] Iteration 88760, lr = 5.89804e-09
I0317 01:48:39.642366 29479 solver.cpp:613] Iteration 88760, avg_grad_norm = 538439
I0317 01:50:00.434149 29479 solver.cpp:214] Iteration 88780, loss = 5421.6
I0317 01:50:00.434304 29479 solver.cpp:229]     Train net output #0: loss = 4947.25 (* 1 = 4947.25 loss)
I0317 01:50:00.796614 29479 solver.cpp:610] Iteration 88780, lr = 5.89709e-09
I0317 01:50:00.796628 29479 solver.cpp:613] Iteration 88780, avg_grad_norm = 483080
I0317 01:50:46.618216 29479 solver.cpp:214] Iteration 88800, loss = 5455.26
I0317 01:50:46.618338 29479 solver.cpp:229]     Train net output #0: loss = 2944.29 (* 1 = 2944.29 loss)
I0317 01:50:46.978282 29479 solver.cpp:610] Iteration 88800, lr = 5.89613e-09
I0317 01:50:46.978296 29479 solver.cpp:613] Iteration 88800, avg_grad_norm = 537801
I0317 01:51:53.770856 29479 solver.cpp:214] Iteration 88820, loss = 5844.73
I0317 01:51:53.771069 29479 solver.cpp:229]     Train net output #0: loss = 4797.58 (* 1 = 4797.58 loss)
I0317 01:51:54.133386 29479 solver.cpp:610] Iteration 88820, lr = 5.89518e-09
I0317 01:51:54.133400 29479 solver.cpp:613] Iteration 88820, avg_grad_norm = 532436
I0317 01:53:01.850970 29479 solver.cpp:214] Iteration 88840, loss = 5267.36
I0317 01:53:01.851181 29479 solver.cpp:229]     Train net output #0: loss = 4765.73 (* 1 = 4765.73 loss)
I0317 01:53:02.214412 29479 solver.cpp:610] Iteration 88840, lr = 5.89422e-09
I0317 01:53:02.214431 29479 solver.cpp:613] Iteration 88840, avg_grad_norm = 485951
I0317 01:54:10.298460 29479 solver.cpp:214] Iteration 88860, loss = 5916.76
I0317 01:54:10.298668 29479 solver.cpp:229]     Train net output #0: loss = 10961.7 (* 1 = 10961.7 loss)
I0317 01:54:10.659447 29479 solver.cpp:610] Iteration 88860, lr = 5.89327e-09
I0317 01:54:10.659461 29479 solver.cpp:613] Iteration 88860, avg_grad_norm = 536028
I0317 01:55:19.573623 29479 solver.cpp:214] Iteration 88880, loss = 5739.44
I0317 01:55:19.573745 29479 solver.cpp:229]     Train net output #0: loss = 3976.03 (* 1 = 3976.03 loss)
I0317 01:55:19.931851 29479 solver.cpp:610] Iteration 88880, lr = 5.89232e-09
I0317 01:55:19.931866 29479 solver.cpp:613] Iteration 88880, avg_grad_norm = 507327
I0317 01:56:44.784677 29479 solver.cpp:214] Iteration 88900, loss = 5939.7
I0317 01:56:44.784818 29479 solver.cpp:229]     Train net output #0: loss = 9263.7 (* 1 = 9263.7 loss)
I0317 01:56:45.149579 29479 solver.cpp:610] Iteration 88900, lr = 5.89136e-09
I0317 01:56:45.149591 29479 solver.cpp:613] Iteration 88900, avg_grad_norm = 509232
I0317 01:57:49.018803 29479 solver.cpp:214] Iteration 88920, loss = 5481.04
I0317 01:57:49.018918 29479 solver.cpp:229]     Train net output #0: loss = 3130.87 (* 1 = 3130.87 loss)
I0317 01:57:49.126624 29479 solver.cpp:610] Iteration 88920, lr = 5.89041e-09
I0317 01:57:49.126638 29479 solver.cpp:613] Iteration 88920, avg_grad_norm = 555714
I0317 01:58:36.938174 29479 solver.cpp:214] Iteration 88940, loss = 5639.64
I0317 01:58:36.938370 29479 solver.cpp:229]     Train net output #0: loss = 3031.23 (* 1 = 3031.23 loss)
I0317 01:58:37.266093 29479 solver.cpp:610] Iteration 88940, lr = 5.88945e-09
I0317 01:58:37.266108 29479 solver.cpp:613] Iteration 88940, avg_grad_norm = 512569
I0317 01:59:44.097672 29479 solver.cpp:214] Iteration 88960, loss = 5354.93
I0317 01:59:44.097862 29479 solver.cpp:229]     Train net output #0: loss = 5168.29 (* 1 = 5168.29 loss)
I0317 01:59:44.441756 29479 solver.cpp:610] Iteration 88960, lr = 5.8885e-09
I0317 01:59:44.441768 29479 solver.cpp:613] Iteration 88960, avg_grad_norm = 519835
I0317 02:00:52.190560 29479 solver.cpp:214] Iteration 88980, loss = 5402.99
I0317 02:00:52.190680 29479 solver.cpp:229]     Train net output #0: loss = 3473.43 (* 1 = 3473.43 loss)
I0317 02:00:52.551307 29479 solver.cpp:610] Iteration 88980, lr = 5.88754e-09
I0317 02:00:52.551321 29479 solver.cpp:613] Iteration 88980, avg_grad_norm = 463319
I0317 02:02:01.137351 29479 solver.cpp:214] Iteration 89000, loss = 5517.4
I0317 02:02:01.137485 29479 solver.cpp:229]     Train net output #0: loss = 5324.12 (* 1 = 5324.12 loss)
I0317 02:02:01.527813 29479 solver.cpp:610] Iteration 89000, lr = 5.88659e-09
I0317 02:02:01.527830 29479 solver.cpp:613] Iteration 89000, avg_grad_norm = 515938
I0317 02:03:09.957797 29479 solver.cpp:214] Iteration 89020, loss = 5595.78
I0317 02:03:09.957934 29479 solver.cpp:229]     Train net output #0: loss = 4254.98 (* 1 = 4254.98 loss)
I0317 02:03:10.315461 29479 solver.cpp:610] Iteration 89020, lr = 5.88563e-09
I0317 02:03:10.315475 29479 solver.cpp:613] Iteration 89020, avg_grad_norm = 492111
I0317 02:04:37.166818 29479 solver.cpp:214] Iteration 89040, loss = 5555.95
I0317 02:04:37.167026 29479 solver.cpp:229]     Train net output #0: loss = 9846.69 (* 1 = 9846.69 loss)
I0317 02:04:37.527134 29479 solver.cpp:610] Iteration 89040, lr = 5.88468e-09
I0317 02:04:37.527149 29479 solver.cpp:613] Iteration 89040, avg_grad_norm = 553765
I0317 02:05:25.671334 29479 solver.cpp:214] Iteration 89060, loss = 5499.82
I0317 02:05:25.671553 29479 solver.cpp:229]     Train net output #0: loss = 7251.42 (* 1 = 7251.42 loss)
I0317 02:05:25.784618 29479 solver.cpp:610] Iteration 89060, lr = 5.88373e-09
I0317 02:05:25.784632 29479 solver.cpp:613] Iteration 89060, avg_grad_norm = 636340
I0317 02:06:30.519649 29479 solver.cpp:214] Iteration 89080, loss = 5643.94
I0317 02:06:30.519835 29479 solver.cpp:229]     Train net output #0: loss = 7600.82 (* 1 = 7600.82 loss)
I0317 02:06:30.882896 29479 solver.cpp:610] Iteration 89080, lr = 5.88277e-09
I0317 02:06:30.882910 29479 solver.cpp:613] Iteration 89080, avg_grad_norm = 494026
I0317 02:07:38.808679 29479 solver.cpp:214] Iteration 89100, loss = 5638.12
I0317 02:07:38.808904 29479 solver.cpp:229]     Train net output #0: loss = 3023.57 (* 1 = 3023.57 loss)
I0317 02:07:39.178870 29479 solver.cpp:610] Iteration 89100, lr = 5.88182e-09
I0317 02:07:39.178885 29479 solver.cpp:613] Iteration 89100, avg_grad_norm = 522980
I0317 02:08:47.999227 29479 solver.cpp:214] Iteration 89120, loss = 5266.1
I0317 02:08:47.999344 29479 solver.cpp:229]     Train net output #0: loss = 7928.83 (* 1 = 7928.83 loss)
I0317 02:08:48.359436 29479 solver.cpp:610] Iteration 89120, lr = 5.88086e-09
I0317 02:08:48.359472 29479 solver.cpp:613] Iteration 89120, avg_grad_norm = 564896
I0317 02:09:57.190781 29479 solver.cpp:214] Iteration 89140, loss = 5667.84
I0317 02:09:57.190910 29479 solver.cpp:229]     Train net output #0: loss = 4774.61 (* 1 = 4774.61 loss)
I0317 02:09:57.551447 29479 solver.cpp:610] Iteration 89140, lr = 5.87991e-09
I0317 02:09:57.551481 29479 solver.cpp:613] Iteration 89140, avg_grad_norm = 476063
I0317 02:11:32.653574 29479 solver.cpp:214] Iteration 89160, loss = 5712.19
I0317 02:11:32.653717 29479 solver.cpp:229]     Train net output #0: loss = 3843.47 (* 1 = 3843.47 loss)
I0317 02:11:33.020788 29479 solver.cpp:610] Iteration 89160, lr = 5.87895e-09
I0317 02:11:33.020823 29479 solver.cpp:613] Iteration 89160, avg_grad_norm = 505067
I0317 02:12:37.771167 29479 solver.cpp:214] Iteration 89180, loss = 5690.47
I0317 02:12:37.771376 29479 solver.cpp:229]     Train net output #0: loss = 5126.79 (* 1 = 5126.79 loss)
I0317 02:12:37.881284 29479 solver.cpp:610] Iteration 89180, lr = 5.878e-09
I0317 02:12:37.881299 29479 solver.cpp:613] Iteration 89180, avg_grad_norm = 522328
I0317 02:13:03.482489 29479 solver.cpp:214] Iteration 89200, loss = 5546.63
I0317 02:13:03.482542 29479 solver.cpp:229]     Train net output #0: loss = 5470.23 (* 1 = 5470.23 loss)
I0317 02:13:03.597399 29479 solver.cpp:610] Iteration 89200, lr = 5.87704e-09
I0317 02:13:03.597432 29479 solver.cpp:613] Iteration 89200, avg_grad_norm = 513097
I0317 02:14:07.883930 29479 solver.cpp:214] Iteration 89220, loss = 5539.78
I0317 02:14:07.884060 29479 solver.cpp:229]     Train net output #0: loss = 3463.72 (* 1 = 3463.72 loss)
I0317 02:14:08.247438 29479 solver.cpp:610] Iteration 89220, lr = 5.87609e-09
I0317 02:14:08.247484 29479 solver.cpp:613] Iteration 89220, avg_grad_norm = 568772
I0317 02:15:16.698343 29479 solver.cpp:214] Iteration 89240, loss = 5863.1
I0317 02:15:16.698464 29479 solver.cpp:229]     Train net output #0: loss = 4849.73 (* 1 = 4849.73 loss)
I0317 02:15:17.058878 29479 solver.cpp:610] Iteration 89240, lr = 5.87513e-09
I0317 02:15:17.058912 29479 solver.cpp:613] Iteration 89240, avg_grad_norm = 553288
I0317 02:16:26.015446 29479 solver.cpp:214] Iteration 89260, loss = 6019.73
I0317 02:16:26.015581 29479 solver.cpp:229]     Train net output #0: loss = 6739.37 (* 1 = 6739.37 loss)
I0317 02:16:26.382338 29479 solver.cpp:610] Iteration 89260, lr = 5.87418e-09
I0317 02:16:26.382371 29479 solver.cpp:613] Iteration 89260, avg_grad_norm = 562061
I0317 02:18:19.198560 29479 solver.cpp:214] Iteration 89280, loss = 5708.24
I0317 02:18:19.198698 29479 solver.cpp:229]     Train net output #0: loss = 5915.89 (* 1 = 5915.89 loss)
I0317 02:18:19.542286 29479 solver.cpp:610] Iteration 89280, lr = 5.87322e-09
I0317 02:18:19.542312 29479 solver.cpp:613] Iteration 89280, avg_grad_norm = 527061
I0317 02:19:27.847543 29479 solver.cpp:214] Iteration 89300, loss = 5546.34
I0317 02:19:27.847666 29479 solver.cpp:229]     Train net output #0: loss = 4228.44 (* 1 = 4228.44 loss)
I0317 02:19:28.216714 29479 solver.cpp:610] Iteration 89300, lr = 5.87227e-09
I0317 02:19:28.216760 29479 solver.cpp:613] Iteration 89300, avg_grad_norm = 523115
I0317 02:20:16.205545 29479 solver.cpp:214] Iteration 89320, loss = 5649.93
I0317 02:20:16.205783 29479 solver.cpp:229]     Train net output #0: loss = 4943.8 (* 1 = 4943.8 loss)
I0317 02:20:16.321841 29479 solver.cpp:610] Iteration 89320, lr = 5.87131e-09
I0317 02:20:16.321868 29479 solver.cpp:613] Iteration 89320, avg_grad_norm = 540104
I0317 02:20:42.534263 29479 solver.cpp:214] Iteration 89340, loss = 5579.13
I0317 02:20:42.534330 29479 solver.cpp:229]     Train net output #0: loss = 4386.63 (* 1 = 4386.63 loss)
I0317 02:20:42.652076 29479 solver.cpp:610] Iteration 89340, lr = 5.87036e-09
I0317 02:20:42.652091 29479 solver.cpp:613] Iteration 89340, avg_grad_norm = 491825
I0317 02:21:39.265436 29479 solver.cpp:214] Iteration 89360, loss = 5566.55
I0317 02:21:39.265588 29479 solver.cpp:229]     Train net output #0: loss = 4913.36 (* 1 = 4913.36 loss)
I0317 02:21:39.625787 29479 solver.cpp:610] Iteration 89360, lr = 5.8694e-09
I0317 02:21:39.625838 29479 solver.cpp:613] Iteration 89360, avg_grad_norm = 524689
I0317 02:22:48.779242 29479 solver.cpp:214] Iteration 89380, loss = 5574.03
I0317 02:22:48.779350 29479 solver.cpp:229]     Train net output #0: loss = 7087.86 (* 1 = 7087.86 loss)
I0317 02:22:49.139605 29479 solver.cpp:610] Iteration 89380, lr = 5.86845e-09
I0317 02:22:49.139617 29479 solver.cpp:613] Iteration 89380, avg_grad_norm = 501941
I0317 02:23:56.867216 29479 solver.cpp:214] Iteration 89400, loss = 5532.78
I0317 02:23:56.867393 29479 solver.cpp:229]     Train net output #0: loss = 8012.91 (* 1 = 8012.91 loss)
I0317 02:23:57.230110 29479 solver.cpp:610] Iteration 89400, lr = 5.86749e-09
I0317 02:23:57.230124 29479 solver.cpp:613] Iteration 89400, avg_grad_norm = 501393
I0317 02:25:26.298463 29479 solver.cpp:214] Iteration 89420, loss = 5642.13
I0317 02:25:26.298668 29479 solver.cpp:229]     Train net output #0: loss = 2021.63 (* 1 = 2021.63 loss)
I0317 02:25:26.661965 29479 solver.cpp:610] Iteration 89420, lr = 5.86654e-09
I0317 02:25:26.661979 29479 solver.cpp:613] Iteration 89420, avg_grad_norm = 534693
I0317 02:26:33.475503 29479 solver.cpp:214] Iteration 89440, loss = 5562.83
I0317 02:26:33.475633 29479 solver.cpp:229]     Train net output #0: loss = 3942.82 (* 1 = 3942.82 loss)
I0317 02:26:33.864758 29479 solver.cpp:610] Iteration 89440, lr = 5.86558e-09
I0317 02:26:33.864773 29479 solver.cpp:613] Iteration 89440, avg_grad_norm = 471330
I0317 02:27:41.208991 29479 solver.cpp:214] Iteration 89460, loss = 5323.96
I0317 02:27:41.209178 29479 solver.cpp:229]     Train net output #0: loss = 3802.5 (* 1 = 3802.5 loss)
I0317 02:27:41.582409 29479 solver.cpp:610] Iteration 89460, lr = 5.86463e-09
I0317 02:27:41.582422 29479 solver.cpp:613] Iteration 89460, avg_grad_norm = 458404
I0317 02:28:21.249078 29479 solver.cpp:214] Iteration 89480, loss = 5536.55
I0317 02:28:21.249320 29479 solver.cpp:229]     Train net output #0: loss = 7288.7 (* 1 = 7288.7 loss)
I0317 02:28:21.365348 29479 solver.cpp:610] Iteration 89480, lr = 5.86367e-09
I0317 02:28:21.365365 29479 solver.cpp:613] Iteration 89480, avg_grad_norm = 486517
I0317 02:29:16.397429 29479 solver.cpp:214] Iteration 89500, loss = 5639.92
I0317 02:29:16.397565 29479 solver.cpp:229]     Train net output #0: loss = 5882.4 (* 1 = 5882.4 loss)
I0317 02:29:16.767001 29479 solver.cpp:610] Iteration 89500, lr = 5.86272e-09
I0317 02:29:16.767014 29479 solver.cpp:613] Iteration 89500, avg_grad_norm = 484594
I0317 02:30:25.205243 29479 solver.cpp:214] Iteration 89520, loss = 5560.71
I0317 02:30:25.205358 29479 solver.cpp:229]     Train net output #0: loss = 4814.45 (* 1 = 4814.45 loss)
I0317 02:30:25.569953 29479 solver.cpp:610] Iteration 89520, lr = 5.86176e-09
I0317 02:30:25.569967 29479 solver.cpp:613] Iteration 89520, avg_grad_norm = 472202
I0317 02:31:58.483705 29479 solver.cpp:214] Iteration 89540, loss = 5627.03
I0317 02:31:58.483913 29479 solver.cpp:229]     Train net output #0: loss = 7553.06 (* 1 = 7553.06 loss)
I0317 02:31:58.846894 29479 solver.cpp:610] Iteration 89540, lr = 5.86081e-09
I0317 02:31:58.846909 29479 solver.cpp:613] Iteration 89540, avg_grad_norm = 525565
I0317 02:33:06.647723 29479 solver.cpp:214] Iteration 89560, loss = 5769.43
I0317 02:33:06.647863 29479 solver.cpp:229]     Train net output #0: loss = 2701.87 (* 1 = 2701.87 loss)
I0317 02:33:07.016707 29479 solver.cpp:610] Iteration 89560, lr = 5.85985e-09
I0317 02:33:07.016747 29479 solver.cpp:613] Iteration 89560, avg_grad_norm = 546286
I0317 02:34:13.905446 29479 solver.cpp:214] Iteration 89580, loss = 5692.92
I0317 02:34:13.905648 29479 solver.cpp:229]     Train net output #0: loss = 5860.42 (* 1 = 5860.42 loss)
I0317 02:34:14.265557 29479 solver.cpp:610] Iteration 89580, lr = 5.8589e-09
I0317 02:34:14.265578 29479 solver.cpp:613] Iteration 89580, avg_grad_norm = 486530
I0317 02:35:21.907918 29479 solver.cpp:214] Iteration 89600, loss = 5345
I0317 02:35:21.908061 29479 solver.cpp:229]     Train net output #0: loss = 4107.5 (* 1 = 4107.5 loss)
I0317 02:35:22.107192 29479 solver.cpp:610] Iteration 89600, lr = 5.85794e-09
I0317 02:35:22.107206 29479 solver.cpp:613] Iteration 89600, avg_grad_norm = 497316
I0317 02:36:07.612351 29479 solver.cpp:214] Iteration 89620, loss = 5725.41
I0317 02:36:07.612475 29479 solver.cpp:229]     Train net output #0: loss = 8953.03 (* 1 = 8953.03 loss)
I0317 02:36:07.984536 29479 solver.cpp:610] Iteration 89620, lr = 5.85699e-09
I0317 02:36:07.984550 29479 solver.cpp:613] Iteration 89620, avg_grad_norm = 526988
I0317 02:37:15.680071 29479 solver.cpp:214] Iteration 89640, loss = 5487.16
I0317 02:37:15.680253 29479 solver.cpp:229]     Train net output #0: loss = 2316.25 (* 1 = 2316.25 loss)
I0317 02:37:16.050832 29479 solver.cpp:610] Iteration 89640, lr = 5.85603e-09
I0317 02:37:16.050845 29479 solver.cpp:613] Iteration 89640, avg_grad_norm = 578487
I0317 02:38:40.378895 29479 solver.cpp:214] Iteration 89660, loss = 5621.12
I0317 02:38:40.379029 29479 solver.cpp:229]     Train net output #0: loss = 3671.47 (* 1 = 3671.47 loss)
I0317 02:38:40.769768 29479 solver.cpp:610] Iteration 89660, lr = 5.85508e-09
I0317 02:38:40.769781 29479 solver.cpp:613] Iteration 89660, avg_grad_norm = 517372
I0317 02:39:47.236142 29479 solver.cpp:214] Iteration 89680, loss = 5503.54
I0317 02:39:47.236265 29479 solver.cpp:229]     Train net output #0: loss = 4466.62 (* 1 = 4466.62 loss)
I0317 02:39:47.597892 29479 solver.cpp:610] Iteration 89680, lr = 5.85412e-09
I0317 02:39:47.597906 29479 solver.cpp:613] Iteration 89680, avg_grad_norm = 487429
I0317 02:40:55.681639 29479 solver.cpp:214] Iteration 89700, loss = 5588.59
I0317 02:40:55.681839 29479 solver.cpp:229]     Train net output #0: loss = 8742.4 (* 1 = 8742.4 loss)
I0317 02:40:56.045081 29479 solver.cpp:610] Iteration 89700, lr = 5.85317e-09
I0317 02:40:56.045099 29479 solver.cpp:613] Iteration 89700, avg_grad_norm = 502234
I0317 02:42:03.589879 29479 solver.cpp:214] Iteration 89720, loss = 5793.94
I0317 02:42:03.590018 29479 solver.cpp:229]     Train net output #0: loss = 7096.55 (* 1 = 7096.55 loss)
I0317 02:42:03.960916 29479 solver.cpp:610] Iteration 89720, lr = 5.85221e-09
I0317 02:42:03.960930 29479 solver.cpp:613] Iteration 89720, avg_grad_norm = 521478
I0317 02:43:11.231382 29479 solver.cpp:214] Iteration 89740, loss = 5620.98
I0317 02:43:11.231501 29479 solver.cpp:229]     Train net output #0: loss = 6954.83 (* 1 = 6954.83 loss)
I0317 02:43:11.591603 29479 solver.cpp:610] Iteration 89740, lr = 5.85126e-09
I0317 02:43:11.591616 29479 solver.cpp:613] Iteration 89740, avg_grad_norm = 516248
I0317 02:43:53.523172 29479 solver.cpp:214] Iteration 89760, loss = 5877.62
I0317 02:43:53.523314 29479 solver.cpp:229]     Train net output #0: loss = 2080.15 (* 1 = 2080.15 loss)
I0317 02:43:53.883786 29479 solver.cpp:610] Iteration 89760, lr = 5.8503e-09
I0317 02:43:53.883800 29479 solver.cpp:613] Iteration 89760, avg_grad_norm = 523104
I0317 02:45:02.347916 29479 solver.cpp:214] Iteration 89780, loss = 5680.41
I0317 02:45:02.348048 29479 solver.cpp:229]     Train net output #0: loss = 6229.12 (* 1 = 6229.12 loss)
I0317 02:45:02.553393 29479 solver.cpp:610] Iteration 89780, lr = 5.84935e-09
I0317 02:45:02.553406 29479 solver.cpp:613] Iteration 89780, avg_grad_norm = 521801
I0317 02:46:27.599799 29479 solver.cpp:214] Iteration 89800, loss = 5911.21
I0317 02:46:27.599952 29479 solver.cpp:229]     Train net output #0: loss = 5137.62 (* 1 = 5137.62 loss)
I0317 02:46:27.970635 29479 solver.cpp:610] Iteration 89800, lr = 5.84839e-09
I0317 02:46:27.970649 29479 solver.cpp:613] Iteration 89800, avg_grad_norm = 523411
I0317 02:47:34.903111 29479 solver.cpp:214] Iteration 89820, loss = 5553.51
I0317 02:47:34.903254 29479 solver.cpp:229]     Train net output #0: loss = 4777.03 (* 1 = 4777.03 loss)
I0317 02:47:35.264153 29479 solver.cpp:610] Iteration 89820, lr = 5.84744e-09
I0317 02:47:35.264166 29479 solver.cpp:613] Iteration 89820, avg_grad_norm = 480418
I0317 02:48:42.397104 29479 solver.cpp:214] Iteration 89840, loss = 5610.27
I0317 02:48:42.397333 29479 solver.cpp:229]     Train net output #0: loss = 4684.14 (* 1 = 4684.14 loss)
I0317 02:48:42.605351 29479 solver.cpp:610] Iteration 89840, lr = 5.84648e-09
I0317 02:48:42.605365 29479 solver.cpp:613] Iteration 89840, avg_grad_norm = 544231
I0317 02:49:50.363251 29479 solver.cpp:214] Iteration 89860, loss = 5498.52
I0317 02:49:50.363386 29479 solver.cpp:229]     Train net output #0: loss = 7185.57 (* 1 = 7185.57 loss)
I0317 02:49:50.724078 29479 solver.cpp:610] Iteration 89860, lr = 5.84553e-09
I0317 02:49:50.724092 29479 solver.cpp:613] Iteration 89860, avg_grad_norm = 522253
I0317 02:50:53.443315 29479 solver.cpp:214] Iteration 89880, loss = 5930.59
I0317 02:50:53.443511 29479 solver.cpp:229]     Train net output #0: loss = 4074.75 (* 1 = 4074.75 loss)
I0317 02:50:53.550420 29479 solver.cpp:610] Iteration 89880, lr = 5.84457e-09
I0317 02:50:53.550458 29479 solver.cpp:613] Iteration 89880, avg_grad_norm = 525031
I0317 02:51:29.540208 29479 solver.cpp:214] Iteration 89900, loss = 5871.84
I0317 02:51:29.540344 29479 solver.cpp:229]     Train net output #0: loss = 6574.61 (* 1 = 6574.61 loss)
I0317 02:51:29.903942 29479 solver.cpp:610] Iteration 89900, lr = 5.84362e-09
I0317 02:51:29.903955 29479 solver.cpp:613] Iteration 89900, avg_grad_norm = 508604
I0317 02:53:09.760850 29479 solver.cpp:214] Iteration 89920, loss = 5713.01
I0317 02:53:09.760979 29479 solver.cpp:229]     Train net output #0: loss = 3727.77 (* 1 = 3727.77 loss)
I0317 02:53:10.086145 29479 solver.cpp:610] Iteration 89920, lr = 5.84266e-09
I0317 02:53:10.086159 29479 solver.cpp:613] Iteration 89920, avg_grad_norm = 514071
I0317 02:54:17.497002 29479 solver.cpp:214] Iteration 89940, loss = 5604.28
I0317 02:54:17.497228 29479 solver.cpp:229]     Train net output #0: loss = 6267.38 (* 1 = 6267.38 loss)
I0317 02:54:17.858950 29479 solver.cpp:610] Iteration 89940, lr = 5.8417e-09
I0317 02:54:17.858964 29479 solver.cpp:613] Iteration 89940, avg_grad_norm = 532068
I0317 02:55:25.310436 29479 solver.cpp:214] Iteration 89960, loss = 5597.56
I0317 02:55:25.310588 29479 solver.cpp:229]     Train net output #0: loss = 3700.62 (* 1 = 3700.62 loss)
I0317 02:55:25.700892 29479 solver.cpp:610] Iteration 89960, lr = 5.84075e-09
I0317 02:55:25.700907 29479 solver.cpp:613] Iteration 89960, avg_grad_norm = 519816
I0317 02:56:33.268463 29479 solver.cpp:214] Iteration 89980, loss = 5838.89
I0317 02:56:33.268586 29479 solver.cpp:229]     Train net output #0: loss = 3292.76 (* 1 = 3292.76 loss)
I0317 02:56:33.630142 29479 solver.cpp:610] Iteration 89980, lr = 5.83979e-09
I0317 02:56:33.630156 29479 solver.cpp:613] Iteration 89980, avg_grad_norm = 529461
I0317 02:57:37.309051 29479 solver.cpp:458] Snapshotting to models/pnet/VGG_VOC2012ext_iter_90000.caffemodel
I0317 02:57:38.591675 29479 solver.cpp:466] Snapshotting solver state to models/pnet/VGG_VOC2012ext_iter_90000.solverstate
I0317 02:57:42.548661 29479 solver.cpp:214] Iteration 90000, loss = 5255.32
I0317 02:57:42.548744 29479 solver.cpp:229]     Train net output #0: loss = 4904.59 (* 1 = 4904.59 loss)
I0317 02:57:42.912242 29479 solver.cpp:610] Iteration 90000, lr = 5.83884e-09
I0317 02:57:42.912257 29479 solver.cpp:613] Iteration 90000, avg_grad_norm = 492209
I0317 02:58:31.632696 29479 solver.cpp:214] Iteration 90020, loss = 5747.84
I0317 02:58:31.632836 29479 solver.cpp:229]     Train net output #0: loss = 4582.61 (* 1 = 4582.61 loss)
I0317 02:58:31.748828 29479 solver.cpp:610] Iteration 90020, lr = 5.83788e-09
I0317 02:58:31.748843 29479 solver.cpp:613] Iteration 90020, avg_grad_norm = 511650
I0317 02:59:24.427271 29479 solver.cpp:214] Iteration 90040, loss = 5701.97
I0317 02:59:24.427481 29479 solver.cpp:229]     Train net output #0: loss = 6514.42 (* 1 = 6514.42 loss)
I0317 02:59:24.810559 29479 solver.cpp:610] Iteration 90040, lr = 5.83693e-09
I0317 02:59:24.810571 29479 solver.cpp:613] Iteration 90040, avg_grad_norm = 500823
I0317 03:00:32.508785 29479 solver.cpp:214] Iteration 90060, loss = 5271.64
I0317 03:00:32.508962 29479 solver.cpp:229]     Train net output #0: loss = 5501.34 (* 1 = 5501.34 loss)
I0317 03:00:32.874408 29479 solver.cpp:610] Iteration 90060, lr = 5.83597e-09
I0317 03:00:32.874421 29479 solver.cpp:613] Iteration 90060, avg_grad_norm = 485505
I0317 03:01:40.463011 29479 solver.cpp:214] Iteration 90080, loss = 5456.35
I0317 03:01:40.463215 29479 solver.cpp:229]     Train net output #0: loss = 4616.69 (* 1 = 4616.69 loss)
I0317 03:01:40.835049 29479 solver.cpp:610] Iteration 90080, lr = 5.83502e-09
I0317 03:01:40.835063 29479 solver.cpp:613] Iteration 90080, avg_grad_norm = 479136
I0317 03:02:48.927134 29479 solver.cpp:214] Iteration 90100, loss = 5714.95
I0317 03:02:48.927254 29479 solver.cpp:229]     Train net output #0: loss = 9527.79 (* 1 = 9527.79 loss)
I0317 03:02:49.287077 29479 solver.cpp:610] Iteration 90100, lr = 5.83406e-09
I0317 03:02:49.287113 29479 solver.cpp:613] Iteration 90100, avg_grad_norm = 480322
I0317 03:03:48.983981 29479 solver.cpp:214] Iteration 90120, loss = 5693.4
I0317 03:03:48.984129 29479 solver.cpp:229]     Train net output #0: loss = 5091.2 (* 1 = 5091.2 loss)
I0317 03:03:49.344487 29479 solver.cpp:610] Iteration 90120, lr = 5.8331e-09
I0317 03:03:49.344522 29479 solver.cpp:613] Iteration 90120, avg_grad_norm = 543392
I0317 03:04:58.381570 29479 solver.cpp:214] Iteration 90140, loss = 5643.74
I0317 03:04:58.381675 29479 solver.cpp:229]     Train net output #0: loss = 11675.3 (* 1 = 11675.3 loss)
I0317 03:04:58.747126 29479 solver.cpp:610] Iteration 90140, lr = 5.83215e-09
I0317 03:04:58.747161 29479 solver.cpp:613] Iteration 90140, avg_grad_norm = 481647
I0317 03:06:07.915374 29479 solver.cpp:214] Iteration 90160, loss = 5941.62
I0317 03:06:07.915485 29479 solver.cpp:229]     Train net output #0: loss = 4229.51 (* 1 = 4229.51 loss)
I0317 03:06:08.275776 29479 solver.cpp:610] Iteration 90160, lr = 5.83119e-09
I0317 03:06:08.275811 29479 solver.cpp:613] Iteration 90160, avg_grad_norm = 479739
I0317 03:07:46.090301 29479 solver.cpp:214] Iteration 90180, loss = 5728.67
I0317 03:07:46.090437 29479 solver.cpp:229]     Train net output #0: loss = 6046.6 (* 1 = 6046.6 loss)
I0317 03:07:46.285621 29479 solver.cpp:610] Iteration 90180, lr = 5.83024e-09
I0317 03:07:46.285635 29479 solver.cpp:613] Iteration 90180, avg_grad_norm = 484543
I0317 03:08:53.763600 29479 solver.cpp:214] Iteration 90200, loss = 5549.17
I0317 03:08:53.763710 29479 solver.cpp:229]     Train net output #0: loss = 4934.69 (* 1 = 4934.69 loss)
I0317 03:08:54.125670 29479 solver.cpp:610] Iteration 90200, lr = 5.82928e-09
I0317 03:08:54.125705 29479 solver.cpp:613] Iteration 90200, avg_grad_norm = 480932
I0317 03:10:02.379091 29479 solver.cpp:214] Iteration 90220, loss = 5317.08
I0317 03:10:02.379228 29479 solver.cpp:229]     Train net output #0: loss = 5359.95 (* 1 = 5359.95 loss)
I0317 03:10:02.738720 29479 solver.cpp:610] Iteration 90220, lr = 5.82833e-09
I0317 03:10:02.738764 29479 solver.cpp:613] Iteration 90220, avg_grad_norm = 514914
I0317 03:11:10.751418 29479 solver.cpp:214] Iteration 90240, loss = 5214.77
I0317 03:11:10.751518 29479 solver.cpp:229]     Train net output #0: loss = 5745.75 (* 1 = 5745.75 loss)
I0317 03:11:11.074530 29479 solver.cpp:610] Iteration 90240, lr = 5.82737e-09
I0317 03:11:11.074564 29479 solver.cpp:613] Iteration 90240, avg_grad_norm = 511011
I0317 03:12:18.610836 29479 solver.cpp:214] Iteration 90260, loss = 5637.11
I0317 03:12:18.610960 29479 solver.cpp:229]     Train net output #0: loss = 4302.6 (* 1 = 4302.6 loss)
I0317 03:12:18.970844 29479 solver.cpp:610] Iteration 90260, lr = 5.82642e-09
I0317 03:12:18.970878 29479 solver.cpp:613] Iteration 90260, avg_grad_norm = 531364
I0317 03:13:27.209030 29479 solver.cpp:214] Iteration 90280, loss = 5563.37
I0317 03:13:27.209144 29479 solver.cpp:229]     Train net output #0: loss = 8300.26 (* 1 = 8300.26 loss)
I0317 03:13:27.570003 29479 solver.cpp:610] Iteration 90280, lr = 5.82546e-09
I0317 03:13:27.570037 29479 solver.cpp:613] Iteration 90280, avg_grad_norm = 495640
I0317 03:15:12.177593 29479 solver.cpp:214] Iteration 90300, loss = 5720.88
I0317 03:15:12.177788 29479 solver.cpp:229]     Train net output #0: loss = 4697.35 (* 1 = 4697.35 loss)
I0317 03:15:12.490878 29479 solver.cpp:610] Iteration 90300, lr = 5.8245e-09
I0317 03:15:12.490905 29479 solver.cpp:613] Iteration 90300, avg_grad_norm = 495785
I0317 03:16:19.251027 29479 solver.cpp:214] Iteration 90320, loss = 5736.68
I0317 03:16:19.251224 29479 solver.cpp:229]     Train net output #0: loss = 4403.48 (* 1 = 4403.48 loss)
I0317 03:16:19.630643 29479 solver.cpp:610] Iteration 90320, lr = 5.82355e-09
I0317 03:16:19.630657 29479 solver.cpp:613] Iteration 90320, avg_grad_norm = 521103
I0317 03:17:26.896572 29479 solver.cpp:214] Iteration 90340, loss = 5762.81
I0317 03:17:26.896757 29479 solver.cpp:229]     Train net output #0: loss = 7811.5 (* 1 = 7811.5 loss)
I0317 03:17:27.255542 29479 solver.cpp:610] Iteration 90340, lr = 5.82259e-09
I0317 03:17:27.255556 29479 solver.cpp:613] Iteration 90340, avg_grad_norm = 516702
I0317 03:18:34.765327 29479 solver.cpp:214] Iteration 90360, loss = 5910.94
I0317 03:18:34.765493 29479 solver.cpp:229]     Train net output #0: loss = 4128.04 (* 1 = 4128.04 loss)
I0317 03:18:35.129662 29479 solver.cpp:610] Iteration 90360, lr = 5.82164e-09
I0317 03:18:35.129676 29479 solver.cpp:613] Iteration 90360, avg_grad_norm = 531897
I0317 03:19:42.751219 29479 solver.cpp:214] Iteration 90380, loss = 5791.19
I0317 03:19:42.751427 29479 solver.cpp:229]     Train net output #0: loss = 3875.66 (* 1 = 3875.66 loss)
I0317 03:19:43.113935 29479 solver.cpp:610] Iteration 90380, lr = 5.82068e-09
I0317 03:19:43.113950 29479 solver.cpp:613] Iteration 90380, avg_grad_norm = 487019
I0317 03:20:51.012095 29479 solver.cpp:214] Iteration 90400, loss = 5733.72
I0317 03:20:51.012224 29479 solver.cpp:229]     Train net output #0: loss = 7249.16 (* 1 = 7249.16 loss)
I0317 03:20:51.347157 29479 solver.cpp:610] Iteration 90400, lr = 5.81973e-09
I0317 03:20:51.347170 29479 solver.cpp:613] Iteration 90400, avg_grad_norm = 492227
I0317 03:22:18.179327 29479 solver.cpp:214] Iteration 90420, loss = 5274.52
I0317 03:22:18.179482 29479 solver.cpp:229]     Train net output #0: loss = 3662.39 (* 1 = 3662.39 loss)
I0317 03:22:18.284667 29479 solver.cpp:610] Iteration 90420, lr = 5.81877e-09
I0317 03:22:18.284682 29479 solver.cpp:613] Iteration 90420, avg_grad_norm = 494496
I0317 03:23:18.592893 29479 solver.cpp:214] Iteration 90440, loss = 5784.18
I0317 03:23:18.593089 29479 solver.cpp:229]     Train net output #0: loss = 8454.15 (* 1 = 8454.15 loss)
I0317 03:23:18.946095 29479 solver.cpp:610] Iteration 90440, lr = 5.81781e-09
I0317 03:23:18.946110 29479 solver.cpp:613] Iteration 90440, avg_grad_norm = 492145
I0317 03:24:25.920002 29479 solver.cpp:214] Iteration 90460, loss = 5528.96
I0317 03:24:25.920205 29479 solver.cpp:229]     Train net output #0: loss = 5023.13 (* 1 = 5023.13 loss)
I0317 03:24:26.285914 29479 solver.cpp:610] Iteration 90460, lr = 5.81686e-09
I0317 03:24:26.285928 29479 solver.cpp:613] Iteration 90460, avg_grad_norm = 479933
I0317 03:25:33.254540 29479 solver.cpp:214] Iteration 90480, loss = 5805.15
I0317 03:25:33.254624 29479 solver.cpp:229]     Train net output #0: loss = 11021.7 (* 1 = 11021.7 loss)
I0317 03:25:33.429817 29479 solver.cpp:610] Iteration 90480, lr = 5.8159e-09
I0317 03:25:33.429831 29479 solver.cpp:613] Iteration 90480, avg_grad_norm = 470868
I0317 03:26:40.455224 29479 solver.cpp:214] Iteration 90500, loss = 5118.36
I0317 03:26:40.455415 29479 solver.cpp:229]     Train net output #0: loss = 3892.1 (* 1 = 3892.1 loss)
I0317 03:26:40.817260 29479 solver.cpp:610] Iteration 90500, lr = 5.81495e-09
I0317 03:26:40.817272 29479 solver.cpp:613] Iteration 90500, avg_grad_norm = 465278
I0317 03:27:47.867164 29479 solver.cpp:214] Iteration 90520, loss = 5611.85
I0317 03:27:47.867287 29479 solver.cpp:229]     Train net output #0: loss = 3882.73 (* 1 = 3882.73 loss)
I0317 03:27:48.252092 29479 solver.cpp:610] Iteration 90520, lr = 5.81399e-09
I0317 03:27:48.252106 29479 solver.cpp:613] Iteration 90520, avg_grad_norm = 482749
I0317 03:28:56.233821 29479 solver.cpp:214] Iteration 90540, loss = 5670.13
I0317 03:28:56.233943 29479 solver.cpp:229]     Train net output #0: loss = 4824.33 (* 1 = 4824.33 loss)
I0317 03:28:56.596320 29479 solver.cpp:610] Iteration 90540, lr = 5.81303e-09
I0317 03:28:56.596334 29479 solver.cpp:613] Iteration 90540, avg_grad_norm = 598922
I0317 03:29:51.523221 29479 solver.cpp:214] Iteration 90560, loss = 5423.25
I0317 03:29:51.523360 29479 solver.cpp:229]     Train net output #0: loss = 5057.53 (* 1 = 5057.53 loss)
I0317 03:29:51.638141 29479 solver.cpp:610] Iteration 90560, lr = 5.81208e-09
I0317 03:29:51.638159 29479 solver.cpp:613] Iteration 90560, avg_grad_norm = 592139
I0317 03:30:52.800854 29479 solver.cpp:214] Iteration 90580, loss = 5370.19
I0317 03:30:52.800951 29479 solver.cpp:229]     Train net output #0: loss = 3978.08 (* 1 = 3978.08 loss)
I0317 03:30:53.161356 29479 solver.cpp:610] Iteration 90580, lr = 5.81112e-09
I0317 03:30:53.161370 29479 solver.cpp:613] Iteration 90580, avg_grad_norm = 528193
I0317 03:32:01.017081 29479 solver.cpp:214] Iteration 90600, loss = 5614.83
I0317 03:32:01.017334 29479 solver.cpp:229]     Train net output #0: loss = 7358.76 (* 1 = 7358.76 loss)
I0317 03:32:01.354578 29479 solver.cpp:610] Iteration 90600, lr = 5.81017e-09
I0317 03:32:01.354591 29479 solver.cpp:613] Iteration 90600, avg_grad_norm = 487970
I0317 03:33:08.333842 29479 solver.cpp:214] Iteration 90620, loss = 5567.44
I0317 03:33:08.333974 29479 solver.cpp:229]     Train net output #0: loss = 3423.51 (* 1 = 3423.51 loss)
I0317 03:33:08.696498 29479 solver.cpp:610] Iteration 90620, lr = 5.80921e-09
I0317 03:33:08.696511 29479 solver.cpp:613] Iteration 90620, avg_grad_norm = 488007
I0317 03:34:16.059276 29479 solver.cpp:214] Iteration 90640, loss = 5460.18
I0317 03:34:16.059414 29479 solver.cpp:229]     Train net output #0: loss = 4272.14 (* 1 = 4272.14 loss)
I0317 03:34:16.425256 29479 solver.cpp:610] Iteration 90640, lr = 5.80825e-09
I0317 03:34:16.425268 29479 solver.cpp:613] Iteration 90640, avg_grad_norm = 492204
I0317 03:35:24.747550 29479 solver.cpp:214] Iteration 90660, loss = 5701.79
I0317 03:35:24.747689 29479 solver.cpp:229]     Train net output #0: loss = 2984.23 (* 1 = 2984.23 loss)
I0317 03:35:25.107789 29479 solver.cpp:610] Iteration 90660, lr = 5.8073e-09
I0317 03:35:25.107805 29479 solver.cpp:613] Iteration 90660, avg_grad_norm = 529857
I0317 03:37:03.152679 29479 solver.cpp:214] Iteration 90680, loss = 5712.01
I0317 03:37:03.152860 29479 solver.cpp:229]     Train net output #0: loss = 2933.13 (* 1 = 2933.13 loss)
I0317 03:37:03.260465 29479 solver.cpp:610] Iteration 90680, lr = 5.80634e-09
I0317 03:37:03.260478 29479 solver.cpp:613] Iteration 90680, avg_grad_norm = 536132
I0317 03:37:44.689019 29479 solver.cpp:214] Iteration 90700, loss = 5491.12
I0317 03:37:44.689162 29479 solver.cpp:229]     Train net output #0: loss = 4429.82 (* 1 = 4429.82 loss)
I0317 03:37:45.048512 29479 solver.cpp:610] Iteration 90700, lr = 5.80539e-09
I0317 03:37:45.048562 29479 solver.cpp:613] Iteration 90700, avg_grad_norm = 584343
I0317 03:38:52.248323 29479 solver.cpp:214] Iteration 90720, loss = 5812.56
I0317 03:38:52.248523 29479 solver.cpp:229]     Train net output #0: loss = 3536.42 (* 1 = 3536.42 loss)
I0317 03:38:52.591428 29479 solver.cpp:610] Iteration 90720, lr = 5.80443e-09
I0317 03:38:52.591440 29479 solver.cpp:613] Iteration 90720, avg_grad_norm = 498715
I0317 03:39:59.984786 29479 solver.cpp:214] Iteration 90740, loss = 5353.2
I0317 03:39:59.985023 29479 solver.cpp:229]     Train net output #0: loss = 8058.51 (* 1 = 8058.51 loss)
I0317 03:40:00.374524 29479 solver.cpp:610] Iteration 90740, lr = 5.80347e-09
I0317 03:40:00.374537 29479 solver.cpp:613] Iteration 90740, avg_grad_norm = 494507
I0317 03:41:07.423962 29479 solver.cpp:214] Iteration 90760, loss = 5597.64
I0317 03:41:07.424094 29479 solver.cpp:229]     Train net output #0: loss = 8153.53 (* 1 = 8153.53 loss)
I0317 03:41:07.811923 29479 solver.cpp:610] Iteration 90760, lr = 5.80252e-09
I0317 03:41:07.811938 29479 solver.cpp:613] Iteration 90760, avg_grad_norm = 541757
I0317 03:42:15.185834 29479 solver.cpp:214] Iteration 90780, loss = 5474.78
I0317 03:42:15.185977 29479 solver.cpp:229]     Train net output #0: loss = 4705.66 (* 1 = 4705.66 loss)
I0317 03:42:15.528426 29479 solver.cpp:610] Iteration 90780, lr = 5.80156e-09
I0317 03:42:15.528439 29479 solver.cpp:613] Iteration 90780, avg_grad_norm = 532887
I0317 03:43:44.540073 29479 solver.cpp:214] Iteration 90800, loss = 5584.15
I0317 03:43:44.540205 29479 solver.cpp:229]     Train net output #0: loss = 5299.45 (* 1 = 5299.45 loss)
I0317 03:43:44.724015 29479 solver.cpp:610] Iteration 90800, lr = 5.80061e-09
I0317 03:43:44.724030 29479 solver.cpp:613] Iteration 90800, avg_grad_norm = 559676
I0317 03:44:43.256991 29479 solver.cpp:214] Iteration 90820, loss = 5432.55
I0317 03:44:43.257252 29479 solver.cpp:229]     Train net output #0: loss = 3174.34 (* 1 = 3174.34 loss)
I0317 03:44:43.370225 29479 solver.cpp:610] Iteration 90820, lr = 5.79965e-09
I0317 03:44:43.370252 29479 solver.cpp:613] Iteration 90820, avg_grad_norm = 488765
I0317 03:45:27.886387 29479 solver.cpp:214] Iteration 90840, loss = 5787.91
I0317 03:45:27.886557 29479 solver.cpp:229]     Train net output #0: loss = 4009.7 (* 1 = 4009.7 loss)
I0317 03:45:28.260689 29479 solver.cpp:610] Iteration 90840, lr = 5.79869e-09
I0317 03:45:28.260701 29479 solver.cpp:613] Iteration 90840, avg_grad_norm = 481881
I0317 03:46:36.047086 29479 solver.cpp:214] Iteration 90860, loss = 5760.56
I0317 03:46:36.047222 29479 solver.cpp:229]     Train net output #0: loss = 3997.91 (* 1 = 3997.91 loss)
I0317 03:46:36.404979 29479 solver.cpp:610] Iteration 90860, lr = 5.79774e-09
I0317 03:46:36.404994 29479 solver.cpp:613] Iteration 90860, avg_grad_norm = 511688
I0317 03:47:44.186187 29479 solver.cpp:214] Iteration 90880, loss = 5650.55
I0317 03:47:44.186295 29479 solver.cpp:229]     Train net output #0: loss = 4530.13 (* 1 = 4530.13 loss)
I0317 03:47:44.555418 29479 solver.cpp:610] Iteration 90880, lr = 5.79678e-09
I0317 03:47:44.555431 29479 solver.cpp:613] Iteration 90880, avg_grad_norm = 544653
I0317 03:48:52.761085 29479 solver.cpp:214] Iteration 90900, loss = 5546.23
I0317 03:48:52.761212 29479 solver.cpp:229]     Train net output #0: loss = 9307.15 (* 1 = 9307.15 loss)
I0317 03:48:53.121621 29479 solver.cpp:610] Iteration 90900, lr = 5.79583e-09
I0317 03:48:53.121657 29479 solver.cpp:613] Iteration 90900, avg_grad_norm = 485408
I0317 03:50:01.267689 29479 solver.cpp:214] Iteration 90920, loss = 5832.45
I0317 03:50:01.267879 29479 solver.cpp:229]     Train net output #0: loss = 5488.97 (* 1 = 5488.97 loss)
I0317 03:50:01.461096 29479 solver.cpp:610] Iteration 90920, lr = 5.79487e-09
I0317 03:50:01.461109 29479 solver.cpp:613] Iteration 90920, avg_grad_norm = 487849
I0317 03:51:25.828414 29479 solver.cpp:214] Iteration 90940, loss = 5780.51
I0317 03:51:25.828555 29479 solver.cpp:229]     Train net output #0: loss = 5095.85 (* 1 = 5095.85 loss)
I0317 03:51:26.188910 29479 solver.cpp:610] Iteration 90940, lr = 5.79391e-09
I0317 03:51:26.188926 29479 solver.cpp:613] Iteration 90940, avg_grad_norm = 511652
I0317 03:52:21.228602 29479 solver.cpp:214] Iteration 90960, loss = 5717.67
I0317 03:52:21.228766 29479 solver.cpp:229]     Train net output #0: loss = 5586.9 (* 1 = 5586.9 loss)
I0317 03:52:21.340360 29479 solver.cpp:610] Iteration 90960, lr = 5.79296e-09
I0317 03:52:21.340375 29479 solver.cpp:613] Iteration 90960, avg_grad_norm = 469267
I0317 03:53:07.890218 29479 solver.cpp:214] Iteration 90980, loss = 5683.45
I0317 03:53:07.890369 29479 solver.cpp:229]     Train net output #0: loss = 3702.16 (* 1 = 3702.16 loss)
I0317 03:53:08.253180 29479 solver.cpp:610] Iteration 90980, lr = 5.792e-09
I0317 03:53:08.253195 29479 solver.cpp:613] Iteration 90980, avg_grad_norm = 506510
I0317 03:54:15.779454 29479 solver.cpp:214] Iteration 91000, loss = 5600.51
I0317 03:54:15.779577 29479 solver.cpp:229]     Train net output #0: loss = 9827.63 (* 1 = 9827.63 loss)
I0317 03:54:16.105391 29479 solver.cpp:610] Iteration 91000, lr = 5.79104e-09
I0317 03:54:16.105404 29479 solver.cpp:613] Iteration 91000, avg_grad_norm = 527102
I0317 03:55:23.426479 29479 solver.cpp:214] Iteration 91020, loss = 5512.26
I0317 03:55:23.426614 29479 solver.cpp:229]     Train net output #0: loss = 5850.85 (* 1 = 5850.85 loss)
I0317 03:55:23.635908 29479 solver.cpp:610] Iteration 91020, lr = 5.79009e-09
I0317 03:55:23.635922 29479 solver.cpp:613] Iteration 91020, avg_grad_norm = 484160
I0317 03:56:32.121443 29479 solver.cpp:214] Iteration 91040, loss = 5678.17
I0317 03:56:32.121559 29479 solver.cpp:229]     Train net output #0: loss = 12831.5 (* 1 = 12831.5 loss)
I0317 03:56:32.481278 29479 solver.cpp:610] Iteration 91040, lr = 5.78913e-09
I0317 03:56:32.481292 29479 solver.cpp:613] Iteration 91040, avg_grad_norm = 519942
I0317 03:57:59.800078 29479 solver.cpp:214] Iteration 91060, loss = 5491.54
I0317 03:57:59.800269 29479 solver.cpp:229]     Train net output #0: loss = 4761.38 (* 1 = 4761.38 loss)
I0317 03:58:00.169692 29479 solver.cpp:610] Iteration 91060, lr = 5.78818e-09
I0317 03:58:00.169705 29479 solver.cpp:613] Iteration 91060, avg_grad_norm = 492749
I0317 03:59:07.916606 29479 solver.cpp:214] Iteration 91080, loss = 5443.5
I0317 03:59:07.916704 29479 solver.cpp:229]     Train net output #0: loss = 2862.68 (* 1 = 2862.68 loss)
I0317 03:59:08.277431 29479 solver.cpp:610] Iteration 91080, lr = 5.78722e-09
I0317 03:59:08.277444 29479 solver.cpp:613] Iteration 91080, avg_grad_norm = 500503
I0317 04:00:00.319551 29479 solver.cpp:214] Iteration 91100, loss = 5491.22
I0317 04:00:00.319665 29479 solver.cpp:229]     Train net output #0: loss = 3971.1 (* 1 = 3971.1 loss)
I0317 04:00:00.435711 29479 solver.cpp:610] Iteration 91100, lr = 5.78626e-09
I0317 04:00:00.435745 29479 solver.cpp:613] Iteration 91100, avg_grad_norm = 499848
I0317 04:00:50.419908 29479 solver.cpp:214] Iteration 91120, loss = 5699.07
I0317 04:00:50.420044 29479 solver.cpp:229]     Train net output #0: loss = 5921.04 (* 1 = 5921.04 loss)
I0317 04:00:50.788898 29479 solver.cpp:610] Iteration 91120, lr = 5.78531e-09
I0317 04:00:50.788913 29479 solver.cpp:613] Iteration 91120, avg_grad_norm = 539928
I0317 04:01:58.567539 29479 solver.cpp:214] Iteration 91140, loss = 5638.99
I0317 04:01:58.567665 29479 solver.cpp:229]     Train net output #0: loss = 3563.15 (* 1 = 3563.15 loss)
I0317 04:01:58.900249 29479 solver.cpp:610] Iteration 91140, lr = 5.78435e-09
I0317 04:01:58.900262 29479 solver.cpp:613] Iteration 91140, avg_grad_norm = 498821
I0317 04:03:06.945888 29479 solver.cpp:214] Iteration 91160, loss = 5821.09
I0317 04:03:06.946003 29479 solver.cpp:229]     Train net output #0: loss = 4713.72 (* 1 = 4713.72 loss)
I0317 04:03:07.308437 29479 solver.cpp:610] Iteration 91160, lr = 5.78339e-09
I0317 04:03:07.308450 29479 solver.cpp:613] Iteration 91160, avg_grad_norm = 489733
I0317 04:04:14.962344 29479 solver.cpp:214] Iteration 91180, loss = 5550.33
I0317 04:04:14.962466 29479 solver.cpp:229]     Train net output #0: loss = 9613.56 (* 1 = 9613.56 loss)
I0317 04:04:15.332119 29479 solver.cpp:610] Iteration 91180, lr = 5.78244e-09
I0317 04:04:15.332132 29479 solver.cpp:613] Iteration 91180, avg_grad_norm = 510131
I0317 04:05:59.938721 29479 solver.cpp:214] Iteration 91200, loss = 5744.59
I0317 04:05:59.938866 29479 solver.cpp:229]     Train net output #0: loss = 4525.9 (* 1 = 4525.9 loss)
I0317 04:06:00.304682 29479 solver.cpp:610] Iteration 91200, lr = 5.78148e-09
I0317 04:06:00.304739 29479 solver.cpp:613] Iteration 91200, avg_grad_norm = 512943
I0317 04:07:08.597870 29479 solver.cpp:214] Iteration 91220, loss = 5702.29
I0317 04:07:08.598009 29479 solver.cpp:229]     Train net output #0: loss = 9266.54 (* 1 = 9266.54 loss)
I0317 04:07:08.957954 29479 solver.cpp:610] Iteration 91220, lr = 5.78052e-09
I0317 04:07:08.957967 29479 solver.cpp:613] Iteration 91220, avg_grad_norm = 544591
I0317 04:07:40.118420 29479 solver.cpp:214] Iteration 91240, loss = 5681.07
I0317 04:07:40.118554 29479 solver.cpp:229]     Train net output #0: loss = 6401.09 (* 1 = 6401.09 loss)
I0317 04:07:40.236318 29479 solver.cpp:610] Iteration 91240, lr = 5.77957e-09
I0317 04:07:40.236335 29479 solver.cpp:613] Iteration 91240, avg_grad_norm = 525373
I0317 04:08:23.874342 29479 solver.cpp:214] Iteration 91260, loss = 5542.64
I0317 04:08:23.874485 29479 solver.cpp:229]     Train net output #0: loss = 7912.78 (* 1 = 7912.78 loss)
I0317 04:08:24.217581 29479 solver.cpp:610] Iteration 91260, lr = 5.77861e-09
I0317 04:08:24.217593 29479 solver.cpp:613] Iteration 91260, avg_grad_norm = 508333
I0317 04:09:32.279912 29479 solver.cpp:214] Iteration 91280, loss = 5553.2
I0317 04:09:32.280026 29479 solver.cpp:229]     Train net output #0: loss = 3543.88 (* 1 = 3543.88 loss)
I0317 04:09:32.642344 29479 solver.cpp:610] Iteration 91280, lr = 5.77765e-09
I0317 04:09:32.642357 29479 solver.cpp:613] Iteration 91280, avg_grad_norm = 516906
I0317 04:10:40.839716 29479 solver.cpp:214] Iteration 91300, loss = 5699.23
I0317 04:10:40.839879 29479 solver.cpp:229]     Train net output #0: loss = 3215.29 (* 1 = 3215.29 loss)
I0317 04:10:41.200572 29479 solver.cpp:610] Iteration 91300, lr = 5.7767e-09
I0317 04:10:41.200585 29479 solver.cpp:613] Iteration 91300, avg_grad_norm = 518896
I0317 04:12:16.800190 29479 solver.cpp:214] Iteration 91320, loss = 5354.49
I0317 04:12:16.800374 29479 solver.cpp:229]     Train net output #0: loss = 5958.34 (* 1 = 5958.34 loss)
I0317 04:12:17.179288 29479 solver.cpp:610] Iteration 91320, lr = 5.77574e-09
I0317 04:12:17.179302 29479 solver.cpp:613] Iteration 91320, avg_grad_norm = 489177
I0317 04:13:24.423334 29479 solver.cpp:214] Iteration 91340, loss = 5712.71
I0317 04:13:24.423480 29479 solver.cpp:229]     Train net output #0: loss = 5624.44 (* 1 = 5624.44 loss)
I0317 04:13:24.786082 29479 solver.cpp:610] Iteration 91340, lr = 5.77478e-09
I0317 04:13:24.786097 29479 solver.cpp:613] Iteration 91340, avg_grad_norm = 497234
I0317 04:14:31.888998 29479 solver.cpp:214] Iteration 91360, loss = 5913.95
I0317 04:14:31.889158 29479 solver.cpp:229]     Train net output #0: loss = 5270.82 (* 1 = 5270.82 loss)
I0317 04:14:32.258723 29479 solver.cpp:610] Iteration 91360, lr = 5.77383e-09
I0317 04:14:32.258738 29479 solver.cpp:613] Iteration 91360, avg_grad_norm = 490325
I0317 04:15:18.602123 29479 solver.cpp:214] Iteration 91380, loss = 5480.1
I0317 04:15:18.602269 29479 solver.cpp:229]     Train net output #0: loss = 7314.08 (* 1 = 7314.08 loss)
I0317 04:15:18.718365 29479 solver.cpp:610] Iteration 91380, lr = 5.77287e-09
I0317 04:15:18.718379 29479 solver.cpp:613] Iteration 91380, avg_grad_norm = 634573
I0317 04:16:15.181756 29479 solver.cpp:214] Iteration 91400, loss = 5704.78
I0317 04:16:15.181866 29479 solver.cpp:229]     Train net output #0: loss = 5032.4 (* 1 = 5032.4 loss)
I0317 04:16:15.549182 29479 solver.cpp:610] Iteration 91400, lr = 5.77191e-09
I0317 04:16:15.549196 29479 solver.cpp:613] Iteration 91400, avg_grad_norm = 503664
I0317 04:17:22.662149 29479 solver.cpp:214] Iteration 91420, loss = 5544.34
I0317 04:17:22.662287 29479 solver.cpp:229]     Train net output #0: loss = 4526.51 (* 1 = 4526.51 loss)
I0317 04:17:23.023377 29479 solver.cpp:610] Iteration 91420, lr = 5.77096e-09
I0317 04:17:23.023391 29479 solver.cpp:613] Iteration 91420, avg_grad_norm = 484426
I0317 04:18:57.914007 29479 solver.cpp:214] Iteration 91440, loss = 5650.53
I0317 04:18:57.914139 29479 solver.cpp:229]     Train net output #0: loss = 8781.13 (* 1 = 8781.13 loss)
I0317 04:18:58.271730 29479 solver.cpp:610] Iteration 91440, lr = 5.77e-09
I0317 04:18:58.271744 29479 solver.cpp:613] Iteration 91440, avg_grad_norm = 485447
I0317 04:20:05.647544 29479 solver.cpp:214] Iteration 91460, loss = 5470.01
I0317 04:20:05.647680 29479 solver.cpp:229]     Train net output #0: loss = 5585.77 (* 1 = 5585.77 loss)
I0317 04:20:06.010582 29479 solver.cpp:610] Iteration 91460, lr = 5.76904e-09
I0317 04:20:06.010596 29479 solver.cpp:613] Iteration 91460, avg_grad_norm = 481617
I0317 04:21:12.835875 29479 solver.cpp:214] Iteration 91480, loss = 5892.97
I0317 04:21:12.836016 29479 solver.cpp:229]     Train net output #0: loss = 3041.39 (* 1 = 3041.39 loss)
I0317 04:21:13.198588 29479 solver.cpp:610] Iteration 91480, lr = 5.76809e-09
I0317 04:21:13.198601 29479 solver.cpp:613] Iteration 91480, avg_grad_norm = 504910
I0317 04:22:20.327674 29479 solver.cpp:214] Iteration 91500, loss = 5820.87
I0317 04:22:20.327797 29479 solver.cpp:229]     Train net output #0: loss = 5943.28 (* 1 = 5943.28 loss)
I0317 04:22:20.689263 29479 solver.cpp:610] Iteration 91500, lr = 5.76713e-09
I0317 04:22:20.689276 29479 solver.cpp:613] Iteration 91500, avg_grad_norm = 525901
I0317 04:23:02.244648 29479 solver.cpp:214] Iteration 91520, loss = 5947.53
I0317 04:23:02.244860 29479 solver.cpp:229]     Train net output #0: loss = 5762.61 (* 1 = 5762.61 loss)
I0317 04:23:02.604419 29479 solver.cpp:610] Iteration 91520, lr = 5.76617e-09
I0317 04:23:02.604432 29479 solver.cpp:613] Iteration 91520, avg_grad_norm = 510438
I0317 04:24:11.146827 29479 solver.cpp:214] Iteration 91540, loss = 5700.04
I0317 04:24:11.147003 29479 solver.cpp:229]     Train net output #0: loss = 5195.39 (* 1 = 5195.39 loss)
I0317 04:24:11.510923 29479 solver.cpp:610] Iteration 91540, lr = 5.76522e-09
I0317 04:24:11.510936 29479 solver.cpp:613] Iteration 91540, avg_grad_norm = 511361
I0317 04:25:20.165216 29479 solver.cpp:214] Iteration 91560, loss = 5785.21
I0317 04:25:20.165436 29479 solver.cpp:229]     Train net output #0: loss = 4361.71 (* 1 = 4361.71 loss)
I0317 04:25:20.522655 29479 solver.cpp:610] Iteration 91560, lr = 5.76426e-09
I0317 04:25:20.522668 29479 solver.cpp:613] Iteration 91560, avg_grad_norm = 478846
I0317 04:26:42.637840 29479 solver.cpp:214] Iteration 91580, loss = 5748.39
I0317 04:26:42.638028 29479 solver.cpp:229]     Train net output #0: loss = 5143.82 (* 1 = 5143.82 loss)
I0317 04:26:42.840708 29479 solver.cpp:610] Iteration 91580, lr = 5.7633e-09
I0317 04:26:42.840724 29479 solver.cpp:613] Iteration 91580, avg_grad_norm = 506871
I0317 04:27:50.388857 29479 solver.cpp:214] Iteration 91600, loss = 5777.93
I0317 04:27:50.388994 29479 solver.cpp:229]     Train net output #0: loss = 7742.04 (* 1 = 7742.04 loss)
I0317 04:27:50.774662 29479 solver.cpp:610] Iteration 91600, lr = 5.76235e-09
I0317 04:27:50.774677 29479 solver.cpp:613] Iteration 91600, avg_grad_norm = 501985
I0317 04:28:58.148581 29479 solver.cpp:214] Iteration 91620, loss = 5614.66
I0317 04:28:58.148783 29479 solver.cpp:229]     Train net output #0: loss = 4492.88 (* 1 = 4492.88 loss)
I0317 04:28:58.518443 29479 solver.cpp:610] Iteration 91620, lr = 5.76139e-09
I0317 04:28:58.518456 29479 solver.cpp:613] Iteration 91620, avg_grad_norm = 483790
I0317 04:30:05.842991 29479 solver.cpp:214] Iteration 91640, loss = 5565.91
I0317 04:30:05.843123 29479 solver.cpp:229]     Train net output #0: loss = 10932.1 (* 1 = 10932.1 loss)
I0317 04:30:06.185557 29479 solver.cpp:610] Iteration 91640, lr = 5.76043e-09
I0317 04:30:06.185580 29479 solver.cpp:613] Iteration 91640, avg_grad_norm = 527829
I0317 04:30:42.362396 29479 solver.cpp:214] Iteration 91660, loss = 5859.3
I0317 04:30:42.362519 29479 solver.cpp:229]     Train net output #0: loss = 5892.1 (* 1 = 5892.1 loss)
I0317 04:30:42.480453 29479 solver.cpp:610] Iteration 91660, lr = 5.75948e-09
I0317 04:30:42.480465 29479 solver.cpp:613] Iteration 91660, avg_grad_norm = 569448
I0317 04:31:28.206078 29479 solver.cpp:214] Iteration 91680, loss = 5601.99
I0317 04:31:28.206192 29479 solver.cpp:229]     Train net output #0: loss = 8000 (* 1 = 8000 loss)
I0317 04:31:28.572407 29479 solver.cpp:610] Iteration 91680, lr = 5.75852e-09
I0317 04:31:28.572420 29479 solver.cpp:613] Iteration 91680, avg_grad_norm = 506352
I0317 04:33:04.619740 29479 solver.cpp:214] Iteration 91700, loss = 5655.44
I0317 04:33:04.619869 29479 solver.cpp:229]     Train net output #0: loss = 6987.25 (* 1 = 6987.25 loss)
I0317 04:33:04.989682 29479 solver.cpp:610] Iteration 91700, lr = 5.75756e-09
I0317 04:33:04.989696 29479 solver.cpp:613] Iteration 91700, avg_grad_norm = 493106
I0317 04:34:12.113636 29479 solver.cpp:214] Iteration 91720, loss = 5470.25
I0317 04:34:12.113756 29479 solver.cpp:229]     Train net output #0: loss = 3814.61 (* 1 = 3814.61 loss)
I0317 04:34:12.472537 29479 solver.cpp:610] Iteration 91720, lr = 5.7566e-09
I0317 04:34:12.472550 29479 solver.cpp:613] Iteration 91720, avg_grad_norm = 519999
I0317 04:35:19.798861 29479 solver.cpp:214] Iteration 91740, loss = 5496.01
I0317 04:35:19.799002 29479 solver.cpp:229]     Train net output #0: loss = 8445.76 (* 1 = 8445.76 loss)
I0317 04:35:20.162081 29479 solver.cpp:610] Iteration 91740, lr = 5.75565e-09
I0317 04:35:20.162096 29479 solver.cpp:613] Iteration 91740, avg_grad_norm = 486938
I0317 04:36:28.315834 29479 solver.cpp:214] Iteration 91760, loss = 5674.34
I0317 04:36:28.315958 29479 solver.cpp:229]     Train net output #0: loss = 8590.14 (* 1 = 8590.14 loss)
I0317 04:36:28.686039 29479 solver.cpp:610] Iteration 91760, lr = 5.75469e-09
I0317 04:36:28.686053 29479 solver.cpp:613] Iteration 91760, avg_grad_norm = 476341
I0317 04:37:35.798969 29479 solver.cpp:214] Iteration 91780, loss = 5713.37
I0317 04:37:35.799118 29479 solver.cpp:229]     Train net output #0: loss = 3501.62 (* 1 = 3501.62 loss)
I0317 04:37:36.168092 29479 solver.cpp:610] Iteration 91780, lr = 5.75373e-09
I0317 04:37:36.168107 29479 solver.cpp:613] Iteration 91780, avg_grad_norm = 473453
I0317 04:38:21.643313 29479 solver.cpp:214] Iteration 91800, loss = 5844.87
I0317 04:38:21.643467 29479 solver.cpp:229]     Train net output #0: loss = 4217.03 (* 1 = 4217.03 loss)
I0317 04:38:21.761405 29479 solver.cpp:610] Iteration 91800, lr = 5.75278e-09
I0317 04:38:21.761436 29479 solver.cpp:613] Iteration 91800, avg_grad_norm = 552538
I0317 04:39:42.084306 29479 solver.cpp:214] Iteration 91820, loss = 5831.71
I0317 04:39:42.084432 29479 solver.cpp:229]     Train net output #0: loss = 4611.64 (* 1 = 4611.64 loss)
I0317 04:39:42.446262 29479 solver.cpp:610] Iteration 91820, lr = 5.75182e-09
I0317 04:39:42.446275 29479 solver.cpp:613] Iteration 91820, avg_grad_norm = 525246
I0317 04:40:49.299878 29479 solver.cpp:214] Iteration 91840, loss = 5779.66
I0317 04:40:49.300012 29479 solver.cpp:229]     Train net output #0: loss = 2894.44 (* 1 = 2894.44 loss)
I0317 04:40:49.659829 29479 solver.cpp:610] Iteration 91840, lr = 5.75086e-09
I0317 04:40:49.659865 29479 solver.cpp:613] Iteration 91840, avg_grad_norm = 546945
I0317 04:41:57.514791 29479 solver.cpp:214] Iteration 91860, loss = 5609.86
I0317 04:41:57.514936 29479 solver.cpp:229]     Train net output #0: loss = 6892.81 (* 1 = 6892.81 loss)
I0317 04:41:57.877460 29479 solver.cpp:610] Iteration 91860, lr = 5.74991e-09
I0317 04:41:57.877473 29479 solver.cpp:613] Iteration 91860, avg_grad_norm = 495666
I0317 04:43:05.586412 29479 solver.cpp:214] Iteration 91880, loss = 5610.15
I0317 04:43:05.586544 29479 solver.cpp:229]     Train net output #0: loss = 3825.39 (* 1 = 3825.39 loss)
I0317 04:43:05.955896 29479 solver.cpp:610] Iteration 91880, lr = 5.74895e-09
I0317 04:43:05.955910 29479 solver.cpp:613] Iteration 91880, avg_grad_norm = 511669
I0317 04:44:13.480329 29479 solver.cpp:214] Iteration 91900, loss = 5611.77
I0317 04:44:13.480448 29479 solver.cpp:229]     Train net output #0: loss = 4188.1 (* 1 = 4188.1 loss)
I0317 04:44:13.850488 29479 solver.cpp:610] Iteration 91900, lr = 5.74799e-09
I0317 04:44:13.850502 29479 solver.cpp:613] Iteration 91900, avg_grad_norm = 516023
I0317 04:45:21.897580 29479 solver.cpp:214] Iteration 91920, loss = 5728.59
I0317 04:45:21.897711 29479 solver.cpp:229]     Train net output #0: loss = 7035.55 (* 1 = 7035.55 loss)
I0317 04:45:22.266068 29479 solver.cpp:610] Iteration 91920, lr = 5.74703e-09
I0317 04:45:22.266119 29479 solver.cpp:613] Iteration 91920, avg_grad_norm = 513996
I0317 04:46:01.625510 29479 solver.cpp:214] Iteration 91940, loss = 5623.2
I0317 04:46:01.625638 29479 solver.cpp:229]     Train net output #0: loss = 4490.16 (* 1 = 4490.16 loss)
I0317 04:46:01.743496 29479 solver.cpp:610] Iteration 91940, lr = 5.74608e-09
I0317 04:46:01.743508 29479 solver.cpp:613] Iteration 91940, avg_grad_norm = 470510
I0317 04:47:27.482997 29479 solver.cpp:214] Iteration 91960, loss = 6011.61
I0317 04:47:27.483153 29479 solver.cpp:229]     Train net output #0: loss = 4789.79 (* 1 = 4789.79 loss)
I0317 04:47:27.843597 29479 solver.cpp:610] Iteration 91960, lr = 5.74512e-09
I0317 04:47:27.843611 29479 solver.cpp:613] Iteration 91960, avg_grad_norm = 511030
I0317 04:48:35.184494 29479 solver.cpp:214] Iteration 91980, loss = 5693
I0317 04:48:35.184623 29479 solver.cpp:229]     Train net output #0: loss = 5074.7 (* 1 = 5074.7 loss)
I0317 04:48:35.550164 29479 solver.cpp:610] Iteration 91980, lr = 5.74416e-09
I0317 04:48:35.550179 29479 solver.cpp:613] Iteration 91980, avg_grad_norm = 498287
I0317 04:49:42.592499 29479 solver.cpp:214] Iteration 92000, loss = 5497.65
I0317 04:49:42.592578 29479 solver.cpp:229]     Train net output #0: loss = 7932.8 (* 1 = 7932.8 loss)
I0317 04:49:42.953568 29479 solver.cpp:610] Iteration 92000, lr = 5.74321e-09
I0317 04:49:42.953583 29479 solver.cpp:613] Iteration 92000, avg_grad_norm = 482937
I0317 04:50:49.517704 29479 solver.cpp:214] Iteration 92020, loss = 5344.56
I0317 04:50:49.517886 29479 solver.cpp:229]     Train net output #0: loss = 2451.57 (* 1 = 2451.57 loss)
I0317 04:50:49.878391 29479 solver.cpp:610] Iteration 92020, lr = 5.74225e-09
I0317 04:50:49.878406 29479 solver.cpp:613] Iteration 92020, avg_grad_norm = 468636
I0317 04:51:57.630095 29479 solver.cpp:214] Iteration 92040, loss = 5664.64
I0317 04:51:57.630228 29479 solver.cpp:229]     Train net output #0: loss = 3729.35 (* 1 = 3729.35 loss)
I0317 04:51:57.972328 29479 solver.cpp:610] Iteration 92040, lr = 5.74129e-09
I0317 04:51:57.972342 29479 solver.cpp:613] Iteration 92040, avg_grad_norm = 491294
I0317 04:53:06.057242 29479 solver.cpp:214] Iteration 92060, loss = 5621.83
I0317 04:53:06.057385 29479 solver.cpp:229]     Train net output #0: loss = 4294.72 (* 1 = 4294.72 loss)
I0317 04:53:06.419242 29479 solver.cpp:610] Iteration 92060, lr = 5.74033e-09
I0317 04:53:06.419256 29479 solver.cpp:613] Iteration 92060, avg_grad_norm = 543301
I0317 04:54:51.722522 29479 solver.cpp:214] Iteration 92080, loss = 5736.76
I0317 04:54:51.722636 29479 solver.cpp:229]     Train net output #0: loss = 4355.67 (* 1 = 4355.67 loss)
I0317 04:54:52.078706 29479 solver.cpp:610] Iteration 92080, lr = 5.73938e-09
I0317 04:54:52.078718 29479 solver.cpp:613] Iteration 92080, avg_grad_norm = 503156
I0317 04:55:58.509482 29479 solver.cpp:214] Iteration 92100, loss = 5652.67
I0317 04:55:58.509605 29479 solver.cpp:229]     Train net output #0: loss = 3345.48 (* 1 = 3345.48 loss)
I0317 04:55:58.868350 29479 solver.cpp:610] Iteration 92100, lr = 5.73842e-09
I0317 04:55:58.868362 29479 solver.cpp:613] Iteration 92100, avg_grad_norm = 518272
I0317 04:57:06.879533 29479 solver.cpp:214] Iteration 92120, loss = 5772.79
I0317 04:57:06.879664 29479 solver.cpp:229]     Train net output #0: loss = 5256.98 (* 1 = 5256.98 loss)
I0317 04:57:07.239562 29479 solver.cpp:610] Iteration 92120, lr = 5.73746e-09
I0317 04:57:07.239575 29479 solver.cpp:613] Iteration 92120, avg_grad_norm = 481016
I0317 04:58:14.987879 29479 solver.cpp:214] Iteration 92140, loss = 6092.77
I0317 04:58:14.988003 29479 solver.cpp:229]     Train net output #0: loss = 3904.58 (* 1 = 3904.58 loss)
I0317 04:58:15.372047 29479 solver.cpp:610] Iteration 92140, lr = 5.7365e-09
I0317 04:58:15.372061 29479 solver.cpp:613] Iteration 92140, avg_grad_norm = 543879
I0317 04:59:22.296960 29479 solver.cpp:214] Iteration 92160, loss = 5531.21
I0317 04:59:22.297155 29479 solver.cpp:229]     Train net output #0: loss = 7984.43 (* 1 = 7984.43 loss)
I0317 04:59:22.660528 29479 solver.cpp:610] Iteration 92160, lr = 5.73555e-09
I0317 04:59:22.660542 29479 solver.cpp:613] Iteration 92160, avg_grad_norm = 513412
I0317 05:00:30.232396 29479 solver.cpp:214] Iteration 92180, loss = 5733.62
I0317 05:00:30.232543 29479 solver.cpp:229]     Train net output #0: loss = 5902.01 (* 1 = 5902.01 loss)
I0317 05:00:30.611655 29479 solver.cpp:610] Iteration 92180, lr = 5.73459e-09
I0317 05:00:30.611685 29479 solver.cpp:613] Iteration 92180, avg_grad_norm = 498156
I0317 05:02:13.609249 29479 solver.cpp:214] Iteration 92200, loss = 5725.43
I0317 05:02:13.609388 29479 solver.cpp:229]     Train net output #0: loss = 4107.87 (* 1 = 4107.87 loss)
I0317 05:02:13.962445 29479 solver.cpp:610] Iteration 92200, lr = 5.73363e-09
I0317 05:02:13.962460 29479 solver.cpp:613] Iteration 92200, avg_grad_norm = 526244
I0317 05:03:20.910626 29479 solver.cpp:214] Iteration 92220, loss = 5539.87
I0317 05:03:20.910771 29479 solver.cpp:229]     Train net output #0: loss = 7122.68 (* 1 = 7122.68 loss)
I0317 05:03:21.264036 29479 solver.cpp:610] Iteration 92220, lr = 5.73268e-09
I0317 05:03:21.264050 29479 solver.cpp:613] Iteration 92220, avg_grad_norm = 531922
I0317 05:04:27.583762 29479 solver.cpp:214] Iteration 92240, loss = 5405.94
I0317 05:04:27.583914 29479 solver.cpp:229]     Train net output #0: loss = 3868.79 (* 1 = 3868.79 loss)
I0317 05:04:27.967988 29479 solver.cpp:610] Iteration 92240, lr = 5.73172e-09
I0317 05:04:27.968001 29479 solver.cpp:613] Iteration 92240, avg_grad_norm = 581937
I0317 05:05:34.781548 29479 solver.cpp:214] Iteration 92260, loss = 5539.44
I0317 05:05:34.781786 29479 solver.cpp:229]     Train net output #0: loss = 6855.52 (* 1 = 6855.52 loss)
I0317 05:05:35.116251 29479 solver.cpp:610] Iteration 92260, lr = 5.73076e-09
I0317 05:05:35.116266 29479 solver.cpp:613] Iteration 92260, avg_grad_norm = 477309
I0317 05:06:41.971289 29479 solver.cpp:214] Iteration 92280, loss = 5228.35
I0317 05:06:41.971441 29479 solver.cpp:229]     Train net output #0: loss = 3554.87 (* 1 = 3554.87 loss)
I0317 05:06:42.171056 29479 solver.cpp:610] Iteration 92280, lr = 5.7298e-09
I0317 05:06:42.171069 29479 solver.cpp:613] Iteration 92280, avg_grad_norm = 476275
I0317 05:07:49.934195 29479 solver.cpp:214] Iteration 92300, loss = 5789.1
I0317 05:07:49.934379 29479 solver.cpp:229]     Train net output #0: loss = 11218.4 (* 1 = 11218.4 loss)
I0317 05:07:50.297076 29479 solver.cpp:610] Iteration 92300, lr = 5.72885e-09
I0317 05:07:50.297089 29479 solver.cpp:613] Iteration 92300, avg_grad_norm = 516202
I0317 05:08:58.155346 29479 solver.cpp:214] Iteration 92320, loss = 5610.13
I0317 05:08:58.155486 29479 solver.cpp:229]     Train net output #0: loss = 5228.5 (* 1 = 5228.5 loss)
I0317 05:08:58.515416 29479 solver.cpp:610] Iteration 92320, lr = 5.72789e-09
I0317 05:08:58.515430 29479 solver.cpp:613] Iteration 92320, avg_grad_norm = 526491
I0317 05:10:28.578749 29479 solver.cpp:214] Iteration 92340, loss = 5624.07
I0317 05:10:28.578888 29479 solver.cpp:229]     Train net output #0: loss = 5701.35 (* 1 = 5701.35 loss)
I0317 05:10:28.892555 29479 solver.cpp:610] Iteration 92340, lr = 5.72693e-09
I0317 05:10:28.892570 29479 solver.cpp:613] Iteration 92340, avg_grad_norm = 457924
I0317 05:11:35.539669 29479 solver.cpp:214] Iteration 92360, loss = 5784.43
I0317 05:11:35.539885 29479 solver.cpp:229]     Train net output #0: loss = 7933.73 (* 1 = 7933.73 loss)
I0317 05:11:35.903033 29479 solver.cpp:610] Iteration 92360, lr = 5.72597e-09
I0317 05:11:35.903046 29479 solver.cpp:613] Iteration 92360, avg_grad_norm = 469211
I0317 05:12:43.008430 29479 solver.cpp:214] Iteration 92380, loss = 5687.87
I0317 05:12:43.008627 29479 solver.cpp:229]     Train net output #0: loss = 9775.91 (* 1 = 9775.91 loss)
I0317 05:12:43.370544 29479 solver.cpp:610] Iteration 92380, lr = 5.72502e-09
I0317 05:12:43.370558 29479 solver.cpp:613] Iteration 92380, avg_grad_norm = 499936
I0317 05:13:50.491020 29479 solver.cpp:214] Iteration 92400, loss = 5726.98
I0317 05:13:50.491216 29479 solver.cpp:229]     Train net output #0: loss = 3023.03 (* 1 = 3023.03 loss)
I0317 05:13:50.850668 29479 solver.cpp:610] Iteration 92400, lr = 5.72406e-09
I0317 05:13:50.850682 29479 solver.cpp:613] Iteration 92400, avg_grad_norm = 502667
I0317 05:14:57.955279 29479 solver.cpp:214] Iteration 92420, loss = 5594.13
I0317 05:14:57.955415 29479 solver.cpp:229]     Train net output #0: loss = 3267.44 (* 1 = 3267.44 loss)
I0317 05:14:58.340652 29479 solver.cpp:610] Iteration 92420, lr = 5.7231e-09
I0317 05:14:58.340665 29479 solver.cpp:613] Iteration 92420, avg_grad_norm = 538149
I0317 05:16:06.983609 29479 solver.cpp:214] Iteration 92440, loss = 5808.22
I0317 05:16:06.983724 29479 solver.cpp:229]     Train net output #0: loss = 4999.94 (* 1 = 4999.94 loss)
I0317 05:16:07.363592 29479 solver.cpp:610] Iteration 92440, lr = 5.72214e-09
I0317 05:16:07.363605 29479 solver.cpp:613] Iteration 92440, avg_grad_norm = 515198
I0317 05:17:53.992477 29479 solver.cpp:214] Iteration 92460, loss = 5550.3
I0317 05:17:53.992676 29479 solver.cpp:229]     Train net output #0: loss = 3626.82 (* 1 = 3626.82 loss)
I0317 05:17:54.096663 29479 solver.cpp:610] Iteration 92460, lr = 5.72119e-09
I0317 05:17:54.096701 29479 solver.cpp:613] Iteration 92460, avg_grad_norm = 557425
I0317 05:18:48.474584 29479 solver.cpp:214] Iteration 92480, loss = 5599.27
I0317 05:18:48.474735 29479 solver.cpp:229]     Train net output #0: loss = 5868.59 (* 1 = 5868.59 loss)
I0317 05:18:48.832849 29479 solver.cpp:610] Iteration 92480, lr = 5.72023e-09
I0317 05:18:48.832862 29479 solver.cpp:613] Iteration 92480, avg_grad_norm = 585884
I0317 05:19:54.937754 29479 solver.cpp:214] Iteration 92500, loss = 5811.34
I0317 05:19:54.937947 29479 solver.cpp:229]     Train net output #0: loss = 10698.7 (* 1 = 10698.7 loss)
I0317 05:19:55.291667 29479 solver.cpp:610] Iteration 92500, lr = 5.71927e-09
I0317 05:19:55.291682 29479 solver.cpp:613] Iteration 92500, avg_grad_norm = 519842
I0317 05:21:02.670986 29479 solver.cpp:214] Iteration 92520, loss = 5771.13
I0317 05:21:02.671103 29479 solver.cpp:229]     Train net output #0: loss = 6039.27 (* 1 = 6039.27 loss)
I0317 05:21:03.040339 29479 solver.cpp:610] Iteration 92520, lr = 5.71831e-09
I0317 05:21:03.040352 29479 solver.cpp:613] Iteration 92520, avg_grad_norm = 516442
I0317 05:22:10.535812 29479 solver.cpp:214] Iteration 92540, loss = 5457.98
I0317 05:22:10.535936 29479 solver.cpp:229]     Train net output #0: loss = 2739.79 (* 1 = 2739.79 loss)
I0317 05:22:10.859223 29479 solver.cpp:610] Iteration 92540, lr = 5.71736e-09
I0317 05:22:10.859236 29479 solver.cpp:613] Iteration 92540, avg_grad_norm = 523063
I0317 05:23:18.982272 29479 solver.cpp:214] Iteration 92560, loss = 5459.94
I0317 05:23:18.982412 29479 solver.cpp:229]     Train net output #0: loss = 3502.49 (* 1 = 3502.49 loss)
I0317 05:23:19.341429 29479 solver.cpp:610] Iteration 92560, lr = 5.7164e-09
I0317 05:23:19.341444 29479 solver.cpp:613] Iteration 92560, avg_grad_norm = 454766
I0317 05:24:51.375063 29479 solver.cpp:214] Iteration 92580, loss = 5319.75
I0317 05:24:51.375159 29479 solver.cpp:229]     Train net output #0: loss = 3830.02 (* 1 = 3830.02 loss)
I0317 05:24:51.756582 29479 solver.cpp:610] Iteration 92580, lr = 5.71544e-09
I0317 05:24:51.756595 29479 solver.cpp:613] Iteration 92580, avg_grad_norm = 455046
I0317 05:25:32.792429 29479 solver.cpp:214] Iteration 92600, loss = 5476.27
I0317 05:25:32.792570 29479 solver.cpp:229]     Train net output #0: loss = 3929.15 (* 1 = 3929.15 loss)
I0317 05:25:33.171458 29479 solver.cpp:610] Iteration 92600, lr = 5.71448e-09
I0317 05:25:33.171473 29479 solver.cpp:613] Iteration 92600, avg_grad_norm = 464045
I0317 05:26:40.710095 29479 solver.cpp:214] Iteration 92620, loss = 5544.58
I0317 05:26:40.710268 29479 solver.cpp:229]     Train net output #0: loss = 5743.69 (* 1 = 5743.69 loss)
I0317 05:26:41.072357 29479 solver.cpp:610] Iteration 92620, lr = 5.71352e-09
I0317 05:26:41.072371 29479 solver.cpp:613] Iteration 92620, avg_grad_norm = 472350
I0317 05:27:49.170909 29479 solver.cpp:214] Iteration 92640, loss = 5552.96
I0317 05:27:49.171015 29479 solver.cpp:229]     Train net output #0: loss = 9600.26 (* 1 = 9600.26 loss)
I0317 05:27:49.533069 29479 solver.cpp:610] Iteration 92640, lr = 5.71257e-09
I0317 05:27:49.533082 29479 solver.cpp:613] Iteration 92640, avg_grad_norm = 522296
I0317 05:28:56.636395 29479 solver.cpp:214] Iteration 92660, loss = 5509.81
I0317 05:28:56.636528 29479 solver.cpp:229]     Train net output #0: loss = 5121.69 (* 1 = 5121.69 loss)
I0317 05:28:57.016877 29479 solver.cpp:610] Iteration 92660, lr = 5.71161e-09
I0317 05:28:57.016891 29479 solver.cpp:613] Iteration 92660, avg_grad_norm = 511558
I0317 05:30:04.545902 29479 solver.cpp:214] Iteration 92680, loss = 5367.47
I0317 05:30:04.546124 29479 solver.cpp:229]     Train net output #0: loss = 4945.77 (* 1 = 4945.77 loss)
I0317 05:30:04.936437 29479 solver.cpp:610] Iteration 92680, lr = 5.71065e-09
I0317 05:30:04.936451 29479 solver.cpp:613] Iteration 92680, avg_grad_norm = 476162
I0317 05:31:13.157881 29479 solver.cpp:214] Iteration 92700, loss = 5464.96
I0317 05:31:13.158030 29479 solver.cpp:229]     Train net output #0: loss = 3750.67 (* 1 = 3750.67 loss)
I0317 05:31:13.526690 29479 solver.cpp:610] Iteration 92700, lr = 5.70969e-09
I0317 05:31:13.526702 29479 solver.cpp:613] Iteration 92700, avg_grad_norm = 471181
I0317 05:32:38.535274 29479 solver.cpp:214] Iteration 92720, loss = 5585.72
I0317 05:32:38.535414 29479 solver.cpp:229]     Train net output #0: loss = 4704.1 (* 1 = 4704.1 loss)
I0317 05:32:38.640660 29479 solver.cpp:610] Iteration 92720, lr = 5.70873e-09
I0317 05:32:38.640677 29479 solver.cpp:613] Iteration 92720, avg_grad_norm = 493578
I0317 05:33:04.499425 29479 solver.cpp:214] Iteration 92740, loss = 5656.67
I0317 05:33:04.499493 29479 solver.cpp:229]     Train net output #0: loss = 5646.54 (* 1 = 5646.54 loss)
I0317 05:33:04.617537 29479 solver.cpp:610] Iteration 92740, lr = 5.70778e-09
I0317 05:33:04.617552 29479 solver.cpp:613] Iteration 92740, avg_grad_norm = 536113
I0317 05:33:30.760563 29479 solver.cpp:214] Iteration 92760, loss = 5431.45
I0317 05:33:30.760747 29479 solver.cpp:229]     Train net output #0: loss = 4995.32 (* 1 = 4995.32 loss)
I0317 05:33:30.876677 29479 solver.cpp:610] Iteration 92760, lr = 5.70682e-09
I0317 05:33:30.876693 29479 solver.cpp:613] Iteration 92760, avg_grad_norm = 530562
I0317 05:34:28.757930 29479 solver.cpp:214] Iteration 92780, loss = 5662.83
I0317 05:34:28.758081 29479 solver.cpp:229]     Train net output #0: loss = 5155.09 (* 1 = 5155.09 loss)
I0317 05:34:29.121484 29479 solver.cpp:610] Iteration 92780, lr = 5.70586e-09
I0317 05:34:29.121497 29479 solver.cpp:613] Iteration 92780, avg_grad_norm = 511348
I0317 05:35:36.391165 29479 solver.cpp:214] Iteration 92800, loss = 5349.83
I0317 05:35:36.391350 29479 solver.cpp:229]     Train net output #0: loss = 2023.06 (* 1 = 2023.06 loss)
I0317 05:35:36.754564 29479 solver.cpp:610] Iteration 92800, lr = 5.7049e-09
I0317 05:35:36.754577 29479 solver.cpp:613] Iteration 92800, avg_grad_norm = 484652
I0317 05:36:55.725899 29479 solver.cpp:214] Iteration 92820, loss = 5489.44
I0317 05:36:55.726101 29479 solver.cpp:229]     Train net output #0: loss = 5117.38 (* 1 = 5117.38 loss)
I0317 05:36:56.793534 29479 solver.cpp:610] Iteration 92820, lr = 5.70395e-09
I0317 05:36:56.793547 29479 solver.cpp:613] Iteration 92820, avg_grad_norm = 490012
I0317 05:39:37.354251 29479 solver.cpp:214] Iteration 92840, loss = 5428.2
I0317 05:39:37.354445 29479 solver.cpp:229]     Train net output #0: loss = 4239.08 (* 1 = 4239.08 loss)
I0317 05:39:38.388964 29479 solver.cpp:610] Iteration 92840, lr = 5.70299e-09
I0317 05:39:38.388980 29479 solver.cpp:613] Iteration 92840, avg_grad_norm = 540771
I0317 05:42:05.993944 29479 solver.cpp:214] Iteration 92860, loss = 5593.04
I0317 05:42:05.994144 29479 solver.cpp:229]     Train net output #0: loss = 4784.54 (* 1 = 4784.54 loss)
I0317 05:42:07.037947 29479 solver.cpp:610] Iteration 92860, lr = 5.70203e-09
I0317 05:42:07.037961 29479 solver.cpp:613] Iteration 92860, avg_grad_norm = 562437
I0317 05:44:34.514088 29479 solver.cpp:214] Iteration 92880, loss = 5913.6
I0317 05:44:34.514219 29479 solver.cpp:229]     Train net output #0: loss = 5166.88 (* 1 = 5166.88 loss)
I0317 05:44:34.694352 29479 solver.cpp:610] Iteration 92880, lr = 5.70107e-09
I0317 05:44:34.694365 29479 solver.cpp:613] Iteration 92880, avg_grad_norm = 517505
I0317 05:47:03.098729 29479 solver.cpp:214] Iteration 92900, loss = 5349.78
I0317 05:47:03.098839 29479 solver.cpp:229]     Train net output #0: loss = 3523.24 (* 1 = 3523.24 loss)
I0317 05:47:03.278511 29479 solver.cpp:610] Iteration 92900, lr = 5.70011e-09
I0317 05:47:03.278524 29479 solver.cpp:613] Iteration 92900, avg_grad_norm = 519972
I0317 05:49:31.733001 29479 solver.cpp:214] Iteration 92920, loss = 5586.88
I0317 05:49:31.733141 29479 solver.cpp:229]     Train net output #0: loss = 5327.26 (* 1 = 5327.26 loss)
I0317 05:49:31.908855 29479 solver.cpp:610] Iteration 92920, lr = 5.69916e-09
I0317 05:49:31.908867 29479 solver.cpp:613] Iteration 92920, avg_grad_norm = 542322
I0317 05:52:00.421336 29479 solver.cpp:214] Iteration 92940, loss = 5918.98
I0317 05:52:00.421464 29479 solver.cpp:229]     Train net output #0: loss = 4370.43 (* 1 = 4370.43 loss)
I0317 05:52:01.461962 29479 solver.cpp:610] Iteration 92940, lr = 5.6982e-09
I0317 05:52:01.461977 29479 solver.cpp:613] Iteration 92940, avg_grad_norm = 527239
I0317 05:54:56.157810 29479 solver.cpp:214] Iteration 92960, loss = 5738
I0317 05:54:56.157950 29479 solver.cpp:229]     Train net output #0: loss = 5818.84 (* 1 = 5818.84 loss)
I0317 05:54:57.209007 29479 solver.cpp:610] Iteration 92960, lr = 5.69724e-09
I0317 05:54:57.209053 29479 solver.cpp:613] Iteration 92960, avg_grad_norm = 498260
I0317 05:56:11.692981 29479 solver.cpp:214] Iteration 92980, loss = 5545.38
I0317 05:56:11.693284 29479 solver.cpp:229]     Train net output #0: loss = 6305.83 (* 1 = 6305.83 loss)
I0317 05:56:11.797665 29479 solver.cpp:610] Iteration 92980, lr = 5.69628e-09
I0317 05:56:11.797679 29479 solver.cpp:613] Iteration 92980, avg_grad_norm = 503529
I0317 05:57:40.348269 29479 solver.cpp:214] Iteration 93000, loss = 5519.21
I0317 05:57:40.348395 29479 solver.cpp:229]     Train net output #0: loss = 4293.3 (* 1 = 4293.3 loss)
I0317 05:57:41.385921 29479 solver.cpp:610] Iteration 93000, lr = 5.69532e-09
I0317 05:57:41.385934 29479 solver.cpp:613] Iteration 93000, avg_grad_norm = 576468
I0317 06:00:08.908459 29479 solver.cpp:214] Iteration 93020, loss = 5604.07
I0317 06:00:08.908660 29479 solver.cpp:229]     Train net output #0: loss = 4843.65 (* 1 = 4843.65 loss)
I0317 06:00:09.946111 29479 solver.cpp:610] Iteration 93020, lr = 5.69437e-09
I0317 06:00:09.946125 29479 solver.cpp:613] Iteration 93020, avg_grad_norm = 546145
I0317 06:02:38.519346 29479 solver.cpp:214] Iteration 93040, loss = 5666.58
I0317 06:02:38.519538 29479 solver.cpp:229]     Train net output #0: loss = 4137.4 (* 1 = 4137.4 loss)
I0317 06:02:39.558367 29479 solver.cpp:610] Iteration 93040, lr = 5.69341e-09
I0317 06:02:39.558382 29479 solver.cpp:613] Iteration 93040, avg_grad_norm = 481777
I0317 06:05:07.109503 29479 solver.cpp:214] Iteration 93060, loss = 5484.76
I0317 06:05:07.109619 29479 solver.cpp:229]     Train net output #0: loss = 2848.5 (* 1 = 2848.5 loss)
I0317 06:05:08.148263 29479 solver.cpp:610] Iteration 93060, lr = 5.69245e-09
I0317 06:05:08.148277 29479 solver.cpp:613] Iteration 93060, avg_grad_norm = 482714
I0317 06:07:36.680785 29479 solver.cpp:214] Iteration 93080, loss = 5757.97
I0317 06:07:36.680919 29479 solver.cpp:229]     Train net output #0: loss = 6910.26 (* 1 = 6910.26 loss)
I0317 06:07:36.847810 29479 solver.cpp:610] Iteration 93080, lr = 5.69149e-09
I0317 06:07:36.847823 29479 solver.cpp:613] Iteration 93080, avg_grad_norm = 515580
I0317 06:10:17.357131 29479 solver.cpp:214] Iteration 93100, loss = 5693.52
I0317 06:10:17.357408 29479 solver.cpp:229]     Train net output #0: loss = 6939.36 (* 1 = 6939.36 loss)
I0317 06:10:17.532490 29479 solver.cpp:610] Iteration 93100, lr = 5.69053e-09
I0317 06:10:17.532521 29479 solver.cpp:613] Iteration 93100, avg_grad_norm = 492984
I0317 06:12:45.995465 29479 solver.cpp:214] Iteration 93120, loss = 5575.84
I0317 06:12:45.995582 29479 solver.cpp:229]     Train net output #0: loss = 5264.52 (* 1 = 5264.52 loss)
I0317 06:12:46.164530 29479 solver.cpp:610] Iteration 93120, lr = 5.68957e-09
I0317 06:12:46.164543 29479 solver.cpp:613] Iteration 93120, avg_grad_norm = 487360
I0317 06:15:14.666452 29479 solver.cpp:214] Iteration 93140, loss = 5636.55
I0317 06:15:14.666587 29479 solver.cpp:229]     Train net output #0: loss = 4701.95 (* 1 = 4701.95 loss)
I0317 06:15:15.708936 29479 solver.cpp:610] Iteration 93140, lr = 5.68862e-09
I0317 06:15:15.708950 29479 solver.cpp:613] Iteration 93140, avg_grad_norm = 465941
I0317 06:16:40.202491 29479 solver.cpp:214] Iteration 93160, loss = 6020.86
I0317 06:16:40.202636 29479 solver.cpp:229]     Train net output #0: loss = 3669.4 (* 1 = 3669.4 loss)
I0317 06:16:40.306772 29479 solver.cpp:610] Iteration 93160, lr = 5.68766e-09
I0317 06:16:40.306787 29479 solver.cpp:613] Iteration 93160, avg_grad_norm = 488831
I0317 06:18:39.778338 29479 solver.cpp:214] Iteration 93180, loss = 5615.93
I0317 06:18:39.778473 29479 solver.cpp:229]     Train net output #0: loss = 4044.5 (* 1 = 4044.5 loss)
I0317 06:18:40.824872 29479 solver.cpp:610] Iteration 93180, lr = 5.6867e-09
I0317 06:18:40.824885 29479 solver.cpp:613] Iteration 93180, avg_grad_norm = 558739
I0317 06:21:08.459543 29479 solver.cpp:214] Iteration 93200, loss = 5651.54
I0317 06:21:08.459663 29479 solver.cpp:229]     Train net output #0: loss = 4075.67 (* 1 = 4075.67 loss)
I0317 06:21:09.529750 29479 solver.cpp:610] Iteration 93200, lr = 5.68574e-09
I0317 06:21:09.529764 29479 solver.cpp:613] Iteration 93200, avg_grad_norm = 511899
I0317 06:23:54.117899 29479 solver.cpp:214] Iteration 93220, loss = 5934.98
I0317 06:23:54.118067 29479 solver.cpp:229]     Train net output #0: loss = 4106.19 (* 1 = 4106.19 loss)
I0317 06:23:55.164146 29479 solver.cpp:610] Iteration 93220, lr = 5.68478e-09
I0317 06:23:55.164163 29479 solver.cpp:613] Iteration 93220, avg_grad_norm = 533738
I0317 06:26:23.643646 29479 solver.cpp:214] Iteration 93240, loss = 5371.77
I0317 06:26:23.643774 29479 solver.cpp:229]     Train net output #0: loss = 6504.78 (* 1 = 6504.78 loss)
I0317 06:26:23.812417 29479 solver.cpp:610] Iteration 93240, lr = 5.68383e-09
I0317 06:26:23.812429 29479 solver.cpp:613] Iteration 93240, avg_grad_norm = 463155
I0317 06:28:53.261402 29479 solver.cpp:214] Iteration 93260, loss = 5413.4
I0317 06:28:53.261514 29479 solver.cpp:229]     Train net output #0: loss = 10311.9 (* 1 = 10311.9 loss)
I0317 06:28:54.298931 29479 solver.cpp:610] Iteration 93260, lr = 5.68287e-09
I0317 06:28:54.298944 29479 solver.cpp:613] Iteration 93260, avg_grad_norm = 528454
I0317 06:31:21.889865 29479 solver.cpp:214] Iteration 93280, loss = 5800.61
I0317 06:31:21.889986 29479 solver.cpp:229]     Train net output #0: loss = 9406.64 (* 1 = 9406.64 loss)
I0317 06:31:22.974362 29479 solver.cpp:610] Iteration 93280, lr = 5.68191e-09
I0317 06:31:22.974377 29479 solver.cpp:613] Iteration 93280, avg_grad_norm = 555528
I0317 06:33:51.446894 29479 solver.cpp:214] Iteration 93300, loss = 5924.97
I0317 06:33:51.447002 29479 solver.cpp:229]     Train net output #0: loss = 6244.04 (* 1 = 6244.04 loss)
I0317 06:33:51.621415 29479 solver.cpp:610] Iteration 93300, lr = 5.68095e-09
I0317 06:33:51.621428 29479 solver.cpp:613] Iteration 93300, avg_grad_norm = 504196
I0317 06:36:19.174006 29479 solver.cpp:214] Iteration 93320, loss = 5751.09
I0317 06:36:19.174100 29479 solver.cpp:229]     Train net output #0: loss = 11358.7 (* 1 = 11358.7 loss)
I0317 06:36:20.255544 29479 solver.cpp:610] Iteration 93320, lr = 5.67999e-09
I0317 06:36:20.255559 29479 solver.cpp:613] Iteration 93320, avg_grad_norm = 482623
I0317 06:37:52.796679 29479 solver.cpp:214] Iteration 93340, loss = 5414.93
I0317 06:37:52.796808 29479 solver.cpp:229]     Train net output #0: loss = 3667.42 (* 1 = 3667.42 loss)
I0317 06:37:52.950655 29479 solver.cpp:610] Iteration 93340, lr = 5.67903e-09
I0317 06:37:52.950670 29479 solver.cpp:613] Iteration 93340, avg_grad_norm = 490631
I0317 06:40:21.324021 29479 solver.cpp:214] Iteration 93360, loss = 5418.15
I0317 06:40:21.324218 29479 solver.cpp:229]     Train net output #0: loss = 4314.94 (* 1 = 4314.94 loss)
I0317 06:40:21.496786 29479 solver.cpp:610] Iteration 93360, lr = 5.67808e-09
I0317 06:40:21.496799 29479 solver.cpp:613] Iteration 93360, avg_grad_norm = 544792
I0317 06:42:49.954349 29479 solver.cpp:214] Iteration 93380, loss = 5584.61
I0317 06:42:49.954463 29479 solver.cpp:229]     Train net output #0: loss = 2740.92 (* 1 = 2740.92 loss)
I0317 06:42:51.006752 29479 solver.cpp:610] Iteration 93380, lr = 5.67712e-09
I0317 06:42:51.006765 29479 solver.cpp:613] Iteration 93380, avg_grad_norm = 496414
I0317 06:45:18.610730 29479 solver.cpp:214] Iteration 93400, loss = 5398.77
I0317 06:45:18.610849 29479 solver.cpp:229]     Train net output #0: loss = 4070.5 (* 1 = 4070.5 loss)
I0317 06:45:19.682286 29479 solver.cpp:610] Iteration 93400, lr = 5.67616e-09
I0317 06:45:19.682301 29479 solver.cpp:613] Iteration 93400, avg_grad_norm = 490877
I0317 06:47:47.082468 29479 solver.cpp:214] Iteration 93420, loss = 5800.65
I0317 06:47:47.082556 29479 solver.cpp:229]     Train net output #0: loss = 5034.86 (* 1 = 5034.86 loss)
I0317 06:47:47.262837 29479 solver.cpp:610] Iteration 93420, lr = 5.6752e-09
I0317 06:47:47.262851 29479 solver.cpp:613] Iteration 93420, avg_grad_norm = 533533
I0317 06:50:15.627396 29479 solver.cpp:214] Iteration 93440, loss = 5681.14
I0317 06:50:15.627521 29479 solver.cpp:229]     Train net output #0: loss = 8660.97 (* 1 = 8660.97 loss)
I0317 06:50:15.849925 29479 solver.cpp:610] Iteration 93440, lr = 5.67424e-09
I0317 06:50:15.849938 29479 solver.cpp:613] Iteration 93440, avg_grad_norm = 528933
I0317 06:52:44.300190 29479 solver.cpp:214] Iteration 93460, loss = 5717.44
I0317 06:52:44.300348 29479 solver.cpp:229]     Train net output #0: loss = 4477.55 (* 1 = 4477.55 loss)
I0317 06:52:44.458905 29479 solver.cpp:610] Iteration 93460, lr = 5.67328e-09
I0317 06:52:44.458920 29479 solver.cpp:613] Iteration 93460, avg_grad_norm = 558425
I0317 06:55:23.979264 29479 solver.cpp:214] Iteration 93480, loss = 5596.27
I0317 06:55:23.979392 29479 solver.cpp:229]     Train net output #0: loss = 4442.87 (* 1 = 4442.87 loss)
I0317 06:55:24.148074 29479 solver.cpp:610] Iteration 93480, lr = 5.67232e-09
I0317 06:55:24.148087 29479 solver.cpp:613] Iteration 93480, avg_grad_norm = 484495
I0317 06:57:13.613011 29479 solver.cpp:214] Iteration 93500, loss = 5604.29
I0317 06:57:13.613154 29479 solver.cpp:229]     Train net output #0: loss = 8176.79 (* 1 = 8176.79 loss)
I0317 06:57:13.717993 29479 solver.cpp:610] Iteration 93500, lr = 5.67137e-09
I0317 06:57:13.718006 29479 solver.cpp:613] Iteration 93500, avg_grad_norm = 477360
I0317 06:59:13.107749 29479 solver.cpp:214] Iteration 93520, loss = 5494.81
I0317 06:59:13.107892 29479 solver.cpp:229]     Train net output #0: loss = 5443.88 (* 1 = 5443.88 loss)
I0317 06:59:13.329706 29479 solver.cpp:610] Iteration 93520, lr = 5.67041e-09
I0317 06:59:13.329757 29479 solver.cpp:613] Iteration 93520, avg_grad_norm = 515611
I0317 07:01:40.861578 29479 solver.cpp:214] Iteration 93540, loss = 5687.43
I0317 07:01:40.861768 29479 solver.cpp:229]     Train net output #0: loss = 5100.22 (* 1 = 5100.22 loss)
I0317 07:01:41.900109 29479 solver.cpp:610] Iteration 93540, lr = 5.66945e-09
I0317 07:01:41.900142 29479 solver.cpp:613] Iteration 93540, avg_grad_norm = 570316
I0317 07:04:10.478175 29479 solver.cpp:214] Iteration 93560, loss = 5759.08
I0317 07:04:10.478313 29479 solver.cpp:229]     Train net output #0: loss = 7037.22 (* 1 = 7037.22 loss)
I0317 07:04:10.649807 29479 solver.cpp:610] Iteration 93560, lr = 5.66849e-09
I0317 07:04:10.649821 29479 solver.cpp:613] Iteration 93560, avg_grad_norm = 490984
I0317 07:06:39.147501 29479 solver.cpp:214] Iteration 93580, loss = 5519.87
I0317 07:06:39.147610 29479 solver.cpp:229]     Train net output #0: loss = 9316.89 (* 1 = 9316.89 loss)
I0317 07:06:40.201787 29479 solver.cpp:610] Iteration 93580, lr = 5.66753e-09
I0317 07:06:40.201802 29479 solver.cpp:613] Iteration 93580, avg_grad_norm = 503420
I0317 07:09:19.847312 29479 solver.cpp:214] Iteration 93600, loss = 5466.95
I0317 07:09:19.847426 29479 solver.cpp:229]     Train net output #0: loss = 6914.84 (* 1 = 6914.84 loss)
I0317 07:09:20.921867 29479 solver.cpp:610] Iteration 93600, lr = 5.66657e-09
I0317 07:09:20.921882 29479 solver.cpp:613] Iteration 93600, avg_grad_norm = 568159
I0317 07:11:49.336817 29479 solver.cpp:214] Iteration 93620, loss = 5659.91
I0317 07:11:49.336954 29479 solver.cpp:229]     Train net output #0: loss = 5244.56 (* 1 = 5244.56 loss)
I0317 07:11:49.511340 29479 solver.cpp:610] Iteration 93620, lr = 5.66561e-09
I0317 07:11:49.511353 29479 solver.cpp:613] Iteration 93620, avg_grad_norm = 482912
I0317 07:14:17.981456 29479 solver.cpp:214] Iteration 93640, loss = 5345.13
I0317 07:14:17.981575 29479 solver.cpp:229]     Train net output #0: loss = 3345.96 (* 1 = 3345.96 loss)
I0317 07:14:19.068269 29479 solver.cpp:610] Iteration 93640, lr = 5.66466e-09
I0317 07:14:19.068284 29479 solver.cpp:613] Iteration 93640, avg_grad_norm = 513231
I0317 07:16:46.567330 29479 solver.cpp:214] Iteration 93660, loss = 5757.68
I0317 07:16:46.567420 29479 solver.cpp:229]     Train net output #0: loss = 7095.2 (* 1 = 7095.2 loss)
I0317 07:16:46.737721 29479 solver.cpp:610] Iteration 93660, lr = 5.6637e-09
I0317 07:16:46.737735 29479 solver.cpp:613] Iteration 93660, avg_grad_norm = 515086
I0317 07:18:01.192505 29479 solver.cpp:214] Iteration 93680, loss = 5575.69
I0317 07:18:01.192625 29479 solver.cpp:229]     Train net output #0: loss = 4168.31 (* 1 = 4168.31 loss)
I0317 07:18:02.235942 29479 solver.cpp:610] Iteration 93680, lr = 5.66274e-09
I0317 07:18:02.235956 29479 solver.cpp:613] Iteration 93680, avg_grad_norm = 464811
I0317 07:20:30.764773 29479 solver.cpp:214] Iteration 93700, loss = 5496.31
I0317 07:20:30.765022 29479 solver.cpp:229]     Train net output #0: loss = 5280.29 (* 1 = 5280.29 loss)
I0317 07:20:30.930356 29479 solver.cpp:610] Iteration 93700, lr = 5.66178e-09
I0317 07:20:30.930377 29479 solver.cpp:613] Iteration 93700, avg_grad_norm = 488923
I0317 07:22:59.416025 29479 solver.cpp:214] Iteration 93720, loss = 5733.95
I0317 07:22:59.416148 29479 solver.cpp:229]     Train net output #0: loss = 5383.23 (* 1 = 5383.23 loss)
I0317 07:23:00.462354 29479 solver.cpp:610] Iteration 93720, lr = 5.66082e-09
I0317 07:23:00.462368 29479 solver.cpp:613] Iteration 93720, avg_grad_norm = 487141
I0317 07:25:39.083101 29479 solver.cpp:214] Iteration 93740, loss = 5924.58
I0317 07:25:39.083242 29479 solver.cpp:229]     Train net output #0: loss = 3841.51 (* 1 = 3841.51 loss)
I0317 07:25:40.164389 29479 solver.cpp:610] Iteration 93740, lr = 5.65986e-09
I0317 07:25:40.164404 29479 solver.cpp:613] Iteration 93740, avg_grad_norm = 491552
I0317 07:28:07.643129 29479 solver.cpp:214] Iteration 93760, loss = 5726.57
I0317 07:28:07.643255 29479 solver.cpp:229]     Train net output #0: loss = 4871.14 (* 1 = 4871.14 loss)
I0317 07:28:08.690898 29479 solver.cpp:610] Iteration 93760, lr = 5.6589e-09
I0317 07:28:08.690912 29479 solver.cpp:613] Iteration 93760, avg_grad_norm = 527825
I0317 07:30:36.253738 29479 solver.cpp:214] Iteration 93780, loss = 5733.13
I0317 07:30:36.253861 29479 solver.cpp:229]     Train net output #0: loss = 3891.54 (* 1 = 3891.54 loss)
I0317 07:30:37.350702 29479 solver.cpp:610] Iteration 93780, lr = 5.65794e-09
I0317 07:30:37.350716 29479 solver.cpp:613] Iteration 93780, avg_grad_norm = 487052
I0317 07:33:04.871229 29479 solver.cpp:214] Iteration 93800, loss = 5778.62
I0317 07:33:04.871343 29479 solver.cpp:229]     Train net output #0: loss = 4157.76 (* 1 = 4157.76 loss)
I0317 07:33:05.923918 29479 solver.cpp:610] Iteration 93800, lr = 5.65699e-09
I0317 07:33:05.923930 29479 solver.cpp:613] Iteration 93800, avg_grad_norm = 497241
I0317 07:35:34.419646 29479 solver.cpp:214] Iteration 93820, loss = 5442.28
I0317 07:35:34.419771 29479 solver.cpp:229]     Train net output #0: loss = 10956 (* 1 = 10956 loss)
I0317 07:35:34.601194 29479 solver.cpp:610] Iteration 93820, lr = 5.65603e-09
I0317 07:35:34.601207 29479 solver.cpp:613] Iteration 93820, avg_grad_norm = 530746
I0317 07:37:47.051975 29479 solver.cpp:214] Iteration 93840, loss = 5809.75
I0317 07:37:47.052106 29479 solver.cpp:229]     Train net output #0: loss = 6246.74 (* 1 = 6246.74 loss)
I0317 07:37:47.156267 29479 solver.cpp:610] Iteration 93840, lr = 5.65507e-09
I0317 07:37:47.156304 29479 solver.cpp:613] Iteration 93840, avg_grad_norm = 551100
I0317 07:39:48.521762 29479 solver.cpp:214] Iteration 93860, loss = 5601.76
I0317 07:39:48.521899 29479 solver.cpp:229]     Train net output #0: loss = 7808.33 (* 1 = 7808.33 loss)
I0317 07:39:49.592687 29479 solver.cpp:610] Iteration 93860, lr = 5.65411e-09
I0317 07:39:49.592715 29479 solver.cpp:613] Iteration 93860, avg_grad_norm = 591078
I0317 07:42:18.097312 29479 solver.cpp:214] Iteration 93880, loss = 5596.07
I0317 07:42:18.097443 29479 solver.cpp:229]     Train net output #0: loss = 6936.05 (* 1 = 6936.05 loss)
I0317 07:42:19.173573 29479 solver.cpp:610] Iteration 93880, lr = 5.65315e-09
I0317 07:42:19.173588 29479 solver.cpp:613] Iteration 93880, avg_grad_norm = 547562
I0317 07:44:47.740916 29479 solver.cpp:214] Iteration 93900, loss = 5863.38
I0317 07:44:47.741129 29479 solver.cpp:229]     Train net output #0: loss = 4579.83 (* 1 = 4579.83 loss)
I0317 07:44:48.810318 29479 solver.cpp:610] Iteration 93900, lr = 5.65219e-09
I0317 07:44:48.810338 29479 solver.cpp:613] Iteration 93900, avg_grad_norm = 487072
I0317 07:47:17.285925 29479 solver.cpp:214] Iteration 93920, loss = 5560.45
I0317 07:47:17.286121 29479 solver.cpp:229]     Train net output #0: loss = 10977.5 (* 1 = 10977.5 loss)
I0317 07:47:17.465878 29479 solver.cpp:610] Iteration 93920, lr = 5.65123e-09
I0317 07:47:17.465891 29479 solver.cpp:613] Iteration 93920, avg_grad_norm = 496610
I0317 07:49:46.017365 29479 solver.cpp:214] Iteration 93940, loss = 5520.73
I0317 07:49:46.017563 29479 solver.cpp:229]     Train net output #0: loss = 9904.71 (* 1 = 9904.71 loss)
I0317 07:49:47.094851 29479 solver.cpp:610] Iteration 93940, lr = 5.65027e-09
I0317 07:49:47.094866 29479 solver.cpp:613] Iteration 93940, avg_grad_norm = 523817
I0317 07:52:15.610587 29479 solver.cpp:214] Iteration 93960, loss = 5460.79
I0317 07:52:15.610795 29479 solver.cpp:229]     Train net output #0: loss = 4791.22 (* 1 = 4791.22 loss)
I0317 07:52:15.778985 29479 solver.cpp:610] Iteration 93960, lr = 5.64931e-09
I0317 07:52:15.778997 29479 solver.cpp:613] Iteration 93960, avg_grad_norm = 562191
I0317 07:54:56.275990 29479 solver.cpp:214] Iteration 93980, loss = 5450.99
I0317 07:54:56.276108 29479 solver.cpp:229]     Train net output #0: loss = 6366.86 (* 1 = 6366.86 loss)
I0317 07:54:57.359000 29479 solver.cpp:610] Iteration 93980, lr = 5.64836e-09
I0317 07:54:57.359016 29479 solver.cpp:613] Iteration 93980, avg_grad_norm = 473448
I0317 07:57:24.868686 29479 solver.cpp:214] Iteration 94000, loss = 5397.6
I0317 07:57:24.868926 29479 solver.cpp:229]     Train net output #0: loss = 7227.36 (* 1 = 7227.36 loss)
I0317 07:57:25.956496 29479 solver.cpp:610] Iteration 94000, lr = 5.6474e-09
I0317 07:57:25.956516 29479 solver.cpp:613] Iteration 94000, avg_grad_norm = 507635
I0317 07:58:42.451935 29479 solver.cpp:214] Iteration 94020, loss = 5513.75
I0317 07:58:42.452097 29479 solver.cpp:229]     Train net output #0: loss = 5569.41 (* 1 = 5569.41 loss)
I0317 07:58:43.521112 29479 solver.cpp:610] Iteration 94020, lr = 5.64644e-09
I0317 07:58:43.521127 29479 solver.cpp:613] Iteration 94020, avg_grad_norm = 495866
I0317 08:01:12.016000 29479 solver.cpp:214] Iteration 94040, loss = 5546.89
I0317 08:01:12.016208 29479 solver.cpp:229]     Train net output #0: loss = 10074.6 (* 1 = 10074.6 loss)
I0317 08:01:13.103492 29479 solver.cpp:610] Iteration 94040, lr = 5.64548e-09
I0317 08:01:13.103507 29479 solver.cpp:613] Iteration 94040, avg_grad_norm = 499051
I0317 08:03:40.587025 29479 solver.cpp:214] Iteration 94060, loss = 5580.1
I0317 08:03:40.587224 29479 solver.cpp:229]     Train net output #0: loss = 3808.29 (* 1 = 3808.29 loss)
I0317 08:03:41.630193 29479 solver.cpp:610] Iteration 94060, lr = 5.64452e-09
I0317 08:03:41.630206 29479 solver.cpp:613] Iteration 94060, avg_grad_norm = 598631
I0317 08:06:09.243448 29479 solver.cpp:214] Iteration 94080, loss = 5331.5
I0317 08:06:09.243580 29479 solver.cpp:229]     Train net output #0: loss = 3444.56 (* 1 = 3444.56 loss)
I0317 08:06:10.316339 29479 solver.cpp:610] Iteration 94080, lr = 5.64356e-09
I0317 08:06:10.316354 29479 solver.cpp:613] Iteration 94080, avg_grad_norm = 571009
I0317 08:08:38.752060 29479 solver.cpp:214] Iteration 94100, loss = 5571.44
I0317 08:08:38.752197 29479 solver.cpp:229]     Train net output #0: loss = 3364.53 (* 1 = 3364.53 loss)
I0317 08:08:38.934049 29479 solver.cpp:610] Iteration 94100, lr = 5.6426e-09
I0317 08:08:38.934062 29479 solver.cpp:613] Iteration 94100, avg_grad_norm = 530265
I0317 08:11:28.431344 29479 solver.cpp:214] Iteration 94120, loss = 5442.38
I0317 08:11:28.431474 29479 solver.cpp:229]     Train net output #0: loss = 3586.51 (* 1 = 3586.51 loss)
I0317 08:11:28.604310 29479 solver.cpp:610] Iteration 94120, lr = 5.64164e-09
I0317 08:11:28.604323 29479 solver.cpp:613] Iteration 94120, avg_grad_norm = 482810
I0317 08:13:57.089388 29479 solver.cpp:214] Iteration 94140, loss = 5523.67
I0317 08:13:57.089501 29479 solver.cpp:229]     Train net output #0: loss = 4052.57 (* 1 = 4052.57 loss)
I0317 08:13:57.257357 29479 solver.cpp:610] Iteration 94140, lr = 5.64068e-09
I0317 08:13:57.257371 29479 solver.cpp:613] Iteration 94140, avg_grad_norm = 480796
I0317 08:16:26.712143 29479 solver.cpp:214] Iteration 94160, loss = 5450.9
I0317 08:16:26.712324 29479 solver.cpp:229]     Train net output #0: loss = 4530.69 (* 1 = 4530.69 loss)
I0317 08:16:26.892256 29479 solver.cpp:610] Iteration 94160, lr = 5.63972e-09
I0317 08:16:26.892268 29479 solver.cpp:613] Iteration 94160, avg_grad_norm = 523189
I0317 08:18:31.400612 29479 solver.cpp:214] Iteration 94180, loss = 5533.86
I0317 08:18:31.400854 29479 solver.cpp:229]     Train net output #0: loss = 3392.76 (* 1 = 3392.76 loss)
I0317 08:18:31.505671 29479 solver.cpp:610] Iteration 94180, lr = 5.63877e-09
I0317 08:18:31.505684 29479 solver.cpp:613] Iteration 94180, avg_grad_norm = 507167
I0317 08:19:56.935279 29479 solver.cpp:214] Iteration 94200, loss = 5748.11
I0317 08:19:56.935413 29479 solver.cpp:229]     Train net output #0: loss = 6500.5 (* 1 = 6500.5 loss)
I0317 08:19:57.109699 29479 solver.cpp:610] Iteration 94200, lr = 5.63781e-09
I0317 08:19:57.109712 29479 solver.cpp:613] Iteration 94200, avg_grad_norm = 519306
I0317 08:22:25.596554 29479 solver.cpp:214] Iteration 94220, loss = 5650.82
I0317 08:22:25.596679 29479 solver.cpp:229]     Train net output #0: loss = 6439.25 (* 1 = 6439.25 loss)
I0317 08:22:25.767838 29479 solver.cpp:610] Iteration 94220, lr = 5.63685e-09
I0317 08:22:25.767851 29479 solver.cpp:613] Iteration 94220, avg_grad_norm = 531144
I0317 08:25:06.177150 29479 solver.cpp:214] Iteration 94240, loss = 5546.03
I0317 08:25:06.177261 29479 solver.cpp:229]     Train net output #0: loss = 4897.39 (* 1 = 4897.39 loss)
I0317 08:25:06.348330 29479 solver.cpp:610] Iteration 94240, lr = 5.63589e-09
I0317 08:25:06.348343 29479 solver.cpp:613] Iteration 94240, avg_grad_norm = 519776
I0317 08:27:34.714094 29479 solver.cpp:214] Iteration 94260, loss = 5422.84
I0317 08:27:34.714210 29479 solver.cpp:229]     Train net output #0: loss = 9173.39 (* 1 = 9173.39 loss)
I0317 08:27:34.885361 29479 solver.cpp:610] Iteration 94260, lr = 5.63493e-09
I0317 08:27:34.885375 29479 solver.cpp:613] Iteration 94260, avg_grad_norm = 491108
I0317 08:30:02.356194 29479 solver.cpp:214] Iteration 94280, loss = 5981.06
I0317 08:30:02.356333 29479 solver.cpp:229]     Train net output #0: loss = 4708.38 (* 1 = 4708.38 loss)
I0317 08:30:03.429636 29479 solver.cpp:610] Iteration 94280, lr = 5.63397e-09
I0317 08:30:03.429649 29479 solver.cpp:613] Iteration 94280, avg_grad_norm = 526937
I0317 08:32:30.948117 29479 solver.cpp:214] Iteration 94300, loss = 5623.19
I0317 08:32:30.948215 29479 solver.cpp:229]     Train net output #0: loss = 3782.67 (* 1 = 3782.67 loss)
I0317 08:32:31.122624 29479 solver.cpp:610] Iteration 94300, lr = 5.63301e-09
I0317 08:32:31.122638 29479 solver.cpp:613] Iteration 94300, avg_grad_norm = 461979
I0317 08:34:58.497696 29479 solver.cpp:214] Iteration 94320, loss = 5402.21
I0317 08:34:58.497822 29479 solver.cpp:229]     Train net output #0: loss = 5568.06 (* 1 = 5568.06 loss)
I0317 08:34:58.682682 29479 solver.cpp:610] Iteration 94320, lr = 5.63205e-09
I0317 08:34:58.682695 29479 solver.cpp:613] Iteration 94320, avg_grad_norm = 518572
I0317 08:37:27.187119 29479 solver.cpp:214] Iteration 94340, loss = 5648.2
I0317 08:37:27.187238 29479 solver.cpp:229]     Train net output #0: loss = 5430.76 (* 1 = 5430.76 loss)
I0317 08:37:28.286274 29479 solver.cpp:610] Iteration 94340, lr = 5.63109e-09
I0317 08:37:28.286288 29479 solver.cpp:613] Iteration 94340, avg_grad_norm = 516868
I0317 08:39:48.376267 29479 solver.cpp:214] Iteration 94360, loss = 5360.67
I0317 08:39:48.376399 29479 solver.cpp:229]     Train net output #0: loss = 2830.54 (* 1 = 2830.54 loss)
I0317 08:39:49.421301 29479 solver.cpp:610] Iteration 94360, lr = 5.63013e-09
I0317 08:39:49.421319 29479 solver.cpp:613] Iteration 94360, avg_grad_norm = 522160
I0317 08:42:17.034648 29479 solver.cpp:214] Iteration 94380, loss = 5763.35
I0317 08:42:17.034759 29479 solver.cpp:229]     Train net output #0: loss = 4254.84 (* 1 = 4254.84 loss)
I0317 08:42:18.108675 29479 solver.cpp:610] Iteration 94380, lr = 5.62917e-09
I0317 08:42:18.108688 29479 solver.cpp:613] Iteration 94380, avg_grad_norm = 483023
I0317 08:44:45.659013 29479 solver.cpp:214] Iteration 94400, loss = 5511.67
I0317 08:44:45.659227 29479 solver.cpp:229]     Train net output #0: loss = 4071.96 (* 1 = 4071.96 loss)
I0317 08:44:46.730887 29479 solver.cpp:610] Iteration 94400, lr = 5.62821e-09
I0317 08:44:46.730901 29479 solver.cpp:613] Iteration 94400, avg_grad_norm = 482249
I0317 08:47:14.217209 29479 solver.cpp:214] Iteration 94420, loss = 5320.43
I0317 08:47:14.217391 29479 solver.cpp:229]     Train net output #0: loss = 3761.53 (* 1 = 3761.53 loss)
I0317 08:47:14.387401 29479 solver.cpp:610] Iteration 94420, lr = 5.62725e-09
I0317 08:47:14.387414 29479 solver.cpp:613] Iteration 94420, avg_grad_norm = 482011
I0317 08:49:42.845744 29479 solver.cpp:214] Iteration 94440, loss = 5453.73
I0317 08:49:42.845881 29479 solver.cpp:229]     Train net output #0: loss = 4871.16 (* 1 = 4871.16 loss)
I0317 08:49:43.933722 29479 solver.cpp:610] Iteration 94440, lr = 5.62629e-09
I0317 08:49:43.933735 29479 solver.cpp:613] Iteration 94440, avg_grad_norm = 503860
I0317 08:52:11.454639 29479 solver.cpp:214] Iteration 94460, loss = 5467.46
I0317 08:52:11.454759 29479 solver.cpp:229]     Train net output #0: loss = 3670.69 (* 1 = 3670.69 loss)
I0317 08:52:12.530534 29479 solver.cpp:610] Iteration 94460, lr = 5.62533e-09
I0317 08:52:12.530547 29479 solver.cpp:613] Iteration 94460, avg_grad_norm = 470405
I0317 08:54:41.011840 29479 solver.cpp:214] Iteration 94480, loss = 5395.21
I0317 08:54:41.011979 29479 solver.cpp:229]     Train net output #0: loss = 10688.1 (* 1 = 10688.1 loss)
I0317 08:54:42.086570 29479 solver.cpp:610] Iteration 94480, lr = 5.62438e-09
I0317 08:54:42.086585 29479 solver.cpp:613] Iteration 94480, avg_grad_norm = 490397
I0317 08:57:07.651999 29479 solver.cpp:214] Iteration 94500, loss = 5569.68
I0317 08:57:07.652148 29479 solver.cpp:229]     Train net output #0: loss = 5020.07 (* 1 = 5020.07 loss)
I0317 08:57:08.734161 29479 solver.cpp:610] Iteration 94500, lr = 5.62342e-09
I0317 08:57:08.734179 29479 solver.cpp:613] Iteration 94500, avg_grad_norm = 514626
I0317 08:59:18.237277 29479 solver.cpp:214] Iteration 94520, loss = 5438.92
I0317 08:59:18.237419 29479 solver.cpp:229]     Train net output #0: loss = 5810.25 (* 1 = 5810.25 loss)
I0317 08:59:18.341531 29479 solver.cpp:610] Iteration 94520, lr = 5.62246e-09
I0317 08:59:18.341545 29479 solver.cpp:613] Iteration 94520, avg_grad_norm = 514084
I0317 09:00:57.790921 29479 solver.cpp:214] Iteration 94540, loss = 5539.18
I0317 09:00:57.791120 29479 solver.cpp:229]     Train net output #0: loss = 9021.68 (* 1 = 9021.68 loss)
I0317 09:00:57.952173 29479 solver.cpp:610] Iteration 94540, lr = 5.6215e-09
I0317 09:00:57.952188 29479 solver.cpp:613] Iteration 94540, avg_grad_norm = 525263
I0317 09:03:26.377404 29479 solver.cpp:214] Iteration 94560, loss = 5674.54
I0317 09:03:26.377595 29479 solver.cpp:229]     Train net output #0: loss = 6979.91 (* 1 = 6979.91 loss)
I0317 09:03:27.422863 29479 solver.cpp:610] Iteration 94560, lr = 5.62054e-09
I0317 09:03:27.422895 29479 solver.cpp:613] Iteration 94560, avg_grad_norm = 504048
I0317 09:05:55.030769 29479 solver.cpp:214] Iteration 94580, loss = 5563.25
I0317 09:05:55.030978 29479 solver.cpp:229]     Train net output #0: loss = 4323.56 (* 1 = 4323.56 loss)
I0317 09:05:56.118438 29479 solver.cpp:610] Iteration 94580, lr = 5.61958e-09
I0317 09:05:56.118453 29479 solver.cpp:613] Iteration 94580, avg_grad_norm = 530069
I0317 09:08:23.645583 29479 solver.cpp:214] Iteration 94600, loss = 5623.35
I0317 09:08:23.645715 29479 solver.cpp:229]     Train net output #0: loss = 5040.9 (* 1 = 5040.9 loss)
I0317 09:08:24.722028 29479 solver.cpp:610] Iteration 94600, lr = 5.61862e-09
I0317 09:08:24.722041 29479 solver.cpp:613] Iteration 94600, avg_grad_norm = 536853
I0317 09:11:04.160707 29479 solver.cpp:214] Iteration 94620, loss = 5536.42
I0317 09:11:04.160828 29479 solver.cpp:229]     Train net output #0: loss = 3065.49 (* 1 = 3065.49 loss)
I0317 09:11:04.330075 29479 solver.cpp:610] Iteration 94620, lr = 5.61766e-09
I0317 09:11:04.330088 29479 solver.cpp:613] Iteration 94620, avg_grad_norm = 519579
I0317 09:13:32.887326 29479 solver.cpp:214] Iteration 94640, loss = 5803.34
I0317 09:13:32.887537 29479 solver.cpp:229]     Train net output #0: loss = 5298.91 (* 1 = 5298.91 loss)
I0317 09:13:33.962589 29479 solver.cpp:610] Iteration 94640, lr = 5.6167e-09
I0317 09:13:33.962604 29479 solver.cpp:613] Iteration 94640, avg_grad_norm = 511779
I0317 09:16:01.318081 29479 solver.cpp:214] Iteration 94660, loss = 5451.13
I0317 09:16:01.318259 29479 solver.cpp:229]     Train net output #0: loss = 4769.84 (* 1 = 4769.84 loss)
I0317 09:16:01.540887 29479 solver.cpp:610] Iteration 94660, lr = 5.61574e-09
I0317 09:16:01.540901 29479 solver.cpp:613] Iteration 94660, avg_grad_norm = 523413
I0317 09:18:30.040817 29479 solver.cpp:214] Iteration 94680, loss = 5580.97
I0317 09:18:30.041013 29479 solver.cpp:229]     Train net output #0: loss = 4039.09 (* 1 = 4039.09 loss)
I0317 09:18:31.082237 29479 solver.cpp:610] Iteration 94680, lr = 5.61478e-09
I0317 09:18:31.082249 29479 solver.cpp:613] Iteration 94680, avg_grad_norm = 563412
I0317 09:19:50.480803 29479 solver.cpp:214] Iteration 94700, loss = 5833.91
I0317 09:19:50.480907 29479 solver.cpp:229]     Train net output #0: loss = 5338.12 (* 1 = 5338.12 loss)
I0317 09:19:50.655529 29479 solver.cpp:610] Iteration 94700, lr = 5.61382e-09
I0317 09:19:50.655542 29479 solver.cpp:613] Iteration 94700, avg_grad_norm = 597720
I0317 09:22:19.156162 29479 solver.cpp:214] Iteration 94720, loss = 5694.28
I0317 09:22:19.156342 29479 solver.cpp:229]     Train net output #0: loss = 4708.61 (* 1 = 4708.61 loss)
I0317 09:22:20.238116 29479 solver.cpp:610] Iteration 94720, lr = 5.61286e-09
I0317 09:22:20.238129 29479 solver.cpp:613] Iteration 94720, avg_grad_norm = 522084
I0317 09:25:00.813060 29479 solver.cpp:214] Iteration 94740, loss = 5542.88
I0317 09:25:00.813272 29479 solver.cpp:229]     Train net output #0: loss = 8935.46 (* 1 = 8935.46 loss)
I0317 09:25:01.886557 29479 solver.cpp:610] Iteration 94740, lr = 5.6119e-09
I0317 09:25:01.886572 29479 solver.cpp:613] Iteration 94740, avg_grad_norm = 530325
I0317 09:27:29.424885 29479 solver.cpp:214] Iteration 94760, loss = 5797.92
I0317 09:27:29.425015 29479 solver.cpp:229]     Train net output #0: loss = 4545.43 (* 1 = 4545.43 loss)
I0317 09:27:30.466436 29479 solver.cpp:610] Iteration 94760, lr = 5.61094e-09
I0317 09:27:30.466467 29479 solver.cpp:613] Iteration 94760, avg_grad_norm = 515666
I0317 09:29:58.067847 29479 solver.cpp:214] Iteration 94780, loss = 5529.88
I0317 09:29:58.067960 29479 solver.cpp:229]     Train net output #0: loss = 3914.78 (* 1 = 3914.78 loss)
I0317 09:29:59.108743 29479 solver.cpp:610] Iteration 94780, lr = 5.60998e-09
I0317 09:29:59.108759 29479 solver.cpp:613] Iteration 94780, avg_grad_norm = 511473
I0317 09:32:27.675947 29479 solver.cpp:214] Iteration 94800, loss = 5592.83
I0317 09:32:27.676059 29479 solver.cpp:229]     Train net output #0: loss = 11933 (* 1 = 11933 loss)
I0317 09:32:27.844669 29479 solver.cpp:610] Iteration 94800, lr = 5.60902e-09
I0317 09:32:27.844682 29479 solver.cpp:613] Iteration 94800, avg_grad_norm = 579004
I0317 09:34:56.307646 29479 solver.cpp:214] Iteration 94820, loss = 5638.02
I0317 09:34:56.307770 29479 solver.cpp:229]     Train net output #0: loss = 6920.1 (* 1 = 6920.1 loss)
I0317 09:34:57.347152 29479 solver.cpp:610] Iteration 94820, lr = 5.60806e-09
I0317 09:34:57.347165 29479 solver.cpp:613] Iteration 94820, avg_grad_norm = 504014
I0317 09:37:24.936050 29479 solver.cpp:214] Iteration 94840, loss = 5703.3
I0317 09:37:24.936250 29479 solver.cpp:229]     Train net output #0: loss = 4554.76 (* 1 = 4554.76 loss)
I0317 09:37:26.017536 29479 solver.cpp:610] Iteration 94840, lr = 5.6071e-09
I0317 09:37:26.017550 29479 solver.cpp:613] Iteration 94840, avg_grad_norm = 539248
I0317 09:39:50.557705 29479 solver.cpp:214] Iteration 94860, loss = 5699.37
I0317 09:39:50.557865 29479 solver.cpp:229]     Train net output #0: loss = 11431 (* 1 = 11431 loss)
I0317 09:39:50.662160 29479 solver.cpp:610] Iteration 94860, lr = 5.60614e-09
I0317 09:39:50.662197 29479 solver.cpp:613] Iteration 94860, avg_grad_norm = 550240
I0317 09:42:35.827332 29479 solver.cpp:214] Iteration 94880, loss = 5381.75
I0317 09:42:35.827524 29479 solver.cpp:229]     Train net output #0: loss = 5322.32 (* 1 = 5322.32 loss)
I0317 09:42:36.002048 29479 solver.cpp:610] Iteration 94880, lr = 5.60518e-09
I0317 09:42:36.002061 29479 solver.cpp:613] Iteration 94880, avg_grad_norm = 515513
I0317 09:45:03.475381 29479 solver.cpp:214] Iteration 94900, loss = 5200.08
I0317 09:45:03.475554 29479 solver.cpp:229]     Train net output #0: loss = 9473.43 (* 1 = 9473.43 loss)
I0317 09:45:04.524798 29479 solver.cpp:610] Iteration 94900, lr = 5.60422e-09
I0317 09:45:04.524812 29479 solver.cpp:613] Iteration 94900, avg_grad_norm = 502914
I0317 09:47:32.073580 29479 solver.cpp:214] Iteration 94920, loss = 5433.02
I0317 09:47:32.073707 29479 solver.cpp:229]     Train net output #0: loss = 7048.02 (* 1 = 7048.02 loss)
I0317 09:47:33.119711 29479 solver.cpp:610] Iteration 94920, lr = 5.60326e-09
I0317 09:47:33.119724 29479 solver.cpp:613] Iteration 94920, avg_grad_norm = 519751
I0317 09:50:00.685677 29479 solver.cpp:214] Iteration 94940, loss = 5738.42
I0317 09:50:00.685866 29479 solver.cpp:229]     Train net output #0: loss = 2662.54 (* 1 = 2662.54 loss)
I0317 09:50:01.766578 29479 solver.cpp:610] Iteration 94940, lr = 5.6023e-09
I0317 09:50:01.766595 29479 solver.cpp:613] Iteration 94940, avg_grad_norm = 554525
I0317 09:52:30.261548 29479 solver.cpp:214] Iteration 94960, loss = 5587.68
I0317 09:52:30.261700 29479 solver.cpp:229]     Train net output #0: loss = 9236.6 (* 1 = 9236.6 loss)
I0317 09:52:31.341778 29479 solver.cpp:610] Iteration 94960, lr = 5.60134e-09
I0317 09:52:31.341792 29479 solver.cpp:613] Iteration 94960, avg_grad_norm = 508442
I0317 09:54:58.872613 29479 solver.cpp:214] Iteration 94980, loss = 5560.42
I0317 09:54:58.872745 29479 solver.cpp:229]     Train net output #0: loss = 4960.52 (* 1 = 4960.52 loss)
I0317 09:54:59.949941 29479 solver.cpp:610] Iteration 94980, lr = 5.60038e-09
I0317 09:54:59.949956 29479 solver.cpp:613] Iteration 94980, avg_grad_norm = 448694
I0317 09:57:43.422551 29479 solver.cpp:214] Iteration 95000, loss = 5772.95
I0317 09:57:43.422688 29479 solver.cpp:229]     Train net output #0: loss = 10426.4 (* 1 = 10426.4 loss)
I0317 09:57:43.605234 29479 solver.cpp:610] Iteration 95000, lr = 5.59942e-09
I0317 09:57:43.605247 29479 solver.cpp:613] Iteration 95000, avg_grad_norm = 500340
I0317 10:00:12.079659 29479 solver.cpp:214] Iteration 95020, loss = 5684.18
I0317 10:00:12.079776 29479 solver.cpp:229]     Train net output #0: loss = 8846.65 (* 1 = 8846.65 loss)
I0317 10:00:12.248695 29479 solver.cpp:610] Iteration 95020, lr = 5.59846e-09
I0317 10:00:12.248708 29479 solver.cpp:613] Iteration 95020, avg_grad_norm = 532907
I0317 10:01:01.614755 29479 solver.cpp:214] Iteration 95040, loss = 5531.06
I0317 10:01:01.614881 29479 solver.cpp:229]     Train net output #0: loss = 1845.52 (* 1 = 1845.52 loss)
I0317 10:01:01.795840 29479 solver.cpp:610] Iteration 95040, lr = 5.5975e-09
I0317 10:01:01.795852 29479 solver.cpp:613] Iteration 95040, avg_grad_norm = 563536
I0317 10:03:31.255333 29479 solver.cpp:214] Iteration 95060, loss = 5514.17
I0317 10:03:31.255458 29479 solver.cpp:229]     Train net output #0: loss = 3136.04 (* 1 = 3136.04 loss)
I0317 10:03:32.298708 29479 solver.cpp:610] Iteration 95060, lr = 5.59654e-09
I0317 10:03:32.298722 29479 solver.cpp:613] Iteration 95060, avg_grad_norm = 504380
I0317 10:06:00.859294 29479 solver.cpp:214] Iteration 95080, loss = 5571.2
I0317 10:06:00.859412 29479 solver.cpp:229]     Train net output #0: loss = 4123.06 (* 1 = 4123.06 loss)
I0317 10:06:01.900980 29479 solver.cpp:610] Iteration 95080, lr = 5.59558e-09
I0317 10:06:01.900995 29479 solver.cpp:613] Iteration 95080, avg_grad_norm = 551297
I0317 10:08:29.562399 29479 solver.cpp:214] Iteration 95100, loss = 5588.32
I0317 10:08:29.562533 29479 solver.cpp:229]     Train net output #0: loss = 4010.01 (* 1 = 4010.01 loss)
I0317 10:08:30.641654 29479 solver.cpp:610] Iteration 95100, lr = 5.59462e-09
I0317 10:08:30.641669 29479 solver.cpp:613] Iteration 95100, avg_grad_norm = 519915
I0317 10:11:10.187271 29479 solver.cpp:214] Iteration 95120, loss = 5753.06
I0317 10:11:10.187383 29479 solver.cpp:229]     Train net output #0: loss = 4891.42 (* 1 = 4891.42 loss)
I0317 10:11:11.276855 29479 solver.cpp:610] Iteration 95120, lr = 5.59366e-09
I0317 10:11:11.276870 29479 solver.cpp:613] Iteration 95120, avg_grad_norm = 475882
I0317 10:13:38.849776 29479 solver.cpp:214] Iteration 95140, loss = 5404.63
I0317 10:13:38.850020 29479 solver.cpp:229]     Train net output #0: loss = 3699.64 (* 1 = 3699.64 loss)
I0317 10:13:39.925665 29479 solver.cpp:610] Iteration 95140, lr = 5.5927e-09
I0317 10:13:39.925680 29479 solver.cpp:613] Iteration 95140, avg_grad_norm = 477472
I0317 10:16:08.408612 29479 solver.cpp:214] Iteration 95160, loss = 5506.55
I0317 10:16:08.408807 29479 solver.cpp:229]     Train net output #0: loss = 4502.23 (* 1 = 4502.23 loss)
I0317 10:16:08.589844 29479 solver.cpp:610] Iteration 95160, lr = 5.59174e-09
I0317 10:16:08.589857 29479 solver.cpp:613] Iteration 95160, avg_grad_norm = 483168
I0317 10:18:37.008982 29479 solver.cpp:214] Iteration 95180, loss = 5444.13
I0317 10:18:37.009115 29479 solver.cpp:229]     Train net output #0: loss = 7534.44 (* 1 = 7534.44 loss)
I0317 10:18:37.231457 29479 solver.cpp:610] Iteration 95180, lr = 5.59078e-09
I0317 10:18:37.231472 29479 solver.cpp:613] Iteration 95180, avg_grad_norm = 488462
I0317 10:20:58.698451 29479 solver.cpp:214] Iteration 95200, loss = 5984.81
I0317 10:20:58.698576 29479 solver.cpp:229]     Train net output #0: loss = 3665.38 (* 1 = 3665.38 loss)
I0317 10:20:58.802485 29479 solver.cpp:610] Iteration 95200, lr = 5.58982e-09
I0317 10:20:58.802498 29479 solver.cpp:613] Iteration 95200, avg_grad_norm = 549018
I0317 10:22:25.188706 29479 solver.cpp:214] Iteration 95220, loss = 5302.65
I0317 10:22:25.188837 29479 solver.cpp:229]     Train net output #0: loss = 5161.13 (* 1 = 5161.13 loss)
I0317 10:22:25.369112 29479 solver.cpp:610] Iteration 95220, lr = 5.58886e-09
I0317 10:22:25.369127 29479 solver.cpp:613] Iteration 95220, avg_grad_norm = 560921
I0317 10:24:53.859820 29479 solver.cpp:214] Iteration 95240, loss = 5820.82
I0317 10:24:53.859933 29479 solver.cpp:229]     Train net output #0: loss = 4694.79 (* 1 = 4694.79 loss)
I0317 10:24:54.018661 29479 solver.cpp:610] Iteration 95240, lr = 5.5879e-09
I0317 10:24:54.018674 29479 solver.cpp:613] Iteration 95240, avg_grad_norm = 520434
I0317 10:27:34.494925 29479 solver.cpp:214] Iteration 95260, loss = 5556.78
I0317 10:27:34.495117 29479 solver.cpp:229]     Train net output #0: loss = 6016.21 (* 1 = 6016.21 loss)
I0317 10:27:35.544874 29479 solver.cpp:610] Iteration 95260, lr = 5.58694e-09
I0317 10:27:35.544888 29479 solver.cpp:613] Iteration 95260, avg_grad_norm = 514948
I0317 10:30:03.179792 29479 solver.cpp:214] Iteration 95280, loss = 5365.74
I0317 10:30:03.179976 29479 solver.cpp:229]     Train net output #0: loss = 4954.97 (* 1 = 4954.97 loss)
I0317 10:30:04.263813 29479 solver.cpp:610] Iteration 95280, lr = 5.58598e-09
I0317 10:30:04.263828 29479 solver.cpp:613] Iteration 95280, avg_grad_norm = 511427
I0317 10:32:31.745489 29479 solver.cpp:214] Iteration 95300, loss = 5663.72
I0317 10:32:31.745718 29479 solver.cpp:229]     Train net output #0: loss = 3681.2 (* 1 = 3681.2 loss)
I0317 10:32:31.922698 29479 solver.cpp:610] Iteration 95300, lr = 5.58502e-09
I0317 10:32:31.922711 29479 solver.cpp:613] Iteration 95300, avg_grad_norm = 488358
I0317 10:35:00.280225 29479 solver.cpp:214] Iteration 95320, loss = 5743.65
I0317 10:35:00.280362 29479 solver.cpp:229]     Train net output #0: loss = 4296.9 (* 1 = 4296.9 loss)
I0317 10:35:00.503365 29479 solver.cpp:610] Iteration 95320, lr = 5.58406e-09
I0317 10:35:00.503378 29479 solver.cpp:613] Iteration 95320, avg_grad_norm = 483277
I0317 10:37:28.020404 29479 solver.cpp:214] Iteration 95340, loss = 5537.48
I0317 10:37:28.020536 29479 solver.cpp:229]     Train net output #0: loss = 4455.21 (* 1 = 4455.21 loss)
I0317 10:37:29.064182 29479 solver.cpp:610] Iteration 95340, lr = 5.5831e-09
I0317 10:37:29.064204 29479 solver.cpp:613] Iteration 95340, avg_grad_norm = 520445
I0317 10:39:57.641919 29479 solver.cpp:214] Iteration 95360, loss = 5668.04
I0317 10:39:57.642041 29479 solver.cpp:229]     Train net output #0: loss = 4850.4 (* 1 = 4850.4 loss)
I0317 10:39:58.689000 29479 solver.cpp:610] Iteration 95360, lr = 5.58214e-09
I0317 10:39:58.689015 29479 solver.cpp:613] Iteration 95360, avg_grad_norm = 539406
I0317 10:42:45.956393 29479 solver.cpp:214] Iteration 95380, loss = 5615.01
I0317 10:42:45.956568 29479 solver.cpp:229]     Train net output #0: loss = 4719.32 (* 1 = 4719.32 loss)
I0317 10:42:46.179402 29479 solver.cpp:610] Iteration 95380, lr = 5.58118e-09
I0317 10:42:46.179415 29479 solver.cpp:613] Iteration 95380, avg_grad_norm = 587854
I0317 10:45:13.690632 29479 solver.cpp:214] Iteration 95400, loss = 5487.83
I0317 10:45:13.690826 29479 solver.cpp:229]     Train net output #0: loss = 3924.14 (* 1 = 3924.14 loss)
I0317 10:45:14.778522 29479 solver.cpp:610] Iteration 95400, lr = 5.58022e-09
I0317 10:45:14.778537 29479 solver.cpp:613] Iteration 95400, avg_grad_norm = 515873
I0317 10:47:43.297307 29479 solver.cpp:214] Iteration 95420, loss = 5724.53
I0317 10:47:43.297508 29479 solver.cpp:229]     Train net output #0: loss = 5439.5 (* 1 = 5439.5 loss)
I0317 10:47:44.335077 29479 solver.cpp:610] Iteration 95420, lr = 5.57926e-09
I0317 10:47:44.335090 29479 solver.cpp:613] Iteration 95420, avg_grad_norm = 494809
I0317 10:50:11.840914 29479 solver.cpp:214] Iteration 95440, loss = 5780.39
I0317 10:50:11.841140 29479 solver.cpp:229]     Train net output #0: loss = 4458.38 (* 1 = 4458.38 loss)
I0317 10:50:12.008411 29479 solver.cpp:610] Iteration 95440, lr = 5.5783e-09
I0317 10:50:12.008425 29479 solver.cpp:613] Iteration 95440, avg_grad_norm = 586104
I0317 10:52:40.419057 29479 solver.cpp:214] Iteration 95460, loss = 5526.69
I0317 10:52:40.419256 29479 solver.cpp:229]     Train net output #0: loss = 10388.3 (* 1 = 10388.3 loss)
I0317 10:52:40.593952 29479 solver.cpp:610] Iteration 95460, lr = 5.57734e-09
I0317 10:52:40.593966 29479 solver.cpp:613] Iteration 95460, avg_grad_norm = 525920
I0317 10:55:09.047389 29479 solver.cpp:214] Iteration 95480, loss = 5460.27
I0317 10:55:09.047516 29479 solver.cpp:229]     Train net output #0: loss = 4859.64 (* 1 = 4859.64 loss)
I0317 10:55:10.097677 29479 solver.cpp:610] Iteration 95480, lr = 5.57638e-09
I0317 10:55:10.097692 29479 solver.cpp:613] Iteration 95480, avg_grad_norm = 464645
I0317 10:57:49.596349 29479 solver.cpp:214] Iteration 95500, loss = 5804.81
I0317 10:57:49.596465 29479 solver.cpp:229]     Train net output #0: loss = 3255.45 (* 1 = 3255.45 loss)
I0317 10:57:49.772261 29479 solver.cpp:610] Iteration 95500, lr = 5.57542e-09
I0317 10:57:49.772275 29479 solver.cpp:613] Iteration 95500, avg_grad_norm = 483074
I0317 11:00:18.248610 29479 solver.cpp:214] Iteration 95520, loss = 5276.07
I0317 11:00:18.248801 29479 solver.cpp:229]     Train net output #0: loss = 3060.5 (* 1 = 3060.5 loss)
I0317 11:00:19.329659 29479 solver.cpp:610] Iteration 95520, lr = 5.57446e-09
I0317 11:00:19.329674 29479 solver.cpp:613] Iteration 95520, avg_grad_norm = 523262
I0317 11:01:54.784027 29479 solver.cpp:214] Iteration 95540, loss = 5838.23
I0317 11:01:54.784173 29479 solver.cpp:229]     Train net output #0: loss = 4671.38 (* 1 = 4671.38 loss)
I0317 11:01:54.888572 29479 solver.cpp:610] Iteration 95540, lr = 5.5735e-09
I0317 11:01:54.888586 29479 solver.cpp:613] Iteration 95540, avg_grad_norm = 472876
I0317 11:03:56.369086 29479 solver.cpp:214] Iteration 95560, loss = 5447.72
I0317 11:03:56.369210 29479 solver.cpp:229]     Train net output #0: loss = 3161.4 (* 1 = 3161.4 loss)
I0317 11:03:56.545142 29479 solver.cpp:610] Iteration 95560, lr = 5.57254e-09
I0317 11:03:56.545156 29479 solver.cpp:613] Iteration 95560, avg_grad_norm = 537688
I0317 11:06:24.054538 29479 solver.cpp:214] Iteration 95580, loss = 5555.7
I0317 11:06:24.054731 29479 solver.cpp:229]     Train net output #0: loss = 5958.44 (* 1 = 5958.44 loss)
I0317 11:06:25.138723 29479 solver.cpp:610] Iteration 95580, lr = 5.57158e-09
I0317 11:06:25.138737 29479 solver.cpp:613] Iteration 95580, avg_grad_norm = 499666
I0317 11:08:53.526793 29479 solver.cpp:214] Iteration 95600, loss = 5687.68
I0317 11:08:53.526918 29479 solver.cpp:229]     Train net output #0: loss = 5842.65 (* 1 = 5842.65 loss)
I0317 11:08:53.750217 29479 solver.cpp:610] Iteration 95600, lr = 5.57062e-09
I0317 11:08:53.750231 29479 solver.cpp:613] Iteration 95600, avg_grad_norm = 505900
I0317 11:11:22.172391 29479 solver.cpp:214] Iteration 95620, loss = 5368.45
I0317 11:11:22.172660 29479 solver.cpp:229]     Train net output #0: loss = 5171.7 (* 1 = 5171.7 loss)
I0317 11:11:22.341817 29479 solver.cpp:610] Iteration 95620, lr = 5.56966e-09
I0317 11:11:22.341830 29479 solver.cpp:613] Iteration 95620, avg_grad_norm = 493843
I0317 11:14:02.850523 29479 solver.cpp:214] Iteration 95640, loss = 5493.66
I0317 11:14:02.850671 29479 solver.cpp:229]     Train net output #0: loss = 3134 (* 1 = 3134 loss)
I0317 11:14:03.890441 29479 solver.cpp:610] Iteration 95640, lr = 5.5687e-09
I0317 11:14:03.890458 29479 solver.cpp:613] Iteration 95640, avg_grad_norm = 495780
I0317 11:16:32.473816 29479 solver.cpp:214] Iteration 95660, loss = 5726.59
I0317 11:16:32.473999 29479 solver.cpp:229]     Train net output #0: loss = 3052.44 (* 1 = 3052.44 loss)
I0317 11:16:33.512590 29479 solver.cpp:610] Iteration 95660, lr = 5.56774e-09
I0317 11:16:33.512605 29479 solver.cpp:613] Iteration 95660, avg_grad_norm = 519925
I0317 11:19:01.080600 29479 solver.cpp:214] Iteration 95680, loss = 5774.78
I0317 11:19:01.080761 29479 solver.cpp:229]     Train net output #0: loss = 3327.16 (* 1 = 3327.16 loss)
I0317 11:19:02.136299 29479 solver.cpp:610] Iteration 95680, lr = 5.56678e-09
I0317 11:19:02.136314 29479 solver.cpp:613] Iteration 95680, avg_grad_norm = 492704
I0317 11:21:30.566006 29479 solver.cpp:214] Iteration 95700, loss = 5518.27
I0317 11:21:30.566134 29479 solver.cpp:229]     Train net output #0: loss = 6634.3 (* 1 = 6634.3 loss)
I0317 11:21:30.745666 29479 solver.cpp:610] Iteration 95700, lr = 5.56582e-09
I0317 11:21:30.745679 29479 solver.cpp:613] Iteration 95700, avg_grad_norm = 491816
I0317 11:22:44.251788 29479 solver.cpp:214] Iteration 95720, loss = 5794.33
I0317 11:22:44.251893 29479 solver.cpp:229]     Train net output #0: loss = 5077.09 (* 1 = 5077.09 loss)
I0317 11:22:45.333060 29479 solver.cpp:610] Iteration 95720, lr = 5.56486e-09
I0317 11:22:45.333076 29479 solver.cpp:613] Iteration 95720, avg_grad_norm = 484825
I0317 11:25:13.827432 29479 solver.cpp:214] Iteration 95740, loss = 5375.24
I0317 11:25:13.827563 29479 solver.cpp:229]     Train net output #0: loss = 8984.29 (* 1 = 8984.29 loss)
I0317 11:25:14.011729 29479 solver.cpp:610] Iteration 95740, lr = 5.5639e-09
I0317 11:25:14.011744 29479 solver.cpp:613] Iteration 95740, avg_grad_norm = 466047
I0317 11:27:56.484519 29479 solver.cpp:214] Iteration 95760, loss = 5749.6
I0317 11:27:56.484653 29479 solver.cpp:229]     Train net output #0: loss = 6142.99 (* 1 = 6142.99 loss)
I0317 11:27:57.528404 29479 solver.cpp:610] Iteration 95760, lr = 5.56294e-09
I0317 11:27:57.528419 29479 solver.cpp:613] Iteration 95760, avg_grad_norm = 505518
I0317 11:30:25.023587 29479 solver.cpp:214] Iteration 95780, loss = 5648.44
I0317 11:30:25.023741 29479 solver.cpp:229]     Train net output #0: loss = 5630.92 (* 1 = 5630.92 loss)
I0317 11:30:25.208441 29479 solver.cpp:610] Iteration 95780, lr = 5.56197e-09
I0317 11:30:25.208454 29479 solver.cpp:613] Iteration 95780, avg_grad_norm = 518004
I0317 11:32:54.619907 29479 solver.cpp:214] Iteration 95800, loss = 5858.82
I0317 11:32:54.620008 29479 solver.cpp:229]     Train net output #0: loss = 5789.42 (* 1 = 5789.42 loss)
I0317 11:32:54.803014 29479 solver.cpp:610] Iteration 95800, lr = 5.56101e-09
I0317 11:32:54.803027 29479 solver.cpp:613] Iteration 95800, avg_grad_norm = 499445
I0317 11:35:23.315174 29479 solver.cpp:214] Iteration 95820, loss = 5649.97
I0317 11:35:23.315299 29479 solver.cpp:229]     Train net output #0: loss = 4426.42 (* 1 = 4426.42 loss)
I0317 11:35:24.352970 29479 solver.cpp:610] Iteration 95820, lr = 5.56005e-09
I0317 11:35:24.352984 29479 solver.cpp:613] Iteration 95820, avg_grad_norm = 507184
I0317 11:37:51.949389 29479 solver.cpp:214] Iteration 95840, loss = 5798.53
I0317 11:37:51.949527 29479 solver.cpp:229]     Train net output #0: loss = 5226.16 (* 1 = 5226.16 loss)
I0317 11:37:53.030462 29479 solver.cpp:610] Iteration 95840, lr = 5.55909e-09
I0317 11:37:53.030478 29479 solver.cpp:613] Iteration 95840, avg_grad_norm = 509459
I0317 11:40:20.568625 29479 solver.cpp:214] Iteration 95860, loss = 5943.62
I0317 11:40:20.568850 29479 solver.cpp:229]     Train net output #0: loss = 7286.38 (* 1 = 7286.38 loss)
I0317 11:40:21.657284 29479 solver.cpp:610] Iteration 95860, lr = 5.55813e-09
I0317 11:40:21.657299 29479 solver.cpp:613] Iteration 95860, avg_grad_norm = 576153
I0317 11:43:00.359513 29479 solver.cpp:214] Iteration 95880, loss = 5525.62
I0317 11:43:00.359652 29479 solver.cpp:229]     Train net output #0: loss = 6483.35 (* 1 = 6483.35 loss)
I0317 11:43:01.410734 29479 solver.cpp:610] Iteration 95880, lr = 5.55717e-09
I0317 11:43:01.410753 29479 solver.cpp:613] Iteration 95880, avg_grad_norm = 506499
I0317 11:45:28.627351 29479 solver.cpp:214] Iteration 95900, loss = 5647.84
I0317 11:45:28.627498 29479 solver.cpp:229]     Train net output #0: loss = 4259.17 (* 1 = 4259.17 loss)
I0317 11:45:29.712688 29479 solver.cpp:610] Iteration 95900, lr = 5.55621e-09
I0317 11:45:29.712702 29479 solver.cpp:613] Iteration 95900, avg_grad_norm = 487028
I0317 11:47:58.173470 29479 solver.cpp:214] Iteration 95920, loss = 5506.06
I0317 11:47:58.173600 29479 solver.cpp:229]     Train net output #0: loss = 4730.89 (* 1 = 4730.89 loss)
I0317 11:47:59.252939 29479 solver.cpp:610] Iteration 95920, lr = 5.55525e-09
I0317 11:47:59.252955 29479 solver.cpp:613] Iteration 95920, avg_grad_norm = 467248
I0317 11:50:27.741266 29479 solver.cpp:214] Iteration 95940, loss = 5359.72
I0317 11:50:27.741403 29479 solver.cpp:229]     Train net output #0: loss = 8954.96 (* 1 = 8954.96 loss)
I0317 11:50:27.925228 29479 solver.cpp:610] Iteration 95940, lr = 5.55429e-09
I0317 11:50:27.925274 29479 solver.cpp:613] Iteration 95940, avg_grad_norm = 486157
I0317 11:52:55.501898 29479 solver.cpp:214] Iteration 95960, loss = 5528.69
I0317 11:52:55.502043 29479 solver.cpp:229]     Train net output #0: loss = 7164.58 (* 1 = 7164.58 loss)
I0317 11:52:56.570778 29479 solver.cpp:610] Iteration 95960, lr = 5.55333e-09
I0317 11:52:56.570792 29479 solver.cpp:613] Iteration 95960, avg_grad_norm = 513862
I0317 11:55:24.122294 29479 solver.cpp:214] Iteration 95980, loss = 5436.53
I0317 11:55:24.122392 29479 solver.cpp:229]     Train net output #0: loss = 7028.09 (* 1 = 7028.09 loss)
I0317 11:55:25.200899 29479 solver.cpp:610] Iteration 95980, lr = 5.55237e-09
I0317 11:55:25.200914 29479 solver.cpp:613] Iteration 95980, avg_grad_norm = 539771
I0317 11:57:53.723490 29479 solver.cpp:214] Iteration 96000, loss = 5271.77
I0317 11:57:53.723631 29479 solver.cpp:229]     Train net output #0: loss = 3709.99 (* 1 = 3709.99 loss)
I0317 11:57:54.801895 29479 solver.cpp:610] Iteration 96000, lr = 5.55141e-09
I0317 11:57:54.801910 29479 solver.cpp:613] Iteration 96000, avg_grad_norm = 477276
I0317 12:00:33.376054 29479 solver.cpp:214] Iteration 96020, loss = 5672.6
I0317 12:00:33.376158 29479 solver.cpp:229]     Train net output #0: loss = 8316.3 (* 1 = 8316.3 loss)
I0317 12:00:34.453929 29479 solver.cpp:610] Iteration 96020, lr = 5.55044e-09
I0317 12:00:34.453944 29479 solver.cpp:613] Iteration 96020, avg_grad_norm = 487436
I0317 12:02:56.971737 29479 solver.cpp:214] Iteration 96040, loss = 5488.1
I0317 12:02:56.971942 29479 solver.cpp:229]     Train net output #0: loss = 2946.52 (* 1 = 2946.52 loss)
I0317 12:02:57.076076 29479 solver.cpp:610] Iteration 96040, lr = 5.54948e-09
I0317 12:02:57.076091 29479 solver.cpp:613] Iteration 96040, avg_grad_norm = 540494
I0317 12:04:04.522742 29479 solver.cpp:214] Iteration 96060, loss = 5652.87
I0317 12:04:04.522888 29479 solver.cpp:229]     Train net output #0: loss = 3941.33 (* 1 = 3941.33 loss)
I0317 12:04:04.691059 29479 solver.cpp:610] Iteration 96060, lr = 5.54852e-09
I0317 12:04:04.691072 29479 solver.cpp:613] Iteration 96060, avg_grad_norm = 575054
I0317 12:06:33.102694 29479 solver.cpp:214] Iteration 96080, loss = 5692.82
I0317 12:06:33.102840 29479 solver.cpp:229]     Train net output #0: loss = 10280.2 (* 1 = 10280.2 loss)
I0317 12:06:33.325441 29479 solver.cpp:610] Iteration 96080, lr = 5.54756e-09
I0317 12:06:33.325455 29479 solver.cpp:613] Iteration 96080, avg_grad_norm = 473118
I0317 12:09:00.820868 29479 solver.cpp:214] Iteration 96100, loss = 5568.45
I0317 12:09:00.821056 29479 solver.cpp:229]     Train net output #0: loss = 3147.59 (* 1 = 3147.59 loss)
I0317 12:09:01.871637 29479 solver.cpp:610] Iteration 96100, lr = 5.5466e-09
I0317 12:09:01.871651 29479 solver.cpp:613] Iteration 96100, avg_grad_norm = 461599
I0317 12:11:29.365916 29479 solver.cpp:214] Iteration 96120, loss = 5814.84
I0317 12:11:29.366058 29479 solver.cpp:229]     Train net output #0: loss = 3886.24 (* 1 = 3886.24 loss)
I0317 12:11:29.546212 29479 solver.cpp:610] Iteration 96120, lr = 5.54564e-09
I0317 12:11:29.546226 29479 solver.cpp:613] Iteration 96120, avg_grad_norm = 502540
I0317 12:14:15.060706 29479 solver.cpp:214] Iteration 96140, loss = 5723.16
I0317 12:14:15.060847 29479 solver.cpp:229]     Train net output #0: loss = 5477.78 (* 1 = 5477.78 loss)
I0317 12:14:16.099500 29479 solver.cpp:610] Iteration 96140, lr = 5.54468e-09
I0317 12:14:16.099514 29479 solver.cpp:613] Iteration 96140, avg_grad_norm = 562821
I0317 12:16:43.724627 29479 solver.cpp:214] Iteration 96160, loss = 5435.14
I0317 12:16:43.724776 29479 solver.cpp:229]     Train net output #0: loss = 8190.19 (* 1 = 8190.19 loss)
I0317 12:16:44.819886 29479 solver.cpp:610] Iteration 96160, lr = 5.54372e-09
I0317 12:16:44.819900 29479 solver.cpp:613] Iteration 96160, avg_grad_norm = 495091
I0317 12:18:55.316251 29479 solver.cpp:214] Iteration 96180, loss = 5521.49
I0317 12:18:55.316448 29479 solver.cpp:229]     Train net output #0: loss = 4840.11 (* 1 = 4840.11 loss)
I0317 12:18:56.399561 29479 solver.cpp:610] Iteration 96180, lr = 5.54276e-09
I0317 12:18:56.399576 29479 solver.cpp:613] Iteration 96180, avg_grad_norm = 510001
I0317 12:21:23.925256 29479 solver.cpp:214] Iteration 96200, loss = 5625.15
I0317 12:21:23.925396 29479 solver.cpp:229]     Train net output #0: loss = 6513.49 (* 1 = 6513.49 loss)
I0317 12:21:25.010079 29479 solver.cpp:610] Iteration 96200, lr = 5.5418e-09
I0317 12:21:25.010094 29479 solver.cpp:613] Iteration 96200, avg_grad_norm = 555929
I0317 12:23:25.456419 29479 solver.cpp:214] Iteration 96220, loss = 5626.02
I0317 12:23:25.456564 29479 solver.cpp:229]     Train net output #0: loss = 7341.07 (* 1 = 7341.07 loss)
I0317 12:23:25.560652 29479 solver.cpp:610] Iteration 96220, lr = 5.54084e-09
I0317 12:23:25.560667 29479 solver.cpp:613] Iteration 96220, avg_grad_norm = 521789
I0317 12:25:12.999614 29479 solver.cpp:214] Iteration 96240, loss = 5723.81
I0317 12:25:12.999732 29479 solver.cpp:229]     Train net output #0: loss = 2458.23 (* 1 = 2458.23 loss)
I0317 12:25:13.169842 29479 solver.cpp:610] Iteration 96240, lr = 5.53988e-09
I0317 12:25:13.169857 29479 solver.cpp:613] Iteration 96240, avg_grad_norm = 509542
I0317 12:27:41.620208 29479 solver.cpp:214] Iteration 96260, loss = 5681.68
I0317 12:27:41.620323 29479 solver.cpp:229]     Train net output #0: loss = 6416.14 (* 1 = 6416.14 loss)
I0317 12:27:42.660773 29479 solver.cpp:610] Iteration 96260, lr = 5.53891e-09
I0317 12:27:42.660789 29479 solver.cpp:613] Iteration 96260, avg_grad_norm = 500341
I0317 12:30:21.303585 29479 solver.cpp:214] Iteration 96280, loss = 5718.13
I0317 12:30:21.303709 29479 solver.cpp:229]     Train net output #0: loss = 4844.21 (* 1 = 4844.21 loss)
I0317 12:30:22.376806 29479 solver.cpp:610] Iteration 96280, lr = 5.53795e-09
I0317 12:30:22.376822 29479 solver.cpp:613] Iteration 96280, avg_grad_norm = 539924
I0317 12:32:50.862018 29479 solver.cpp:214] Iteration 96300, loss = 5891.57
I0317 12:32:50.862139 29479 solver.cpp:229]     Train net output #0: loss = 7062.47 (* 1 = 7062.47 loss)
I0317 12:32:51.911058 29479 solver.cpp:610] Iteration 96300, lr = 5.53699e-09
I0317 12:32:51.911072 29479 solver.cpp:613] Iteration 96300, avg_grad_norm = 537323
I0317 12:35:20.477428 29479 solver.cpp:214] Iteration 96320, loss = 5745.46
I0317 12:35:20.477538 29479 solver.cpp:229]     Train net output #0: loss = 3061.61 (* 1 = 3061.61 loss)
I0317 12:35:20.652884 29479 solver.cpp:610] Iteration 96320, lr = 5.53603e-09
I0317 12:35:20.652896 29479 solver.cpp:613] Iteration 96320, avg_grad_norm = 534893
I0317 12:37:48.200996 29479 solver.cpp:214] Iteration 96340, loss = 5845.82
I0317 12:37:48.201184 29479 solver.cpp:229]     Train net output #0: loss = 7041.2 (* 1 = 7041.2 loss)
I0317 12:37:49.281740 29479 solver.cpp:610] Iteration 96340, lr = 5.53507e-09
I0317 12:37:49.281754 29479 solver.cpp:613] Iteration 96340, avg_grad_norm = 533903
I0317 12:40:16.828232 29479 solver.cpp:214] Iteration 96360, loss = 5477.31
I0317 12:40:16.828341 29479 solver.cpp:229]     Train net output #0: loss = 2745.9 (* 1 = 2745.9 loss)
I0317 12:40:17.912084 29479 solver.cpp:610] Iteration 96360, lr = 5.53411e-09
I0317 12:40:17.912099 29479 solver.cpp:613] Iteration 96360, avg_grad_norm = 479594
I0317 12:42:45.429894 29479 solver.cpp:214] Iteration 96380, loss = 5610.1
I0317 12:42:45.430019 29479 solver.cpp:229]     Train net output #0: loss = 4711.49 (* 1 = 4711.49 loss)
I0317 12:42:45.599390 29479 solver.cpp:610] Iteration 96380, lr = 5.53315e-09
I0317 12:42:45.599402 29479 solver.cpp:613] Iteration 96380, avg_grad_norm = 478384
I0317 12:45:38.056639 29479 solver.cpp:214] Iteration 96400, loss = 5409.3
I0317 12:45:38.056854 29479 solver.cpp:229]     Train net output #0: loss = 6290.13 (* 1 = 6290.13 loss)
I0317 12:45:38.279742 29479 solver.cpp:610] Iteration 96400, lr = 5.53219e-09
I0317 12:45:38.279757 29479 solver.cpp:613] Iteration 96400, avg_grad_norm = 488380
I0317 12:48:05.837761 29479 solver.cpp:214] Iteration 96420, loss = 5387.06
I0317 12:48:05.837954 29479 solver.cpp:229]     Train net output #0: loss = 4562.5 (* 1 = 4562.5 loss)
I0317 12:48:06.911761 29479 solver.cpp:610] Iteration 96420, lr = 5.53122e-09
I0317 12:48:06.911775 29479 solver.cpp:613] Iteration 96420, avg_grad_norm = 552631
I0317 12:50:34.415113 29479 solver.cpp:214] Iteration 96440, loss = 5755.89
I0317 12:50:34.415236 29479 solver.cpp:229]     Train net output #0: loss = 3052.68 (* 1 = 3052.68 loss)
I0317 12:50:35.464750 29479 solver.cpp:610] Iteration 96440, lr = 5.53026e-09
I0317 12:50:35.464763 29479 solver.cpp:613] Iteration 96440, avg_grad_norm = 583105
I0317 12:53:02.995703 29479 solver.cpp:214] Iteration 96460, loss = 5237.21
I0317 12:53:02.995896 29479 solver.cpp:229]     Train net output #0: loss = 4657.58 (* 1 = 4657.58 loss)
I0317 12:53:04.040169 29479 solver.cpp:610] Iteration 96460, lr = 5.5293e-09
I0317 12:53:04.040184 29479 solver.cpp:613] Iteration 96460, avg_grad_norm = 478733
I0317 12:55:32.618831 29479 solver.cpp:214] Iteration 96480, loss = 5863.39
I0317 12:55:32.618948 29479 solver.cpp:229]     Train net output #0: loss = 4765.46 (* 1 = 4765.46 loss)
I0317 12:55:33.699105 29479 solver.cpp:610] Iteration 96480, lr = 5.52834e-09
I0317 12:55:33.699118 29479 solver.cpp:613] Iteration 96480, avg_grad_norm = 532796
I0317 12:58:02.180562 29479 solver.cpp:214] Iteration 96500, loss = 5694.03
I0317 12:58:02.180739 29479 solver.cpp:229]     Train net output #0: loss = 4368.07 (* 1 = 4368.07 loss)
I0317 12:58:02.344194 29479 solver.cpp:610] Iteration 96500, lr = 5.52738e-09
I0317 12:58:02.344208 29479 solver.cpp:613] Iteration 96500, avg_grad_norm = 536631
I0317 13:00:44.815948 29479 solver.cpp:214] Iteration 96520, loss = 5981.5
I0317 13:00:44.816057 29479 solver.cpp:229]     Train net output #0: loss = 9714.93 (* 1 = 9714.93 loss)
I0317 13:00:44.969244 29479 solver.cpp:610] Iteration 96520, lr = 5.52642e-09
I0317 13:00:44.969259 29479 solver.cpp:613] Iteration 96520, avg_grad_norm = 479506
I0317 13:03:13.473084 29479 solver.cpp:214] Iteration 96540, loss = 5360.24
I0317 13:03:13.473325 29479 solver.cpp:229]     Train net output #0: loss = 6795.61 (* 1 = 6795.61 loss)
I0317 13:03:13.639087 29479 solver.cpp:610] Iteration 96540, lr = 5.52546e-09
I0317 13:03:13.639122 29479 solver.cpp:613] Iteration 96540, avg_grad_norm = 494997
I0317 13:04:33.092059 29479 solver.cpp:214] Iteration 96560, loss = 5579.11
I0317 13:04:33.092170 29479 solver.cpp:229]     Train net output #0: loss = 4555.12 (* 1 = 4555.12 loss)
I0317 13:04:34.133723 29479 solver.cpp:610] Iteration 96560, lr = 5.5245e-09
I0317 13:04:34.133735 29479 solver.cpp:613] Iteration 96560, avg_grad_norm = 498707
I0317 13:07:02.615301 29479 solver.cpp:214] Iteration 96580, loss = 5284.89
I0317 13:07:02.615479 29479 solver.cpp:229]     Train net output #0: loss = 4343.72 (* 1 = 4343.72 loss)
I0317 13:07:02.778756 29479 solver.cpp:610] Iteration 96580, lr = 5.52353e-09
I0317 13:07:02.778770 29479 solver.cpp:613] Iteration 96580, avg_grad_norm = 511596
I0317 13:09:30.295002 29479 solver.cpp:214] Iteration 96600, loss = 5424
I0317 13:09:30.295133 29479 solver.cpp:229]     Train net output #0: loss = 3798.23 (* 1 = 3798.23 loss)
I0317 13:09:31.373744 29479 solver.cpp:610] Iteration 96600, lr = 5.52257e-09
I0317 13:09:31.373759 29479 solver.cpp:613] Iteration 96600, avg_grad_norm = 463295
I0317 13:11:58.862304 29479 solver.cpp:214] Iteration 96620, loss = 5392.17
I0317 13:11:58.862504 29479 solver.cpp:229]     Train net output #0: loss = 5283.01 (* 1 = 5283.01 loss)
I0317 13:11:59.901223 29479 solver.cpp:610] Iteration 96620, lr = 5.52161e-09
I0317 13:11:59.901238 29479 solver.cpp:613] Iteration 96620, avg_grad_norm = 512711
I0317 13:14:28.534106 29479 solver.cpp:214] Iteration 96640, loss = 5616.05
I0317 13:14:28.534226 29479 solver.cpp:229]     Train net output #0: loss = 5187.72 (* 1 = 5187.72 loss)
I0317 13:14:29.604315 29479 solver.cpp:610] Iteration 96640, lr = 5.52065e-09
I0317 13:14:29.604328 29479 solver.cpp:613] Iteration 96640, avg_grad_norm = 494411
I0317 13:17:09.157187 29479 solver.cpp:214] Iteration 96660, loss = 5491.69
I0317 13:17:09.157376 29479 solver.cpp:229]     Train net output #0: loss = 6498.59 (* 1 = 6498.59 loss)
I0317 13:17:10.226063 29479 solver.cpp:610] Iteration 96660, lr = 5.51969e-09
I0317 13:17:10.226076 29479 solver.cpp:613] Iteration 96660, avg_grad_norm = 528174
I0317 13:19:37.674906 29479 solver.cpp:214] Iteration 96680, loss = 5472.23
I0317 13:19:37.675042 29479 solver.cpp:229]     Train net output #0: loss = 7848.34 (* 1 = 7848.34 loss)
I0317 13:19:38.718667 29479 solver.cpp:610] Iteration 96680, lr = 5.51873e-09
I0317 13:19:38.718680 29479 solver.cpp:613] Iteration 96680, avg_grad_norm = 521367
I0317 13:22:06.277509 29479 solver.cpp:214] Iteration 96700, loss = 5572.12
I0317 13:22:06.277714 29479 solver.cpp:229]     Train net output #0: loss = 8650.12 (* 1 = 8650.12 loss)
I0317 13:22:07.321081 29479 solver.cpp:610] Iteration 96700, lr = 5.51777e-09
I0317 13:22:07.321113 29479 solver.cpp:613] Iteration 96700, avg_grad_norm = 478290
I0317 13:24:27.895546 29479 solver.cpp:214] Iteration 96720, loss = 5585.3
I0317 13:24:27.895752 29479 solver.cpp:229]     Train net output #0: loss = 7650.87 (* 1 = 7650.87 loss)
I0317 13:24:28.001057 29479 solver.cpp:610] Iteration 96720, lr = 5.5168e-09
I0317 13:24:28.001096 29479 solver.cpp:613] Iteration 96720, avg_grad_norm = 489914
I0317 13:25:03.457370 29479 solver.cpp:214] Iteration 96740, loss = 5196.41
I0317 13:25:03.457469 29479 solver.cpp:229]     Train net output #0: loss = 4808.64 (* 1 = 4808.64 loss)
I0317 13:25:04.507962 29479 solver.cpp:610] Iteration 96740, lr = 5.51584e-09
I0317 13:25:04.507975 29479 solver.cpp:613] Iteration 96740, avg_grad_norm = 480628
I0317 13:27:30.110409 29479 solver.cpp:214] Iteration 96760, loss = 5611.36
I0317 13:27:30.110611 29479 solver.cpp:229]     Train net output #0: loss = 3948.88 (* 1 = 3948.88 loss)
I0317 13:27:31.189128 29479 solver.cpp:610] Iteration 96760, lr = 5.51488e-09
I0317 13:27:31.189143 29479 solver.cpp:613] Iteration 96760, avg_grad_norm = 474318
I0317 13:30:12.753108 29479 solver.cpp:214] Iteration 96780, loss = 5682.62
I0317 13:30:12.753311 29479 solver.cpp:229]     Train net output #0: loss = 4083.12 (* 1 = 4083.12 loss)
I0317 13:30:12.915998 29479 solver.cpp:610] Iteration 96780, lr = 5.51392e-09
I0317 13:30:12.916013 29479 solver.cpp:613] Iteration 96780, avg_grad_norm = 500218
I0317 13:32:42.346441 29479 solver.cpp:214] Iteration 96800, loss = 5647.08
I0317 13:32:42.346567 29479 solver.cpp:229]     Train net output #0: loss = 5363.66 (* 1 = 5363.66 loss)
I0317 13:32:42.500180 29479 solver.cpp:610] Iteration 96800, lr = 5.51296e-09
I0317 13:32:42.500192 29479 solver.cpp:613] Iteration 96800, avg_grad_norm = 464992
I0317 13:35:10.970700 29479 solver.cpp:214] Iteration 96820, loss = 5520.73
I0317 13:35:10.970935 29479 solver.cpp:229]     Train net output #0: loss = 6641.29 (* 1 = 6641.29 loss)
I0317 13:35:12.020367 29479 solver.cpp:610] Iteration 96820, lr = 5.512e-09
I0317 13:35:12.020385 29479 solver.cpp:613] Iteration 96820, avg_grad_norm = 503123
I0317 13:37:40.676348 29479 solver.cpp:214] Iteration 96840, loss = 5566.92
I0317 13:37:40.676486 29479 solver.cpp:229]     Train net output #0: loss = 9095.66 (* 1 = 9095.66 loss)
I0317 13:37:41.753430 29479 solver.cpp:610] Iteration 96840, lr = 5.51104e-09
I0317 13:37:41.753445 29479 solver.cpp:613] Iteration 96840, avg_grad_norm = 667116
I0317 13:40:08.312865 29479 solver.cpp:214] Iteration 96860, loss = 5755.6
I0317 13:40:08.313000 29479 solver.cpp:229]     Train net output #0: loss = 5227.98 (* 1 = 5227.98 loss)
I0317 13:40:09.386143 29479 solver.cpp:610] Iteration 96860, lr = 5.51007e-09
I0317 13:40:09.386158 29479 solver.cpp:613] Iteration 96860, avg_grad_norm = 488355
I0317 13:42:36.954625 29479 solver.cpp:214] Iteration 96880, loss = 5917.34
I0317 13:42:36.954735 29479 solver.cpp:229]     Train net output #0: loss = 3949.97 (* 1 = 3949.97 loss)
I0317 13:42:38.039316 29479 solver.cpp:610] Iteration 96880, lr = 5.50911e-09
I0317 13:42:38.039330 29479 solver.cpp:613] Iteration 96880, avg_grad_norm = 520033
I0317 13:44:56.594596 29479 solver.cpp:214] Iteration 96900, loss = 5695.23
I0317 13:44:56.594734 29479 solver.cpp:229]     Train net output #0: loss = 9072.72 (* 1 = 9072.72 loss)
I0317 13:44:56.698715 29479 solver.cpp:610] Iteration 96900, lr = 5.50815e-09
I0317 13:44:56.698760 29479 solver.cpp:613] Iteration 96900, avg_grad_norm = 518326
I0317 13:46:37.234352 29479 solver.cpp:214] Iteration 96920, loss = 5471.64
I0317 13:46:37.234539 29479 solver.cpp:229]     Train net output #0: loss = 5752.29 (* 1 = 5752.29 loss)
I0317 13:46:38.304594 29479 solver.cpp:610] Iteration 96920, lr = 5.50719e-09
I0317 13:46:38.304610 29479 solver.cpp:613] Iteration 96920, avg_grad_norm = 595543
I0317 13:49:07.710383 29479 solver.cpp:214] Iteration 96940, loss = 5613.83
I0317 13:49:07.710510 29479 solver.cpp:229]     Train net output #0: loss = 7641.16 (* 1 = 7641.16 loss)
I0317 13:49:07.881778 29479 solver.cpp:610] Iteration 96940, lr = 5.50623e-09
I0317 13:49:07.881790 29479 solver.cpp:613] Iteration 96940, avg_grad_norm = 572404
I0317 13:51:36.381094 29479 solver.cpp:214] Iteration 96960, loss = 5563.81
I0317 13:51:36.381213 29479 solver.cpp:229]     Train net output #0: loss = 9826.45 (* 1 = 9826.45 loss)
I0317 13:51:37.454782 29479 solver.cpp:610] Iteration 96960, lr = 5.50527e-09
I0317 13:51:37.454798 29479 solver.cpp:613] Iteration 96960, avg_grad_norm = 490448
I0317 13:54:07.010326 29479 solver.cpp:214] Iteration 96980, loss = 5484.5
I0317 13:54:07.010462 29479 solver.cpp:229]     Train net output #0: loss = 9475.65 (* 1 = 9475.65 loss)
I0317 13:54:07.169826 29479 solver.cpp:610] Iteration 96980, lr = 5.5043e-09
I0317 13:54:07.169838 29479 solver.cpp:613] Iteration 96980, avg_grad_norm = 491734
I0317 13:56:36.521538 29479 solver.cpp:214] Iteration 97000, loss = 5527.79
I0317 13:56:36.521760 29479 solver.cpp:229]     Train net output #0: loss = 3297.52 (* 1 = 3297.52 loss)
I0317 13:56:36.676208 29479 solver.cpp:610] Iteration 97000, lr = 5.50334e-09
I0317 13:56:36.676221 29479 solver.cpp:613] Iteration 97000, avg_grad_norm = 531793
I0317 13:59:03.208876 29479 solver.cpp:214] Iteration 97020, loss = 5467.3
I0317 13:59:03.209070 29479 solver.cpp:229]     Train net output #0: loss = 6009.55 (* 1 = 6009.55 loss)
I0317 13:59:04.255509 29479 solver.cpp:610] Iteration 97020, lr = 5.50238e-09
I0317 13:59:04.255543 29479 solver.cpp:613] Iteration 97020, avg_grad_norm = 486630
I0317 14:01:48.674612 29479 solver.cpp:214] Iteration 97040, loss = 5594.59
I0317 14:01:48.674809 29479 solver.cpp:229]     Train net output #0: loss = 6423.37 (* 1 = 6423.37 loss)
I0317 14:01:48.897621 29479 solver.cpp:610] Iteration 97040, lr = 5.50142e-09
I0317 14:01:48.897635 29479 solver.cpp:613] Iteration 97040, avg_grad_norm = 487534
I0317 14:04:17.368485 29479 solver.cpp:214] Iteration 97060, loss = 5503.14
I0317 14:04:17.368649 29479 solver.cpp:229]     Train net output #0: loss = 4506.72 (* 1 = 4506.72 loss)
I0317 14:04:17.544126 29479 solver.cpp:610] Iteration 97060, lr = 5.50046e-09
I0317 14:04:17.544140 29479 solver.cpp:613] Iteration 97060, avg_grad_norm = 505344
I0317 14:05:37.853550 29479 solver.cpp:214] Iteration 97080, loss = 5282.88
I0317 14:05:37.853684 29479 solver.cpp:229]     Train net output #0: loss = 10031.4 (* 1 = 10031.4 loss)
I0317 14:05:38.076297 29479 solver.cpp:610] Iteration 97080, lr = 5.4995e-09
I0317 14:05:38.076310 29479 solver.cpp:613] Iteration 97080, avg_grad_norm = 502655
I0317 14:08:05.632563 29479 solver.cpp:214] Iteration 97100, loss = 5489.88
I0317 14:08:05.632696 29479 solver.cpp:229]     Train net output #0: loss = 7345.43 (* 1 = 7345.43 loss)
I0317 14:08:06.719806 29479 solver.cpp:610] Iteration 97100, lr = 5.49853e-09
I0317 14:08:06.719856 29479 solver.cpp:613] Iteration 97100, avg_grad_norm = 475407
I0317 14:10:35.178977 29479 solver.cpp:214] Iteration 97120, loss = 5515.65
I0317 14:10:35.179091 29479 solver.cpp:229]     Train net output #0: loss = 3306 (* 1 = 3306 loss)
I0317 14:10:35.336351 29479 solver.cpp:610] Iteration 97120, lr = 5.49757e-09
I0317 14:10:35.336365 29479 solver.cpp:613] Iteration 97120, avg_grad_norm = 494970
I0317 14:13:02.831446 29479 solver.cpp:214] Iteration 97140, loss = 5580.19
I0317 14:13:02.831637 29479 solver.cpp:229]     Train net output #0: loss = 12264.7 (* 1 = 12264.7 loss)
I0317 14:13:03.884053 29479 solver.cpp:610] Iteration 97140, lr = 5.49661e-09
I0317 14:13:03.884068 29479 solver.cpp:613] Iteration 97140, avg_grad_norm = 463842
I0317 14:15:46.489433 29479 solver.cpp:214] Iteration 97160, loss = 5526.69
I0317 14:15:46.489660 29479 solver.cpp:229]     Train net output #0: loss = 4457.63 (* 1 = 4457.63 loss)
I0317 14:15:46.646858 29479 solver.cpp:610] Iteration 97160, lr = 5.49565e-09
I0317 14:15:46.646875 29479 solver.cpp:613] Iteration 97160, avg_grad_norm = 474764
I0317 14:18:14.110024 29479 solver.cpp:214] Iteration 97180, loss = 5739.94
I0317 14:18:14.110167 29479 solver.cpp:229]     Train net output #0: loss = 6254.73 (* 1 = 6254.73 loss)
I0317 14:18:15.152820 29479 solver.cpp:610] Iteration 97180, lr = 5.49469e-09
I0317 14:18:15.152833 29479 solver.cpp:613] Iteration 97180, avg_grad_norm = 497487
I0317 14:20:42.677043 29479 solver.cpp:214] Iteration 97200, loss = 5703.07
I0317 14:20:42.677237 29479 solver.cpp:229]     Train net output #0: loss = 9381.99 (* 1 = 9381.99 loss)
I0317 14:20:42.850020 29479 solver.cpp:610] Iteration 97200, lr = 5.49372e-09
I0317 14:20:42.850033 29479 solver.cpp:613] Iteration 97200, avg_grad_norm = 490726
I0317 14:23:12.322579 29479 solver.cpp:214] Iteration 97220, loss = 5291.84
I0317 14:23:12.322702 29479 solver.cpp:229]     Train net output #0: loss = 4699.02 (* 1 = 4699.02 loss)
I0317 14:23:12.477658 29479 solver.cpp:610] Iteration 97220, lr = 5.49276e-09
I0317 14:23:12.477670 29479 solver.cpp:613] Iteration 97220, avg_grad_norm = 474987
I0317 14:25:29.918545 29479 solver.cpp:214] Iteration 97240, loss = 5642.13
I0317 14:25:29.918757 29479 solver.cpp:229]     Train net output #0: loss = 4723.83 (* 1 = 4723.83 loss)
I0317 14:25:30.023136 29479 solver.cpp:610] Iteration 97240, lr = 5.4918e-09
I0317 14:25:30.023150 29479 solver.cpp:613] Iteration 97240, avg_grad_norm = 495212
I0317 14:26:28.470808 29479 solver.cpp:214] Iteration 97260, loss = 5450.24
I0317 14:26:28.470945 29479 solver.cpp:229]     Train net output #0: loss = 4574.03 (* 1 = 4574.03 loss)
I0317 14:26:29.512114 29479 solver.cpp:610] Iteration 97260, lr = 5.49084e-09
I0317 14:26:29.512127 29479 solver.cpp:613] Iteration 97260, avg_grad_norm = 506008
I0317 14:29:09.161725 29479 solver.cpp:214] Iteration 97280, loss = 5585.21
I0317 14:29:09.161906 29479 solver.cpp:229]     Train net output #0: loss = 4721.08 (* 1 = 4721.08 loss)
I0317 14:29:10.196543 29479 solver.cpp:610] Iteration 97280, lr = 5.48988e-09
I0317 14:29:10.196563 29479 solver.cpp:613] Iteration 97280, avg_grad_norm = 484111
I0317 14:31:38.772101 29479 solver.cpp:214] Iteration 97300, loss = 5487
I0317 14:31:38.772233 29479 solver.cpp:229]     Train net output #0: loss = 5951.88 (* 1 = 5951.88 loss)
I0317 14:31:39.819102 29479 solver.cpp:610] Iteration 97300, lr = 5.48891e-09
I0317 14:31:39.819116 29479 solver.cpp:613] Iteration 97300, avg_grad_norm = 562405
I0317 14:34:07.281610 29479 solver.cpp:214] Iteration 97320, loss = 5526.94
I0317 14:34:07.281743 29479 solver.cpp:229]     Train net output #0: loss = 9350.36 (* 1 = 9350.36 loss)
I0317 14:34:07.472713 29479 solver.cpp:610] Iteration 97320, lr = 5.48795e-09
I0317 14:34:07.472738 29479 solver.cpp:613] Iteration 97320, avg_grad_norm = 505266
I0317 14:36:35.959918 29479 solver.cpp:214] Iteration 97340, loss = 5716.1
I0317 14:36:35.960114 29479 solver.cpp:229]     Train net output #0: loss = 4837.86 (* 1 = 4837.86 loss)
I0317 14:36:36.128144 29479 solver.cpp:610] Iteration 97340, lr = 5.48699e-09
I0317 14:36:36.128156 29479 solver.cpp:613] Iteration 97340, avg_grad_norm = 553919
I0317 14:39:04.588265 29479 solver.cpp:214] Iteration 97360, loss = 5618.29
I0317 14:39:04.588397 29479 solver.cpp:229]     Train net output #0: loss = 7195.22 (* 1 = 7195.22 loss)
I0317 14:39:05.661903 29479 solver.cpp:610] Iteration 97360, lr = 5.48603e-09
I0317 14:39:05.661917 29479 solver.cpp:613] Iteration 97360, avg_grad_norm = 517529
I0317 14:41:33.101217 29479 solver.cpp:214] Iteration 97380, loss = 5788.24
I0317 14:41:33.101372 29479 solver.cpp:229]     Train net output #0: loss = 4703.91 (* 1 = 4703.91 loss)
I0317 14:41:33.255785 29479 solver.cpp:610] Iteration 97380, lr = 5.48507e-09
I0317 14:41:33.255800 29479 solver.cpp:613] Iteration 97380, avg_grad_norm = 490567
I0317 14:44:00.786641 29479 solver.cpp:214] Iteration 97400, loss = 5596.76
I0317 14:44:00.786835 29479 solver.cpp:229]     Train net output #0: loss = 4147.15 (* 1 = 4147.15 loss)
I0317 14:44:01.868139 29479 solver.cpp:610] Iteration 97400, lr = 5.4841e-09
I0317 14:44:01.868154 29479 solver.cpp:613] Iteration 97400, avg_grad_norm = 516531
I0317 14:45:58.338536 29479 solver.cpp:214] Iteration 97420, loss = 5881.29
I0317 14:45:58.338671 29479 solver.cpp:229]     Train net output #0: loss = 4958.49 (* 1 = 4958.49 loss)
I0317 14:45:58.444180 29479 solver.cpp:610] Iteration 97420, lr = 5.48314e-09
I0317 14:45:58.444207 29479 solver.cpp:613] Iteration 97420, avg_grad_norm = 501646
I0317 14:47:22.866873 29479 solver.cpp:214] Iteration 97440, loss = 5562.43
I0317 14:47:22.866988 29479 solver.cpp:229]     Train net output #0: loss = 9520.67 (* 1 = 9520.67 loss)
I0317 14:47:23.020297 29479 solver.cpp:610] Iteration 97440, lr = 5.48218e-09
I0317 14:47:23.020309 29479 solver.cpp:613] Iteration 97440, avg_grad_norm = 509115
I0317 14:49:51.472697 29479 solver.cpp:214] Iteration 97460, loss = 5547.56
I0317 14:49:51.472857 29479 solver.cpp:229]     Train net output #0: loss = 9247.31 (* 1 = 9247.31 loss)
I0317 14:49:52.520834 29479 solver.cpp:610] Iteration 97460, lr = 5.48122e-09
I0317 14:49:52.520851 29479 solver.cpp:613] Iteration 97460, avg_grad_norm = 519559
I0317 14:52:20.155315 29479 solver.cpp:214] Iteration 97480, loss = 5426.45
I0317 14:52:20.155433 29479 solver.cpp:229]     Train net output #0: loss = 3628.03 (* 1 = 3628.03 loss)
I0317 14:52:21.229281 29479 solver.cpp:610] Iteration 97480, lr = 5.48025e-09
I0317 14:52:21.229296 29479 solver.cpp:613] Iteration 97480, avg_grad_norm = 492034
I0317 14:54:50.758656 29479 solver.cpp:214] Iteration 97500, loss = 5921.7
I0317 14:54:50.758877 29479 solver.cpp:229]     Train net output #0: loss = 3803.32 (* 1 = 3803.32 loss)
I0317 14:54:50.912642 29479 solver.cpp:610] Iteration 97500, lr = 5.47929e-09
I0317 14:54:50.912655 29479 solver.cpp:613] Iteration 97500, avg_grad_norm = 514464
I0317 14:57:18.388746 29479 solver.cpp:214] Iteration 97520, loss = 5831.27
I0317 14:57:18.388973 29479 solver.cpp:229]     Train net output #0: loss = 3929.98 (* 1 = 3929.98 loss)
I0317 14:57:19.463223 29479 solver.cpp:610] Iteration 97520, lr = 5.47833e-09
I0317 14:57:19.463248 29479 solver.cpp:613] Iteration 97520, avg_grad_norm = 508522
I0317 14:59:59.888882 29479 solver.cpp:214] Iteration 97540, loss = 5674.91
I0317 14:59:59.889017 29479 solver.cpp:229]     Train net output #0: loss = 7257.67 (* 1 = 7257.67 loss)
I0317 15:00:00.066184 29479 solver.cpp:610] Iteration 97540, lr = 5.47737e-09
I0317 15:00:00.066196 29479 solver.cpp:613] Iteration 97540, avg_grad_norm = 496618
I0317 15:02:28.534857 29479 solver.cpp:214] Iteration 97560, loss = 5561.48
I0317 15:02:28.535054 29479 solver.cpp:229]     Train net output #0: loss = 6875.15 (* 1 = 6875.15 loss)
I0317 15:02:28.709206 29479 solver.cpp:610] Iteration 97560, lr = 5.47641e-09
I0317 15:02:28.709219 29479 solver.cpp:613] Iteration 97560, avg_grad_norm = 498528
I0317 15:04:56.144804 29479 solver.cpp:214] Iteration 97580, loss = 5536.7
I0317 15:04:56.144997 29479 solver.cpp:229]     Train net output #0: loss = 7046.25 (* 1 = 7046.25 loss)
I0317 15:04:57.203368 29479 solver.cpp:610] Iteration 97580, lr = 5.47544e-09
I0317 15:04:57.203402 29479 solver.cpp:613] Iteration 97580, avg_grad_norm = 537916
I0317 15:06:26.750879 29479 solver.cpp:214] Iteration 97600, loss = 5785.25
I0317 15:06:26.751026 29479 solver.cpp:229]     Train net output #0: loss = 4716.33 (* 1 = 4716.33 loss)
I0317 15:06:26.855849 29479 solver.cpp:610] Iteration 97600, lr = 5.47448e-09
I0317 15:06:26.855862 29479 solver.cpp:613] Iteration 97600, avg_grad_norm = 508965
I0317 15:08:45.236925 29479 solver.cpp:214] Iteration 97620, loss = 5204.59
I0317 15:08:45.237058 29479 solver.cpp:229]     Train net output #0: loss = 3917.83 (* 1 = 3917.83 loss)
I0317 15:08:45.459698 29479 solver.cpp:610] Iteration 97620, lr = 5.47352e-09
I0317 15:08:45.459712 29479 solver.cpp:613] Iteration 97620, avg_grad_norm = 502868
I0317 15:11:12.985857 29479 solver.cpp:214] Iteration 97640, loss = 5738.62
I0317 15:11:12.985987 29479 solver.cpp:229]     Train net output #0: loss = 5271.17 (* 1 = 5271.17 loss)
I0317 15:11:14.062397 29479 solver.cpp:610] Iteration 97640, lr = 5.47256e-09
I0317 15:11:14.062412 29479 solver.cpp:613] Iteration 97640, avg_grad_norm = 511845
I0317 15:13:57.689303 29479 solver.cpp:214] Iteration 97660, loss = 5646.35
I0317 15:13:57.689419 29479 solver.cpp:229]     Train net output #0: loss = 3555.73 (* 1 = 3555.73 loss)
I0317 15:13:58.781416 29479 solver.cpp:610] Iteration 97660, lr = 5.47159e-09
I0317 15:13:58.781435 29479 solver.cpp:613] Iteration 97660, avg_grad_norm = 492827
I0317 15:16:27.199481 29479 solver.cpp:214] Iteration 97680, loss = 5214.23
I0317 15:16:27.199672 29479 solver.cpp:229]     Train net output #0: loss = 5141.68 (* 1 = 5141.68 loss)
I0317 15:16:27.374378 29479 solver.cpp:610] Iteration 97680, lr = 5.47063e-09
I0317 15:16:27.374392 29479 solver.cpp:613] Iteration 97680, avg_grad_norm = 470884
I0317 15:18:55.882314 29479 solver.cpp:214] Iteration 97700, loss = 5473.99
I0317 15:18:55.882500 29479 solver.cpp:229]     Train net output #0: loss = 7026.74 (* 1 = 7026.74 loss)
I0317 15:18:56.917400 29479 solver.cpp:610] Iteration 97700, lr = 5.46967e-09
I0317 15:18:56.917418 29479 solver.cpp:613] Iteration 97700, avg_grad_norm = 470053
I0317 15:21:25.419667 29479 solver.cpp:214] Iteration 97720, loss = 5647.94
I0317 15:21:25.419898 29479 solver.cpp:229]     Train net output #0: loss = 2813.41 (* 1 = 2813.41 loss)
I0317 15:21:26.453786 29479 solver.cpp:610] Iteration 97720, lr = 5.46871e-09
I0317 15:21:26.453806 29479 solver.cpp:613] Iteration 97720, avg_grad_norm = 482561
I0317 15:23:54.968788 29479 solver.cpp:214] Iteration 97740, loss = 5616.05
I0317 15:23:54.968956 29479 solver.cpp:229]     Train net output #0: loss = 4834.8 (* 1 = 4834.8 loss)
I0317 15:23:55.129642 29479 solver.cpp:610] Iteration 97740, lr = 5.46774e-09
I0317 15:23:55.129660 29479 solver.cpp:613] Iteration 97740, avg_grad_norm = 549467
I0317 15:26:22.567261 29479 solver.cpp:214] Iteration 97760, loss = 5597.32
I0317 15:26:22.567469 29479 solver.cpp:229]     Train net output #0: loss = 5615.01 (* 1 = 5615.01 loss)
I0317 15:26:22.730950 29479 solver.cpp:610] Iteration 97760, lr = 5.46678e-09
I0317 15:26:22.730963 29479 solver.cpp:613] Iteration 97760, avg_grad_norm = 513407
I0317 15:27:41.227484 29479 solver.cpp:214] Iteration 97780, loss = 5933.29
I0317 15:27:41.227681 29479 solver.cpp:229]     Train net output #0: loss = 8320.86 (* 1 = 8320.86 loss)
I0317 15:27:42.309703 29479 solver.cpp:610] Iteration 97780, lr = 5.46582e-09
I0317 15:27:42.309718 29479 solver.cpp:613] Iteration 97780, avg_grad_norm = 538111
I0317 15:30:21.794215 29479 solver.cpp:214] Iteration 97800, loss = 5674.11
I0317 15:30:21.794356 29479 solver.cpp:229]     Train net output #0: loss = 7846.71 (* 1 = 7846.71 loss)
I0317 15:30:22.837170 29479 solver.cpp:610] Iteration 97800, lr = 5.46486e-09
I0317 15:30:22.837187 29479 solver.cpp:613] Iteration 97800, avg_grad_norm = 495832
I0317 15:32:50.390997 29479 solver.cpp:214] Iteration 97820, loss = 5456.41
I0317 15:32:50.391197 29479 solver.cpp:229]     Train net output #0: loss = 6035.72 (* 1 = 6035.72 loss)
I0317 15:32:51.464581 29479 solver.cpp:610] Iteration 97820, lr = 5.46389e-09
I0317 15:32:51.464596 29479 solver.cpp:613] Iteration 97820, avg_grad_norm = 498250
I0317 15:35:19.965322 29479 solver.cpp:214] Iteration 97840, loss = 5265.45
I0317 15:35:19.965471 29479 solver.cpp:229]     Train net output #0: loss = 4928.18 (* 1 = 4928.18 loss)
I0317 15:35:20.122254 29479 solver.cpp:610] Iteration 97840, lr = 5.46293e-09
I0317 15:35:20.122268 29479 solver.cpp:613] Iteration 97840, avg_grad_norm = 478879
I0317 15:37:36.657570 29479 solver.cpp:214] Iteration 97860, loss = 5137.54
I0317 15:37:36.657708 29479 solver.cpp:229]     Train net output #0: loss = 3072 (* 1 = 3072 loss)
I0317 15:37:37.694129 29479 solver.cpp:610] Iteration 97860, lr = 5.46197e-09
I0317 15:37:37.694144 29479 solver.cpp:613] Iteration 97860, avg_grad_norm = 480871
I0317 15:40:07.221508 29479 solver.cpp:214] Iteration 97880, loss = 5648.93
I0317 15:40:07.221709 29479 solver.cpp:229]     Train net output #0: loss = 9223.21 (* 1 = 9223.21 loss)
I0317 15:40:07.396039 29479 solver.cpp:610] Iteration 97880, lr = 5.46101e-09
I0317 15:40:07.396052 29479 solver.cpp:613] Iteration 97880, avg_grad_norm = 489810
I0317 15:42:35.833562 29479 solver.cpp:214] Iteration 97900, loss = 5473.22
I0317 15:42:35.833698 29479 solver.cpp:229]     Train net output #0: loss = 4996.69 (* 1 = 4996.69 loss)
I0317 15:42:36.877993 29479 solver.cpp:610] Iteration 97900, lr = 5.46004e-09
I0317 15:42:36.878006 29479 solver.cpp:613] Iteration 97900, avg_grad_norm = 476972
I0317 15:45:21.544353 29479 solver.cpp:214] Iteration 97920, loss = 5690.05
I0317 15:45:21.544481 29479 solver.cpp:229]     Train net output #0: loss = 2559.1 (* 1 = 2559.1 loss)
I0317 15:45:22.624565 29479 solver.cpp:610] Iteration 97920, lr = 5.45908e-09
I0317 15:45:22.624583 29479 solver.cpp:613] Iteration 97920, avg_grad_norm = 502580
I0317 15:47:00.127411 29479 solver.cpp:214] Iteration 97940, loss = 5705.59
I0317 15:47:00.127535 29479 solver.cpp:229]     Train net output #0: loss = 7167.3 (* 1 = 7167.3 loss)
I0317 15:47:00.231788 29479 solver.cpp:610] Iteration 97940, lr = 5.45812e-09
I0317 15:47:00.231801 29479 solver.cpp:613] Iteration 97940, avg_grad_norm = 565392
I0317 15:48:01.710067 29479 solver.cpp:214] Iteration 97960, loss = 5711.5
I0317 15:48:01.710268 29479 solver.cpp:229]     Train net output #0: loss = 5221.58 (* 1 = 5221.58 loss)
I0317 15:48:01.862977 29479 solver.cpp:610] Iteration 97960, lr = 5.45716e-09
I0317 15:48:01.862992 29479 solver.cpp:613] Iteration 97960, avg_grad_norm = 502200
I0317 15:50:30.243281 29479 solver.cpp:214] Iteration 97980, loss = 5867.16
I0317 15:50:30.243477 29479 solver.cpp:229]     Train net output #0: loss = 8003.42 (* 1 = 8003.42 loss)
I0317 15:50:30.405840 29479 solver.cpp:610] Iteration 97980, lr = 5.45619e-09
I0317 15:50:30.405854 29479 solver.cpp:613] Iteration 97980, avg_grad_norm = 517242
I0317 15:52:59.886344 29479 solver.cpp:214] Iteration 98000, loss = 5692.41
I0317 15:52:59.886592 29479 solver.cpp:229]     Train net output #0: loss = 5200.71 (* 1 = 5200.71 loss)
I0317 15:53:00.964406 29479 solver.cpp:610] Iteration 98000, lr = 5.45523e-09
I0317 15:53:00.964421 29479 solver.cpp:613] Iteration 98000, avg_grad_norm = 498334
I0317 15:55:29.525585 29479 solver.cpp:214] Iteration 98020, loss = 5704.08
I0317 15:55:29.525786 29479 solver.cpp:229]     Train net output #0: loss = 3150.19 (* 1 = 3150.19 loss)
I0317 15:55:30.612226 29479 solver.cpp:610] Iteration 98020, lr = 5.45427e-09
I0317 15:55:30.612241 29479 solver.cpp:613] Iteration 98020, avg_grad_norm = 536272
I0317 15:58:13.098876 29479 solver.cpp:214] Iteration 98040, loss = 5222.45
I0317 15:58:13.098992 29479 solver.cpp:229]     Train net output #0: loss = 8525.59 (* 1 = 8525.59 loss)
I0317 15:58:13.262519 29479 solver.cpp:610] Iteration 98040, lr = 5.45331e-09
I0317 15:58:13.262545 29479 solver.cpp:613] Iteration 98040, avg_grad_norm = 494498
I0317 16:00:41.669314 29479 solver.cpp:214] Iteration 98060, loss = 5689.48
I0317 16:00:41.669453 29479 solver.cpp:229]     Train net output #0: loss = 4391.36 (* 1 = 4391.36 loss)
I0317 16:00:41.843767 29479 solver.cpp:610] Iteration 98060, lr = 5.45234e-09
I0317 16:00:41.843781 29479 solver.cpp:613] Iteration 98060, avg_grad_norm = 501235
I0317 16:03:09.291726 29479 solver.cpp:214] Iteration 98080, loss = 5522.38
I0317 16:03:09.291923 29479 solver.cpp:229]     Train net output #0: loss = 5980.68 (* 1 = 5980.68 loss)
I0317 16:03:09.452760 29479 solver.cpp:610] Iteration 98080, lr = 5.45138e-09
I0317 16:03:09.452791 29479 solver.cpp:613] Iteration 98080, avg_grad_norm = 487891
I0317 16:05:37.967591 29479 solver.cpp:214] Iteration 98100, loss = 5755.15
I0317 16:05:37.967715 29479 solver.cpp:229]     Train net output #0: loss = 7856.53 (* 1 = 7856.53 loss)
I0317 16:05:39.044142 29479 solver.cpp:610] Iteration 98100, lr = 5.45042e-09
I0317 16:05:39.044157 29479 solver.cpp:613] Iteration 98100, avg_grad_norm = 504064
I0317 16:07:28.511322 29479 solver.cpp:214] Iteration 98120, loss = 5092.82
I0317 16:07:28.511463 29479 solver.cpp:229]     Train net output #0: loss = 4520.06 (* 1 = 4520.06 loss)
I0317 16:07:28.615439 29479 solver.cpp:610] Iteration 98120, lr = 5.44945e-09
I0317 16:07:28.615474 29479 solver.cpp:613] Iteration 98120, avg_grad_norm = 519648
I0317 16:09:27.105345 29479 solver.cpp:214] Iteration 98140, loss = 5568.97
I0317 16:09:27.105622 29479 solver.cpp:229]     Train net output #0: loss = 3317.82 (* 1 = 3317.82 loss)
I0317 16:09:28.183866 29479 solver.cpp:610] Iteration 98140, lr = 5.44849e-09
I0317 16:09:28.183881 29479 solver.cpp:613] Iteration 98140, avg_grad_norm = 487069
I0317 16:11:53.649868 29479 solver.cpp:214] Iteration 98160, loss = 5575.46
I0317 16:11:53.650009 29479 solver.cpp:229]     Train net output #0: loss = 2433.23 (* 1 = 2433.23 loss)
I0317 16:11:54.686228 29479 solver.cpp:610] Iteration 98160, lr = 5.44753e-09
I0317 16:11:54.686241 29479 solver.cpp:613] Iteration 98160, avg_grad_norm = 507745
I0317 16:14:35.248576 29479 solver.cpp:214] Iteration 98180, loss = 5406.87
I0317 16:14:35.248708 29479 solver.cpp:229]     Train net output #0: loss = 9729.69 (* 1 = 9729.69 loss)
I0317 16:14:36.329183 29479 solver.cpp:610] Iteration 98180, lr = 5.44657e-09
I0317 16:14:36.329198 29479 solver.cpp:613] Iteration 98180, avg_grad_norm = 495730
I0317 16:17:04.760754 29479 solver.cpp:214] Iteration 98200, loss = 5335.28
I0317 16:17:04.760895 29479 solver.cpp:229]     Train net output #0: loss = 3447.83 (* 1 = 3447.83 loss)
I0317 16:17:04.925438 29479 solver.cpp:610] Iteration 98200, lr = 5.4456e-09
I0317 16:17:04.925451 29479 solver.cpp:613] Iteration 98200, avg_grad_norm = 518618
I0317 16:19:33.431920 29479 solver.cpp:214] Iteration 98220, loss = 5554.24
I0317 16:19:33.432037 29479 solver.cpp:229]     Train net output #0: loss = 9111.37 (* 1 = 9111.37 loss)
I0317 16:19:34.508301 29479 solver.cpp:610] Iteration 98220, lr = 5.44464e-09
I0317 16:19:34.508318 29479 solver.cpp:613] Iteration 98220, avg_grad_norm = 469692
I0317 16:22:02.982656 29479 solver.cpp:214] Iteration 98240, loss = 5512.06
I0317 16:22:02.982851 29479 solver.cpp:229]     Train net output #0: loss = 3668.23 (* 1 = 3668.23 loss)
I0317 16:22:03.142632 29479 solver.cpp:610] Iteration 98240, lr = 5.44368e-09
I0317 16:22:03.142647 29479 solver.cpp:613] Iteration 98240, avg_grad_norm = 489763
I0317 16:24:31.652987 29479 solver.cpp:214] Iteration 98260, loss = 5448.64
I0317 16:24:31.653185 29479 solver.cpp:229]     Train net output #0: loss = 7965.17 (* 1 = 7965.17 loss)
I0317 16:24:32.727246 29479 solver.cpp:610] Iteration 98260, lr = 5.44271e-09
I0317 16:24:32.727262 29479 solver.cpp:613] Iteration 98260, avg_grad_norm = 495801
I0317 16:27:01.206184 29479 solver.cpp:214] Iteration 98280, loss = 5649.94
I0317 16:27:01.206323 29479 solver.cpp:229]     Train net output #0: loss = 5509.55 (* 1 = 5509.55 loss)
I0317 16:27:01.354473 29479 solver.cpp:610] Iteration 98280, lr = 5.44175e-09
I0317 16:27:01.354487 29479 solver.cpp:613] Iteration 98280, avg_grad_norm = 493716
I0317 16:29:00.684139 29479 solver.cpp:214] Iteration 98300, loss = 5653.28
I0317 16:29:00.684283 29479 solver.cpp:229]     Train net output #0: loss = 3944.5 (* 1 = 3944.5 loss)
I0317 16:29:01.723536 29479 solver.cpp:610] Iteration 98300, lr = 5.44079e-09
I0317 16:29:01.723552 29479 solver.cpp:613] Iteration 98300, avg_grad_norm = 510008
I0317 16:31:29.321424 29479 solver.cpp:214] Iteration 98320, loss = 5428.09
I0317 16:31:29.321548 29479 solver.cpp:229]     Train net output #0: loss = 8454.23 (* 1 = 8454.23 loss)
I0317 16:31:30.404630 29479 solver.cpp:610] Iteration 98320, lr = 5.43983e-09
I0317 16:31:30.404645 29479 solver.cpp:613] Iteration 98320, avg_grad_norm = 508627
I0317 16:33:58.867640 29479 solver.cpp:214] Iteration 98340, loss = 5778.57
I0317 16:33:58.867833 29479 solver.cpp:229]     Train net output #0: loss = 6850.96 (* 1 = 6850.96 loss)
I0317 16:33:59.021222 29479 solver.cpp:610] Iteration 98340, lr = 5.43886e-09
I0317 16:33:59.021236 29479 solver.cpp:613] Iteration 98340, avg_grad_norm = 495842
I0317 16:36:27.506567 29479 solver.cpp:214] Iteration 98360, loss = 5258.85
I0317 16:36:27.506690 29479 solver.cpp:229]     Train net output #0: loss = 3828.46 (* 1 = 3828.46 loss)
I0317 16:36:28.599285 29479 solver.cpp:610] Iteration 98360, lr = 5.4379e-09
I0317 16:36:28.599300 29479 solver.cpp:613] Iteration 98360, avg_grad_norm = 467241
I0317 16:38:58.083547 29479 solver.cpp:214] Iteration 98380, loss = 5549.84
I0317 16:38:58.083667 29479 solver.cpp:229]     Train net output #0: loss = 5183.37 (* 1 = 5183.37 loss)
I0317 16:38:58.258839 29479 solver.cpp:610] Iteration 98380, lr = 5.43694e-09
I0317 16:38:58.258852 29479 solver.cpp:613] Iteration 98380, avg_grad_norm = 496128
I0317 16:41:25.752998 29479 solver.cpp:214] Iteration 98400, loss = 5469.31
I0317 16:41:25.753199 29479 solver.cpp:229]     Train net output #0: loss = 5670.95 (* 1 = 5670.95 loss)
I0317 16:41:26.795647 29479 solver.cpp:610] Iteration 98400, lr = 5.43597e-09
I0317 16:41:26.795668 29479 solver.cpp:613] Iteration 98400, avg_grad_norm = 472127
I0317 16:44:07.409742 29479 solver.cpp:214] Iteration 98420, loss = 5491.3
I0317 16:44:07.409853 29479 solver.cpp:229]     Train net output #0: loss = 5023.05 (* 1 = 5023.05 loss)
I0317 16:44:08.478035 29479 solver.cpp:610] Iteration 98420, lr = 5.43501e-09
I0317 16:44:08.478050 29479 solver.cpp:613] Iteration 98420, avg_grad_norm = 536421
I0317 16:46:36.913187 29479 solver.cpp:214] Iteration 98440, loss = 5400.76
I0317 16:46:36.913300 29479 solver.cpp:229]     Train net output #0: loss = 3970.16 (* 1 = 3970.16 loss)
I0317 16:46:37.087743 29479 solver.cpp:610] Iteration 98440, lr = 5.43405e-09
I0317 16:46:37.087757 29479 solver.cpp:613] Iteration 98440, avg_grad_norm = 474508
I0317 16:48:08.493793 29479 solver.cpp:214] Iteration 98460, loss = 5790.98
I0317 16:48:08.493924 29479 solver.cpp:229]     Train net output #0: loss = 7386.34 (* 1 = 7386.34 loss)
I0317 16:48:08.599385 29479 solver.cpp:610] Iteration 98460, lr = 5.43308e-09
I0317 16:48:08.599407 29479 solver.cpp:613] Iteration 98460, avg_grad_norm = 539495
I0317 16:49:56.108924 29479 solver.cpp:214] Iteration 98480, loss = 5672.26
I0317 16:49:56.109159 29479 solver.cpp:229]     Train net output #0: loss = 8552.99 (* 1 = 8552.99 loss)
I0317 16:49:57.187028 29479 solver.cpp:610] Iteration 98480, lr = 5.43212e-09
I0317 16:49:57.187043 29479 solver.cpp:613] Iteration 98480, avg_grad_norm = 488698
I0317 16:52:24.694762 29479 solver.cpp:214] Iteration 98500, loss = 5588.86
I0317 16:52:24.694955 29479 solver.cpp:229]     Train net output #0: loss = 3472.08 (* 1 = 3472.08 loss)
I0317 16:52:24.848263 29479 solver.cpp:610] Iteration 98500, lr = 5.43116e-09
I0317 16:52:24.848276 29479 solver.cpp:613] Iteration 98500, avg_grad_norm = 496551
I0317 16:54:52.310492 29479 solver.cpp:214] Iteration 98520, loss = 5497.62
I0317 16:54:52.310686 29479 solver.cpp:229]     Train net output #0: loss = 5319.1 (* 1 = 5319.1 loss)
I0317 16:54:53.356477 29479 solver.cpp:610] Iteration 98520, lr = 5.4302e-09
I0317 16:54:53.356494 29479 solver.cpp:613] Iteration 98520, avg_grad_norm = 508788
I0317 16:57:21.935930 29479 solver.cpp:214] Iteration 98540, loss = 5802.02
I0317 16:57:21.936064 29479 solver.cpp:229]     Train net output #0: loss = 4861.57 (* 1 = 4861.57 loss)
I0317 16:57:22.979147 29479 solver.cpp:610] Iteration 98540, lr = 5.42923e-09
I0317 16:57:22.979162 29479 solver.cpp:613] Iteration 98540, avg_grad_norm = 594932
I0317 17:00:09.477892 29479 solver.cpp:214] Iteration 98560, loss = 5799.68
I0317 17:00:09.478034 29479 solver.cpp:229]     Train net output #0: loss = 6842.63 (* 1 = 6842.63 loss)
I0317 17:00:09.641742 29479 solver.cpp:610] Iteration 98560, lr = 5.42827e-09
I0317 17:00:09.641757 29479 solver.cpp:613] Iteration 98560, avg_grad_norm = 586092
I0317 17:02:38.142374 29479 solver.cpp:214] Iteration 98580, loss = 5610.63
I0317 17:02:38.142576 29479 solver.cpp:229]     Train net output #0: loss = 7519.69 (* 1 = 7519.69 loss)
I0317 17:02:39.197675 29479 solver.cpp:610] Iteration 98580, lr = 5.42731e-09
I0317 17:02:39.197690 29479 solver.cpp:613] Iteration 98580, avg_grad_norm = 500050
I0317 17:05:07.759228 29479 solver.cpp:214] Iteration 98600, loss = 5602.89
I0317 17:05:07.759362 29479 solver.cpp:229]     Train net output #0: loss = 2275.45 (* 1 = 2275.45 loss)
I0317 17:05:08.803879 29479 solver.cpp:610] Iteration 98600, lr = 5.42634e-09
I0317 17:05:08.803891 29479 solver.cpp:613] Iteration 98600, avg_grad_norm = 520944
I0317 17:07:37.407425 29479 solver.cpp:214] Iteration 98620, loss = 5621.73
I0317 17:07:37.407548 29479 solver.cpp:229]     Train net output #0: loss = 7895.69 (* 1 = 7895.69 loss)
I0317 17:07:38.442747 29479 solver.cpp:610] Iteration 98620, lr = 5.42538e-09
I0317 17:07:38.442761 29479 solver.cpp:613] Iteration 98620, avg_grad_norm = 513691
I0317 17:08:58.039180 29479 solver.cpp:214] Iteration 98640, loss = 5470.79
I0317 17:08:58.039327 29479 solver.cpp:229]     Train net output #0: loss = 11708.4 (* 1 = 11708.4 loss)
I0317 17:08:59.124956 29479 solver.cpp:610] Iteration 98640, lr = 5.42442e-09
I0317 17:08:59.124971 29479 solver.cpp:613] Iteration 98640, avg_grad_norm = 487133
I0317 17:11:25.615008 29479 solver.cpp:214] Iteration 98660, loss = 5635.86
I0317 17:11:25.615144 29479 solver.cpp:229]     Train net output #0: loss = 10678.4 (* 1 = 10678.4 loss)
I0317 17:11:26.667153 29479 solver.cpp:610] Iteration 98660, lr = 5.42345e-09
I0317 17:11:26.667170 29479 solver.cpp:613] Iteration 98660, avg_grad_norm = 521169
I0317 17:14:16.283215 29479 solver.cpp:214] Iteration 98680, loss = 5423.77
I0317 17:14:16.283372 29479 solver.cpp:229]     Train net output #0: loss = 3946.75 (* 1 = 3946.75 loss)
I0317 17:14:17.316203 29479 solver.cpp:610] Iteration 98680, lr = 5.42249e-09
I0317 17:14:17.316218 29479 solver.cpp:613] Iteration 98680, avg_grad_norm = 507850
I0317 17:16:45.944689 29479 solver.cpp:214] Iteration 98700, loss = 5416.27
I0317 17:16:45.944839 29479 solver.cpp:229]     Train net output #0: loss = 1853.37 (* 1 = 1853.37 loss)
I0317 17:16:46.987926 29479 solver.cpp:610] Iteration 98700, lr = 5.42153e-09
I0317 17:16:46.987944 29479 solver.cpp:613] Iteration 98700, avg_grad_norm = 533444
I0317 17:19:15.548269 29479 solver.cpp:214] Iteration 98720, loss = 5416.39
I0317 17:19:15.548444 29479 solver.cpp:229]     Train net output #0: loss = 3458.64 (* 1 = 3458.64 loss)
I0317 17:19:15.701958 29479 solver.cpp:610] Iteration 98720, lr = 5.42056e-09
I0317 17:19:15.701972 29479 solver.cpp:613] Iteration 98720, avg_grad_norm = 516473
I0317 17:21:43.211925 29479 solver.cpp:214] Iteration 98740, loss = 5692.52
I0317 17:21:43.212015 29479 solver.cpp:229]     Train net output #0: loss = 5114.93 (* 1 = 5114.93 loss)
I0317 17:21:44.288053 29479 solver.cpp:610] Iteration 98740, lr = 5.4196e-09
I0317 17:21:44.288069 29479 solver.cpp:613] Iteration 98740, avg_grad_norm = 500366
I0317 17:24:12.810781 29479 solver.cpp:214] Iteration 98760, loss = 5564.79
I0317 17:24:12.810915 29479 solver.cpp:229]     Train net output #0: loss = 4337.5 (* 1 = 4337.5 loss)
I0317 17:24:13.892153 29479 solver.cpp:610] Iteration 98760, lr = 5.41863e-09
I0317 17:24:13.892168 29479 solver.cpp:613] Iteration 98760, avg_grad_norm = 484251
I0317 17:26:42.404464 29479 solver.cpp:214] Iteration 98780, loss = 5773.53
I0317 17:26:42.404594 29479 solver.cpp:229]     Train net output #0: loss = 2821.32 (* 1 = 2821.32 loss)
I0317 17:26:43.478519 29479 solver.cpp:610] Iteration 98780, lr = 5.41767e-09
I0317 17:26:43.478533 29479 solver.cpp:613] Iteration 98780, avg_grad_norm = 477374
I0317 17:28:40.957942 29479 solver.cpp:214] Iteration 98800, loss = 5599.95
I0317 17:28:40.958091 29479 solver.cpp:229]     Train net output #0: loss = 12400.9 (* 1 = 12400.9 loss)
I0317 17:28:41.063773 29479 solver.cpp:610] Iteration 98800, lr = 5.41671e-09
I0317 17:28:41.063786 29479 solver.cpp:613] Iteration 98800, avg_grad_norm = 479811
I0317 17:31:34.487057 29479 solver.cpp:214] Iteration 98820, loss = 5624.06
I0317 17:31:34.487236 29479 solver.cpp:229]     Train net output #0: loss = 4771.29 (* 1 = 4771.29 loss)
I0317 17:31:34.648624 29479 solver.cpp:610] Iteration 98820, lr = 5.41575e-09
I0317 17:31:34.648638 29479 solver.cpp:613] Iteration 98820, avg_grad_norm = 526795
I0317 17:34:04.056128 29479 solver.cpp:214] Iteration 98840, loss = 5661.83
I0317 17:34:04.056252 29479 solver.cpp:229]     Train net output #0: loss = 2706.75 (* 1 = 2706.75 loss)
I0317 17:34:04.219647 29479 solver.cpp:610] Iteration 98840, lr = 5.41478e-09
I0317 17:34:04.219661 29479 solver.cpp:613] Iteration 98840, avg_grad_norm = 510178
I0317 17:36:32.741652 29479 solver.cpp:214] Iteration 98860, loss = 5626.29
I0317 17:36:32.741832 29479 solver.cpp:229]     Train net output #0: loss = 4717.75 (* 1 = 4717.75 loss)
I0317 17:36:33.810463 29479 solver.cpp:610] Iteration 98860, lr = 5.41382e-09
I0317 17:36:33.810478 29479 solver.cpp:613] Iteration 98860, avg_grad_norm = 516692
I0317 17:39:02.267061 29479 solver.cpp:214] Iteration 98880, loss = 5494.61
I0317 17:39:02.267197 29479 solver.cpp:229]     Train net output #0: loss = 6838.8 (* 1 = 6838.8 loss)
I0317 17:39:02.422911 29479 solver.cpp:610] Iteration 98880, lr = 5.41285e-09
I0317 17:39:02.422925 29479 solver.cpp:613] Iteration 98880, avg_grad_norm = 490927
I0317 17:41:30.940965 29479 solver.cpp:214] Iteration 98900, loss = 5505.5
I0317 17:41:30.941082 29479 solver.cpp:229]     Train net output #0: loss = 4950.91 (* 1 = 4950.91 loss)
I0317 17:41:32.019857 29479 solver.cpp:610] Iteration 98900, lr = 5.41189e-09
I0317 17:41:32.019871 29479 solver.cpp:613] Iteration 98900, avg_grad_norm = 499417
I0317 17:44:00.525897 29479 solver.cpp:214] Iteration 98920, loss = 5635.27
I0317 17:44:00.526036 29479 solver.cpp:229]     Train net output #0: loss = 4346.99 (* 1 = 4346.99 loss)
I0317 17:44:00.680708 29479 solver.cpp:610] Iteration 98920, lr = 5.41093e-09
I0317 17:44:00.680742 29479 solver.cpp:613] Iteration 98920, avg_grad_norm = 503956
I0317 17:46:52.188011 29479 solver.cpp:214] Iteration 98940, loss = 5304.04
I0317 17:46:52.188205 29479 solver.cpp:229]     Train net output #0: loss = 3232.82 (* 1 = 3232.82 loss)
I0317 17:46:53.271050 29479 solver.cpp:610] Iteration 98940, lr = 5.40996e-09
I0317 17:46:53.271065 29479 solver.cpp:613] Iteration 98940, avg_grad_norm = 476129
I0317 17:49:03.770601 29479 solver.cpp:214] Iteration 98960, loss = 5685.52
I0317 17:49:03.770769 29479 solver.cpp:229]     Train net output #0: loss = 4415.85 (* 1 = 4415.85 loss)
I0317 17:49:03.874799 29479 solver.cpp:610] Iteration 98960, lr = 5.409e-09
I0317 17:49:03.874811 29479 solver.cpp:613] Iteration 98960, avg_grad_norm = 502342
I0317 17:50:41.353934 29479 solver.cpp:214] Iteration 98980, loss = 5937.41
I0317 17:50:41.354142 29479 solver.cpp:229]     Train net output #0: loss = 7259.89 (* 1 = 7259.89 loss)
I0317 17:50:42.398506 29479 solver.cpp:610] Iteration 98980, lr = 5.40804e-09
I0317 17:50:42.398520 29479 solver.cpp:613] Iteration 98980, avg_grad_norm = 492225
I0317 17:53:09.039485 29479 solver.cpp:214] Iteration 99000, loss = 5417.38
I0317 17:53:09.039610 29479 solver.cpp:229]     Train net output #0: loss = 7392.47 (* 1 = 7392.47 loss)
I0317 17:53:10.112025 29479 solver.cpp:610] Iteration 99000, lr = 5.40707e-09
I0317 17:53:10.112038 29479 solver.cpp:613] Iteration 99000, avg_grad_norm = 547341
I0317 17:55:37.702050 29479 solver.cpp:214] Iteration 99020, loss = 5613.38
I0317 17:55:37.702185 29479 solver.cpp:229]     Train net output #0: loss = 4184.87 (* 1 = 4184.87 loss)
I0317 17:55:38.780163 29479 solver.cpp:610] Iteration 99020, lr = 5.40611e-09
I0317 17:55:38.780177 29479 solver.cpp:613] Iteration 99020, avg_grad_norm = 512517
I0317 17:58:07.222790 29479 solver.cpp:214] Iteration 99040, loss = 5513.03
I0317 17:58:07.222977 29479 solver.cpp:229]     Train net output #0: loss = 6303.15 (* 1 = 6303.15 loss)
I0317 17:58:07.391546 29479 solver.cpp:610] Iteration 99040, lr = 5.40515e-09
I0317 17:58:07.391561 29479 solver.cpp:613] Iteration 99040, avg_grad_norm = 526626
I0317 18:00:48.845880 29479 solver.cpp:214] Iteration 99060, loss = 5603.99
I0317 18:00:48.846017 29479 solver.cpp:229]     Train net output #0: loss = 3280.28 (* 1 = 3280.28 loss)
I0317 18:00:49.003614 29479 solver.cpp:610] Iteration 99060, lr = 5.40418e-09
I0317 18:00:49.003628 29479 solver.cpp:613] Iteration 99060, avg_grad_norm = 501973
I0317 18:03:17.457677 29479 solver.cpp:214] Iteration 99080, loss = 5433.82
I0317 18:03:17.457803 29479 solver.cpp:229]     Train net output #0: loss = 6719.14 (* 1 = 6719.14 loss)
I0317 18:03:18.498134 29479 solver.cpp:610] Iteration 99080, lr = 5.40322e-09
I0317 18:03:18.498148 29479 solver.cpp:613] Iteration 99080, avg_grad_norm = 492992
I0317 18:05:45.107256 29479 solver.cpp:214] Iteration 99100, loss = 5839.95
I0317 18:05:45.107394 29479 solver.cpp:229]     Train net output #0: loss = 7265.81 (* 1 = 7265.81 loss)
I0317 18:05:46.195869 29479 solver.cpp:610] Iteration 99100, lr = 5.40226e-09
I0317 18:05:46.195884 29479 solver.cpp:613] Iteration 99100, avg_grad_norm = 515607
I0317 18:08:13.577431 29479 solver.cpp:214] Iteration 99120, loss = 5750.92
I0317 18:08:13.577555 29479 solver.cpp:229]     Train net output #0: loss = 4250.72 (* 1 = 4250.72 loss)
I0317 18:08:13.800395 29479 solver.cpp:610] Iteration 99120, lr = 5.40129e-09
I0317 18:08:13.800410 29479 solver.cpp:613] Iteration 99120, avg_grad_norm = 572481
I0317 18:09:33.307518 29479 solver.cpp:214] Iteration 99140, loss = 5976.73
I0317 18:09:33.307632 29479 solver.cpp:229]     Train net output #0: loss = 4982.13 (* 1 = 4982.13 loss)
I0317 18:09:34.375828 29479 solver.cpp:610] Iteration 99140, lr = 5.40033e-09
I0317 18:09:34.375841 29479 solver.cpp:613] Iteration 99140, avg_grad_norm = 499584
I0317 18:12:01.948655 29479 solver.cpp:214] Iteration 99160, loss = 5636.24
I0317 18:12:01.948849 29479 solver.cpp:229]     Train net output #0: loss = 7826.36 (* 1 = 7826.36 loss)
I0317 18:12:03.022773 29479 solver.cpp:610] Iteration 99160, lr = 5.39936e-09
I0317 18:12:03.022788 29479 solver.cpp:613] Iteration 99160, avg_grad_norm = 483860
I0317 18:14:32.550076 29479 solver.cpp:214] Iteration 99180, loss = 5724.64
I0317 18:14:32.550209 29479 solver.cpp:229]     Train net output #0: loss = 7105.55 (* 1 = 7105.55 loss)
I0317 18:14:33.636723 29479 solver.cpp:610] Iteration 99180, lr = 5.3984e-09
I0317 18:14:33.636741 29479 solver.cpp:613] Iteration 99180, avg_grad_norm = 480850
I0317 18:17:16.164016 29479 solver.cpp:214] Iteration 99200, loss = 5705.34
I0317 18:17:16.164201 29479 solver.cpp:229]     Train net output #0: loss = 8121.99 (* 1 = 8121.99 loss)
I0317 18:17:17.211485 29479 solver.cpp:610] Iteration 99200, lr = 5.39744e-09
I0317 18:17:17.211499 29479 solver.cpp:613] Iteration 99200, avg_grad_norm = 500823
I0317 18:19:45.812005 29479 solver.cpp:214] Iteration 99220, loss = 5700.45
I0317 18:19:45.812134 29479 solver.cpp:229]     Train net output #0: loss = 3215.73 (* 1 = 3215.73 loss)
I0317 18:19:46.851924 29479 solver.cpp:610] Iteration 99220, lr = 5.39647e-09
I0317 18:19:46.851938 29479 solver.cpp:613] Iteration 99220, avg_grad_norm = 495382
I0317 18:22:14.419910 29479 solver.cpp:214] Iteration 99240, loss = 5638.13
I0317 18:22:14.420043 29479 solver.cpp:229]     Train net output #0: loss = 12158.3 (* 1 = 12158.3 loss)
I0317 18:22:15.494256 29479 solver.cpp:610] Iteration 99240, lr = 5.39551e-09
I0317 18:22:15.494271 29479 solver.cpp:613] Iteration 99240, avg_grad_norm = 494604
I0317 18:24:44.064913 29479 solver.cpp:214] Iteration 99260, loss = 5521.01
I0317 18:24:44.065124 29479 solver.cpp:229]     Train net output #0: loss = 6353.33 (* 1 = 6353.33 loss)
I0317 18:24:45.143105 29479 solver.cpp:610] Iteration 99260, lr = 5.39454e-09
I0317 18:24:45.143121 29479 solver.cpp:613] Iteration 99260, avg_grad_norm = 531440
I0317 18:27:13.720286 29479 solver.cpp:214] Iteration 99280, loss = 5766.72
I0317 18:27:13.720422 29479 solver.cpp:229]     Train net output #0: loss = 5060.97 (* 1 = 5060.97 loss)
I0317 18:27:14.796843 29479 solver.cpp:610] Iteration 99280, lr = 5.39358e-09
I0317 18:27:14.796857 29479 solver.cpp:613] Iteration 99280, avg_grad_norm = 574796
I0317 18:29:37.263090 29479 solver.cpp:214] Iteration 99300, loss = 5551.32
I0317 18:29:37.263242 29479 solver.cpp:229]     Train net output #0: loss = 3950.73 (* 1 = 3950.73 loss)
I0317 18:29:37.367377 29479 solver.cpp:610] Iteration 99300, lr = 5.39262e-09
I0317 18:29:37.367391 29479 solver.cpp:613] Iteration 99300, avg_grad_norm = 500196
I0317 18:31:30.149672 29479 solver.cpp:214] Iteration 99320, loss = 5643.94
I0317 18:31:30.149799 29479 solver.cpp:229]     Train net output #0: loss = 5554.69 (* 1 = 5554.69 loss)
I0317 18:31:30.320369 29479 solver.cpp:610] Iteration 99320, lr = 5.39165e-09
I0317 18:31:30.320381 29479 solver.cpp:613] Iteration 99320, avg_grad_norm = 483748
I0317 18:33:58.817565 29479 solver.cpp:214] Iteration 99340, loss = 5408.77
I0317 18:33:58.817713 29479 solver.cpp:229]     Train net output #0: loss = 4585.84 (* 1 = 4585.84 loss)
I0317 18:33:59.858360 29479 solver.cpp:610] Iteration 99340, lr = 5.39069e-09
I0317 18:33:59.858374 29479 solver.cpp:613] Iteration 99340, avg_grad_norm = 505385
I0317 18:36:27.463773 29479 solver.cpp:214] Iteration 99360, loss = 5475.99
I0317 18:36:27.463891 29479 solver.cpp:229]     Train net output #0: loss = 6645.35 (* 1 = 6645.35 loss)
I0317 18:36:28.543663 29479 solver.cpp:610] Iteration 99360, lr = 5.38972e-09
I0317 18:36:28.543678 29479 solver.cpp:613] Iteration 99360, avg_grad_norm = 473076
I0317 18:38:57.047314 29479 solver.cpp:214] Iteration 99380, loss = 5635.66
I0317 18:38:57.047452 29479 solver.cpp:229]     Train net output #0: loss = 4396.34 (* 1 = 4396.34 loss)
I0317 18:38:57.203761 29479 solver.cpp:610] Iteration 99380, lr = 5.38876e-09
I0317 18:38:57.203775 29479 solver.cpp:613] Iteration 99380, avg_grad_norm = 480857
I0317 18:41:24.715914 29479 solver.cpp:214] Iteration 99400, loss = 5644.66
I0317 18:41:24.716037 29479 solver.cpp:229]     Train net output #0: loss = 6148.65 (* 1 = 6148.65 loss)
I0317 18:41:25.790143 29479 solver.cpp:610] Iteration 99400, lr = 5.3878e-09
I0317 18:41:25.790156 29479 solver.cpp:613] Iteration 99400, avg_grad_norm = 490989
I0317 18:43:54.252321 29479 solver.cpp:214] Iteration 99420, loss = 5799.17
I0317 18:43:54.252455 29479 solver.cpp:229]     Train net output #0: loss = 6340.79 (* 1 = 6340.79 loss)
I0317 18:43:54.432288 29479 solver.cpp:610] Iteration 99420, lr = 5.38683e-09
I0317 18:43:54.432302 29479 solver.cpp:613] Iteration 99420, avg_grad_norm = 556585
I0317 18:47:06.022194 29479 solver.cpp:214] Iteration 99440, loss = 5749.81
I0317 18:47:06.022367 29479 solver.cpp:229]     Train net output #0: loss = 4139.25 (* 1 = 4139.25 loss)
I0317 18:47:06.183826 29479 solver.cpp:610] Iteration 99440, lr = 5.38587e-09
I0317 18:47:06.183840 29479 solver.cpp:613] Iteration 99440, avg_grad_norm = 482359
I0317 18:49:34.604864 29479 solver.cpp:214] Iteration 99460, loss = 5760.55
I0317 18:49:34.605154 29479 solver.cpp:229]     Train net output #0: loss = 6310.55 (* 1 = 6310.55 loss)
I0317 18:49:34.758584 29479 solver.cpp:610] Iteration 99460, lr = 5.3849e-09
I0317 18:49:34.758599 29479 solver.cpp:613] Iteration 99460, avg_grad_norm = 494151
I0317 18:50:37.246523 29479 solver.cpp:214] Iteration 99480, loss = 5585.68
I0317 18:50:37.246678 29479 solver.cpp:229]     Train net output #0: loss = 11550.1 (* 1 = 11550.1 loss)
I0317 18:50:38.286176 29479 solver.cpp:610] Iteration 99480, lr = 5.38394e-09
I0317 18:50:38.286192 29479 solver.cpp:613] Iteration 99480, avg_grad_norm = 489996
I0317 18:53:06.853345 29479 solver.cpp:214] Iteration 99500, loss = 5519.31
I0317 18:53:06.853454 29479 solver.cpp:229]     Train net output #0: loss = 6038.49 (* 1 = 6038.49 loss)
I0317 18:53:07.903388 29479 solver.cpp:610] Iteration 99500, lr = 5.38298e-09
I0317 18:53:07.903403 29479 solver.cpp:613] Iteration 99500, avg_grad_norm = 461519
I0317 18:55:36.452805 29479 solver.cpp:214] Iteration 99520, loss = 5543.56
I0317 18:55:36.452999 29479 solver.cpp:229]     Train net output #0: loss = 4686.01 (* 1 = 4686.01 loss)
I0317 18:55:37.537398 29479 solver.cpp:610] Iteration 99520, lr = 5.38201e-09
I0317 18:55:37.537413 29479 solver.cpp:613] Iteration 99520, avg_grad_norm = 468466
I0317 18:57:55.145187 29479 solver.cpp:214] Iteration 99540, loss = 5725.72
I0317 18:57:55.145303 29479 solver.cpp:229]     Train net output #0: loss = 9674.86 (* 1 = 9674.86 loss)
I0317 18:57:56.219295 29479 solver.cpp:610] Iteration 99540, lr = 5.38105e-09
I0317 18:57:56.219315 29479 solver.cpp:613] Iteration 99540, avg_grad_norm = 520349
I0317 19:00:24.747547 29479 solver.cpp:214] Iteration 99560, loss = 5582.94
I0317 19:00:24.747656 29479 solver.cpp:229]     Train net output #0: loss = 3107.52 (* 1 = 3107.52 loss)
I0317 19:00:24.917054 29479 solver.cpp:610] Iteration 99560, lr = 5.38008e-09
I0317 19:00:24.917068 29479 solver.cpp:613] Iteration 99560, avg_grad_norm = 459593
I0317 19:03:20.405216 29479 solver.cpp:214] Iteration 99580, loss = 5920.94
I0317 19:03:20.405341 29479 solver.cpp:229]     Train net output #0: loss = 3340.57 (* 1 = 3340.57 loss)
I0317 19:03:21.445911 29479 solver.cpp:610] Iteration 99580, lr = 5.37912e-09
I0317 19:03:21.445925 29479 solver.cpp:613] Iteration 99580, avg_grad_norm = 505446
I0317 19:05:48.059409 29479 solver.cpp:214] Iteration 99600, loss = 5660.89
I0317 19:05:48.059525 29479 solver.cpp:229]     Train net output #0: loss = 6155.52 (* 1 = 6155.52 loss)
I0317 19:05:49.129842 29479 solver.cpp:610] Iteration 99600, lr = 5.37816e-09
I0317 19:05:49.129855 29479 solver.cpp:613] Iteration 99600, avg_grad_norm = 538554
I0317 19:08:17.573387 29479 solver.cpp:214] Iteration 99620, loss = 5472.32
I0317 19:08:17.573509 29479 solver.cpp:229]     Train net output #0: loss = 3629.57 (* 1 = 3629.57 loss)
I0317 19:08:17.742779 29479 solver.cpp:610] Iteration 99620, lr = 5.37719e-09
I0317 19:08:17.742791 29479 solver.cpp:613] Iteration 99620, avg_grad_norm = 495320
I0317 19:10:15.181973 29479 solver.cpp:214] Iteration 99640, loss = 5302.79
I0317 19:10:15.182113 29479 solver.cpp:229]     Train net output #0: loss = 7655.08 (* 1 = 7655.08 loss)
I0317 19:10:15.286202 29479 solver.cpp:610] Iteration 99640, lr = 5.37623e-09
I0317 19:10:15.286216 29479 solver.cpp:613] Iteration 99640, avg_grad_norm = 481153
I0317 19:12:00.755688 29479 solver.cpp:214] Iteration 99660, loss = 5640.74
I0317 19:12:00.755895 29479 solver.cpp:229]     Train net output #0: loss = 6501.78 (* 1 = 6501.78 loss)
I0317 19:12:01.792601 29479 solver.cpp:610] Iteration 99660, lr = 5.37526e-09
I0317 19:12:01.792615 29479 solver.cpp:613] Iteration 99660, avg_grad_norm = 501094
I0317 19:14:30.358299 29479 solver.cpp:214] Iteration 99680, loss = 5551.49
I0317 19:14:30.358481 29479 solver.cpp:229]     Train net output #0: loss = 3402.92 (* 1 = 3402.92 loss)
I0317 19:14:31.402295 29479 solver.cpp:610] Iteration 99680, lr = 5.3743e-09
I0317 19:14:31.402309 29479 solver.cpp:613] Iteration 99680, avg_grad_norm = 508295
I0317 19:17:26.915143 29479 solver.cpp:214] Iteration 99700, loss = 5666.76
I0317 19:17:26.915287 29479 solver.cpp:229]     Train net output #0: loss = 2872.77 (* 1 = 2872.77 loss)
I0317 19:17:27.095088 29479 solver.cpp:610] Iteration 99700, lr = 5.37333e-09
I0317 19:17:27.095101 29479 solver.cpp:613] Iteration 99700, avg_grad_norm = 508202
I0317 19:19:54.602726 29479 solver.cpp:214] Iteration 99720, loss = 5645.65
I0317 19:19:54.602911 29479 solver.cpp:229]     Train net output #0: loss = 5662.36 (* 1 = 5662.36 loss)
I0317 19:19:55.676303 29479 solver.cpp:610] Iteration 99720, lr = 5.37237e-09
I0317 19:19:55.676318 29479 solver.cpp:613] Iteration 99720, avg_grad_norm = 502998
I0317 19:22:24.070636 29479 solver.cpp:214] Iteration 99740, loss = 5689.29
I0317 19:22:24.070732 29479 solver.cpp:229]     Train net output #0: loss = 4735.3 (* 1 = 4735.3 loss)
I0317 19:22:24.239217 29479 solver.cpp:610] Iteration 99740, lr = 5.37141e-09
I0317 19:22:24.239230 29479 solver.cpp:613] Iteration 99740, avg_grad_norm = 503429
I0317 19:24:52.791451 29479 solver.cpp:214] Iteration 99760, loss = 6044.15
I0317 19:24:52.791568 29479 solver.cpp:229]     Train net output #0: loss = 3435.5 (* 1 = 3435.5 loss)
I0317 19:24:53.839663 29479 solver.cpp:610] Iteration 99760, lr = 5.37044e-09
I0317 19:24:53.839675 29479 solver.cpp:613] Iteration 99760, avg_grad_norm = 509712
I0317 19:27:21.411746 29479 solver.cpp:214] Iteration 99780, loss = 5561.96
I0317 19:27:21.411855 29479 solver.cpp:229]     Train net output #0: loss = 5508.21 (* 1 = 5508.21 loss)
I0317 19:27:22.489801 29479 solver.cpp:610] Iteration 99780, lr = 5.36948e-09
I0317 19:27:22.489816 29479 solver.cpp:613] Iteration 99780, avg_grad_norm = 465534
I0317 19:29:51.059274 29479 solver.cpp:214] Iteration 99800, loss = 5642.29
I0317 19:29:51.059453 29479 solver.cpp:229]     Train net output #0: loss = 2823.65 (* 1 = 2823.65 loss)
I0317 19:29:52.136068 29479 solver.cpp:610] Iteration 99800, lr = 5.36851e-09
I0317 19:29:52.136082 29479 solver.cpp:613] Iteration 99800, avg_grad_norm = 569889
I0317 19:31:58.894610 29479 solver.cpp:214] Iteration 99820, loss = 5698.5
I0317 19:31:58.894721 29479 solver.cpp:229]     Train net output #0: loss = 3668.2 (* 1 = 3668.2 loss)
I0317 19:31:59.052036 29479 solver.cpp:610] Iteration 99820, lr = 5.36755e-09
I0317 19:31:59.052048 29479 solver.cpp:613] Iteration 99820, avg_grad_norm = 583858
I0317 19:34:27.502528 29479 solver.cpp:214] Iteration 99840, loss = 5561.06
I0317 19:34:27.502651 29479 solver.cpp:229]     Train net output #0: loss = 4542.97 (* 1 = 4542.97 loss)
I0317 19:34:28.587628 29479 solver.cpp:610] Iteration 99840, lr = 5.36658e-09
I0317 19:34:28.587642 29479 solver.cpp:613] Iteration 99840, avg_grad_norm = 575769
I0317 19:36:56.133546 29479 solver.cpp:214] Iteration 99860, loss = 5361.71
I0317 19:36:56.133661 29479 solver.cpp:229]     Train net output #0: loss = 5014.34 (* 1 = 5014.34 loss)
I0317 19:36:57.208361 29479 solver.cpp:610] Iteration 99860, lr = 5.36562e-09
I0317 19:36:57.208379 29479 solver.cpp:613] Iteration 99860, avg_grad_norm = 540097
I0317 19:39:25.720248 29479 solver.cpp:214] Iteration 99880, loss = 5481.03
I0317 19:39:25.720341 29479 solver.cpp:229]     Train net output #0: loss = 3447.81 (* 1 = 3447.81 loss)
I0317 19:39:26.716322 29479 solver.cpp:610] Iteration 99880, lr = 5.36465e-09
I0317 19:39:26.716336 29479 solver.cpp:613] Iteration 99880, avg_grad_norm = 499891
I0317 19:41:54.324136 29479 solver.cpp:214] Iteration 99900, loss = 5183.92
I0317 19:41:54.324273 29479 solver.cpp:229]     Train net output #0: loss = 5229.04 (* 1 = 5229.04 loss)
I0317 19:41:55.361937 29479 solver.cpp:610] Iteration 99900, lr = 5.36369e-09
I0317 19:41:55.361949 29479 solver.cpp:613] Iteration 99900, avg_grad_norm = 505854
I0317 19:44:23.902407 29479 solver.cpp:214] Iteration 99920, loss = 5768.06
I0317 19:44:23.902581 29479 solver.cpp:229]     Train net output #0: loss = 4990.86 (* 1 = 4990.86 loss)
I0317 19:44:24.073361 29479 solver.cpp:610] Iteration 99920, lr = 5.36273e-09
I0317 19:44:24.073379 29479 solver.cpp:613] Iteration 99920, avg_grad_norm = 515069
I0317 19:46:53.541178 29479 solver.cpp:214] Iteration 99940, loss = 5540.96
I0317 19:46:53.541306 29479 solver.cpp:229]     Train net output #0: loss = 8848 (* 1 = 8848 loss)
I0317 19:46:53.710173 29479 solver.cpp:610] Iteration 99940, lr = 5.36176e-09
I0317 19:46:53.710186 29479 solver.cpp:613] Iteration 99940, avg_grad_norm = 492698
I0317 19:49:50.289330 29479 solver.cpp:214] Iteration 99960, loss = 5537.22
I0317 19:49:50.289471 29479 solver.cpp:229]     Train net output #0: loss = 5543.05 (* 1 = 5543.05 loss)
I0317 19:49:51.356557 29479 solver.cpp:610] Iteration 99960, lr = 5.3608e-09
I0317 19:49:51.356575 29479 solver.cpp:613] Iteration 99960, avg_grad_norm = 499524
I0317 19:51:24.841851 29479 solver.cpp:214] Iteration 99980, loss = 5787.48
I0317 19:51:24.842003 29479 solver.cpp:229]     Train net output #0: loss = 7722.6 (* 1 = 7722.6 loss)
I0317 19:51:24.947427 29479 solver.cpp:610] Iteration 99980, lr = 5.35983e-09
I0317 19:51:24.947440 29479 solver.cpp:613] Iteration 99980, avg_grad_norm = 498357
I0317 19:53:33.472261 29479 solver.cpp:458] Snapshotting to models/pnet/VGG_VOC2012ext_iter_100000.caffemodel
I0317 19:53:34.702139 29479 solver.cpp:466] Snapshotting solver state to models/pnet/VGG_VOC2012ext_iter_100000.solverstate
I0317 19:53:42.466322 29479 solver.cpp:214] Iteration 100000, loss = 5661.51
I0317 19:53:42.466370 29479 solver.cpp:229]     Train net output #0: loss = 4390.86 (* 1 = 4390.86 loss)
I0317 19:53:42.623162 29479 solver.cpp:610] Iteration 100000, lr = 5.35887e-09
I0317 19:53:42.623175 29479 solver.cpp:613] Iteration 100000, avg_grad_norm = 577664
I0317 19:56:12.051292 29479 solver.cpp:214] Iteration 100020, loss = 5680.9
I0317 19:56:12.051501 29479 solver.cpp:229]     Train net output #0: loss = 8040.32 (* 1 = 8040.32 loss)
I0317 19:56:12.208854 29479 solver.cpp:610] Iteration 100020, lr = 5.3579e-09
I0317 19:56:12.208868 29479 solver.cpp:613] Iteration 100020, avg_grad_norm = 522257
I0317 19:58:40.701447 29479 solver.cpp:214] Iteration 100040, loss = 5513.09
I0317 19:58:40.701561 29479 solver.cpp:229]     Train net output #0: loss = 2839.94 (* 1 = 2839.94 loss)
I0317 19:58:41.735606 29479 solver.cpp:610] Iteration 100040, lr = 5.35694e-09
I0317 19:58:41.735620 29479 solver.cpp:613] Iteration 100040, avg_grad_norm = 560805
I0317 20:01:10.297845 29479 solver.cpp:214] Iteration 100060, loss = 5797.99
I0317 20:01:10.297951 29479 solver.cpp:229]     Train net output #0: loss = 7419.6 (* 1 = 7419.6 loss)
I0317 20:01:11.348256 29479 solver.cpp:610] Iteration 100060, lr = 5.35597e-09
I0317 20:01:11.348273 29479 solver.cpp:613] Iteration 100060, avg_grad_norm = 582741
I0317 20:04:01.974503 29479 solver.cpp:214] Iteration 100080, loss = 5449.01
I0317 20:04:01.974642 29479 solver.cpp:229]     Train net output #0: loss = 4163.67 (* 1 = 4163.67 loss)
I0317 20:04:03.008420 29479 solver.cpp:610] Iteration 100080, lr = 5.35501e-09
I0317 20:04:03.008435 29479 solver.cpp:613] Iteration 100080, avg_grad_norm = 491429
I0317 20:06:30.581529 29479 solver.cpp:214] Iteration 100100, loss = 5609.61
I0317 20:06:30.581739 29479 solver.cpp:229]     Train net output #0: loss = 6441.27 (* 1 = 6441.27 loss)
I0317 20:06:31.622871 29479 solver.cpp:610] Iteration 100100, lr = 5.35404e-09
I0317 20:06:31.622886 29479 solver.cpp:613] Iteration 100100, avg_grad_norm = 574194
I0317 20:08:58.189347 29479 solver.cpp:214] Iteration 100120, loss = 5750.4
I0317 20:08:58.189492 29479 solver.cpp:229]     Train net output #0: loss = 4288.31 (* 1 = 4288.31 loss)
I0317 20:08:59.247164 29479 solver.cpp:610] Iteration 100120, lr = 5.35308e-09
I0317 20:08:59.247181 29479 solver.cpp:613] Iteration 100120, avg_grad_norm = 499212
I0317 20:11:26.752014 29479 solver.cpp:214] Iteration 100140, loss = 5699.18
I0317 20:11:26.752199 29479 solver.cpp:229]     Train net output #0: loss = 5563.42 (* 1 = 5563.42 loss)
I0317 20:11:26.919332 29479 solver.cpp:610] Iteration 100140, lr = 5.35211e-09
I0317 20:11:26.919345 29479 solver.cpp:613] Iteration 100140, avg_grad_norm = 493394
I0317 20:12:46.427639 29479 solver.cpp:214] Iteration 100160, loss = 5461.39
I0317 20:12:46.427778 29479 solver.cpp:229]     Train net output #0: loss = 7808.41 (* 1 = 7808.41 loss)
I0317 20:12:47.503589 29479 solver.cpp:610] Iteration 100160, lr = 5.35115e-09
I0317 20:12:47.503604 29479 solver.cpp:613] Iteration 100160, avg_grad_norm = 559073
I0317 20:15:16.018111 29479 solver.cpp:214] Iteration 100180, loss = 5409.53
I0317 20:15:16.018244 29479 solver.cpp:229]     Train net output #0: loss = 3150.54 (* 1 = 3150.54 loss)
I0317 20:15:17.103310 29479 solver.cpp:610] Iteration 100180, lr = 5.35019e-09
I0317 20:15:17.103324 29479 solver.cpp:613] Iteration 100180, avg_grad_norm = 488941
I0317 20:18:14.591126 29479 solver.cpp:214] Iteration 100200, loss = 5259.94
I0317 20:18:14.591248 29479 solver.cpp:229]     Train net output #0: loss = 3667.62 (* 1 = 3667.62 loss)
I0317 20:18:14.755091 29479 solver.cpp:610] Iteration 100200, lr = 5.34922e-09
I0317 20:18:14.755105 29479 solver.cpp:613] Iteration 100200, avg_grad_norm = 476060
I0317 20:20:43.246464 29479 solver.cpp:214] Iteration 100220, loss = 5475.76
I0317 20:20:43.246654 29479 solver.cpp:229]     Train net output #0: loss = 4398.66 (* 1 = 4398.66 loss)
I0317 20:20:44.348912 29479 solver.cpp:610] Iteration 100220, lr = 5.34826e-09
I0317 20:20:44.348927 29479 solver.cpp:613] Iteration 100220, avg_grad_norm = 464945
I0317 20:23:11.814978 29479 solver.cpp:214] Iteration 100240, loss = 5474.37
I0317 20:23:11.815094 29479 solver.cpp:229]     Train net output #0: loss = 2749.46 (* 1 = 2749.46 loss)
I0317 20:23:11.996261 29479 solver.cpp:610] Iteration 100240, lr = 5.34729e-09
I0317 20:23:11.996276 29479 solver.cpp:613] Iteration 100240, avg_grad_norm = 521994
I0317 20:25:41.423138 29479 solver.cpp:214] Iteration 100260, loss = 5526.34
I0317 20:25:41.423259 29479 solver.cpp:229]     Train net output #0: loss = 6634.89 (* 1 = 6634.89 loss)
I0317 20:25:41.597451 29479 solver.cpp:610] Iteration 100260, lr = 5.34633e-09
I0317 20:25:41.597465 29479 solver.cpp:613] Iteration 100260, avg_grad_norm = 611288
I0317 20:28:10.059839 29479 solver.cpp:214] Iteration 100280, loss = 5480.32
I0317 20:28:10.059959 29479 solver.cpp:229]     Train net output #0: loss = 2747.62 (* 1 = 2747.62 loss)
I0317 20:28:11.100232 29479 solver.cpp:610] Iteration 100280, lr = 5.34536e-09
I0317 20:28:11.100246 29479 solver.cpp:613] Iteration 100280, avg_grad_norm = 581504
I0317 20:30:39.593335 29479 solver.cpp:214] Iteration 100300, loss = 5273.05
I0317 20:30:39.593457 29479 solver.cpp:229]     Train net output #0: loss = 3336.74 (* 1 = 3336.74 loss)
I0317 20:30:39.770987 29479 solver.cpp:610] Iteration 100300, lr = 5.3444e-09
I0317 20:30:39.771000 29479 solver.cpp:613] Iteration 100300, avg_grad_norm = 477440
I0317 20:31:58.184528 29479 solver.cpp:214] Iteration 100320, loss = 5471.14
I0317 20:31:58.184666 29479 solver.cpp:229]     Train net output #0: loss = 4718.18 (* 1 = 4718.18 loss)
I0317 20:31:58.290205 29479 solver.cpp:610] Iteration 100320, lr = 5.34343e-09
I0317 20:31:58.290241 29479 solver.cpp:613] Iteration 100320, avg_grad_norm = 488631
I0317 20:34:30.853730 29479 solver.cpp:214] Iteration 100340, loss = 5511.48
I0317 20:34:30.853868 29479 solver.cpp:229]     Train net output #0: loss = 3957.57 (* 1 = 3957.57 loss)
I0317 20:34:31.006193 29479 solver.cpp:610] Iteration 100340, lr = 5.34247e-09
I0317 20:34:31.006216 29479 solver.cpp:613] Iteration 100340, avg_grad_norm = 472674
I0317 20:36:59.467787 29479 solver.cpp:214] Iteration 100360, loss = 5607.5
I0317 20:36:59.467959 29479 solver.cpp:229]     Train net output #0: loss = 4581.88 (* 1 = 4581.88 loss)
I0317 20:37:00.516616 29479 solver.cpp:610] Iteration 100360, lr = 5.3415e-09
I0317 20:37:00.516629 29479 solver.cpp:613] Iteration 100360, avg_grad_norm = 460103
I0317 20:39:28.144292 29479 solver.cpp:214] Iteration 100380, loss = 5349.45
I0317 20:39:28.144475 29479 solver.cpp:229]     Train net output #0: loss = 4870.63 (* 1 = 4870.63 loss)
I0317 20:39:29.234467 29479 solver.cpp:610] Iteration 100380, lr = 5.34054e-09
I0317 20:39:29.234484 29479 solver.cpp:613] Iteration 100380, avg_grad_norm = 457368
I0317 20:41:57.770731 29479 solver.cpp:214] Iteration 100400, loss = 5638.18
I0317 20:41:57.770825 29479 solver.cpp:229]     Train net output #0: loss = 2923.68 (* 1 = 2923.68 loss)
I0317 20:41:58.827558 29479 solver.cpp:610] Iteration 100400, lr = 5.33957e-09
I0317 20:41:58.827572 29479 solver.cpp:613] Iteration 100400, avg_grad_norm = 479929
I0317 20:44:27.383373 29479 solver.cpp:214] Iteration 100420, loss = 5322.49
I0317 20:44:27.383481 29479 solver.cpp:229]     Train net output #0: loss = 6383.09 (* 1 = 6383.09 loss)
I0317 20:44:28.420761 29479 solver.cpp:610] Iteration 100420, lr = 5.33861e-09
I0317 20:44:28.420775 29479 solver.cpp:613] Iteration 100420, avg_grad_norm = 499349
I0317 20:46:56.044535 29479 solver.cpp:214] Iteration 100440, loss = 5405.58
I0317 20:46:56.044646 29479 solver.cpp:229]     Train net output #0: loss = 3003.52 (* 1 = 3003.52 loss)
I0317 20:46:57.127514 29479 solver.cpp:610] Iteration 100440, lr = 5.33764e-09
I0317 20:46:57.127532 29479 solver.cpp:613] Iteration 100440, avg_grad_norm = 457914
I0317 20:50:03.669335 29479 solver.cpp:214] Iteration 100460, loss = 5371.31
I0317 20:50:03.669456 29479 solver.cpp:229]     Train net output #0: loss = 7619.78 (* 1 = 7619.78 loss)
I0317 20:50:03.830204 29479 solver.cpp:610] Iteration 100460, lr = 5.33668e-09
I0317 20:50:03.830219 29479 solver.cpp:613] Iteration 100460, avg_grad_norm = 482492
I0317 20:52:03.266919 29479 solver.cpp:214] Iteration 100480, loss = 5539.58
I0317 20:52:03.267058 29479 solver.cpp:229]     Train net output #0: loss = 3235.31 (* 1 = 3235.31 loss)
I0317 20:52:03.371376 29479 solver.cpp:610] Iteration 100480, lr = 5.33571e-09
I0317 20:52:03.371390 29479 solver.cpp:613] Iteration 100480, avg_grad_norm = 553331
I0317 20:53:49.799270 29479 solver.cpp:214] Iteration 100500, loss = 5873.91
I0317 20:53:49.799386 29479 solver.cpp:229]     Train net output #0: loss = 6162.44 (* 1 = 6162.44 loss)
I0317 20:53:50.834758 29479 solver.cpp:610] Iteration 100500, lr = 5.33475e-09
I0317 20:53:50.834774 29479 solver.cpp:613] Iteration 100500, avg_grad_norm = 492083
I0317 20:56:19.401381 29479 solver.cpp:214] Iteration 100520, loss = 5298.55
I0317 20:56:19.401573 29479 solver.cpp:229]     Train net output #0: loss = 2766.96 (* 1 = 2766.96 loss)
I0317 20:56:19.576292 29479 solver.cpp:610] Iteration 100520, lr = 5.33378e-09
I0317 20:56:19.576305 29479 solver.cpp:613] Iteration 100520, avg_grad_norm = 478857
I0317 20:58:49.065157 29479 solver.cpp:214] Iteration 100540, loss = 5541.47
I0317 20:58:49.065359 29479 solver.cpp:229]     Train net output #0: loss = 4996.58 (* 1 = 4996.58 loss)
I0317 20:58:49.220816 29479 solver.cpp:610] Iteration 100540, lr = 5.33282e-09
I0317 20:58:49.220830 29479 solver.cpp:613] Iteration 100540, avg_grad_norm = 493396
I0317 21:01:16.742171 29479 solver.cpp:214] Iteration 100560, loss = 5847.6
I0317 21:01:16.742280 29479 solver.cpp:229]     Train net output #0: loss = 7063.35 (* 1 = 7063.35 loss)
I0317 21:01:17.812947 29479 solver.cpp:610] Iteration 100560, lr = 5.33185e-09
I0317 21:01:17.812960 29479 solver.cpp:613] Iteration 100560, avg_grad_norm = 486106
I0317 21:04:26.404348 29479 solver.cpp:214] Iteration 100580, loss = 5669.32
I0317 21:04:26.404461 29479 solver.cpp:229]     Train net output #0: loss = 2023.83 (* 1 = 2023.83 loss)
I0317 21:04:27.487838 29479 solver.cpp:610] Iteration 100580, lr = 5.33089e-09
I0317 21:04:27.487854 29479 solver.cpp:613] Iteration 100580, avg_grad_norm = 564492
I0317 21:06:56.054862 29479 solver.cpp:214] Iteration 100600, loss = 5511.89
I0317 21:06:56.055061 29479 solver.cpp:229]     Train net output #0: loss = 3603.79 (* 1 = 3603.79 loss)
I0317 21:06:57.098395 29479 solver.cpp:610] Iteration 100600, lr = 5.32992e-09
I0317 21:06:57.098409 29479 solver.cpp:613] Iteration 100600, avg_grad_norm = 524926
I0317 21:09:25.663951 29479 solver.cpp:214] Iteration 100620, loss = 5510.01
I0317 21:09:25.664136 29479 solver.cpp:229]     Train net output #0: loss = 4376.81 (* 1 = 4376.81 loss)
I0317 21:09:25.820883 29479 solver.cpp:610] Iteration 100620, lr = 5.32896e-09
I0317 21:09:25.820899 29479 solver.cpp:613] Iteration 100620, avg_grad_norm = 510712
I0317 21:11:54.300483 29479 solver.cpp:214] Iteration 100640, loss = 5529.05
I0317 21:11:54.300613 29479 solver.cpp:229]     Train net output #0: loss = 3406.8 (* 1 = 3406.8 loss)
I0317 21:11:54.450274 29479 solver.cpp:610] Iteration 100640, lr = 5.32799e-09
I0317 21:11:54.450287 29479 solver.cpp:613] Iteration 100640, avg_grad_norm = 540093
I0317 21:12:31.855839 29479 solver.cpp:214] Iteration 100660, loss = 5655.51
I0317 21:12:31.855984 29479 solver.cpp:229]     Train net output #0: loss = 4459.83 (* 1 = 4459.83 loss)
I0317 21:12:31.961339 29479 solver.cpp:610] Iteration 100660, lr = 5.32703e-09
I0317 21:12:31.961354 29479 solver.cpp:613] Iteration 100660, avg_grad_norm = 480117
I0317 21:14:57.481062 29479 solver.cpp:214] Iteration 100680, loss = 5440.9
I0317 21:14:57.481168 29479 solver.cpp:229]     Train net output #0: loss = 5081.98 (* 1 = 5081.98 loss)
I0317 21:14:58.566350 29479 solver.cpp:610] Iteration 100680, lr = 5.32606e-09
I0317 21:14:58.566365 29479 solver.cpp:613] Iteration 100680, avg_grad_norm = 501557
I0317 21:17:27.091658 29479 solver.cpp:214] Iteration 100700, loss = 5687.11
I0317 21:17:27.091783 29479 solver.cpp:229]     Train net output #0: loss = 10084.1 (* 1 = 10084.1 loss)
I0317 21:17:28.135869 29479 solver.cpp:610] Iteration 100700, lr = 5.32509e-09
I0317 21:17:28.135885 29479 solver.cpp:613] Iteration 100700, avg_grad_norm = 475560
I0317 21:20:13.770268 29479 solver.cpp:214] Iteration 100720, loss = 5642.22
I0317 21:20:13.770395 29479 solver.cpp:229]     Train net output #0: loss = 7260.26 (* 1 = 7260.26 loss)
I0317 21:20:14.809901 29479 solver.cpp:610] Iteration 100720, lr = 5.32413e-09
I0317 21:20:14.809916 29479 solver.cpp:613] Iteration 100720, avg_grad_norm = 482341
I0317 21:22:42.373644 29479 solver.cpp:214] Iteration 100740, loss = 5517.07
I0317 21:22:42.373764 29479 solver.cpp:229]     Train net output #0: loss = 4456.51 (* 1 = 4456.51 loss)
I0317 21:22:43.417402 29479 solver.cpp:610] Iteration 100740, lr = 5.32316e-09
I0317 21:22:43.417414 29479 solver.cpp:613] Iteration 100740, avg_grad_norm = 497215
I0317 21:25:10.910397 29479 solver.cpp:214] Iteration 100760, loss = 5619.1
I0317 21:25:10.910501 29479 solver.cpp:229]     Train net output #0: loss = 8367.29 (* 1 = 8367.29 loss)
I0317 21:25:11.086148 29479 solver.cpp:610] Iteration 100760, lr = 5.3222e-09
I0317 21:25:11.086160 29479 solver.cpp:613] Iteration 100760, avg_grad_norm = 499365
I0317 21:27:39.616624 29479 solver.cpp:214] Iteration 100780, loss = 5971.79
I0317 21:27:39.616765 29479 solver.cpp:229]     Train net output #0: loss = 7761.75 (* 1 = 7761.75 loss)
I0317 21:27:40.656872 29479 solver.cpp:610] Iteration 100780, lr = 5.32123e-09
I0317 21:27:40.656886 29479 solver.cpp:613] Iteration 100780, avg_grad_norm = 532748
I0317 21:30:08.241524 29479 solver.cpp:214] Iteration 100800, loss = 5569.13
I0317 21:30:08.241637 29479 solver.cpp:229]     Train net output #0: loss = 3799.5 (* 1 = 3799.5 loss)
I0317 21:30:09.323719 29479 solver.cpp:610] Iteration 100800, lr = 5.32027e-09
I0317 21:30:09.323732 29479 solver.cpp:613] Iteration 100800, avg_grad_norm = 554355
I0317 21:32:36.843839 29479 solver.cpp:214] Iteration 100820, loss = 5612.81
I0317 21:32:36.844028 29479 solver.cpp:229]     Train net output #0: loss = 4345.23 (* 1 = 4345.23 loss)
I0317 21:32:36.947402 29479 solver.cpp:610] Iteration 100820, lr = 5.3193e-09
I0317 21:32:36.947455 29479 solver.cpp:613] Iteration 100820, avg_grad_norm = 488496
I0317 21:34:18.028617 29479 solver.cpp:214] Iteration 100840, loss = 5856.38
I0317 21:34:18.028774 29479 solver.cpp:229]     Train net output #0: loss = 7427.8 (* 1 = 7427.8 loss)
I0317 21:34:19.071106 29479 solver.cpp:610] Iteration 100840, lr = 5.31834e-09
I0317 21:34:19.071120 29479 solver.cpp:613] Iteration 100840, avg_grad_norm = 576494
I0317 21:36:47.629731 29479 solver.cpp:214] Iteration 100860, loss = 5320.45
I0317 21:36:47.629906 29479 solver.cpp:229]     Train net output #0: loss = 3425.18 (* 1 = 3425.18 loss)
I0317 21:36:47.791759 29479 solver.cpp:610] Iteration 100860, lr = 5.31737e-09
I0317 21:36:47.791772 29479 solver.cpp:613] Iteration 100860, avg_grad_norm = 511186
I0317 21:39:17.267417 29479 solver.cpp:214] Iteration 100880, loss = 5402.46
I0317 21:39:17.267546 29479 solver.cpp:229]     Train net output #0: loss = 4286.59 (* 1 = 4286.59 loss)
I0317 21:39:17.424620 29479 solver.cpp:610] Iteration 100880, lr = 5.31641e-09
I0317 21:39:17.424633 29479 solver.cpp:613] Iteration 100880, avg_grad_norm = 544315
I0317 21:41:45.911201 29479 solver.cpp:214] Iteration 100900, loss = 5758.74
I0317 21:41:45.911336 29479 solver.cpp:229]     Train net output #0: loss = 5243.33 (* 1 = 5243.33 loss)
I0317 21:41:46.953651 29479 solver.cpp:610] Iteration 100900, lr = 5.31544e-09
I0317 21:41:46.953671 29479 solver.cpp:613] Iteration 100900, avg_grad_norm = 513046
I0317 21:44:14.566885 29479 solver.cpp:214] Iteration 100920, loss = 5887.25
I0317 21:44:14.567078 29479 solver.cpp:229]     Train net output #0: loss = 4479.6 (* 1 = 4479.6 loss)
I0317 21:44:15.608309 29479 solver.cpp:610] Iteration 100920, lr = 5.31448e-09
I0317 21:44:15.608322 29479 solver.cpp:613] Iteration 100920, avg_grad_norm = 510578
I0317 21:46:44.196051 29479 solver.cpp:214] Iteration 100940, loss = 5686.49
I0317 21:46:44.196179 29479 solver.cpp:229]     Train net output #0: loss = 5773.28 (* 1 = 5773.28 loss)
I0317 21:46:45.281198 29479 solver.cpp:610] Iteration 100940, lr = 5.31351e-09
I0317 21:46:45.281213 29479 solver.cpp:613] Iteration 100940, avg_grad_norm = 497222
I0317 21:49:28.837023 29479 solver.cpp:214] Iteration 100960, loss = 5376.05
I0317 21:49:28.837153 29479 solver.cpp:229]     Train net output #0: loss = 3778.97 (* 1 = 3778.97 loss)
I0317 21:49:29.879031 29479 solver.cpp:610] Iteration 100960, lr = 5.31254e-09
I0317 21:49:29.879046 29479 solver.cpp:613] Iteration 100960, avg_grad_norm = 493806
I0317 21:51:57.398602 29479 solver.cpp:214] Iteration 100980, loss = 5401.24
I0317 21:51:57.398754 29479 solver.cpp:229]     Train net output #0: loss = 5577.73 (* 1 = 5577.73 loss)
I0317 21:51:57.579269 29479 solver.cpp:610] Iteration 100980, lr = 5.31158e-09
I0317 21:51:57.579284 29479 solver.cpp:613] Iteration 100980, avg_grad_norm = 520172
I0317 21:53:23.972441 29479 solver.cpp:214] Iteration 101000, loss = 5526.65
I0317 21:53:23.972585 29479 solver.cpp:229]     Train net output #0: loss = 6734.32 (* 1 = 6734.32 loss)
I0317 21:53:24.076575 29479 solver.cpp:610] Iteration 101000, lr = 5.31061e-09
I0317 21:53:24.076588 29479 solver.cpp:613] Iteration 101000, avg_grad_norm = 475922
I0317 21:55:10.514860 29479 solver.cpp:214] Iteration 101020, loss = 5392.88
I0317 21:55:10.514983 29479 solver.cpp:229]     Train net output #0: loss = 8925.31 (* 1 = 8925.31 loss)
I0317 21:55:10.684833 29479 solver.cpp:610] Iteration 101020, lr = 5.30965e-09
I0317 21:55:10.684845 29479 solver.cpp:613] Iteration 101020, avg_grad_norm = 481224
I0317 21:57:39.218870 29479 solver.cpp:214] Iteration 101040, loss = 5724.14
I0317 21:57:39.218999 29479 solver.cpp:229]     Train net output #0: loss = 4641 (* 1 = 4641 loss)
I0317 21:57:40.298283 29479 solver.cpp:610] Iteration 101040, lr = 5.30868e-09
I0317 21:57:40.298298 29479 solver.cpp:613] Iteration 101040, avg_grad_norm = 504574
I0317 22:00:09.776762 29479 solver.cpp:214] Iteration 101060, loss = 5614.58
I0317 22:00:09.776875 29479 solver.cpp:229]     Train net output #0: loss = 5399.48 (* 1 = 5399.48 loss)
I0317 22:00:09.930477 29479 solver.cpp:610] Iteration 101060, lr = 5.30772e-09
I0317 22:00:09.930490 29479 solver.cpp:613] Iteration 101060, avg_grad_norm = 485501
I0317 22:02:39.467454 29479 solver.cpp:214] Iteration 101080, loss = 5673.66
I0317 22:02:39.467586 29479 solver.cpp:229]     Train net output #0: loss = 6054.45 (* 1 = 6054.45 loss)
I0317 22:02:40.511243 29479 solver.cpp:610] Iteration 101080, lr = 5.30675e-09
I0317 22:02:40.511257 29479 solver.cpp:613] Iteration 101080, avg_grad_norm = 478939
I0317 22:05:28.029661 29479 solver.cpp:214] Iteration 101100, loss = 5567.67
I0317 22:05:28.029809 29479 solver.cpp:229]     Train net output #0: loss = 4369.47 (* 1 = 4369.47 loss)
I0317 22:05:28.204840 29479 solver.cpp:610] Iteration 101100, lr = 5.30579e-09
I0317 22:05:28.204854 29479 solver.cpp:613] Iteration 101100, avg_grad_norm = 504465
I0317 22:07:57.730000 29479 solver.cpp:214] Iteration 101120, loss = 5536.74
I0317 22:07:57.730139 29479 solver.cpp:229]     Train net output #0: loss = 3966.83 (* 1 = 3966.83 loss)
I0317 22:07:58.812618 29479 solver.cpp:610] Iteration 101120, lr = 5.30482e-09
I0317 22:07:58.812633 29479 solver.cpp:613] Iteration 101120, avg_grad_norm = 514733
I0317 22:10:27.323832 29479 solver.cpp:214] Iteration 101140, loss = 5552.43
I0317 22:10:27.323956 29479 solver.cpp:229]     Train net output #0: loss = 9120.01 (* 1 = 9120.01 loss)
I0317 22:10:27.477869 29479 solver.cpp:610] Iteration 101140, lr = 5.30385e-09
I0317 22:10:27.477881 29479 solver.cpp:613] Iteration 101140, avg_grad_norm = 447958
I0317 22:12:54.984441 29479 solver.cpp:214] Iteration 101160, loss = 5591.03
I0317 22:12:54.984581 29479 solver.cpp:229]     Train net output #0: loss = 3848.53 (* 1 = 3848.53 loss)
I0317 22:12:56.062629 29479 solver.cpp:610] Iteration 101160, lr = 5.30289e-09
I0317 22:12:56.062645 29479 solver.cpp:613] Iteration 101160, avg_grad_norm = 522119
I0317 22:14:15.529338 29479 solver.cpp:214] Iteration 101180, loss = 5678.41
I0317 22:14:15.529466 29479 solver.cpp:229]     Train net output #0: loss = 3350.19 (* 1 = 3350.19 loss)
I0317 22:14:16.572886 29479 solver.cpp:610] Iteration 101180, lr = 5.30192e-09
I0317 22:14:16.572899 29479 solver.cpp:613] Iteration 101180, avg_grad_norm = 468616
I0317 22:16:44.240090 29479 solver.cpp:214] Iteration 101200, loss = 5503.18
I0317 22:16:44.240203 29479 solver.cpp:229]     Train net output #0: loss = 3401.64 (* 1 = 3401.64 loss)
I0317 22:16:45.318316 29479 solver.cpp:610] Iteration 101200, lr = 5.30096e-09
I0317 22:16:45.318331 29479 solver.cpp:613] Iteration 101200, avg_grad_norm = 554275
I0317 22:19:20.388097 29479 solver.cpp:214] Iteration 101220, loss = 5394.36
I0317 22:19:20.388209 29479 solver.cpp:229]     Train net output #0: loss = 3537.94 (* 1 = 3537.94 loss)
I0317 22:19:21.427373 29479 solver.cpp:610] Iteration 101220, lr = 5.29999e-09
I0317 22:19:21.427387 29479 solver.cpp:613] Iteration 101220, avg_grad_norm = 521122
I0317 22:21:50.049695 29479 solver.cpp:214] Iteration 101240, loss = 5638.34
I0317 22:21:50.049895 29479 solver.cpp:229]     Train net output #0: loss = 4636.44 (* 1 = 4636.44 loss)
I0317 22:21:51.097775 29479 solver.cpp:610] Iteration 101240, lr = 5.29903e-09
I0317 22:21:51.097789 29479 solver.cpp:613] Iteration 101240, avg_grad_norm = 545005
I0317 22:24:18.632455 29479 solver.cpp:214] Iteration 101260, loss = 5321.35
I0317 22:24:18.632642 29479 solver.cpp:229]     Train net output #0: loss = 5507.08 (* 1 = 5507.08 loss)
I0317 22:24:19.668843 29479 solver.cpp:610] Iteration 101260, lr = 5.29806e-09
I0317 22:24:19.668862 29479 solver.cpp:613] Iteration 101260, avg_grad_norm = 521635
I0317 22:26:48.217123 29479 solver.cpp:214] Iteration 101280, loss = 5717.88
I0317 22:26:48.217344 29479 solver.cpp:229]     Train net output #0: loss = 8325.7 (* 1 = 8325.7 loss)
I0317 22:26:48.389096 29479 solver.cpp:610] Iteration 101280, lr = 5.29709e-09
I0317 22:26:48.389114 29479 solver.cpp:613] Iteration 101280, avg_grad_norm = 569093
I0317 22:29:17.784963 29479 solver.cpp:214] Iteration 101300, loss = 5538.87
I0317 22:29:17.785084 29479 solver.cpp:229]     Train net output #0: loss = 6707.61 (* 1 = 6707.61 loss)
I0317 22:29:17.948884 29479 solver.cpp:610] Iteration 101300, lr = 5.29613e-09
I0317 22:29:17.948897 29479 solver.cpp:613] Iteration 101300, avg_grad_norm = 494960
I0317 22:31:46.500474 29479 solver.cpp:214] Iteration 101320, loss = 5459.33
I0317 22:31:46.500694 29479 solver.cpp:229]     Train net output #0: loss = 3921.85 (* 1 = 3921.85 loss)
I0317 22:31:47.580080 29479 solver.cpp:610] Iteration 101320, lr = 5.29516e-09
I0317 22:31:47.580099 29479 solver.cpp:613] Iteration 101320, avg_grad_norm = 562898
I0317 22:33:58.143282 29479 solver.cpp:214] Iteration 101340, loss = 5701.55
I0317 22:33:58.143412 29479 solver.cpp:229]     Train net output #0: loss = 3413.01 (* 1 = 3413.01 loss)
I0317 22:33:58.248375 29479 solver.cpp:610] Iteration 101340, lr = 5.2942e-09
I0317 22:33:58.248392 29479 solver.cpp:613] Iteration 101340, avg_grad_norm = 538646
I0317 22:37:11.647512 29479 solver.cpp:214] Iteration 101360, loss = 5908.13
I0317 22:37:11.647631 29479 solver.cpp:229]     Train net output #0: loss = 4467.68 (* 1 = 4467.68 loss)
I0317 22:37:12.686302 29479 solver.cpp:610] Iteration 101360, lr = 5.29323e-09
I0317 22:37:12.686316 29479 solver.cpp:613] Iteration 101360, avg_grad_norm = 541543
I0317 22:39:41.239915 29479 solver.cpp:214] Iteration 101380, loss = 5698.86
I0317 22:39:41.240026 29479 solver.cpp:229]     Train net output #0: loss = 4638.87 (* 1 = 4638.87 loss)
I0317 22:39:41.393622 29479 solver.cpp:610] Iteration 101380, lr = 5.29226e-09
I0317 22:39:41.393635 29479 solver.cpp:613] Iteration 101380, avg_grad_norm = 498641
I0317 22:42:09.901793 29479 solver.cpp:214] Iteration 101400, loss = 5684.73
I0317 22:42:09.901909 29479 solver.cpp:229]     Train net output #0: loss = 4446.64 (* 1 = 4446.64 loss)
I0317 22:42:10.944502 29479 solver.cpp:610] Iteration 101400, lr = 5.2913e-09
I0317 22:42:10.944516 29479 solver.cpp:613] Iteration 101400, avg_grad_norm = 469471
I0317 22:44:39.551972 29479 solver.cpp:214] Iteration 101420, loss = 5704.1
I0317 22:44:39.552165 29479 solver.cpp:229]     Train net output #0: loss = 7385.2 (* 1 = 7385.2 loss)
I0317 22:44:40.593299 29479 solver.cpp:610] Iteration 101420, lr = 5.29033e-09
I0317 22:44:40.593315 29479 solver.cpp:613] Iteration 101420, avg_grad_norm = 504175
I0317 22:47:09.214768 29479 solver.cpp:214] Iteration 101440, loss = 5442.86
I0317 22:47:09.214954 29479 solver.cpp:229]     Train net output #0: loss = 4526.78 (* 1 = 4526.78 loss)
I0317 22:47:10.254705 29479 solver.cpp:610] Iteration 101440, lr = 5.28937e-09
I0317 22:47:10.254719 29479 solver.cpp:613] Iteration 101440, avg_grad_norm = 483831
I0317 22:49:37.799643 29479 solver.cpp:214] Iteration 101460, loss = 5710.17
I0317 22:49:37.799777 29479 solver.cpp:229]     Train net output #0: loss = 6550.34 (* 1 = 6550.34 loss)
I0317 22:49:38.836062 29479 solver.cpp:610] Iteration 101460, lr = 5.2884e-09
I0317 22:49:38.836076 29479 solver.cpp:613] Iteration 101460, avg_grad_norm = 467288
I0317 22:52:20.502007 29479 solver.cpp:214] Iteration 101480, loss = 5521.64
I0317 22:52:20.502207 29479 solver.cpp:229]     Train net output #0: loss = 4292.17 (* 1 = 4292.17 loss)
I0317 22:52:21.578160 29479 solver.cpp:610] Iteration 101480, lr = 5.28743e-09
I0317 22:52:21.578174 29479 solver.cpp:613] Iteration 101480, avg_grad_norm = 485845
I0317 22:54:46.107730 29479 solver.cpp:214] Iteration 101500, loss = 5627.36
I0317 22:54:46.107875 29479 solver.cpp:229]     Train net output #0: loss = 7102.08 (* 1 = 7102.08 loss)
I0317 22:54:46.212080 29479 solver.cpp:610] Iteration 101500, lr = 5.28647e-09
I0317 22:54:46.212129 29479 solver.cpp:613] Iteration 101500, avg_grad_norm = 511323
I0317 22:56:10.668831 29479 solver.cpp:214] Iteration 101520, loss = 5738.74
I0317 22:56:10.668997 29479 solver.cpp:229]     Train net output #0: loss = 4307.04 (* 1 = 4307.04 loss)
I0317 22:56:10.843976 29479 solver.cpp:610] Iteration 101520, lr = 5.2855e-09
I0317 22:56:10.843996 29479 solver.cpp:613] Iteration 101520, avg_grad_norm = 483091
I0317 22:58:39.346005 29479 solver.cpp:214] Iteration 101540, loss = 5539.4
I0317 22:58:39.346206 29479 solver.cpp:229]     Train net output #0: loss = 3812.21 (* 1 = 3812.21 loss)
I0317 22:58:40.394510 29479 solver.cpp:610] Iteration 101540, lr = 5.28454e-09
I0317 22:58:40.394525 29479 solver.cpp:613] Iteration 101540, avg_grad_norm = 515461
I0317 23:01:08.956485 29479 solver.cpp:214] Iteration 101560, loss = 5455.72
I0317 23:01:08.956651 29479 solver.cpp:229]     Train net output #0: loss = 4342.84 (* 1 = 4342.84 loss)
I0317 23:01:09.997371 29479 solver.cpp:610] Iteration 101560, lr = 5.28357e-09
I0317 23:01:09.997390 29479 solver.cpp:613] Iteration 101560, avg_grad_norm = 458260
I0317 23:03:38.518069 29479 solver.cpp:214] Iteration 101580, loss = 5447.32
I0317 23:03:38.518178 29479 solver.cpp:229]     Train net output #0: loss = 2634.11 (* 1 = 2634.11 loss)
I0317 23:03:38.681859 29479 solver.cpp:610] Iteration 101580, lr = 5.2826e-09
I0317 23:03:38.681874 29479 solver.cpp:613] Iteration 101580, avg_grad_norm = 515277
I0317 23:06:21.186581 29479 solver.cpp:214] Iteration 101600, loss = 5388.49
I0317 23:06:21.186702 29479 solver.cpp:229]     Train net output #0: loss = 6010.86 (* 1 = 6010.86 loss)
I0317 23:06:21.358655 29479 solver.cpp:610] Iteration 101600, lr = 5.28164e-09
I0317 23:06:21.358669 29479 solver.cpp:613] Iteration 101600, avg_grad_norm = 499680
I0317 23:08:49.757361 29479 solver.cpp:214] Iteration 101620, loss = 5367.18
I0317 23:08:49.757469 29479 solver.cpp:229]     Train net output #0: loss = 2676.5 (* 1 = 2676.5 loss)
I0317 23:08:49.925421 29479 solver.cpp:610] Iteration 101620, lr = 5.28067e-09
I0317 23:08:49.925434 29479 solver.cpp:613] Iteration 101620, avg_grad_norm = 520024
I0317 23:11:18.257118 29479 solver.cpp:214] Iteration 101640, loss = 5483.25
I0317 23:11:18.257318 29479 solver.cpp:229]     Train net output #0: loss = 4279 (* 1 = 4279 loss)
I0317 23:11:18.480309 29479 solver.cpp:610] Iteration 101640, lr = 5.27971e-09
I0317 23:11:18.480329 29479 solver.cpp:613] Iteration 101640, avg_grad_norm = 534651
I0317 23:13:46.001919 29479 solver.cpp:214] Iteration 101660, loss = 5522.31
I0317 23:13:46.002063 29479 solver.cpp:229]     Train net output #0: loss = 5797.14 (* 1 = 5797.14 loss)
I0317 23:13:47.040292 29479 solver.cpp:610] Iteration 101660, lr = 5.27874e-09
I0317 23:13:47.040305 29479 solver.cpp:613] Iteration 101660, avg_grad_norm = 560598
I0317 23:15:14.559489 29479 solver.cpp:214] Iteration 101680, loss = 5535
I0317 23:15:14.559623 29479 solver.cpp:229]     Train net output #0: loss = 7138.11 (* 1 = 7138.11 loss)
I0317 23:15:14.663853 29479 solver.cpp:610] Iteration 101680, lr = 5.27777e-09
I0317 23:15:14.663872 29479 solver.cpp:613] Iteration 101680, avg_grad_norm = 583668
I0317 23:17:20.169147 29479 solver.cpp:214] Iteration 101700, loss = 5291.3
I0317 23:17:20.169378 29479 solver.cpp:229]     Train net output #0: loss = 5080.35 (* 1 = 5080.35 loss)
I0317 23:17:20.330709 29479 solver.cpp:610] Iteration 101700, lr = 5.27681e-09
I0317 23:17:20.330724 29479 solver.cpp:613] Iteration 101700, avg_grad_norm = 522754
I0317 23:19:48.786566 29479 solver.cpp:214] Iteration 101720, loss = 5478.41
I0317 23:19:48.786700 29479 solver.cpp:229]     Train net output #0: loss = 4893.42 (* 1 = 4893.42 loss)
I0317 23:19:48.980485 29479 solver.cpp:610] Iteration 101720, lr = 5.27584e-09
I0317 23:19:48.980499 29479 solver.cpp:613] Iteration 101720, avg_grad_norm = 498489
I0317 23:22:31.474705 29479 solver.cpp:214] Iteration 101740, loss = 5437.14
I0317 23:22:31.474884 29479 solver.cpp:229]     Train net output #0: loss = 8938.65 (* 1 = 8938.65 loss)
I0317 23:22:31.640895 29479 solver.cpp:610] Iteration 101740, lr = 5.27487e-09
I0317 23:22:31.640908 29479 solver.cpp:613] Iteration 101740, avg_grad_norm = 498666
I0317 23:25:00.102973 29479 solver.cpp:214] Iteration 101760, loss = 5496.87
I0317 23:25:00.103067 29479 solver.cpp:229]     Train net output #0: loss = 7909.71 (* 1 = 7909.71 loss)
I0317 23:25:01.153684 29479 solver.cpp:610] Iteration 101760, lr = 5.27391e-09
I0317 23:25:01.153697 29479 solver.cpp:613] Iteration 101760, avg_grad_norm = 490375
I0317 23:27:28.721375 29479 solver.cpp:214] Iteration 101780, loss = 5372.67
I0317 23:27:28.721472 29479 solver.cpp:229]     Train net output #0: loss = 5210.41 (* 1 = 5210.41 loss)
I0317 23:27:28.882895 29479 solver.cpp:610] Iteration 101780, lr = 5.27294e-09
I0317 23:27:28.882908 29479 solver.cpp:613] Iteration 101780, avg_grad_norm = 496041
I0317 23:29:57.343132 29479 solver.cpp:214] Iteration 101800, loss = 5526.3
I0317 23:29:57.343374 29479 solver.cpp:229]     Train net output #0: loss = 5246.76 (* 1 = 5246.76 loss)
I0317 23:29:58.394116 29479 solver.cpp:610] Iteration 101800, lr = 5.27197e-09
I0317 23:29:58.394130 29479 solver.cpp:613] Iteration 101800, avg_grad_norm = 503000
I0317 23:32:26.950989 29479 solver.cpp:214] Iteration 101820, loss = 5734.19
I0317 23:32:26.951129 29479 solver.cpp:229]     Train net output #0: loss = 7907.17 (* 1 = 7907.17 loss)
I0317 23:32:28.003003 29479 solver.cpp:610] Iteration 101820, lr = 5.27101e-09
I0317 23:32:28.003016 29479 solver.cpp:613] Iteration 101820, avg_grad_norm = 554518
I0317 23:34:56.553253 29479 solver.cpp:214] Iteration 101840, loss = 5555.61
I0317 23:34:56.553437 29479 solver.cpp:229]     Train net output #0: loss = 6954.63 (* 1 = 6954.63 loss)
I0317 23:34:57.590373 29479 solver.cpp:610] Iteration 101840, lr = 5.27004e-09
I0317 23:34:57.590425 29479 solver.cpp:613] Iteration 101840, avg_grad_norm = 495908
I0317 23:37:17.785589 29479 solver.cpp:214] Iteration 101860, loss = 5483.72
I0317 23:37:17.785739 29479 solver.cpp:229]     Train net output #0: loss = 3383.94 (* 1 = 3383.94 loss)
I0317 23:37:17.939379 29479 solver.cpp:610] Iteration 101860, lr = 5.26908e-09
I0317 23:37:17.939393 29479 solver.cpp:613] Iteration 101860, avg_grad_norm = 491490
I0317 23:39:46.374758 29479 solver.cpp:214] Iteration 101880, loss = 5398.38
I0317 23:39:46.374903 29479 solver.cpp:229]     Train net output #0: loss = 3439.76 (* 1 = 3439.76 loss)
I0317 23:39:46.553153 29479 solver.cpp:610] Iteration 101880, lr = 5.26811e-09
I0317 23:39:46.553166 29479 solver.cpp:613] Iteration 101880, avg_grad_norm = 486177
I0317 23:42:14.095051 29479 solver.cpp:214] Iteration 101900, loss = 5955.27
I0317 23:42:14.095269 29479 solver.cpp:229]     Train net output #0: loss = 2674.99 (* 1 = 2674.99 loss)
I0317 23:42:15.181154 29479 solver.cpp:610] Iteration 101900, lr = 5.26714e-09
I0317 23:42:15.181172 29479 solver.cpp:613] Iteration 101900, avg_grad_norm = 522143
I0317 23:44:44.694293 29479 solver.cpp:214] Iteration 101920, loss = 5563.12
I0317 23:44:44.694423 29479 solver.cpp:229]     Train net output #0: loss = 5392.49 (* 1 = 5392.49 loss)
I0317 23:44:44.874055 29479 solver.cpp:610] Iteration 101920, lr = 5.26618e-09
I0317 23:44:44.874068 29479 solver.cpp:613] Iteration 101920, avg_grad_norm = 469991
I0317 23:47:13.455445 29479 solver.cpp:214] Iteration 101940, loss = 5380.15
I0317 23:47:13.455642 29479 solver.cpp:229]     Train net output #0: loss = 3658.51 (* 1 = 3658.51 loss)
I0317 23:47:14.530594 29479 solver.cpp:610] Iteration 101940, lr = 5.26521e-09
I0317 23:47:14.530609 29479 solver.cpp:613] Iteration 101940, avg_grad_norm = 526857
I0317 23:49:43.093098 29479 solver.cpp:214] Iteration 101960, loss = 5575.73
I0317 23:49:43.093245 29479 solver.cpp:229]     Train net output #0: loss = 3715.96 (* 1 = 3715.96 loss)
I0317 23:49:44.168946 29479 solver.cpp:610] Iteration 101960, lr = 5.26424e-09
I0317 23:49:44.168961 29479 solver.cpp:613] Iteration 101960, avg_grad_norm = 507055
I0317 23:52:25.676255 29479 solver.cpp:214] Iteration 101980, loss = 5316.15
I0317 23:52:25.676398 29479 solver.cpp:229]     Train net output #0: loss = 2395.44 (* 1 = 2395.44 loss)
I0317 23:52:26.759141 29479 solver.cpp:610] Iteration 101980, lr = 5.26328e-09
I0317 23:52:26.759155 29479 solver.cpp:613] Iteration 101980, avg_grad_norm = 510376
I0317 23:54:55.254794 29479 solver.cpp:214] Iteration 102000, loss = 5724.62
I0317 23:54:55.254927 29479 solver.cpp:229]     Train net output #0: loss = 6097.52 (* 1 = 6097.52 loss)
I0317 23:54:55.408293 29479 solver.cpp:610] Iteration 102000, lr = 5.26231e-09
I0317 23:54:55.408306 29479 solver.cpp:613] Iteration 102000, avg_grad_norm = 542949
I0317 23:56:14.969954 29479 solver.cpp:214] Iteration 102020, loss = 5489.86
I0317 23:56:14.970078 29479 solver.cpp:229]     Train net output #0: loss = 3351.49 (* 1 = 3351.49 loss)
I0317 23:56:16.040455 29479 solver.cpp:610] Iteration 102020, lr = 5.26134e-09
I0317 23:56:16.040470 29479 solver.cpp:613] Iteration 102020, avg_grad_norm = 501632
I0317 23:58:45.475191 29479 solver.cpp:214] Iteration 102040, loss = 5237.09
I0317 23:58:45.475358 29479 solver.cpp:229]     Train net output #0: loss = 3909.76 (* 1 = 3909.76 loss)
I0317 23:58:46.517446 29479 solver.cpp:610] Iteration 102040, lr = 5.26038e-09
I0317 23:58:46.517460 29479 solver.cpp:613] Iteration 102040, avg_grad_norm = 453091
I0318 00:01:14.102901 29479 solver.cpp:214] Iteration 102060, loss = 5408.63
I0318 00:01:14.103044 29479 solver.cpp:229]     Train net output #0: loss = 3686.41 (* 1 = 3686.41 loss)
I0318 00:01:15.185940 29479 solver.cpp:610] Iteration 102060, lr = 5.25941e-09
I0318 00:01:15.185953 29479 solver.cpp:613] Iteration 102060, avg_grad_norm = 460990
I0318 00:03:44.662765 29479 solver.cpp:214] Iteration 102080, loss = 5436.83
I0318 00:03:44.662883 29479 solver.cpp:229]     Train net output #0: loss = 3645.43 (* 1 = 3645.43 loss)
I0318 00:03:44.818472 29479 solver.cpp:610] Iteration 102080, lr = 5.25844e-09
I0318 00:03:44.818486 29479 solver.cpp:613] Iteration 102080, avg_grad_norm = 460406
I0318 00:06:13.281929 29479 solver.cpp:214] Iteration 102100, loss = 5355.4
I0318 00:06:13.282152 29479 solver.cpp:229]     Train net output #0: loss = 4413.55 (* 1 = 4413.55 loss)
I0318 00:06:13.451804 29479 solver.cpp:610] Iteration 102100, lr = 5.25748e-09
I0318 00:06:13.451818 29479 solver.cpp:613] Iteration 102100, avg_grad_norm = 459167
I0318 00:08:54.982532 29479 solver.cpp:214] Iteration 102120, loss = 5543.54
I0318 00:08:54.982653 29479 solver.cpp:229]     Train net output #0: loss = 5144.29 (* 1 = 5144.29 loss)
I0318 00:08:55.141348 29479 solver.cpp:610] Iteration 102120, lr = 5.25651e-09
I0318 00:08:55.141362 29479 solver.cpp:613] Iteration 102120, avg_grad_norm = 517045
I0318 00:11:22.646940 29479 solver.cpp:214] Iteration 102140, loss = 5387.65
I0318 00:11:22.647068 29479 solver.cpp:229]     Train net output #0: loss = 3502.6 (* 1 = 3502.6 loss)
I0318 00:11:23.723215 29479 solver.cpp:610] Iteration 102140, lr = 5.25554e-09
I0318 00:11:23.723229 29479 solver.cpp:613] Iteration 102140, avg_grad_norm = 560124
I0318 00:13:51.215281 29479 solver.cpp:214] Iteration 102160, loss = 5512.19
I0318 00:13:51.215404 29479 solver.cpp:229]     Train net output #0: loss = 4006.42 (* 1 = 4006.42 loss)
I0318 00:13:52.298470 29479 solver.cpp:610] Iteration 102160, lr = 5.25458e-09
I0318 00:13:52.298485 29479 solver.cpp:613] Iteration 102160, avg_grad_norm = 484145
I0318 00:16:06.835353 29479 solver.cpp:214] Iteration 102180, loss = 5649.71
I0318 00:16:06.835490 29479 solver.cpp:229]     Train net output #0: loss = 4286.64 (* 1 = 4286.64 loss)
I0318 00:16:06.941162 29479 solver.cpp:610] Iteration 102180, lr = 5.25361e-09
I0318 00:16:06.941179 29479 solver.cpp:613] Iteration 102180, avg_grad_norm = 580585
I0318 00:16:32.423832 29479 solver.cpp:214] Iteration 102200, loss = 5611.36
I0318 00:16:32.423880 29479 solver.cpp:229]     Train net output #0: loss = 9667.8 (* 1 = 9667.8 loss)
I0318 00:16:33.498863 29479 solver.cpp:610] Iteration 102200, lr = 5.25264e-09
I0318 00:16:33.498878 29479 solver.cpp:613] Iteration 102200, avg_grad_norm = 526023
I0318 00:19:01.976933 29479 solver.cpp:214] Iteration 102220, loss = 5546.07
I0318 00:19:01.977061 29479 solver.cpp:229]     Train net output #0: loss = 3202.03 (* 1 = 3202.03 loss)
I0318 00:19:02.152442 29479 solver.cpp:610] Iteration 102220, lr = 5.25168e-09
I0318 00:19:02.152456 29479 solver.cpp:613] Iteration 102220, avg_grad_norm = 541140
I0318 00:21:43.624948 29479 solver.cpp:214] Iteration 102240, loss = 5453.41
I0318 00:21:43.625138 29479 solver.cpp:229]     Train net output #0: loss = 2981.2 (* 1 = 2981.2 loss)
I0318 00:21:44.664757 29479 solver.cpp:610] Iteration 102240, lr = 5.25071e-09
I0318 00:21:44.664772 29479 solver.cpp:613] Iteration 102240, avg_grad_norm = 521595
I0318 00:24:13.164865 29479 solver.cpp:214] Iteration 102260, loss = 5777.46
I0318 00:24:13.165071 29479 solver.cpp:229]     Train net output #0: loss = 3175.47 (* 1 = 3175.47 loss)
I0318 00:24:13.320672 29479 solver.cpp:610] Iteration 102260, lr = 5.24974e-09
I0318 00:24:13.320685 29479 solver.cpp:613] Iteration 102260, avg_grad_norm = 534602
I0318 00:26:41.904171 29479 solver.cpp:214] Iteration 102280, loss = 5451.29
I0318 00:26:41.904424 29479 solver.cpp:229]     Train net output #0: loss = 3693.61 (* 1 = 3693.61 loss)
I0318 00:26:42.986306 29479 solver.cpp:610] Iteration 102280, lr = 5.24878e-09
I0318 00:26:42.986325 29479 solver.cpp:613] Iteration 102280, avg_grad_norm = 524836
I0318 00:29:11.486062 29479 solver.cpp:214] Iteration 102300, loss = 5500.55
I0318 00:29:11.486184 29479 solver.cpp:229]     Train net output #0: loss = 2064.66 (* 1 = 2064.66 loss)
I0318 00:29:12.522912 29479 solver.cpp:610] Iteration 102300, lr = 5.24781e-09
I0318 00:29:12.522927 29479 solver.cpp:613] Iteration 102300, avg_grad_norm = 543905
I0318 00:31:41.107091 29479 solver.cpp:214] Iteration 102320, loss = 5838.02
I0318 00:31:41.107296 29479 solver.cpp:229]     Train net output #0: loss = 3646.55 (* 1 = 3646.55 loss)
I0318 00:31:41.268432 29479 solver.cpp:610] Iteration 102320, lr = 5.24684e-09
I0318 00:31:41.268445 29479 solver.cpp:613] Iteration 102320, avg_grad_norm = 655267
I0318 00:34:09.757696 29479 solver.cpp:214] Iteration 102340, loss = 5630.49
I0318 00:34:09.757891 29479 solver.cpp:229]     Train net output #0: loss = 3694.68 (* 1 = 3694.68 loss)
I0318 00:34:09.937553 29479 solver.cpp:610] Iteration 102340, lr = 5.24588e-09
I0318 00:34:09.937567 29479 solver.cpp:613] Iteration 102340, avg_grad_norm = 533941
I0318 00:36:35.537729 29479 solver.cpp:214] Iteration 102360, loss = 5543.28
I0318 00:36:35.537873 29479 solver.cpp:229]     Train net output #0: loss = 4837.93 (* 1 = 4837.93 loss)
I0318 00:36:35.642149 29479 solver.cpp:610] Iteration 102360, lr = 5.24491e-09
I0318 00:36:35.642185 29479 solver.cpp:613] Iteration 102360, avg_grad_norm = 546860
I0318 00:38:00.097124 29479 solver.cpp:214] Iteration 102380, loss = 5708.93
I0318 00:38:00.097265 29479 solver.cpp:229]     Train net output #0: loss = 3533.92 (* 1 = 3533.92 loss)
I0318 00:38:01.153156 29479 solver.cpp:610] Iteration 102380, lr = 5.24394e-09
I0318 00:38:01.153167 29479 solver.cpp:613] Iteration 102380, avg_grad_norm = 475097
I0318 00:40:28.765518 29479 solver.cpp:214] Iteration 102400, loss = 5527.49
I0318 00:40:28.765643 29479 solver.cpp:229]     Train net output #0: loss = 6187.51 (* 1 = 6187.51 loss)
I0318 00:40:29.850319 29479 solver.cpp:610] Iteration 102400, lr = 5.24298e-09
I0318 00:40:29.850333 29479 solver.cpp:613] Iteration 102400, avg_grad_norm = 477804
I0318 00:42:57.321470 29479 solver.cpp:214] Iteration 102420, loss = 5504.36
I0318 00:42:57.321589 29479 solver.cpp:229]     Train net output #0: loss = 5313.83 (* 1 = 5313.83 loss)
I0318 00:42:58.373360 29479 solver.cpp:610] Iteration 102420, lr = 5.24201e-09
I0318 00:42:58.373373 29479 solver.cpp:613] Iteration 102420, avg_grad_norm = 541422
I0318 00:45:25.948256 29479 solver.cpp:214] Iteration 102440, loss = 5627.15
I0318 00:45:25.948405 29479 solver.cpp:229]     Train net output #0: loss = 7678.79 (* 1 = 7678.79 loss)
I0318 00:45:26.101696 29479 solver.cpp:610] Iteration 102440, lr = 5.24104e-09
I0318 00:45:26.101708 29479 solver.cpp:613] Iteration 102440, avg_grad_norm = 527596
I0318 00:47:54.699388 29479 solver.cpp:214] Iteration 102460, loss = 5608.85
I0318 00:47:54.699528 29479 solver.cpp:229]     Train net output #0: loss = 4263.31 (* 1 = 4263.31 loss)
I0318 00:47:55.776803 29479 solver.cpp:610] Iteration 102460, lr = 5.24007e-09
I0318 00:47:55.776818 29479 solver.cpp:613] Iteration 102460, avg_grad_norm = 495184
I0318 00:50:24.344668 29479 solver.cpp:214] Iteration 102480, loss = 5679.63
I0318 00:50:24.344898 29479 solver.cpp:229]     Train net output #0: loss = 7208.89 (* 1 = 7208.89 loss)
I0318 00:50:25.417323 29479 solver.cpp:610] Iteration 102480, lr = 5.23911e-09
I0318 00:50:25.417347 29479 solver.cpp:613] Iteration 102480, avg_grad_norm = 548916
I0318 00:53:06.906596 29479 solver.cpp:214] Iteration 102500, loss = 5343.26
I0318 00:53:06.906730 29479 solver.cpp:229]     Train net output #0: loss = 3948.03 (* 1 = 3948.03 loss)
I0318 00:53:07.084520 29479 solver.cpp:610] Iteration 102500, lr = 5.23814e-09
I0318 00:53:07.084534 29479 solver.cpp:613] Iteration 102500, avg_grad_norm = 518730
I0318 00:55:35.575572 29479 solver.cpp:214] Iteration 102520, loss = 5146.37
I0318 00:55:35.575793 29479 solver.cpp:229]     Train net output #0: loss = 5284.42 (* 1 = 5284.42 loss)
I0318 00:55:36.618837 29479 solver.cpp:610] Iteration 102520, lr = 5.23717e-09
I0318 00:55:36.618851 29479 solver.cpp:613] Iteration 102520, avg_grad_norm = 491527
I0318 00:57:04.187780 29479 solver.cpp:214] Iteration 102540, loss = 5411.03
I0318 00:57:04.187932 29479 solver.cpp:229]     Train net output #0: loss = 5877.11 (* 1 = 5877.11 loss)
I0318 00:57:04.292459 29479 solver.cpp:610] Iteration 102540, lr = 5.23621e-09
I0318 00:57:04.292474 29479 solver.cpp:613] Iteration 102540, avg_grad_norm = 528701
I0318 00:59:23.733090 29479 solver.cpp:214] Iteration 102560, loss = 5717.49
I0318 00:59:23.733270 29479 solver.cpp:229]     Train net output #0: loss = 8043.68 (* 1 = 8043.68 loss)
I0318 00:59:23.915438 29479 solver.cpp:610] Iteration 102560, lr = 5.23524e-09
I0318 00:59:23.915452 29479 solver.cpp:613] Iteration 102560, avg_grad_norm = 581373
I0318 01:01:53.428787 29479 solver.cpp:214] Iteration 102580, loss = 5592.3
I0318 01:01:53.429018 29479 solver.cpp:229]     Train net output #0: loss = 10117.3 (* 1 = 10117.3 loss)
I0318 01:01:53.582617 29479 solver.cpp:610] Iteration 102580, lr = 5.23427e-09
I0318 01:01:53.582630 29479 solver.cpp:613] Iteration 102580, avg_grad_norm = 524425
I0318 01:04:21.129211 29479 solver.cpp:214] Iteration 102600, loss = 5474.75
I0318 01:04:21.129323 29479 solver.cpp:229]     Train net output #0: loss = 5541.16 (* 1 = 5541.16 loss)
I0318 01:04:22.168285 29479 solver.cpp:610] Iteration 102600, lr = 5.23331e-09
I0318 01:04:22.168299 29479 solver.cpp:613] Iteration 102600, avg_grad_norm = 466515
I0318 01:07:06.873875 29479 solver.cpp:214] Iteration 102620, loss = 5700.27
I0318 01:07:06.873993 29479 solver.cpp:229]     Train net output #0: loss = 2152.07 (* 1 = 2152.07 loss)
I0318 01:07:07.942142 29479 solver.cpp:610] Iteration 102620, lr = 5.23234e-09
I0318 01:07:07.942157 29479 solver.cpp:613] Iteration 102620, avg_grad_norm = 548222
I0318 01:09:35.485543 29479 solver.cpp:214] Iteration 102640, loss = 5705.78
I0318 01:09:35.485682 29479 solver.cpp:229]     Train net output #0: loss = 4199.8 (* 1 = 4199.8 loss)
I0318 01:09:36.563016 29479 solver.cpp:610] Iteration 102640, lr = 5.23137e-09
I0318 01:09:36.563035 29479 solver.cpp:613] Iteration 102640, avg_grad_norm = 536552
I0318 01:12:04.093323 29479 solver.cpp:214] Iteration 102660, loss = 5462.66
I0318 01:12:04.093430 29479 solver.cpp:229]     Train net output #0: loss = 6885.82 (* 1 = 6885.82 loss)
I0318 01:12:05.166332 29479 solver.cpp:610] Iteration 102660, lr = 5.2304e-09
I0318 01:12:05.166345 29479 solver.cpp:613] Iteration 102660, avg_grad_norm = 501961
I0318 01:14:32.702222 29479 solver.cpp:214] Iteration 102680, loss = 5474.49
I0318 01:14:32.702312 29479 solver.cpp:229]     Train net output #0: loss = 3667.38 (* 1 = 3667.38 loss)
I0318 01:14:33.777072 29479 solver.cpp:610] Iteration 102680, lr = 5.22944e-09
I0318 01:14:33.777087 29479 solver.cpp:613] Iteration 102680, avg_grad_norm = 463365
I0318 01:17:01.288497 29479 solver.cpp:214] Iteration 102700, loss = 5521.69
I0318 01:17:01.288614 29479 solver.cpp:229]     Train net output #0: loss = 5236.55 (* 1 = 5236.55 loss)
I0318 01:17:01.443514 29479 solver.cpp:610] Iteration 102700, lr = 5.22847e-09
I0318 01:17:01.443527 29479 solver.cpp:613] Iteration 102700, avg_grad_norm = 526708
I0318 01:17:32.909868 29479 solver.cpp:214] Iteration 102720, loss = 5542.68
I0318 01:17:32.910078 29479 solver.cpp:229]     Train net output #0: loss = 6778.69 (* 1 = 6778.69 loss)
I0318 01:17:33.015413 29479 solver.cpp:610] Iteration 102720, lr = 5.2275e-09
I0318 01:17:33.015425 29479 solver.cpp:613] Iteration 102720, avg_grad_norm = 535315
I0318 01:19:41.638682 29479 solver.cpp:214] Iteration 102740, loss = 5704.67
I0318 01:19:41.638803 29479 solver.cpp:229]     Train net output #0: loss = 6728.15 (* 1 = 6728.15 loss)
I0318 01:19:41.807448 29479 solver.cpp:610] Iteration 102740, lr = 5.22653e-09
I0318 01:19:41.807461 29479 solver.cpp:613] Iteration 102740, avg_grad_norm = 468272
I0318 01:22:09.287761 29479 solver.cpp:214] Iteration 102760, loss = 5407.12
I0318 01:22:09.287972 29479 solver.cpp:229]     Train net output #0: loss = 6354.51 (* 1 = 6354.51 loss)
I0318 01:22:10.373335 29479 solver.cpp:610] Iteration 102760, lr = 5.22557e-09
I0318 01:22:10.373352 29479 solver.cpp:613] Iteration 102760, avg_grad_norm = 470838
I0318 01:24:38.795739 29479 solver.cpp:214] Iteration 102780, loss = 5470.18
I0318 01:24:38.795924 29479 solver.cpp:229]     Train net output #0: loss = 5513.55 (* 1 = 5513.55 loss)
I0318 01:24:38.965075 29479 solver.cpp:610] Iteration 102780, lr = 5.2246e-09
I0318 01:24:38.965090 29479 solver.cpp:613] Iteration 102780, avg_grad_norm = 501655
I0318 01:27:05.526710 29479 solver.cpp:214] Iteration 102800, loss = 5423.28
I0318 01:27:05.526900 29479 solver.cpp:229]     Train net output #0: loss = 4538.3 (* 1 = 4538.3 loss)
I0318 01:27:06.598023 29479 solver.cpp:610] Iteration 102800, lr = 5.22363e-09
I0318 01:27:06.598050 29479 solver.cpp:613] Iteration 102800, avg_grad_norm = 494204
I0318 01:29:34.094104 29479 solver.cpp:214] Iteration 102820, loss = 5877.21
I0318 01:29:34.094229 29479 solver.cpp:229]     Train net output #0: loss = 7996 (* 1 = 7996 loss)
I0318 01:29:35.168818 29479 solver.cpp:610] Iteration 102820, lr = 5.22267e-09
I0318 01:29:35.168833 29479 solver.cpp:613] Iteration 102820, avg_grad_norm = 499102
I0318 01:32:02.690052 29479 solver.cpp:214] Iteration 102840, loss = 5252.11
I0318 01:32:02.690178 29479 solver.cpp:229]     Train net output #0: loss = 5575.06 (* 1 = 5575.06 loss)
I0318 01:32:03.730960 29479 solver.cpp:610] Iteration 102840, lr = 5.2217e-09
I0318 01:32:03.730973 29479 solver.cpp:613] Iteration 102840, avg_grad_norm = 525679
I0318 01:34:32.309072 29479 solver.cpp:214] Iteration 102860, loss = 5780.49
I0318 01:34:32.309180 29479 solver.cpp:229]     Train net output #0: loss = 5733.09 (* 1 = 5733.09 loss)
I0318 01:34:33.390511 29479 solver.cpp:610] Iteration 102860, lr = 5.22073e-09
I0318 01:34:33.390523 29479 solver.cpp:613] Iteration 102860, avg_grad_norm = 500586
I0318 01:37:19.940393 29479 solver.cpp:214] Iteration 102880, loss = 5524.05
I0318 01:37:19.940523 29479 solver.cpp:229]     Train net output #0: loss = 6684.51 (* 1 = 6684.51 loss)
I0318 01:37:21.024926 29479 solver.cpp:610] Iteration 102880, lr = 5.21976e-09
I0318 01:37:21.024942 29479 solver.cpp:613] Iteration 102880, avg_grad_norm = 498249
I0318 01:39:31.537626 29479 solver.cpp:214] Iteration 102900, loss = 5295.4
I0318 01:39:31.537801 29479 solver.cpp:229]     Train net output #0: loss = 4792.68 (* 1 = 4792.68 loss)
I0318 01:39:31.693298 29479 solver.cpp:610] Iteration 102900, lr = 5.2188e-09
I0318 01:39:31.693311 29479 solver.cpp:613] Iteration 102900, avg_grad_norm = 486225
I0318 01:42:01.159795 29479 solver.cpp:214] Iteration 102920, loss = 5622.75
I0318 01:42:01.159925 29479 solver.cpp:229]     Train net output #0: loss = 3686.1 (* 1 = 3686.1 loss)
I0318 01:42:01.315201 29479 solver.cpp:610] Iteration 102920, lr = 5.21783e-09
I0318 01:42:01.315215 29479 solver.cpp:613] Iteration 102920, avg_grad_norm = 462712
I0318 01:44:29.825592 29479 solver.cpp:214] Iteration 102940, loss = 5735.92
I0318 01:44:29.825706 29479 solver.cpp:229]     Train net output #0: loss = 8312.12 (* 1 = 8312.12 loss)
I0318 01:44:30.902034 29479 solver.cpp:610] Iteration 102940, lr = 5.21686e-09
I0318 01:44:30.902047 29479 solver.cpp:613] Iteration 102940, avg_grad_norm = 450996
I0318 01:46:59.384816 29479 solver.cpp:214] Iteration 102960, loss = 5506.02
I0318 01:46:59.384948 29479 solver.cpp:229]     Train net output #0: loss = 5850.8 (* 1 = 5850.8 loss)
I0318 01:47:00.463865 29479 solver.cpp:610] Iteration 102960, lr = 5.21589e-09
I0318 01:47:00.463881 29479 solver.cpp:613] Iteration 102960, avg_grad_norm = 546683
I0318 01:49:28.993502 29479 solver.cpp:214] Iteration 102980, loss = 5621.42
I0318 01:49:28.993652 29479 solver.cpp:229]     Train net output #0: loss = 7210.26 (* 1 = 7210.26 loss)
I0318 01:49:30.032853 29479 solver.cpp:610] Iteration 102980, lr = 5.21493e-09
I0318 01:49:30.032869 29479 solver.cpp:613] Iteration 102980, avg_grad_norm = 619938
I0318 01:52:11.672897 29479 solver.cpp:214] Iteration 103000, loss = 5530.41
I0318 01:52:11.673050 29479 solver.cpp:229]     Train net output #0: loss = 7740.16 (* 1 = 7740.16 loss)
I0318 01:52:12.750242 29479 solver.cpp:610] Iteration 103000, lr = 5.21396e-09
I0318 01:52:12.750293 29479 solver.cpp:613] Iteration 103000, avg_grad_norm = 557806
I0318 01:54:41.227989 29479 solver.cpp:214] Iteration 103020, loss = 5481.24
I0318 01:54:41.228147 29479 solver.cpp:229]     Train net output #0: loss = 3940.87 (* 1 = 3940.87 loss)
I0318 01:54:41.412102 29479 solver.cpp:610] Iteration 103020, lr = 5.21299e-09
I0318 01:54:41.412116 29479 solver.cpp:613] Iteration 103020, avg_grad_norm = 503698
I0318 01:57:07.867540 29479 solver.cpp:214] Iteration 103040, loss = 5638.83
I0318 01:57:07.867674 29479 solver.cpp:229]     Train net output #0: loss = 7699.56 (* 1 = 7699.56 loss)
I0318 01:57:08.045400 29479 solver.cpp:610] Iteration 103040, lr = 5.21202e-09
I0318 01:57:08.045413 29479 solver.cpp:613] Iteration 103040, avg_grad_norm = 472956
I0318 01:58:28.474436 29479 solver.cpp:214] Iteration 103060, loss = 5725.67
I0318 01:58:28.474619 29479 solver.cpp:229]     Train net output #0: loss = 6171.71 (* 1 = 6171.71 loss)
I0318 01:58:28.648952 29479 solver.cpp:610] Iteration 103060, lr = 5.21106e-09
I0318 01:58:28.648964 29479 solver.cpp:613] Iteration 103060, avg_grad_norm = 570790
I0318 02:00:56.206343 29479 solver.cpp:214] Iteration 103080, loss = 5542.5
I0318 02:00:56.206480 29479 solver.cpp:229]     Train net output #0: loss = 8185.62 (* 1 = 8185.62 loss)
I0318 02:00:57.286766 29479 solver.cpp:610] Iteration 103080, lr = 5.21009e-09
I0318 02:00:57.286779 29479 solver.cpp:613] Iteration 103080, avg_grad_norm = 490728
I0318 02:03:25.775421 29479 solver.cpp:214] Iteration 103100, loss = 5366.72
I0318 02:03:25.775553 29479 solver.cpp:229]     Train net output #0: loss = 10499.4 (* 1 = 10499.4 loss)
I0318 02:03:26.822892 29479 solver.cpp:610] Iteration 103100, lr = 5.20912e-09
I0318 02:03:26.822906 29479 solver.cpp:613] Iteration 103100, avg_grad_norm = 472688
I0318 02:06:09.428830 29479 solver.cpp:214] Iteration 103120, loss = 5761.81
I0318 02:06:09.428947 29479 solver.cpp:229]     Train net output #0: loss = 4387.58 (* 1 = 4387.58 loss)
I0318 02:06:10.481259 29479 solver.cpp:610] Iteration 103120, lr = 5.20815e-09
I0318 02:06:10.481276 29479 solver.cpp:613] Iteration 103120, avg_grad_norm = 521530
I0318 02:08:38.060616 29479 solver.cpp:214] Iteration 103140, loss = 5252.05
I0318 02:08:38.060811 29479 solver.cpp:229]     Train net output #0: loss = 5192.87 (* 1 = 5192.87 loss)
I0318 02:08:39.097311 29479 solver.cpp:610] Iteration 103140, lr = 5.20719e-09
I0318 02:08:39.097326 29479 solver.cpp:613] Iteration 103140, avg_grad_norm = 466016
I0318 02:11:06.725256 29479 solver.cpp:214] Iteration 103160, loss = 5769.15
I0318 02:11:06.725383 29479 solver.cpp:229]     Train net output #0: loss = 4751.8 (* 1 = 4751.8 loss)
I0318 02:11:07.798477 29479 solver.cpp:610] Iteration 103160, lr = 5.20622e-09
I0318 02:11:07.798491 29479 solver.cpp:613] Iteration 103160, avg_grad_norm = 486805
I0318 02:13:36.318703 29479 solver.cpp:214] Iteration 103180, loss = 5398.09
I0318 02:13:36.318847 29479 solver.cpp:229]     Train net output #0: loss = 3826 (* 1 = 3826 loss)
I0318 02:13:36.493640 29479 solver.cpp:610] Iteration 103180, lr = 5.20525e-09
I0318 02:13:36.493677 29479 solver.cpp:613] Iteration 103180, avg_grad_norm = 471127
I0318 02:16:04.994460 29479 solver.cpp:214] Iteration 103200, loss = 5484.53
I0318 02:16:04.994643 29479 solver.cpp:229]     Train net output #0: loss = 3857.73 (* 1 = 3857.73 loss)
I0318 02:16:06.042855 29479 solver.cpp:610] Iteration 103200, lr = 5.20428e-09
I0318 02:16:06.042870 29479 solver.cpp:613] Iteration 103200, avg_grad_norm = 503582
I0318 02:18:11.617434 29479 solver.cpp:214] Iteration 103220, loss = 5714.3
I0318 02:18:11.617624 29479 solver.cpp:229]     Train net output #0: loss = 5588.24 (* 1 = 5588.24 loss)
I0318 02:18:11.721814 29479 solver.cpp:610] Iteration 103220, lr = 5.20331e-09
I0318 02:18:11.721828 29479 solver.cpp:613] Iteration 103220, avg_grad_norm = 516912
I0318 02:19:14.222461 29479 solver.cpp:214] Iteration 103240, loss = 5321.73
I0318 02:19:14.222580 29479 solver.cpp:229]     Train net output #0: loss = 9930.94 (* 1 = 9930.94 loss)
I0318 02:19:15.297888 29479 solver.cpp:610] Iteration 103240, lr = 5.20235e-09
I0318 02:19:15.297901 29479 solver.cpp:613] Iteration 103240, avg_grad_norm = 482510
I0318 02:21:56.945772 29479 solver.cpp:214] Iteration 103260, loss = 5461.71
I0318 02:21:56.945955 29479 solver.cpp:229]     Train net output #0: loss = 7110.69 (* 1 = 7110.69 loss)
I0318 02:21:58.014178 29479 solver.cpp:610] Iteration 103260, lr = 5.20138e-09
I0318 02:21:58.014191 29479 solver.cpp:613] Iteration 103260, avg_grad_norm = 538125
I0318 02:24:26.539475 29479 solver.cpp:214] Iteration 103280, loss = 5661.36
I0318 02:24:26.539604 29479 solver.cpp:229]     Train net output #0: loss = 7812.63 (* 1 = 7812.63 loss)
I0318 02:24:27.616436 29479 solver.cpp:610] Iteration 103280, lr = 5.20041e-09
I0318 02:24:27.616449 29479 solver.cpp:613] Iteration 103280, avg_grad_norm = 504803
I0318 02:26:55.164963 29479 solver.cpp:214] Iteration 103300, loss = 5694.28
I0318 02:26:55.165087 29479 solver.cpp:229]     Train net output #0: loss = 4494.32 (* 1 = 4494.32 loss)
I0318 02:26:56.218041 29479 solver.cpp:610] Iteration 103300, lr = 5.19944e-09
I0318 02:26:56.218055 29479 solver.cpp:613] Iteration 103300, avg_grad_norm = 519426
I0318 02:29:22.772536 29479 solver.cpp:214] Iteration 103320, loss = 5511.7
I0318 02:29:22.772670 29479 solver.cpp:229]     Train net output #0: loss = 4113.8 (* 1 = 4113.8 loss)
I0318 02:29:22.926445 29479 solver.cpp:610] Iteration 103320, lr = 5.19847e-09
I0318 02:29:22.926460 29479 solver.cpp:613] Iteration 103320, avg_grad_norm = 508826
I0318 02:31:50.406930 29479 solver.cpp:214] Iteration 103340, loss = 5710.06
I0318 02:31:50.407063 29479 solver.cpp:229]     Train net output #0: loss = 3365.47 (* 1 = 3365.47 loss)
I0318 02:31:50.582187 29479 solver.cpp:610] Iteration 103340, lr = 5.19751e-09
I0318 02:31:50.582201 29479 solver.cpp:613] Iteration 103340, avg_grad_norm = 492611
I0318 02:34:19.090291 29479 solver.cpp:214] Iteration 103360, loss = 5363.26
I0318 02:34:19.090406 29479 solver.cpp:229]     Train net output #0: loss = 3297.01 (* 1 = 3297.01 loss)
I0318 02:34:20.138051 29479 solver.cpp:610] Iteration 103360, lr = 5.19654e-09
I0318 02:34:20.138067 29479 solver.cpp:613] Iteration 103360, avg_grad_norm = 486173
I0318 02:37:01.702548 29479 solver.cpp:214] Iteration 103380, loss = 5765.76
I0318 02:37:01.702666 29479 solver.cpp:229]     Train net output #0: loss = 4141.94 (* 1 = 4141.94 loss)
I0318 02:37:01.877513 29479 solver.cpp:610] Iteration 103380, lr = 5.19557e-09
I0318 02:37:01.877527 29479 solver.cpp:613] Iteration 103380, avg_grad_norm = 484148
I0318 02:38:40.336756 29479 solver.cpp:214] Iteration 103400, loss = 5556.12
I0318 02:38:40.336900 29479 solver.cpp:229]     Train net output #0: loss = 5324.19 (* 1 = 5324.19 loss)
I0318 02:38:40.440842 29479 solver.cpp:610] Iteration 103400, lr = 5.1946e-09
I0318 02:38:40.440855 29479 solver.cpp:613] Iteration 103400, avg_grad_norm = 495826
I0318 02:40:38.967931 29479 solver.cpp:214] Iteration 103420, loss = 5876.14
I0318 02:40:38.968109 29479 solver.cpp:229]     Train net output #0: loss = 3580.62 (* 1 = 3580.62 loss)
I0318 02:40:39.124933 29479 solver.cpp:610] Iteration 103420, lr = 5.19364e-09
I0318 02:40:39.124946 29479 solver.cpp:613] Iteration 103420, avg_grad_norm = 491118
I0318 02:43:07.568125 29479 solver.cpp:214] Iteration 103440, loss = 5605.64
I0318 02:43:07.568251 29479 solver.cpp:229]     Train net output #0: loss = 7111 (* 1 = 7111 loss)
I0318 02:43:07.726313 29479 solver.cpp:610] Iteration 103440, lr = 5.19267e-09
I0318 02:43:07.726327 29479 solver.cpp:613] Iteration 103440, avg_grad_norm = 509164
I0318 02:45:37.230612 29479 solver.cpp:214] Iteration 103460, loss = 5704.92
I0318 02:45:37.230784 29479 solver.cpp:229]     Train net output #0: loss = 4023.78 (* 1 = 4023.78 loss)
I0318 02:45:38.280205 29479 solver.cpp:610] Iteration 103460, lr = 5.1917e-09
I0318 02:45:38.280220 29479 solver.cpp:613] Iteration 103460, avg_grad_norm = 496551
I0318 02:48:05.802558 29479 solver.cpp:214] Iteration 103480, loss = 5895.71
I0318 02:48:05.802662 29479 solver.cpp:229]     Train net output #0: loss = 4631.8 (* 1 = 4631.8 loss)
I0318 02:48:06.840062 29479 solver.cpp:610] Iteration 103480, lr = 5.19073e-09
I0318 02:48:06.840076 29479 solver.cpp:613] Iteration 103480, avg_grad_norm = 522604
I0318 02:50:48.459450 29479 solver.cpp:214] Iteration 103500, loss = 5536.81
I0318 02:50:48.459554 29479 solver.cpp:229]     Train net output #0: loss = 11021.4 (* 1 = 11021.4 loss)
I0318 02:50:49.542876 29479 solver.cpp:610] Iteration 103500, lr = 5.18976e-09
I0318 02:50:49.542889 29479 solver.cpp:613] Iteration 103500, avg_grad_norm = 506940
I0318 02:53:17.010267 29479 solver.cpp:214] Iteration 103520, loss = 5603.32
I0318 02:53:17.010391 29479 solver.cpp:229]     Train net output #0: loss = 6878.22 (* 1 = 6878.22 loss)
I0318 02:53:18.048558 29479 solver.cpp:610] Iteration 103520, lr = 5.1888e-09
I0318 02:53:18.048571 29479 solver.cpp:613] Iteration 103520, avg_grad_norm = 507359
I0318 02:55:45.621659 29479 solver.cpp:214] Iteration 103540, loss = 5417.4
I0318 02:55:45.621800 29479 solver.cpp:229]     Train net output #0: loss = 8353.81 (* 1 = 8353.81 loss)
I0318 02:55:46.657424 29479 solver.cpp:610] Iteration 103540, lr = 5.18783e-09
I0318 02:55:46.657438 29479 solver.cpp:613] Iteration 103540, avg_grad_norm = 488010
I0318 02:58:14.281779 29479 solver.cpp:214] Iteration 103560, loss = 5356.4
I0318 02:58:14.281980 29479 solver.cpp:229]     Train net output #0: loss = 8085.91 (* 1 = 8085.91 loss)
I0318 02:58:15.367341 29479 solver.cpp:610] Iteration 103560, lr = 5.18686e-09
I0318 02:58:15.367362 29479 solver.cpp:613] Iteration 103560, avg_grad_norm = 487313
I0318 02:59:34.846854 29479 solver.cpp:214] Iteration 103580, loss = 5452.61
I0318 02:59:34.846964 29479 solver.cpp:229]     Train net output #0: loss = 3504.26 (* 1 = 3504.26 loss)
I0318 02:59:35.892277 29479 solver.cpp:610] Iteration 103580, lr = 5.18589e-09
I0318 02:59:35.892289 29479 solver.cpp:613] Iteration 103580, avg_grad_norm = 472123
I0318 03:02:03.518237 29479 solver.cpp:214] Iteration 103600, loss = 5394.9
I0318 03:02:03.518388 29479 solver.cpp:229]     Train net output #0: loss = 4153.8 (* 1 = 4153.8 loss)
I0318 03:02:04.601524 29479 solver.cpp:610] Iteration 103600, lr = 5.18492e-09
I0318 03:02:04.601539 29479 solver.cpp:613] Iteration 103600, avg_grad_norm = 465421
I0318 03:04:33.060708 29479 solver.cpp:214] Iteration 103620, loss = 5260.37
I0318 03:04:33.060853 29479 solver.cpp:229]     Train net output #0: loss = 5720.73 (* 1 = 5720.73 loss)
I0318 03:04:33.283860 29479 solver.cpp:610] Iteration 103620, lr = 5.18396e-09
I0318 03:04:33.283874 29479 solver.cpp:613] Iteration 103620, avg_grad_norm = 501623
I0318 03:07:13.866178 29479 solver.cpp:214] Iteration 103640, loss = 5638.84
I0318 03:07:13.866310 29479 solver.cpp:229]     Train net output #0: loss = 8282.04 (* 1 = 8282.04 loss)
I0318 03:07:14.953996 29479 solver.cpp:610] Iteration 103640, lr = 5.18299e-09
I0318 03:07:14.954011 29479 solver.cpp:613] Iteration 103640, avg_grad_norm = 540213
I0318 03:09:43.440032 29479 solver.cpp:214] Iteration 103660, loss = 5411.92
I0318 03:09:43.440161 29479 solver.cpp:229]     Train net output #0: loss = 3468.21 (* 1 = 3468.21 loss)
I0318 03:09:44.471793 29479 solver.cpp:610] Iteration 103660, lr = 5.18202e-09
I0318 03:09:44.471807 29479 solver.cpp:613] Iteration 103660, avg_grad_norm = 538843
I0318 03:12:12.009815 29479 solver.cpp:214] Iteration 103680, loss = 5665.08
I0318 03:12:12.010015 29479 solver.cpp:229]     Train net output #0: loss = 7768.03 (* 1 = 7768.03 loss)
I0318 03:12:13.053076 29479 solver.cpp:610] Iteration 103680, lr = 5.18105e-09
I0318 03:12:13.053097 29479 solver.cpp:613] Iteration 103680, avg_grad_norm = 556969
I0318 03:14:40.669472 29479 solver.cpp:214] Iteration 103700, loss = 5617.32
I0318 03:14:40.669661 29479 solver.cpp:229]     Train net output #0: loss = 3849.62 (* 1 = 3849.62 loss)
I0318 03:14:41.745487 29479 solver.cpp:610] Iteration 103700, lr = 5.18008e-09
I0318 03:14:41.745501 29479 solver.cpp:613] Iteration 103700, avg_grad_norm = 449591
I0318 03:17:09.311365 29479 solver.cpp:214] Iteration 103720, loss = 5559.89
I0318 03:17:09.311556 29479 solver.cpp:229]     Train net output #0: loss = 2763.48 (* 1 = 2763.48 loss)
I0318 03:17:10.360417 29479 solver.cpp:610] Iteration 103720, lr = 5.17911e-09
I0318 03:17:10.360431 29479 solver.cpp:613] Iteration 103720, avg_grad_norm = 489185
I0318 03:19:13.899379 29479 solver.cpp:214] Iteration 103740, loss = 5724.73
I0318 03:19:13.899519 29479 solver.cpp:229]     Train net output #0: loss = 5281.71 (* 1 = 5281.71 loss)
I0318 03:19:14.005239 29479 solver.cpp:610] Iteration 103740, lr = 5.17815e-09
I0318 03:19:14.005285 29479 solver.cpp:613] Iteration 103740, avg_grad_norm = 506524
I0318 03:21:05.574288 29479 solver.cpp:214] Iteration 103760, loss = 5708.62
I0318 03:21:05.574373 29479 solver.cpp:229]     Train net output #0: loss = 5073.89 (* 1 = 5073.89 loss)
I0318 03:21:06.650995 29479 solver.cpp:610] Iteration 103760, lr = 5.17718e-09
I0318 03:21:06.651010 29479 solver.cpp:613] Iteration 103760, avg_grad_norm = 558226
I0318 03:23:35.177502 29479 solver.cpp:214] Iteration 103780, loss = 5420.24
I0318 03:23:35.177610 29479 solver.cpp:229]     Train net output #0: loss = 8878.37 (* 1 = 8878.37 loss)
I0318 03:23:36.219619 29479 solver.cpp:610] Iteration 103780, lr = 5.17621e-09
I0318 03:23:36.219633 29479 solver.cpp:613] Iteration 103780, avg_grad_norm = 463184
I0318 03:26:04.794489 29479 solver.cpp:214] Iteration 103800, loss = 5443.59
I0318 03:26:04.794615 29479 solver.cpp:229]     Train net output #0: loss = 3751.33 (* 1 = 3751.33 loss)
I0318 03:26:05.878752 29479 solver.cpp:610] Iteration 103800, lr = 5.17524e-09
I0318 03:26:05.878767 29479 solver.cpp:613] Iteration 103800, avg_grad_norm = 526066
I0318 03:28:33.420788 29479 solver.cpp:214] Iteration 103820, loss = 5613.65
I0318 03:28:33.420989 29479 solver.cpp:229]     Train net output #0: loss = 4386.08 (* 1 = 4386.08 loss)
I0318 03:28:34.493702 29479 solver.cpp:610] Iteration 103820, lr = 5.17427e-09
I0318 03:28:34.493717 29479 solver.cpp:613] Iteration 103820, avg_grad_norm = 545757
I0318 03:31:01.941300 29479 solver.cpp:214] Iteration 103840, loss = 5580.22
I0318 03:31:01.941498 29479 solver.cpp:229]     Train net output #0: loss = 6136.78 (* 1 = 6136.78 loss)
I0318 03:31:02.987413 29479 solver.cpp:610] Iteration 103840, lr = 5.1733e-09
I0318 03:31:02.987427 29479 solver.cpp:613] Iteration 103840, avg_grad_norm = 488067
I0318 03:33:31.635495 29479 solver.cpp:214] Iteration 103860, loss = 5650.77
I0318 03:33:31.635607 29479 solver.cpp:229]     Train net output #0: loss = 4292.05 (* 1 = 4292.05 loss)
I0318 03:33:32.704041 29479 solver.cpp:610] Iteration 103860, lr = 5.17234e-09
I0318 03:33:32.704056 29479 solver.cpp:613] Iteration 103860, avg_grad_norm = 473680
I0318 03:36:15.179847 29479 solver.cpp:214] Iteration 103880, loss = 5678.29
I0318 03:36:15.179975 29479 solver.cpp:229]     Train net output #0: loss = 4730.42 (* 1 = 4730.42 loss)
I0318 03:36:15.353982 29479 solver.cpp:610] Iteration 103880, lr = 5.17137e-09
I0318 03:36:15.353996 29479 solver.cpp:613] Iteration 103880, avg_grad_norm = 477114
I0318 03:38:43.859249 29479 solver.cpp:214] Iteration 103900, loss = 5666.78
I0318 03:38:43.859447 29479 solver.cpp:229]     Train net output #0: loss = 4366.05 (* 1 = 4366.05 loss)
I0318 03:38:44.940603 29479 solver.cpp:610] Iteration 103900, lr = 5.1704e-09
I0318 03:38:44.940616 29479 solver.cpp:613] Iteration 103900, avg_grad_norm = 483886
I0318 03:40:00.462036 29479 solver.cpp:214] Iteration 103920, loss = 5834.2
I0318 03:40:00.462168 29479 solver.cpp:229]     Train net output #0: loss = 6995.11 (* 1 = 6995.11 loss)
I0318 03:40:01.540141 29479 solver.cpp:610] Iteration 103920, lr = 5.16943e-09
I0318 03:40:01.540155 29479 solver.cpp:613] Iteration 103920, avg_grad_norm = 472876
I0318 03:42:30.093837 29479 solver.cpp:214] Iteration 103940, loss = 5692.14
I0318 03:42:30.094012 29479 solver.cpp:229]     Train net output #0: loss = 5560.9 (* 1 = 5560.9 loss)
I0318 03:42:31.182651 29479 solver.cpp:610] Iteration 103940, lr = 5.16846e-09
I0318 03:42:31.182689 29479 solver.cpp:613] Iteration 103940, avg_grad_norm = 577605
I0318 03:44:58.837761 29479 solver.cpp:214] Iteration 103960, loss = 5801.08
I0318 03:44:58.837942 29479 solver.cpp:229]     Train net output #0: loss = 3572.57 (* 1 = 3572.57 loss)
I0318 03:44:59.908193 29479 solver.cpp:610] Iteration 103960, lr = 5.16749e-09
I0318 03:44:59.908268 29479 solver.cpp:613] Iteration 103960, avg_grad_norm = 575118
I0318 03:47:30.325992 29479 solver.cpp:214] Iteration 103980, loss = 5436.2
I0318 03:47:30.326095 29479 solver.cpp:229]     Train net output #0: loss = 6713.31 (* 1 = 6713.31 loss)
I0318 03:47:30.548694 29479 solver.cpp:610] Iteration 103980, lr = 5.16652e-09
I0318 03:47:30.548729 29479 solver.cpp:613] Iteration 103980, avg_grad_norm = 594970
I0318 03:50:00.096850 29479 solver.cpp:214] Iteration 104000, loss = 5560.59
I0318 03:50:00.097030 29479 solver.cpp:229]     Train net output #0: loss = 4928.99 (* 1 = 4928.99 loss)
I0318 03:50:01.139520 29479 solver.cpp:610] Iteration 104000, lr = 5.16556e-09
I0318 03:50:01.139534 29479 solver.cpp:613] Iteration 104000, avg_grad_norm = 532202
I0318 03:52:41.698534 29479 solver.cpp:214] Iteration 104020, loss = 5368.12
I0318 03:52:41.698649 29479 solver.cpp:229]     Train net output #0: loss = 8002.38 (* 1 = 8002.38 loss)
I0318 03:52:41.853127 29479 solver.cpp:610] Iteration 104020, lr = 5.16459e-09
I0318 03:52:41.853142 29479 solver.cpp:613] Iteration 104020, avg_grad_norm = 501836
I0318 03:55:11.329926 29479 solver.cpp:214] Iteration 104040, loss = 5344.55
I0318 03:55:11.330121 29479 solver.cpp:229]     Train net output #0: loss = 4294.64 (* 1 = 4294.64 loss)
I0318 03:55:11.487592 29479 solver.cpp:610] Iteration 104040, lr = 5.16362e-09
I0318 03:55:11.487607 29479 solver.cpp:613] Iteration 104040, avg_grad_norm = 477605
I0318 03:57:39.943262 29479 solver.cpp:214] Iteration 104060, loss = 5755.71
I0318 03:57:39.943395 29479 solver.cpp:229]     Train net output #0: loss = 7902.92 (* 1 = 7902.92 loss)
I0318 03:57:40.104080 29479 solver.cpp:610] Iteration 104060, lr = 5.16265e-09
I0318 03:57:40.104094 29479 solver.cpp:613] Iteration 104060, avg_grad_norm = 497926
I0318 03:59:47.607020 29479 solver.cpp:214] Iteration 104080, loss = 5177.92
I0318 03:59:47.607151 29479 solver.cpp:229]     Train net output #0: loss = 7112.36 (* 1 = 7112.36 loss)
I0318 03:59:47.710729 29479 solver.cpp:610] Iteration 104080, lr = 5.16168e-09
I0318 03:59:47.710777 29479 solver.cpp:613] Iteration 104080, avg_grad_norm = 480210
I0318 04:01:29.146674 29479 solver.cpp:214] Iteration 104100, loss = 5804.25
I0318 04:01:29.146801 29479 solver.cpp:229]     Train net output #0: loss = 5925.28 (* 1 = 5925.28 loss)
I0318 04:01:29.303705 29479 solver.cpp:610] Iteration 104100, lr = 5.16071e-09
I0318 04:01:29.303719 29479 solver.cpp:613] Iteration 104100, avg_grad_norm = 500216
I0318 04:03:57.775208 29479 solver.cpp:214] Iteration 104120, loss = 5582.81
I0318 04:03:57.776165 29479 solver.cpp:229]     Train net output #0: loss = 2109.87 (* 1 = 2109.87 loss)
I0318 04:03:58.859498 29479 solver.cpp:610] Iteration 104120, lr = 5.15974e-09
I0318 04:03:58.859515 29479 solver.cpp:613] Iteration 104120, avg_grad_norm = 523868
I0318 04:06:51.372862 29479 solver.cpp:214] Iteration 104140, loss = 6003.55
I0318 04:06:51.372979 29479 solver.cpp:229]     Train net output #0: loss = 2927.67 (* 1 = 2927.67 loss)
I0318 04:06:52.458122 29479 solver.cpp:610] Iteration 104140, lr = 5.15878e-09
I0318 04:06:52.458137 29479 solver.cpp:613] Iteration 104140, avg_grad_norm = 542244
I0318 04:09:21.939188 29479 solver.cpp:214] Iteration 104160, loss = 5330.04
I0318 04:09:21.939347 29479 solver.cpp:229]     Train net output #0: loss = 8074.19 (* 1 = 8074.19 loss)
I0318 04:09:22.106254 29479 solver.cpp:610] Iteration 104160, lr = 5.15781e-09
I0318 04:09:22.106307 29479 solver.cpp:613] Iteration 104160, avg_grad_norm = 524996
I0318 04:11:51.494084 29479 solver.cpp:214] Iteration 104180, loss = 5549.34
I0318 04:11:51.494266 29479 solver.cpp:229]     Train net output #0: loss = 2854.69 (* 1 = 2854.69 loss)
I0318 04:11:51.717116 29479 solver.cpp:610] Iteration 104180, lr = 5.15684e-09
I0318 04:11:51.717129 29479 solver.cpp:613] Iteration 104180, avg_grad_norm = 493779
I0318 04:14:20.250924 29479 solver.cpp:214] Iteration 104200, loss = 5264.99
I0318 04:14:20.251076 29479 solver.cpp:229]     Train net output #0: loss = 7037.37 (* 1 = 7037.37 loss)
I0318 04:14:21.331782 29479 solver.cpp:610] Iteration 104200, lr = 5.15587e-09
I0318 04:14:21.331797 29479 solver.cpp:613] Iteration 104200, avg_grad_norm = 524559
I0318 04:16:49.795917 29479 solver.cpp:214] Iteration 104220, loss = 5350.18
I0318 04:16:49.796044 29479 solver.cpp:229]     Train net output #0: loss = 3328.94 (* 1 = 3328.94 loss)
I0318 04:16:49.971124 29479 solver.cpp:610] Iteration 104220, lr = 5.1549e-09
I0318 04:16:49.971138 29479 solver.cpp:613] Iteration 104220, avg_grad_norm = 494907
I0318 04:19:19.403872 29479 solver.cpp:214] Iteration 104240, loss = 5370.24
I0318 04:19:19.403975 29479 solver.cpp:229]     Train net output #0: loss = 4843.13 (* 1 = 4843.13 loss)
I0318 04:19:19.575479 29479 solver.cpp:610] Iteration 104240, lr = 5.15393e-09
I0318 04:19:19.575494 29479 solver.cpp:613] Iteration 104240, avg_grad_norm = 497780
I0318 04:20:25.987104 29479 solver.cpp:214] Iteration 104260, loss = 5620.34
I0318 04:20:25.987253 29479 solver.cpp:229]     Train net output #0: loss = 7577.61 (* 1 = 7577.61 loss)
I0318 04:20:26.142061 29479 solver.cpp:610] Iteration 104260, lr = 5.15296e-09
I0318 04:20:26.142076 29479 solver.cpp:613] Iteration 104260, avg_grad_norm = 497325
I0318 04:23:20.619215 29479 solver.cpp:214] Iteration 104280, loss = 5413.54
I0318 04:23:20.619371 29479 solver.cpp:229]     Train net output #0: loss = 6957.33 (* 1 = 6957.33 loss)
I0318 04:23:20.793854 29479 solver.cpp:610] Iteration 104280, lr = 5.152e-09
I0318 04:23:20.793876 29479 solver.cpp:613] Iteration 104280, avg_grad_norm = 570944
I0318 04:25:50.208577 29479 solver.cpp:214] Iteration 104300, loss = 5380.89
I0318 04:25:50.208739 29479 solver.cpp:229]     Train net output #0: loss = 4990.31 (* 1 = 4990.31 loss)
I0318 04:25:50.363461 29479 solver.cpp:610] Iteration 104300, lr = 5.15103e-09
I0318 04:25:50.363474 29479 solver.cpp:613] Iteration 104300, avg_grad_norm = 597038
I0318 04:28:18.791242 29479 solver.cpp:214] Iteration 104320, loss = 5539.79
I0318 04:28:18.791338 29479 solver.cpp:229]     Train net output #0: loss = 4015.1 (* 1 = 4015.1 loss)
I0318 04:28:18.945693 29479 solver.cpp:610] Iteration 104320, lr = 5.15006e-09
I0318 04:28:18.945708 29479 solver.cpp:613] Iteration 104320, avg_grad_norm = 468830
I0318 04:30:48.348369 29479 solver.cpp:214] Iteration 104340, loss = 5527.05
I0318 04:30:48.348522 29479 solver.cpp:229]     Train net output #0: loss = 4860.93 (* 1 = 4860.93 loss)
I0318 04:30:48.509444 29479 solver.cpp:610] Iteration 104340, lr = 5.14909e-09
I0318 04:30:48.509457 29479 solver.cpp:613] Iteration 104340, avg_grad_norm = 526574
I0318 04:33:17.992564 29479 solver.cpp:214] Iteration 104360, loss = 5188.01
I0318 04:33:17.992687 29479 solver.cpp:229]     Train net output #0: loss = 5772.32 (* 1 = 5772.32 loss)
I0318 04:33:19.028705 29479 solver.cpp:610] Iteration 104360, lr = 5.14812e-09
I0318 04:33:19.028748 29479 solver.cpp:613] Iteration 104360, avg_grad_norm = 511002
I0318 04:35:47.556246 29479 solver.cpp:214] Iteration 104380, loss = 5629.39
I0318 04:35:47.556396 29479 solver.cpp:229]     Train net output #0: loss = 4796.65 (* 1 = 4796.65 loss)
I0318 04:35:47.710105 29479 solver.cpp:610] Iteration 104380, lr = 5.14715e-09
I0318 04:35:47.710119 29479 solver.cpp:613] Iteration 104380, avg_grad_norm = 555791
I0318 04:38:28.284646 29479 solver.cpp:214] Iteration 104400, loss = 5674.04
I0318 04:38:28.284863 29479 solver.cpp:229]     Train net output #0: loss = 8415.31 (* 1 = 8415.31 loss)
I0318 04:38:29.367874 29479 solver.cpp:610] Iteration 104400, lr = 5.14618e-09
I0318 04:38:29.367889 29479 solver.cpp:613] Iteration 104400, avg_grad_norm = 525606
I0318 04:40:20.930071 29479 solver.cpp:214] Iteration 104420, loss = 5559.81
I0318 04:40:20.930269 29479 solver.cpp:229]     Train net output #0: loss = 2699.33 (* 1 = 2699.33 loss)
I0318 04:40:21.034410 29479 solver.cpp:610] Iteration 104420, lr = 5.14521e-09
I0318 04:40:21.034443 29479 solver.cpp:613] Iteration 104420, avg_grad_norm = 528991
I0318 04:42:12.578456 29479 solver.cpp:214] Iteration 104440, loss = 5508.61
I0318 04:42:12.578557 29479 solver.cpp:229]     Train net output #0: loss = 6450.45 (* 1 = 6450.45 loss)
I0318 04:42:13.663718 29479 solver.cpp:610] Iteration 104440, lr = 5.14424e-09
I0318 04:42:13.663733 29479 solver.cpp:613] Iteration 104440, avg_grad_norm = 515918
I0318 04:44:42.128499 29479 solver.cpp:214] Iteration 104460, loss = 5517.14
I0318 04:44:42.128633 29479 solver.cpp:229]     Train net output #0: loss = 3735.08 (* 1 = 3735.08 loss)
I0318 04:44:43.209381 29479 solver.cpp:610] Iteration 104460, lr = 5.14327e-09
I0318 04:44:43.209395 29479 solver.cpp:613] Iteration 104460, avg_grad_norm = 611836
I0318 04:47:10.746124 29479 solver.cpp:214] Iteration 104480, loss = 5731.93
I0318 04:47:10.746268 29479 solver.cpp:229]     Train net output #0: loss = 7287.22 (* 1 = 7287.22 loss)
I0318 04:47:11.783514 29479 solver.cpp:610] Iteration 104480, lr = 5.14231e-09
I0318 04:47:11.783529 29479 solver.cpp:613] Iteration 104480, avg_grad_norm = 523584
I0318 04:49:40.373641 29479 solver.cpp:214] Iteration 104500, loss = 5831.06
I0318 04:49:40.373762 29479 solver.cpp:229]     Train net output #0: loss = 5632.61 (* 1 = 5632.61 loss)
I0318 04:49:41.418761 29479 solver.cpp:610] Iteration 104500, lr = 5.14134e-09
I0318 04:49:41.418774 29479 solver.cpp:613] Iteration 104500, avg_grad_norm = 496786
I0318 04:52:22.041985 29479 solver.cpp:214] Iteration 104520, loss = 5651.77
I0318 04:52:22.042134 29479 solver.cpp:229]     Train net output #0: loss = 3013.63 (* 1 = 3013.63 loss)
I0318 04:52:23.130735 29479 solver.cpp:610] Iteration 104520, lr = 5.14037e-09
I0318 04:52:23.130749 29479 solver.cpp:613] Iteration 104520, avg_grad_norm = 520686
I0318 04:54:51.655314 29479 solver.cpp:214] Iteration 104540, loss = 5440.21
I0318 04:54:51.655410 29479 solver.cpp:229]     Train net output #0: loss = 5405.06 (* 1 = 5405.06 loss)
I0318 04:54:51.826259 29479 solver.cpp:610] Iteration 104540, lr = 5.1394e-09
I0318 04:54:51.826273 29479 solver.cpp:613] Iteration 104540, avg_grad_norm = 542719
I0318 04:57:19.364037 29479 solver.cpp:214] Iteration 104560, loss = 5531.94
I0318 04:57:19.364179 29479 solver.cpp:229]     Train net output #0: loss = 4617.9 (* 1 = 4617.9 loss)
I0318 04:57:20.445497 29479 solver.cpp:610] Iteration 104560, lr = 5.13843e-09
I0318 04:57:20.445545 29479 solver.cpp:613] Iteration 104560, avg_grad_norm = 496559
I0318 04:59:36.908968 29479 solver.cpp:214] Iteration 104580, loss = 5501.09
I0318 04:59:36.909174 29479 solver.cpp:229]     Train net output #0: loss = 4506.31 (* 1 = 4506.31 loss)
I0318 04:59:37.950757 29479 solver.cpp:610] Iteration 104580, lr = 5.13746e-09
I0318 04:59:37.950780 29479 solver.cpp:613] Iteration 104580, avg_grad_norm = 496124
I0318 05:00:49.484907 29479 solver.cpp:214] Iteration 104600, loss = 5454.56
I0318 05:00:49.485047 29479 solver.cpp:229]     Train net output #0: loss = 3701.64 (* 1 = 3701.64 loss)
I0318 05:00:49.590601 29479 solver.cpp:610] Iteration 104600, lr = 5.13649e-09
I0318 05:00:49.590615 29479 solver.cpp:613] Iteration 104600, avg_grad_norm = 522734
I0318 05:02:53.089324 29479 solver.cpp:214] Iteration 104620, loss = 5495.1
I0318 05:02:53.089465 29479 solver.cpp:229]     Train net output #0: loss = 5271.19 (* 1 = 5271.19 loss)
I0318 05:02:54.135738 29479 solver.cpp:610] Iteration 104620, lr = 5.13552e-09
I0318 05:02:54.135779 29479 solver.cpp:613] Iteration 104620, avg_grad_norm = 475696
I0318 05:05:20.686568 29479 solver.cpp:214] Iteration 104640, loss = 5463.04
I0318 05:05:20.686731 29479 solver.cpp:229]     Train net output #0: loss = 5398.97 (* 1 = 5398.97 loss)
I0318 05:05:20.839953 29479 solver.cpp:610] Iteration 104640, lr = 5.13455e-09
I0318 05:05:20.839967 29479 solver.cpp:613] Iteration 104640, avg_grad_norm = 476443
I0318 05:08:03.260959 29479 solver.cpp:214] Iteration 104660, loss = 5544.59
I0318 05:08:03.261234 29479 solver.cpp:229]     Train net output #0: loss = 9594.81 (* 1 = 9594.81 loss)
I0318 05:08:03.445688 29479 solver.cpp:610] Iteration 104660, lr = 5.13358e-09
I0318 05:08:03.445703 29479 solver.cpp:613] Iteration 104660, avg_grad_norm = 479174
I0318 05:10:32.893620 29479 solver.cpp:214] Iteration 104680, loss = 5450.88
I0318 05:10:32.893726 29479 solver.cpp:229]     Train net output #0: loss = 7428.53 (* 1 = 7428.53 loss)
I0318 05:10:33.068524 29479 solver.cpp:610] Iteration 104680, lr = 5.13261e-09
I0318 05:10:33.068538 29479 solver.cpp:613] Iteration 104680, avg_grad_norm = 475932
I0318 05:13:02.593236 29479 solver.cpp:214] Iteration 104700, loss = 5215.45
I0318 05:13:02.593341 29479 solver.cpp:229]     Train net output #0: loss = 8117.31 (* 1 = 8117.31 loss)
I0318 05:13:03.633023 29479 solver.cpp:610] Iteration 104700, lr = 5.13164e-09
I0318 05:13:03.633046 29479 solver.cpp:613] Iteration 104700, avg_grad_norm = 522695
I0318 05:15:32.177410 29479 solver.cpp:214] Iteration 104720, loss = 5479.04
I0318 05:15:32.177554 29479 solver.cpp:229]     Train net output #0: loss = 4195.48 (* 1 = 4195.48 loss)
I0318 05:15:32.353694 29479 solver.cpp:610] Iteration 104720, lr = 5.13068e-09
I0318 05:15:32.353735 29479 solver.cpp:613] Iteration 104720, avg_grad_norm = 545672
I0318 05:18:00.852675 29479 solver.cpp:214] Iteration 104740, loss = 5476.85
I0318 05:18:00.852855 29479 solver.cpp:229]     Train net output #0: loss = 6317.33 (* 1 = 6317.33 loss)
I0318 05:18:01.887300 29479 solver.cpp:610] Iteration 104740, lr = 5.12971e-09
I0318 05:18:01.887316 29479 solver.cpp:613] Iteration 104740, avg_grad_norm = 482114
I0318 05:20:30.420356 29479 solver.cpp:214] Iteration 104760, loss = 5520.57
I0318 05:20:30.420490 29479 solver.cpp:229]     Train net output #0: loss = 7353.24 (* 1 = 7353.24 loss)
I0318 05:20:30.578527 29479 solver.cpp:610] Iteration 104760, lr = 5.12874e-09
I0318 05:20:30.578542 29479 solver.cpp:613] Iteration 104760, avg_grad_norm = 467346
I0318 05:22:46.690593 29479 solver.cpp:214] Iteration 104780, loss = 5504.98
I0318 05:22:46.690701 29479 solver.cpp:229]     Train net output #0: loss = 4935.51 (* 1 = 4935.51 loss)
I0318 05:22:47.762068 29479 solver.cpp:610] Iteration 104780, lr = 5.12777e-09
I0318 05:22:47.762086 29479 solver.cpp:613] Iteration 104780, avg_grad_norm = 473783
I0318 05:25:16.272287 29479 solver.cpp:214] Iteration 104800, loss = 5711.12
I0318 05:25:16.272434 29479 solver.cpp:229]     Train net output #0: loss = 12083.9 (* 1 = 12083.9 loss)
I0318 05:25:17.306512 29479 solver.cpp:610] Iteration 104800, lr = 5.1268e-09
I0318 05:25:17.306527 29479 solver.cpp:613] Iteration 104800, avg_grad_norm = 475818
I0318 05:27:45.877238 29479 solver.cpp:214] Iteration 104820, loss = 5639.1
I0318 05:27:45.877424 29479 solver.cpp:229]     Train net output #0: loss = 6193.82 (* 1 = 6193.82 loss)
I0318 05:27:46.043270 29479 solver.cpp:610] Iteration 104820, lr = 5.12583e-09
I0318 05:27:46.043284 29479 solver.cpp:613] Iteration 104820, avg_grad_norm = 490332
I0318 05:30:15.522315 29479 solver.cpp:214] Iteration 104840, loss = 5260.2
I0318 05:30:15.522441 29479 solver.cpp:229]     Train net output #0: loss = 7919.01 (* 1 = 7919.01 loss)
I0318 05:30:15.676214 29479 solver.cpp:610] Iteration 104840, lr = 5.12486e-09
I0318 05:30:15.676229 29479 solver.cpp:613] Iteration 104840, avg_grad_norm = 458441
I0318 05:32:45.231308 29479 solver.cpp:214] Iteration 104860, loss = 5573.29
I0318 05:32:45.231434 29479 solver.cpp:229]     Train net output #0: loss = 5184.8 (* 1 = 5184.8 loss)
I0318 05:32:46.317178 29479 solver.cpp:610] Iteration 104860, lr = 5.12389e-09
I0318 05:32:46.317193 29479 solver.cpp:613] Iteration 104860, avg_grad_norm = 501511
I0318 05:35:14.774816 29479 solver.cpp:214] Iteration 104880, loss = 5391.9
I0318 05:35:14.775015 29479 solver.cpp:229]     Train net output #0: loss = 5171.41 (* 1 = 5171.41 loss)
I0318 05:35:15.814888 29479 solver.cpp:610] Iteration 104880, lr = 5.12292e-09
I0318 05:35:15.814903 29479 solver.cpp:613] Iteration 104880, avg_grad_norm = 551691
I0318 05:37:57.358459 29479 solver.cpp:214] Iteration 104900, loss = 5539.13
I0318 05:37:57.358583 29479 solver.cpp:229]     Train net output #0: loss = 3535.57 (* 1 = 3535.57 loss)
I0318 05:37:57.520042 29479 solver.cpp:610] Iteration 104900, lr = 5.12195e-09
I0318 05:37:57.520056 29479 solver.cpp:613] Iteration 104900, avg_grad_norm = 479880
I0318 05:40:25.050366 29479 solver.cpp:214] Iteration 104920, loss = 5457.75
I0318 05:40:25.050464 29479 solver.cpp:229]     Train net output #0: loss = 2847.48 (* 1 = 2847.48 loss)
I0318 05:40:26.085686 29479 solver.cpp:610] Iteration 104920, lr = 5.12098e-09
I0318 05:40:26.085700 29479 solver.cpp:613] Iteration 104920, avg_grad_norm = 525951
I0318 05:41:43.585952 29479 solver.cpp:214] Iteration 104940, loss = 5494.34
I0318 05:41:43.586030 29479 solver.cpp:229]     Train net output #0: loss = 4666.04 (* 1 = 4666.04 loss)
I0318 05:41:43.752867 29479 solver.cpp:610] Iteration 104940, lr = 5.12001e-09
I0318 05:41:43.752881 29479 solver.cpp:613] Iteration 104940, avg_grad_norm = 589966
I0318 05:44:12.246021 29479 solver.cpp:214] Iteration 104960, loss = 5682.05
I0318 05:44:12.246165 29479 solver.cpp:229]     Train net output #0: loss = 7430.37 (* 1 = 7430.37 loss)
I0318 05:44:13.328999 29479 solver.cpp:610] Iteration 104960, lr = 5.11904e-09
I0318 05:44:13.329016 29479 solver.cpp:613] Iteration 104960, avg_grad_norm = 610291
I0318 05:46:41.862344 29479 solver.cpp:214] Iteration 104980, loss = 5585.75
I0318 05:46:41.862431 29479 solver.cpp:229]     Train net output #0: loss = 7787.77 (* 1 = 7787.77 loss)
I0318 05:46:42.941654 29479 solver.cpp:610] Iteration 104980, lr = 5.11807e-09
I0318 05:46:42.941668 29479 solver.cpp:613] Iteration 104980, avg_grad_norm = 531003
I0318 05:49:10.409824 29479 solver.cpp:214] Iteration 105000, loss = 5742.28
I0318 05:49:10.409976 29479 solver.cpp:229]     Train net output #0: loss = 3362.08 (* 1 = 3362.08 loss)
I0318 05:49:10.563874 29479 solver.cpp:610] Iteration 105000, lr = 5.1171e-09
I0318 05:49:10.563887 29479 solver.cpp:613] Iteration 105000, avg_grad_norm = 484419
I0318 05:51:39.983981 29479 solver.cpp:214] Iteration 105020, loss = 5562.48
I0318 05:51:39.984096 29479 solver.cpp:229]     Train net output #0: loss = 5404.73 (* 1 = 5404.73 loss)
I0318 05:51:40.141206 29479 solver.cpp:610] Iteration 105020, lr = 5.11613e-09
I0318 05:51:40.141219 29479 solver.cpp:613] Iteration 105020, avg_grad_norm = 471641
I0318 05:54:21.572284 29479 solver.cpp:214] Iteration 105040, loss = 5789.73
I0318 05:54:21.572367 29479 solver.cpp:229]     Train net output #0: loss = 5184.4 (* 1 = 5184.4 loss)
I0318 05:54:21.733316 29479 solver.cpp:610] Iteration 105040, lr = 5.11516e-09
I0318 05:54:21.733330 29479 solver.cpp:613] Iteration 105040, avg_grad_norm = 467635
I0318 05:56:50.255331 29479 solver.cpp:214] Iteration 105060, loss = 5503.1
I0318 05:56:50.255466 29479 solver.cpp:229]     Train net output #0: loss = 4660.91 (* 1 = 4660.91 loss)
I0318 05:56:51.336122 29479 solver.cpp:610] Iteration 105060, lr = 5.1142e-09
I0318 05:56:51.336141 29479 solver.cpp:613] Iteration 105060, avg_grad_norm = 504330
I0318 05:59:19.867730 29479 solver.cpp:214] Iteration 105080, loss = 5553.89
I0318 05:59:19.867853 29479 solver.cpp:229]     Train net output #0: loss = 4690.62 (* 1 = 4690.62 loss)
I0318 05:59:20.950582 29479 solver.cpp:610] Iteration 105080, lr = 5.11323e-09
I0318 05:59:20.950595 29479 solver.cpp:613] Iteration 105080, avg_grad_norm = 510448
I0318 06:01:40.457231 29479 solver.cpp:214] Iteration 105100, loss = 5373.71
I0318 06:01:40.457442 29479 solver.cpp:229]     Train net output #0: loss = 6022.13 (* 1 = 6022.13 loss)
I0318 06:01:40.560773 29479 solver.cpp:610] Iteration 105100, lr = 5.11226e-09
I0318 06:01:40.560823 29479 solver.cpp:613] Iteration 105100, avg_grad_norm = 478067
I0318 06:02:04.011723 29479 solver.cpp:214] Iteration 105120, loss = 5843.82
I0318 06:02:04.011778 29479 solver.cpp:229]     Train net output #0: loss = 5005.54 (* 1 = 5005.54 loss)
I0318 06:02:04.116178 29479 solver.cpp:610] Iteration 105120, lr = 5.11129e-09
I0318 06:02:04.116191 29479 solver.cpp:613] Iteration 105120, avg_grad_norm = 480300
I0318 06:03:56.649266 29479 solver.cpp:214] Iteration 105140, loss = 5790.76
I0318 06:03:56.649435 29479 solver.cpp:229]     Train net output #0: loss = 3563.09 (* 1 = 3563.09 loss)
I0318 06:03:57.686491 29479 solver.cpp:610] Iteration 105140, lr = 5.11032e-09
I0318 06:03:57.686506 29479 solver.cpp:613] Iteration 105140, avg_grad_norm = 530714
I0318 06:06:37.255807 29479 solver.cpp:214] Iteration 105160, loss = 5665.88
I0318 06:06:37.255955 29479 solver.cpp:229]     Train net output #0: loss = 8250.93 (* 1 = 8250.93 loss)
I0318 06:06:38.334080 29479 solver.cpp:610] Iteration 105160, lr = 5.10935e-09
I0318 06:06:38.334095 29479 solver.cpp:613] Iteration 105160, avg_grad_norm = 511446
I0318 06:09:06.891687 29479 solver.cpp:214] Iteration 105180, loss = 5474.02
I0318 06:09:06.891803 29479 solver.cpp:229]     Train net output #0: loss = 4983.91 (* 1 = 4983.91 loss)
I0318 06:09:07.969096 29479 solver.cpp:610] Iteration 105180, lr = 5.10838e-09
I0318 06:09:07.969110 29479 solver.cpp:613] Iteration 105180, avg_grad_norm = 511132
I0318 06:11:36.489120 29479 solver.cpp:214] Iteration 105200, loss = 5508.23
I0318 06:11:36.489238 29479 solver.cpp:229]     Train net output #0: loss = 7721.9 (* 1 = 7721.9 loss)
I0318 06:11:37.569833 29479 solver.cpp:610] Iteration 105200, lr = 5.10741e-09
I0318 06:11:37.569849 29479 solver.cpp:613] Iteration 105200, avg_grad_norm = 492165
I0318 06:14:06.102421 29479 solver.cpp:214] Iteration 105220, loss = 5730.68
I0318 06:14:06.102550 29479 solver.cpp:229]     Train net output #0: loss = 6264.81 (* 1 = 6264.81 loss)
I0318 06:14:07.135483 29479 solver.cpp:610] Iteration 105220, lr = 5.10644e-09
I0318 06:14:07.135496 29479 solver.cpp:613] Iteration 105220, avg_grad_norm = 524673
I0318 06:16:35.639287 29479 solver.cpp:214] Iteration 105240, loss = 5185.59
I0318 06:16:35.639389 29479 solver.cpp:229]     Train net output #0: loss = 7101.61 (* 1 = 7101.61 loss)
I0318 06:16:35.795387 29479 solver.cpp:610] Iteration 105240, lr = 5.10547e-09
I0318 06:16:35.795403 29479 solver.cpp:613] Iteration 105240, avg_grad_norm = 515927
I0318 06:19:05.304463 29479 solver.cpp:214] Iteration 105260, loss = 5673.47
I0318 06:19:05.304558 29479 solver.cpp:229]     Train net output #0: loss = 4145.02 (* 1 = 4145.02 loss)
I0318 06:19:06.333533 29479 solver.cpp:610] Iteration 105260, lr = 5.1045e-09
I0318 06:19:06.333547 29479 solver.cpp:613] Iteration 105260, avg_grad_norm = 488366
I0318 06:21:46.873167 29479 solver.cpp:214] Iteration 105280, loss = 5644.52
I0318 06:21:46.873296 29479 solver.cpp:229]     Train net output #0: loss = 4394.01 (* 1 = 4394.01 loss)
I0318 06:21:47.034108 29479 solver.cpp:610] Iteration 105280, lr = 5.10353e-09
I0318 06:21:47.034122 29479 solver.cpp:613] Iteration 105280, avg_grad_norm = 461626
I0318 06:23:06.516024 29479 solver.cpp:214] Iteration 105300, loss = 5108.63
I0318 06:23:06.516232 29479 solver.cpp:229]     Train net output #0: loss = 2791.2 (* 1 = 2791.2 loss)
I0318 06:23:07.554041 29479 solver.cpp:610] Iteration 105300, lr = 5.10256e-09
I0318 06:23:07.554054 29479 solver.cpp:613] Iteration 105300, avg_grad_norm = 479600
I0318 06:25:37.024092 29479 solver.cpp:214] Iteration 105320, loss = 5475.19
I0318 06:25:37.024227 29479 solver.cpp:229]     Train net output #0: loss = 7173.63 (* 1 = 7173.63 loss)
I0318 06:25:37.179280 29479 solver.cpp:610] Iteration 105320, lr = 5.10159e-09
I0318 06:25:37.179293 29479 solver.cpp:613] Iteration 105320, avg_grad_norm = 501084
I0318 06:28:04.703361 29479 solver.cpp:214] Iteration 105340, loss = 5573.88
I0318 06:28:04.703515 29479 solver.cpp:229]     Train net output #0: loss = 4002.86 (* 1 = 4002.86 loss)
I0318 06:28:05.781973 29479 solver.cpp:610] Iteration 105340, lr = 5.10062e-09
I0318 06:28:05.781988 29479 solver.cpp:613] Iteration 105340, avg_grad_norm = 504710
I0318 06:30:35.191838 29479 solver.cpp:214] Iteration 105360, loss = 5636.51
I0318 06:30:35.192016 29479 solver.cpp:229]     Train net output #0: loss = 6484.4 (* 1 = 6484.4 loss)
I0318 06:30:35.353638 29479 solver.cpp:610] Iteration 105360, lr = 5.09965e-09
I0318 06:30:35.353652 29479 solver.cpp:613] Iteration 105360, avg_grad_norm = 562446
I0318 06:33:03.906318 29479 solver.cpp:214] Iteration 105380, loss = 5502.15
I0318 06:33:03.906450 29479 solver.cpp:229]     Train net output #0: loss = 7141.38 (* 1 = 7141.38 loss)
I0318 06:33:04.983363 29479 solver.cpp:610] Iteration 105380, lr = 5.09868e-09
I0318 06:33:04.983394 29479 solver.cpp:613] Iteration 105380, avg_grad_norm = 491122
I0318 06:35:33.564102 29479 solver.cpp:214] Iteration 105400, loss = 5904.14
I0318 06:35:33.564249 29479 solver.cpp:229]     Train net output #0: loss = 5512.94 (* 1 = 5512.94 loss)
I0318 06:35:34.605726 29479 solver.cpp:610] Iteration 105400, lr = 5.09771e-09
I0318 06:35:34.605739 29479 solver.cpp:613] Iteration 105400, avg_grad_norm = 508713
I0318 06:38:15.218824 29479 solver.cpp:214] Iteration 105420, loss = 5640.48
I0318 06:38:15.218973 29479 solver.cpp:229]     Train net output #0: loss = 7174.72 (* 1 = 7174.72 loss)
I0318 06:38:16.286686 29479 solver.cpp:610] Iteration 105420, lr = 5.09674e-09
I0318 06:38:16.286702 29479 solver.cpp:613] Iteration 105420, avg_grad_norm = 493044
I0318 06:40:44.723160 29479 solver.cpp:214] Iteration 105440, loss = 5399.93
I0318 06:40:44.723242 29479 solver.cpp:229]     Train net output #0: loss = 2524.65 (* 1 = 2524.65 loss)
I0318 06:40:44.884220 29479 solver.cpp:610] Iteration 105440, lr = 5.09577e-09
I0318 06:40:44.884234 29479 solver.cpp:613] Iteration 105440, avg_grad_norm = 464824
I0318 06:42:37.351198 29479 solver.cpp:214] Iteration 105460, loss = 5235.34
I0318 06:42:37.351336 29479 solver.cpp:229]     Train net output #0: loss = 3761.55 (* 1 = 3761.55 loss)
I0318 06:42:37.455436 29479 solver.cpp:610] Iteration 105460, lr = 5.0948e-09
I0318 06:42:37.455473 29479 solver.cpp:613] Iteration 105460, avg_grad_norm = 520167
I0318 06:44:32.006048 29479 solver.cpp:214] Iteration 105480, loss = 5136.5
I0318 06:44:32.006172 29479 solver.cpp:229]     Train net output #0: loss = 2807.3 (* 1 = 2807.3 loss)
I0318 06:44:33.076261 29479 solver.cpp:610] Iteration 105480, lr = 5.09383e-09
I0318 06:44:33.076287 29479 solver.cpp:613] Iteration 105480, avg_grad_norm = 531600
I0318 06:47:02.537627 29479 solver.cpp:214] Iteration 105500, loss = 5599.62
I0318 06:47:02.537850 29479 solver.cpp:229]     Train net output #0: loss = 6375.69 (* 1 = 6375.69 loss)
I0318 06:47:02.692694 29479 solver.cpp:610] Iteration 105500, lr = 5.09286e-09
I0318 06:47:02.692708 29479 solver.cpp:613] Iteration 105500, avg_grad_norm = 474750
I0318 06:49:30.238020 29479 solver.cpp:214] Iteration 105520, loss = 5467.69
I0318 06:49:30.238113 29479 solver.cpp:229]     Train net output #0: loss = 8016.95 (* 1 = 8016.95 loss)
I0318 06:49:31.312166 29479 solver.cpp:610] Iteration 105520, lr = 5.09189e-09
I0318 06:49:31.312180 29479 solver.cpp:613] Iteration 105520, avg_grad_norm = 507283
I0318 06:52:11.779608 29479 solver.cpp:214] Iteration 105540, loss = 5628.17
I0318 06:52:11.779741 29479 solver.cpp:229]     Train net output #0: loss = 3749.48 (* 1 = 3749.48 loss)
I0318 06:52:11.936913 29479 solver.cpp:610] Iteration 105540, lr = 5.09092e-09
I0318 06:52:11.936928 29479 solver.cpp:613] Iteration 105540, avg_grad_norm = 480482
I0318 06:54:41.388206 29479 solver.cpp:214] Iteration 105560, loss = 5673
I0318 06:54:41.388350 29479 solver.cpp:229]     Train net output #0: loss = 9509.89 (* 1 = 9509.89 loss)
I0318 06:54:42.431383 29479 solver.cpp:610] Iteration 105560, lr = 5.08995e-09
I0318 06:54:42.431399 29479 solver.cpp:613] Iteration 105560, avg_grad_norm = 492237
I0318 06:57:11.986649 29479 solver.cpp:214] Iteration 105580, loss = 5616.88
I0318 06:57:11.986793 29479 solver.cpp:229]     Train net output #0: loss = 3143.94 (* 1 = 3143.94 loss)
I0318 06:57:12.140167 29479 solver.cpp:610] Iteration 105580, lr = 5.08898e-09
I0318 06:57:12.140182 29479 solver.cpp:613] Iteration 105580, avg_grad_norm = 489877
I0318 06:59:41.639240 29479 solver.cpp:214] Iteration 105600, loss = 5832.96
I0318 06:59:41.639418 29479 solver.cpp:229]     Train net output #0: loss = 5004.28 (* 1 = 5004.28 loss)
I0318 06:59:42.682906 29479 solver.cpp:610] Iteration 105600, lr = 5.08801e-09
I0318 06:59:42.682921 29479 solver.cpp:613] Iteration 105600, avg_grad_norm = 507746
I0318 07:02:10.232167 29479 solver.cpp:214] Iteration 105620, loss = 5718.64
I0318 07:02:10.232296 29479 solver.cpp:229]     Train net output #0: loss = 5241.54 (* 1 = 5241.54 loss)
I0318 07:02:11.313490 29479 solver.cpp:610] Iteration 105620, lr = 5.08704e-09
I0318 07:02:11.313505 29479 solver.cpp:613] Iteration 105620, avg_grad_norm = 496182
I0318 07:03:05.754921 29479 solver.cpp:214] Iteration 105640, loss = 5611.63
I0318 07:03:05.755059 29479 solver.cpp:229]     Train net output #0: loss = 3713.15 (* 1 = 3713.15 loss)
I0318 07:03:05.859213 29479 solver.cpp:610] Iteration 105640, lr = 5.08607e-09
I0318 07:03:05.859261 29479 solver.cpp:613] Iteration 105640, avg_grad_norm = 476989
I0318 07:05:47.302012 29479 solver.cpp:214] Iteration 105660, loss = 5236.52
I0318 07:05:47.302140 29479 solver.cpp:229]     Train net output #0: loss = 6398 (* 1 = 6398 loss)
I0318 07:05:47.525218 29479 solver.cpp:610] Iteration 105660, lr = 5.0851e-09
I0318 07:05:47.525230 29479 solver.cpp:613] Iteration 105660, avg_grad_norm = 503730
I0318 07:08:16.043874 29479 solver.cpp:214] Iteration 105680, loss = 5671.48
I0318 07:08:16.044028 29479 solver.cpp:229]     Train net output #0: loss = 4404.2 (* 1 = 4404.2 loss)
I0318 07:08:17.080049 29479 solver.cpp:610] Iteration 105680, lr = 5.08413e-09
I0318 07:08:17.080062 29479 solver.cpp:613] Iteration 105680, avg_grad_norm = 488649
I0318 07:10:45.642094 29479 solver.cpp:214] Iteration 105700, loss = 5434.08
I0318 07:10:45.642223 29479 solver.cpp:229]     Train net output #0: loss = 3323.58 (* 1 = 3323.58 loss)
I0318 07:10:46.681077 29479 solver.cpp:610] Iteration 105700, lr = 5.08316e-09
I0318 07:10:46.681110 29479 solver.cpp:613] Iteration 105700, avg_grad_norm = 515700
I0318 07:13:16.200224 29479 solver.cpp:214] Iteration 105720, loss = 5747.31
I0318 07:13:16.200358 29479 solver.cpp:229]     Train net output #0: loss = 5197.03 (* 1 = 5197.03 loss)
I0318 07:13:16.374807 29479 solver.cpp:610] Iteration 105720, lr = 5.08219e-09
I0318 07:13:16.374820 29479 solver.cpp:613] Iteration 105720, avg_grad_norm = 534841
I0318 07:15:44.905310 29479 solver.cpp:214] Iteration 105740, loss = 5040.44
I0318 07:15:44.905529 29479 solver.cpp:229]     Train net output #0: loss = 3667.85 (* 1 = 3667.85 loss)
I0318 07:15:45.982041 29479 solver.cpp:610] Iteration 105740, lr = 5.08122e-09
I0318 07:15:45.982066 29479 solver.cpp:613] Iteration 105740, avg_grad_norm = 491269
I0318 07:18:14.433681 29479 solver.cpp:214] Iteration 105760, loss = 5511.84
I0318 07:18:14.433825 29479 solver.cpp:229]     Train net output #0: loss = 3249.86 (* 1 = 3249.86 loss)
I0318 07:18:15.473809 29479 solver.cpp:610] Iteration 105760, lr = 5.08025e-09
I0318 07:18:15.473860 29479 solver.cpp:613] Iteration 105760, avg_grad_norm = 478456
I0318 07:20:44.069886 29479 solver.cpp:214] Iteration 105780, loss = 5591.32
I0318 07:20:44.070035 29479 solver.cpp:229]     Train net output #0: loss = 4178.96 (* 1 = 4178.96 loss)
I0318 07:20:45.151589 29479 solver.cpp:610] Iteration 105780, lr = 5.07928e-09
I0318 07:20:45.151604 29479 solver.cpp:613] Iteration 105780, avg_grad_norm = 513843
I0318 07:23:10.644433 29479 solver.cpp:214] Iteration 105800, loss = 5324.5
I0318 07:23:10.644568 29479 solver.cpp:229]     Train net output #0: loss = 3845.5 (* 1 = 3845.5 loss)
I0318 07:23:10.750202 29479 solver.cpp:610] Iteration 105800, lr = 5.07831e-09
I0318 07:23:10.750253 29479 solver.cpp:613] Iteration 105800, avg_grad_norm = 537316
I0318 07:24:43.254480 29479 solver.cpp:214] Iteration 105820, loss = 5330.69
I0318 07:24:43.254673 29479 solver.cpp:229]     Train net output #0: loss = 6081.91 (* 1 = 6081.91 loss)
I0318 07:24:44.297368 29479 solver.cpp:610] Iteration 105820, lr = 5.07733e-09
I0318 07:24:44.297381 29479 solver.cpp:613] Iteration 105820, avg_grad_norm = 526181
I0318 07:27:12.816766 29479 solver.cpp:214] Iteration 105840, loss = 5461.9
I0318 07:27:12.817011 29479 solver.cpp:229]     Train net output #0: loss = 3271.43 (* 1 = 3271.43 loss)
I0318 07:27:12.969804 29479 solver.cpp:610] Iteration 105840, lr = 5.07636e-09
I0318 07:27:12.969818 29479 solver.cpp:613] Iteration 105840, avg_grad_norm = 553386
I0318 07:29:41.510658 29479 solver.cpp:214] Iteration 105860, loss = 5511.18
I0318 07:29:41.510854 29479 solver.cpp:229]     Train net output #0: loss = 6571.11 (* 1 = 6571.11 loss)
I0318 07:29:41.665295 29479 solver.cpp:610] Iteration 105860, lr = 5.07539e-09
I0318 07:29:41.665309 29479 solver.cpp:613] Iteration 105860, avg_grad_norm = 518751
I0318 07:32:10.223914 29479 solver.cpp:214] Iteration 105880, loss = 5426.45
I0318 07:32:10.224026 29479 solver.cpp:229]     Train net output #0: loss = 4060.38 (* 1 = 4060.38 loss)
I0318 07:32:11.305163 29479 solver.cpp:610] Iteration 105880, lr = 5.07442e-09
I0318 07:32:11.305177 29479 solver.cpp:613] Iteration 105880, avg_grad_norm = 535862
I0318 07:34:39.710928 29479 solver.cpp:214] Iteration 105900, loss = 5619.75
I0318 07:34:39.711071 29479 solver.cpp:229]     Train net output #0: loss = 10493.3 (* 1 = 10493.3 loss)
I0318 07:34:40.751286 29479 solver.cpp:610] Iteration 105900, lr = 5.07345e-09
I0318 07:34:40.751301 29479 solver.cpp:613] Iteration 105900, avg_grad_norm = 522109
I0318 07:37:22.292191 29479 solver.cpp:214] Iteration 105920, loss = 5581.8
I0318 07:37:22.292384 29479 solver.cpp:229]     Train net output #0: loss = 4307.12 (* 1 = 4307.12 loss)
I0318 07:37:22.445791 29479 solver.cpp:610] Iteration 105920, lr = 5.07248e-09
I0318 07:37:22.445804 29479 solver.cpp:613] Iteration 105920, avg_grad_norm = 521113
I0318 07:39:50.995975 29479 solver.cpp:214] Iteration 105940, loss = 5459.24
I0318 07:39:50.996101 29479 solver.cpp:229]     Train net output #0: loss = 3835.9 (* 1 = 3835.9 loss)
I0318 07:39:52.062922 29479 solver.cpp:610] Iteration 105940, lr = 5.07151e-09
I0318 07:39:52.062937 29479 solver.cpp:613] Iteration 105940, avg_grad_norm = 510312
I0318 07:42:20.538861 29479 solver.cpp:214] Iteration 105960, loss = 5722.35
I0318 07:42:20.538998 29479 solver.cpp:229]     Train net output #0: loss = 5439.14 (* 1 = 5439.14 loss)
I0318 07:42:20.692942 29479 solver.cpp:610] Iteration 105960, lr = 5.07054e-09
I0318 07:42:20.692955 29479 solver.cpp:613] Iteration 105960, avg_grad_norm = 486553
I0318 07:43:39.124160 29479 solver.cpp:214] Iteration 105980, loss = 5148.08
I0318 07:43:39.124282 29479 solver.cpp:229]     Train net output #0: loss = 3881.7 (* 1 = 3881.7 loss)
I0318 07:43:40.215405 29479 solver.cpp:610] Iteration 105980, lr = 5.06957e-09
I0318 07:43:40.215420 29479 solver.cpp:613] Iteration 105980, avg_grad_norm = 466235
I0318 07:46:08.687332 29479 solver.cpp:214] Iteration 106000, loss = 5529.22
I0318 07:46:08.687466 29479 solver.cpp:229]     Train net output #0: loss = 4036 (* 1 = 4036 loss)
I0318 07:46:08.848055 29479 solver.cpp:610] Iteration 106000, lr = 5.0686e-09
I0318 07:46:08.848068 29479 solver.cpp:613] Iteration 106000, avg_grad_norm = 501646
I0318 07:48:38.351701 29479 solver.cpp:214] Iteration 106020, loss = 5464.28
I0318 07:48:38.351835 29479 solver.cpp:229]     Train net output #0: loss = 7957.03 (* 1 = 7957.03 loss)
I0318 07:48:39.395037 29479 solver.cpp:610] Iteration 106020, lr = 5.06763e-09
I0318 07:48:39.395051 29479 solver.cpp:613] Iteration 106020, avg_grad_norm = 510462
I0318 07:51:20.006145 29479 solver.cpp:214] Iteration 106040, loss = 5425.43
I0318 07:51:20.006294 29479 solver.cpp:229]     Train net output #0: loss = 3837.04 (* 1 = 3837.04 loss)
I0318 07:51:21.083412 29479 solver.cpp:610] Iteration 106040, lr = 5.06666e-09
I0318 07:51:21.083428 29479 solver.cpp:613] Iteration 106040, avg_grad_norm = 488469
I0318 07:53:48.593096 29479 solver.cpp:214] Iteration 106060, loss = 5430.45
I0318 07:53:48.593231 29479 solver.cpp:229]     Train net output #0: loss = 10704.3 (* 1 = 10704.3 loss)
I0318 07:53:49.681304 29479 solver.cpp:610] Iteration 106060, lr = 5.06569e-09
I0318 07:53:49.681318 29479 solver.cpp:613] Iteration 106060, avg_grad_norm = 481005
I0318 07:56:18.206696 29479 solver.cpp:214] Iteration 106080, loss = 5739.91
I0318 07:56:18.206946 29479 solver.cpp:229]     Train net output #0: loss = 5687.56 (* 1 = 5687.56 loss)
I0318 07:56:19.236402 29479 solver.cpp:610] Iteration 106080, lr = 5.06472e-09
I0318 07:56:19.236415 29479 solver.cpp:613] Iteration 106080, avg_grad_norm = 465696
I0318 07:58:46.874593 29479 solver.cpp:214] Iteration 106100, loss = 5601.88
I0318 07:58:46.874743 29479 solver.cpp:229]     Train net output #0: loss = 4052.31 (* 1 = 4052.31 loss)
I0318 07:58:47.944828 29479 solver.cpp:610] Iteration 106100, lr = 5.06375e-09
I0318 07:58:47.944845 29479 solver.cpp:613] Iteration 106100, avg_grad_norm = 469484
I0318 08:01:15.493955 29479 solver.cpp:214] Iteration 106120, loss = 5592.77
I0318 08:01:15.494094 29479 solver.cpp:229]     Train net output #0: loss = 11162.8 (* 1 = 11162.8 loss)
I0318 08:01:16.529712 29479 solver.cpp:610] Iteration 106120, lr = 5.06278e-09
I0318 08:01:16.529747 29479 solver.cpp:613] Iteration 106120, avg_grad_norm = 481163
I0318 08:03:44.164949 29479 solver.cpp:214] Iteration 106140, loss = 5440.39
I0318 08:03:44.165199 29479 solver.cpp:229]     Train net output #0: loss = 5300.76 (* 1 = 5300.76 loss)
I0318 08:03:44.269309 29479 solver.cpp:610] Iteration 106140, lr = 5.06181e-09
I0318 08:03:44.269322 29479 solver.cpp:613] Iteration 106140, avg_grad_norm = 471582
I0318 08:04:07.708278 29479 solver.cpp:214] Iteration 106160, loss = 5720.94
I0318 08:04:07.708325 29479 solver.cpp:229]     Train net output #0: loss = 5328.26 (* 1 = 5328.26 loss)
I0318 08:04:07.813938 29479 solver.cpp:610] Iteration 106160, lr = 5.06084e-09
I0318 08:04:07.813988 29479 solver.cpp:613] Iteration 106160, avg_grad_norm = 469261
I0318 08:06:36.375174 29479 solver.cpp:214] Iteration 106180, loss = 5798.42
I0318 08:06:36.375322 29479 solver.cpp:229]     Train net output #0: loss = 7133.33 (* 1 = 7133.33 loss)
I0318 08:06:37.416298 29479 solver.cpp:610] Iteration 106180, lr = 5.05986e-09
I0318 08:06:37.416312 29479 solver.cpp:613] Iteration 106180, avg_grad_norm = 562010
I0318 08:09:06.047531 29479 solver.cpp:214] Iteration 106200, loss = 5563.49
I0318 08:09:06.047657 29479 solver.cpp:229]     Train net output #0: loss = 8105.78 (* 1 = 8105.78 loss)
I0318 08:09:06.202940 29479 solver.cpp:610] Iteration 106200, lr = 5.05889e-09
I0318 08:09:06.202955 29479 solver.cpp:613] Iteration 106200, avg_grad_norm = 515753
I0318 08:11:35.569811 29479 solver.cpp:214] Iteration 106220, loss = 5538.05
I0318 08:11:35.570027 29479 solver.cpp:229]     Train net output #0: loss = 5247.4 (* 1 = 5247.4 loss)
I0318 08:11:35.723433 29479 solver.cpp:610] Iteration 106220, lr = 5.05792e-09
I0318 08:11:35.723446 29479 solver.cpp:613] Iteration 106220, avg_grad_norm = 489951
I0318 08:14:05.194906 29479 solver.cpp:214] Iteration 106240, loss = 5625.39
I0318 08:14:05.195056 29479 solver.cpp:229]     Train net output #0: loss = 4886.15 (* 1 = 4886.15 loss)
I0318 08:14:05.348573 29479 solver.cpp:610] Iteration 106240, lr = 5.05695e-09
I0318 08:14:05.348587 29479 solver.cpp:613] Iteration 106240, avg_grad_norm = 507359
I0318 08:16:34.840349 29479 solver.cpp:214] Iteration 106260, loss = 5387.77
I0318 08:16:34.840469 29479 solver.cpp:229]     Train net output #0: loss = 5171.5 (* 1 = 5171.5 loss)
I0318 08:16:34.996326 29479 solver.cpp:610] Iteration 106260, lr = 5.05598e-09
I0318 08:16:34.996340 29479 solver.cpp:613] Iteration 106260, avg_grad_norm = 481007
I0318 08:19:04.459094 29479 solver.cpp:214] Iteration 106280, loss = 5565.1
I0318 08:19:04.459226 29479 solver.cpp:229]     Train net output #0: loss = 6973.44 (* 1 = 6973.44 loss)
I0318 08:19:04.579936 29479 solver.cpp:610] Iteration 106280, lr = 5.05501e-09
I0318 08:19:04.579967 29479 solver.cpp:613] Iteration 106280, avg_grad_norm = 538562
I0318 08:21:06.024580 29479 solver.cpp:214] Iteration 106300, loss = 5358.78
I0318 08:21:06.024740 29479 solver.cpp:229]     Train net output #0: loss = 3366.16 (* 1 = 3366.16 loss)
I0318 08:21:07.128001 29479 solver.cpp:610] Iteration 106300, lr = 5.05404e-09
I0318 08:21:07.128015 29479 solver.cpp:613] Iteration 106300, avg_grad_norm = 513973
I0318 08:23:34.605382 29479 solver.cpp:214] Iteration 106320, loss = 5431.7
I0318 08:23:34.605598 29479 solver.cpp:229]     Train net output #0: loss = 6151.37 (* 1 = 6151.37 loss)
I0318 08:23:35.692036 29479 solver.cpp:610] Iteration 106320, lr = 5.05307e-09
I0318 08:23:35.692080 29479 solver.cpp:613] Iteration 106320, avg_grad_norm = 504974
I0318 08:24:54.133275 29479 solver.cpp:214] Iteration 106340, loss = 5360.57
I0318 08:24:54.133373 29479 solver.cpp:229]     Train net output #0: loss = 4884.65 (* 1 = 4884.65 loss)
I0318 08:24:54.286844 29479 solver.cpp:610] Iteration 106340, lr = 5.0521e-09
I0318 08:24:54.286857 29479 solver.cpp:613] Iteration 106340, avg_grad_norm = 507214
I0318 08:27:22.862475 29479 solver.cpp:214] Iteration 106360, loss = 5652.17
I0318 08:27:22.862623 29479 solver.cpp:229]     Train net output #0: loss = 2721.73 (* 1 = 2721.73 loss)
I0318 08:27:23.938628 29479 solver.cpp:610] Iteration 106360, lr = 5.05113e-09
I0318 08:27:23.938683 29479 solver.cpp:613] Iteration 106360, avg_grad_norm = 497557
I0318 08:29:52.502188 29479 solver.cpp:214] Iteration 106380, loss = 5588.53
I0318 08:29:52.502321 29479 solver.cpp:229]     Train net output #0: loss = 7082.7 (* 1 = 7082.7 loss)
I0318 08:29:53.581300 29479 solver.cpp:610] Iteration 106380, lr = 5.05016e-09
I0318 08:29:53.581316 29479 solver.cpp:613] Iteration 106380, avg_grad_norm = 489218
I0318 08:32:22.026422 29479 solver.cpp:214] Iteration 106400, loss = 5681.35
I0318 08:32:22.026629 29479 solver.cpp:229]     Train net output #0: loss = 5317.13 (* 1 = 5317.13 loss)
I0318 08:32:22.183389 29479 solver.cpp:610] Iteration 106400, lr = 5.04918e-09
I0318 08:32:22.183403 29479 solver.cpp:613] Iteration 106400, avg_grad_norm = 469539
I0318 08:34:51.559861 29479 solver.cpp:214] Iteration 106420, loss = 5511.7
I0318 08:34:51.559990 29479 solver.cpp:229]     Train net output #0: loss = 3634.84 (* 1 = 3634.84 loss)
I0318 08:34:51.783109 29479 solver.cpp:610] Iteration 106420, lr = 5.04821e-09
I0318 08:34:51.783124 29479 solver.cpp:613] Iteration 106420, avg_grad_norm = 466952
I0318 08:37:19.275018 29479 solver.cpp:214] Iteration 106440, loss = 5595.49
I0318 08:37:19.275169 29479 solver.cpp:229]     Train net output #0: loss = 3304.28 (* 1 = 3304.28 loss)
I0318 08:37:20.311496 29479 solver.cpp:610] Iteration 106440, lr = 5.04724e-09
I0318 08:37:20.311511 29479 solver.cpp:613] Iteration 106440, avg_grad_norm = 466208
I0318 08:39:48.874147 29479 solver.cpp:214] Iteration 106460, loss = 5604.41
I0318 08:39:48.874281 29479 solver.cpp:229]     Train net output #0: loss = 5173.38 (* 1 = 5173.38 loss)
I0318 08:39:49.914803 29479 solver.cpp:610] Iteration 106460, lr = 5.04627e-09
I0318 08:39:49.914818 29479 solver.cpp:613] Iteration 106460, avg_grad_norm = 506737
I0318 08:42:18.396553 29479 solver.cpp:214] Iteration 106480, loss = 5616.31
I0318 08:42:18.396697 29479 solver.cpp:229]     Train net output #0: loss = 5657.24 (* 1 = 5657.24 loss)
I0318 08:42:18.569365 29479 solver.cpp:610] Iteration 106480, lr = 5.0453e-09
I0318 08:42:18.569378 29479 solver.cpp:613] Iteration 106480, avg_grad_norm = 508357
I0318 08:44:41.050667 29479 solver.cpp:214] Iteration 106500, loss = 5422.9
I0318 08:44:41.050796 29479 solver.cpp:229]     Train net output #0: loss = 3599.28 (* 1 = 3599.28 loss)
I0318 08:44:41.154780 29479 solver.cpp:610] Iteration 106500, lr = 5.04433e-09
I0318 08:44:41.154815 29479 solver.cpp:613] Iteration 106500, avg_grad_norm = 506282
I0318 08:45:24.582789 29479 solver.cpp:214] Iteration 106520, loss = 5430.23
I0318 08:45:24.582914 29479 solver.cpp:229]     Train net output #0: loss = 5609.96 (* 1 = 5609.96 loss)
I0318 08:45:24.746585 29479 solver.cpp:610] Iteration 106520, lr = 5.04336e-09
I0318 08:45:24.746598 29479 solver.cpp:613] Iteration 106520, avg_grad_norm = 461760
I0318 08:47:53.314788 29479 solver.cpp:214] Iteration 106540, loss = 5596.98
I0318 08:47:53.314944 29479 solver.cpp:229]     Train net output #0: loss = 4806.42 (* 1 = 4806.42 loss)
I0318 08:47:54.388420 29479 solver.cpp:610] Iteration 106540, lr = 5.04239e-09
I0318 08:47:54.388435 29479 solver.cpp:613] Iteration 106540, avg_grad_norm = 496492
I0318 08:50:23.893683 29479 solver.cpp:214] Iteration 106560, loss = 5266.76
I0318 08:50:23.893798 29479 solver.cpp:229]     Train net output #0: loss = 3413.21 (* 1 = 3413.21 loss)
I0318 08:50:24.932781 29479 solver.cpp:610] Iteration 106560, lr = 5.04142e-09
I0318 08:50:24.932799 29479 solver.cpp:613] Iteration 106560, avg_grad_norm = 462760
I0318 08:52:53.513542 29479 solver.cpp:214] Iteration 106580, loss = 5675.05
I0318 08:52:53.513648 29479 solver.cpp:229]     Train net output #0: loss = 8766.82 (* 1 = 8766.82 loss)
I0318 08:52:54.559857 29479 solver.cpp:610] Iteration 106580, lr = 5.04045e-09
I0318 08:52:54.559873 29479 solver.cpp:613] Iteration 106580, avg_grad_norm = 493536
I0318 08:55:22.053781 29479 solver.cpp:214] Iteration 106600, loss = 5913.44
I0318 08:55:22.053911 29479 solver.cpp:229]     Train net output #0: loss = 8746.05 (* 1 = 8746.05 loss)
I0318 08:55:23.092193 29479 solver.cpp:610] Iteration 106600, lr = 5.03947e-09
I0318 08:55:23.092207 29479 solver.cpp:613] Iteration 106600, avg_grad_norm = 488601
I0318 08:57:51.610795 29479 solver.cpp:214] Iteration 106620, loss = 5363.57
I0318 08:57:51.610990 29479 solver.cpp:229]     Train net output #0: loss = 3417.04 (* 1 = 3417.04 loss)
I0318 08:57:51.765076 29479 solver.cpp:610] Iteration 106620, lr = 5.0385e-09
I0318 08:57:51.765090 29479 solver.cpp:613] Iteration 106620, avg_grad_norm = 534590
I0318 09:00:20.223815 29479 solver.cpp:214] Iteration 106640, loss = 5527.04
I0318 09:00:20.223918 29479 solver.cpp:229]     Train net output #0: loss = 4544.73 (* 1 = 4544.73 loss)
I0318 09:00:20.376981 29479 solver.cpp:610] Iteration 106640, lr = 5.03753e-09
I0318 09:00:20.376994 29479 solver.cpp:613] Iteration 106640, avg_grad_norm = 496781
I0318 09:02:48.959857 29479 solver.cpp:214] Iteration 106660, loss = 5477
I0318 09:02:48.959965 29479 solver.cpp:229]     Train net output #0: loss = 3684.45 (* 1 = 3684.45 loss)
I0318 09:02:50.036479 29479 solver.cpp:610] Iteration 106660, lr = 5.03656e-09
I0318 09:02:50.036494 29479 solver.cpp:613] Iteration 106660, avg_grad_norm = 478700
I0318 09:05:09.597494 29479 solver.cpp:214] Iteration 106680, loss = 5585.86
I0318 09:05:09.597628 29479 solver.cpp:229]     Train net output #0: loss = 4849.3 (* 1 = 4849.3 loss)
I0318 09:05:09.703068 29479 solver.cpp:610] Iteration 106680, lr = 5.03559e-09
I0318 09:05:09.703119 29479 solver.cpp:613] Iteration 106680, avg_grad_norm = 510740
I0318 09:06:38.181102 29479 solver.cpp:214] Iteration 106700, loss = 5383.79
I0318 09:06:38.181242 29479 solver.cpp:229]     Train net output #0: loss = 4215.29 (* 1 = 4215.29 loss)
I0318 09:06:39.228610 29479 solver.cpp:610] Iteration 106700, lr = 5.03462e-09
I0318 09:06:39.228626 29479 solver.cpp:613] Iteration 106700, avg_grad_norm = 509795
I0318 09:09:07.740929 29479 solver.cpp:214] Iteration 106720, loss = 5790.74
I0318 09:09:07.741106 29479 solver.cpp:229]     Train net output #0: loss = 8846.91 (* 1 = 8846.91 loss)
I0318 09:09:07.894656 29479 solver.cpp:610] Iteration 106720, lr = 5.03365e-09
I0318 09:09:07.894670 29479 solver.cpp:613] Iteration 106720, avg_grad_norm = 456793
I0318 09:11:35.409524 29479 solver.cpp:214] Iteration 106740, loss = 5729.93
I0318 09:11:35.409766 29479 solver.cpp:229]     Train net output #0: loss = 10539.1 (* 1 = 10539.1 loss)
I0318 09:11:36.495409 29479 solver.cpp:610] Iteration 106740, lr = 5.03268e-09
I0318 09:11:36.495434 29479 solver.cpp:613] Iteration 106740, avg_grad_norm = 546254
I0318 09:14:04.943637 29479 solver.cpp:214] Iteration 106760, loss = 5858.93
I0318 09:14:04.943747 29479 solver.cpp:229]     Train net output #0: loss = 3791.33 (* 1 = 3791.33 loss)
I0318 09:14:05.098548 29479 solver.cpp:610] Iteration 106760, lr = 5.0317e-09
I0318 09:14:05.098562 29479 solver.cpp:613] Iteration 106760, avg_grad_norm = 509042
I0318 09:16:34.595649 29479 solver.cpp:214] Iteration 106780, loss = 5582.59
I0318 09:16:34.595908 29479 solver.cpp:229]     Train net output #0: loss = 3261.93 (* 1 = 3261.93 loss)
I0318 09:16:35.638811 29479 solver.cpp:610] Iteration 106780, lr = 5.03073e-09
I0318 09:16:35.638825 29479 solver.cpp:613] Iteration 106780, avg_grad_norm = 475237
I0318 09:19:04.220054 29479 solver.cpp:214] Iteration 106800, loss = 5733.98
I0318 09:19:04.220167 29479 solver.cpp:229]     Train net output #0: loss = 4548.95 (* 1 = 4548.95 loss)
I0318 09:19:05.293378 29479 solver.cpp:610] Iteration 106800, lr = 5.02976e-09
I0318 09:19:05.293393 29479 solver.cpp:613] Iteration 106800, avg_grad_norm = 488666
I0318 09:21:32.830111 29479 solver.cpp:214] Iteration 106820, loss = 5668.95
I0318 09:21:32.830229 29479 solver.cpp:229]     Train net output #0: loss = 4293.28 (* 1 = 4293.28 loss)
I0318 09:21:33.905495 29479 solver.cpp:610] Iteration 106820, lr = 5.02879e-09
I0318 09:21:33.905509 29479 solver.cpp:613] Iteration 106820, avg_grad_norm = 505533
I0318 09:24:02.350811 29479 solver.cpp:214] Iteration 106840, loss = 5687.97
I0318 09:24:02.350953 29479 solver.cpp:229]     Train net output #0: loss = 5703.92 (* 1 = 5703.92 loss)
I0318 09:24:02.504482 29479 solver.cpp:610] Iteration 106840, lr = 5.02782e-09
I0318 09:24:02.504495 29479 solver.cpp:613] Iteration 106840, avg_grad_norm = 529666
I0318 09:25:38.012233 29479 solver.cpp:214] Iteration 106860, loss = 5526.2
I0318 09:25:38.012370 29479 solver.cpp:229]     Train net output #0: loss = 4079.7 (* 1 = 4079.7 loss)
I0318 09:25:38.116602 29479 solver.cpp:610] Iteration 106860, lr = 5.02685e-09
I0318 09:25:38.116638 29479 solver.cpp:613] Iteration 106860, avg_grad_norm = 480485
I0318 09:27:49.624626 29479 solver.cpp:214] Iteration 106880, loss = 5514.17
I0318 09:27:49.624774 29479 solver.cpp:229]     Train net output #0: loss = 4612.9 (* 1 = 4612.9 loss)
I0318 09:27:50.703054 29479 solver.cpp:610] Iteration 106880, lr = 5.02588e-09
I0318 09:27:50.703093 29479 solver.cpp:613] Iteration 106880, avg_grad_norm = 490684
I0318 09:30:20.267529 29479 solver.cpp:214] Iteration 106900, loss = 5695.92
I0318 09:30:20.267673 29479 solver.cpp:229]     Train net output #0: loss = 3773.27 (* 1 = 3773.27 loss)
I0318 09:30:21.352028 29479 solver.cpp:610] Iteration 106900, lr = 5.0249e-09
I0318 09:30:21.352042 29479 solver.cpp:613] Iteration 106900, avg_grad_norm = 512655
I0318 09:32:49.886546 29479 solver.cpp:214] Iteration 106920, loss = 5550.24
I0318 09:32:49.886683 29479 solver.cpp:229]     Train net output #0: loss = 8908.99 (* 1 = 8908.99 loss)
I0318 09:32:50.958597 29479 solver.cpp:610] Iteration 106920, lr = 5.02393e-09
I0318 09:32:50.958612 29479 solver.cpp:613] Iteration 106920, avg_grad_norm = 483280
I0318 09:35:18.539079 29479 solver.cpp:214] Iteration 106940, loss = 5567.17
I0318 09:35:18.539202 29479 solver.cpp:229]     Train net output #0: loss = 4433.64 (* 1 = 4433.64 loss)
I0318 09:35:19.627578 29479 solver.cpp:610] Iteration 106940, lr = 5.02296e-09
I0318 09:35:19.627595 29479 solver.cpp:613] Iteration 106940, avg_grad_norm = 457172
I0318 09:37:48.114089 29479 solver.cpp:214] Iteration 106960, loss = 5341.13
I0318 09:37:48.114208 29479 solver.cpp:229]     Train net output #0: loss = 7227.08 (* 1 = 7227.08 loss)
I0318 09:37:49.159083 29479 solver.cpp:610] Iteration 106960, lr = 5.02199e-09
I0318 09:37:49.159098 29479 solver.cpp:613] Iteration 106960, avg_grad_norm = 511298
I0318 09:40:17.755940 29479 solver.cpp:214] Iteration 106980, loss = 5435.99
I0318 09:40:17.756086 29479 solver.cpp:229]     Train net output #0: loss = 5265.39 (* 1 = 5265.39 loss)
I0318 09:40:18.790154 29479 solver.cpp:610] Iteration 106980, lr = 5.02102e-09
I0318 09:40:18.790169 29479 solver.cpp:613] Iteration 106980, avg_grad_norm = 462674
I0318 09:42:46.346482 29479 solver.cpp:214] Iteration 107000, loss = 5610.93
I0318 09:42:46.346663 29479 solver.cpp:229]     Train net output #0: loss = 4784.67 (* 1 = 4784.67 loss)
I0318 09:42:47.412753 29479 solver.cpp:610] Iteration 107000, lr = 5.02005e-09
I0318 09:42:47.412768 29479 solver.cpp:613] Iteration 107000, avg_grad_norm = 480327
I0318 09:45:16.883154 29479 solver.cpp:214] Iteration 107020, loss = 5555.96
I0318 09:45:16.883419 29479 solver.cpp:229]     Train net output #0: loss = 3208.08 (* 1 = 3208.08 loss)
I0318 09:45:17.036671 29479 solver.cpp:610] Iteration 107020, lr = 5.01907e-09
I0318 09:45:17.036687 29479 solver.cpp:613] Iteration 107020, avg_grad_norm = 492110
I0318 09:46:06.484488 29479 solver.cpp:214] Iteration 107040, loss = 5767.85
I0318 09:46:06.484622 29479 solver.cpp:229]     Train net output #0: loss = 4480.07 (* 1 = 4480.07 loss)
I0318 09:46:06.589244 29479 solver.cpp:610] Iteration 107040, lr = 5.0181e-09
I0318 09:46:06.589282 29479 solver.cpp:613] Iteration 107040, avg_grad_norm = 497279
I0318 09:48:16.041903 29479 solver.cpp:214] Iteration 107060, loss = 5724.94
I0318 09:48:16.041981 29479 solver.cpp:229]     Train net output #0: loss = 4007.71 (* 1 = 4007.71 loss)
I0318 09:48:16.199007 29479 solver.cpp:610] Iteration 107060, lr = 5.01713e-09
I0318 09:48:16.199021 29479 solver.cpp:613] Iteration 107060, avg_grad_norm = 527383
I0318 09:50:44.711834 29479 solver.cpp:214] Iteration 107080, loss = 5748.59
I0318 09:50:44.711997 29479 solver.cpp:229]     Train net output #0: loss = 6548.46 (* 1 = 6548.46 loss)
I0318 09:50:45.781770 29479 solver.cpp:610] Iteration 107080, lr = 5.01616e-09
I0318 09:50:45.781785 29479 solver.cpp:613] Iteration 107080, avg_grad_norm = 561318
I0318 09:53:14.225500 29479 solver.cpp:214] Iteration 107100, loss = 5581.97
I0318 09:53:14.225704 29479 solver.cpp:229]     Train net output #0: loss = 3335.2 (* 1 = 3335.2 loss)
I0318 09:53:14.400216 29479 solver.cpp:610] Iteration 107100, lr = 5.01519e-09
I0318 09:53:14.400231 29479 solver.cpp:613] Iteration 107100, avg_grad_norm = 536916
I0318 09:55:42.802279 29479 solver.cpp:214] Iteration 107120, loss = 5428.85
I0318 09:55:42.802402 29479 solver.cpp:229]     Train net output #0: loss = 4426.91 (* 1 = 4426.91 loss)
I0318 09:55:42.977717 29479 solver.cpp:610] Iteration 107120, lr = 5.01422e-09
I0318 09:55:42.977731 29479 solver.cpp:613] Iteration 107120, avg_grad_norm = 485503
I0318 09:58:12.422678 29479 solver.cpp:214] Iteration 107140, loss = 5535.43
I0318 09:58:12.422807 29479 solver.cpp:229]     Train net output #0: loss = 4513.76 (* 1 = 4513.76 loss)
I0318 09:58:12.576650 29479 solver.cpp:610] Iteration 107140, lr = 5.01324e-09
I0318 09:58:12.576663 29479 solver.cpp:613] Iteration 107140, avg_grad_norm = 500491
I0318 10:00:41.060578 29479 solver.cpp:214] Iteration 107160, loss = 5671.17
I0318 10:00:41.060710 29479 solver.cpp:229]     Train net output #0: loss = 4374.23 (* 1 = 4374.23 loss)
I0318 10:00:42.137739 29479 solver.cpp:610] Iteration 107160, lr = 5.01227e-09
I0318 10:00:42.137754 29479 solver.cpp:613] Iteration 107160, avg_grad_norm = 522657
I0318 10:03:10.665727 29479 solver.cpp:214] Iteration 107180, loss = 5572.25
I0318 10:03:10.665863 29479 solver.cpp:229]     Train net output #0: loss = 4847.17 (* 1 = 4847.17 loss)
I0318 10:03:11.703814 29479 solver.cpp:610] Iteration 107180, lr = 5.0113e-09
I0318 10:03:11.703826 29479 solver.cpp:613] Iteration 107180, avg_grad_norm = 472461
I0318 10:05:40.279359 29479 solver.cpp:214] Iteration 107200, loss = 5882.23
I0318 10:05:40.279474 29479 solver.cpp:229]     Train net output #0: loss = 3493.97 (* 1 = 3493.97 loss)
I0318 10:05:41.356371 29479 solver.cpp:610] Iteration 107200, lr = 5.01033e-09
I0318 10:05:41.356386 29479 solver.cpp:613] Iteration 107200, avg_grad_norm = 506295
I0318 10:06:50.830416 29479 solver.cpp:214] Iteration 107220, loss = 5575.21
I0318 10:06:50.830551 29479 solver.cpp:229]     Train net output #0: loss = 2793.18 (* 1 = 2793.18 loss)
I0318 10:06:51.904008 29479 solver.cpp:610] Iteration 107220, lr = 5.00936e-09
I0318 10:06:51.904023 29479 solver.cpp:613] Iteration 107220, avg_grad_norm = 487127
I0318 10:09:20.360921 29479 solver.cpp:214] Iteration 107240, loss = 5444.69
I0318 10:09:20.361033 29479 solver.cpp:229]     Train net output #0: loss = 4957.06 (* 1 = 4957.06 loss)
I0318 10:09:21.407554 29479 solver.cpp:610] Iteration 107240, lr = 5.00838e-09
I0318 10:09:21.407572 29479 solver.cpp:613] Iteration 107240, avg_grad_norm = 470489
I0318 10:11:49.919592 29479 solver.cpp:214] Iteration 107260, loss = 5288.54
I0318 10:11:49.919770 29479 solver.cpp:229]     Train net output #0: loss = 4545.44 (* 1 = 4545.44 loss)
I0318 10:11:50.083358 29479 solver.cpp:610] Iteration 107260, lr = 5.00741e-09
I0318 10:11:50.083371 29479 solver.cpp:613] Iteration 107260, avg_grad_norm = 474608
I0318 10:14:18.655190 29479 solver.cpp:214] Iteration 107280, loss = 5586.56
I0318 10:14:18.655331 29479 solver.cpp:229]     Train net output #0: loss = 3305.08 (* 1 = 3305.08 loss)
I0318 10:14:19.734765 29479 solver.cpp:610] Iteration 107280, lr = 5.00644e-09
I0318 10:14:19.734779 29479 solver.cpp:613] Iteration 107280, avg_grad_norm = 542711
I0318 10:16:48.283761 29479 solver.cpp:214] Iteration 107300, loss = 5503.25
I0318 10:16:48.283885 29479 solver.cpp:229]     Train net output #0: loss = 3460.93 (* 1 = 3460.93 loss)
I0318 10:16:49.358994 29479 solver.cpp:610] Iteration 107300, lr = 5.00547e-09
I0318 10:16:49.359009 29479 solver.cpp:613] Iteration 107300, avg_grad_norm = 481360
I0318 10:19:17.896587 29479 solver.cpp:214] Iteration 107320, loss = 5637.94
I0318 10:19:17.896687 29479 solver.cpp:229]     Train net output #0: loss = 5621.71 (* 1 = 5621.71 loss)
I0318 10:19:18.930948 29479 solver.cpp:610] Iteration 107320, lr = 5.0045e-09
I0318 10:19:18.930961 29479 solver.cpp:613] Iteration 107320, avg_grad_norm = 507307
I0318 10:21:46.513947 29479 solver.cpp:214] Iteration 107340, loss = 5667.97
I0318 10:21:46.514080 29479 solver.cpp:229]     Train net output #0: loss = 10150.1 (* 1 = 10150.1 loss)
I0318 10:21:47.554697 29479 solver.cpp:610] Iteration 107340, lr = 5.00352e-09
I0318 10:21:47.554710 29479 solver.cpp:613] Iteration 107340, avg_grad_norm = 527407
I0318 10:24:15.170698 29479 solver.cpp:214] Iteration 107360, loss = 5631.31
I0318 10:24:15.170845 29479 solver.cpp:229]     Train net output #0: loss = 6787.75 (* 1 = 6787.75 loss)
I0318 10:24:16.244863 29479 solver.cpp:610] Iteration 107360, lr = 5.00255e-09
I0318 10:24:16.244877 29479 solver.cpp:613] Iteration 107360, avg_grad_norm = 498820
I0318 10:26:39.732280 29479 solver.cpp:214] Iteration 107380, loss = 5995.99
I0318 10:26:39.732421 29479 solver.cpp:229]     Train net output #0: loss = 3913.83 (* 1 = 3913.83 loss)
I0318 10:26:39.836602 29479 solver.cpp:610] Iteration 107380, lr = 5.00158e-09
I0318 10:26:39.836654 29479 solver.cpp:613] Iteration 107380, avg_grad_norm = 529326
I0318 10:28:04.285168 29479 solver.cpp:214] Iteration 107400, loss = 5539.25
I0318 10:28:04.285307 29479 solver.cpp:229]     Train net output #0: loss = 6201 (* 1 = 6201 loss)
I0318 10:28:05.327653 29479 solver.cpp:610] Iteration 107400, lr = 5.00061e-09
I0318 10:28:05.327667 29479 solver.cpp:613] Iteration 107400, avg_grad_norm = 464941
I0318 10:30:33.919853 29479 solver.cpp:214] Iteration 107420, loss = 5578.67
I0318 10:30:33.919991 29479 solver.cpp:229]     Train net output #0: loss = 6747.97 (* 1 = 6747.97 loss)
I0318 10:30:34.963583 29479 solver.cpp:610] Iteration 107420, lr = 4.99964e-09
I0318 10:30:34.963603 29479 solver.cpp:613] Iteration 107420, avg_grad_norm = 568106
I0318 10:33:03.465549 29479 solver.cpp:214] Iteration 107440, loss = 5602.42
I0318 10:33:03.465772 29479 solver.cpp:229]     Train net output #0: loss = 4444.03 (* 1 = 4444.03 loss)
I0318 10:33:03.621347 29479 solver.cpp:610] Iteration 107440, lr = 4.99867e-09
I0318 10:33:03.621361 29479 solver.cpp:613] Iteration 107440, avg_grad_norm = 581340
I0318 10:35:33.019248 29479 solver.cpp:214] Iteration 107460, loss = 5589.07
I0318 10:35:33.019388 29479 solver.cpp:229]     Train net output #0: loss = 7462.56 (* 1 = 7462.56 loss)
I0318 10:35:33.193917 29479 solver.cpp:610] Iteration 107460, lr = 4.99769e-09
I0318 10:35:33.193930 29479 solver.cpp:613] Iteration 107460, avg_grad_norm = 540328
I0318 10:38:02.679538 29479 solver.cpp:214] Iteration 107480, loss = 5289.42
I0318 10:38:02.679662 29479 solver.cpp:229]     Train net output #0: loss = 3965.76 (* 1 = 3965.76 loss)
I0318 10:38:03.718403 29479 solver.cpp:610] Iteration 107480, lr = 4.99672e-09
I0318 10:38:03.718418 29479 solver.cpp:613] Iteration 107480, avg_grad_norm = 563314
I0318 10:40:32.308169 29479 solver.cpp:214] Iteration 107500, loss = 5439.48
I0318 10:40:32.308362 29479 solver.cpp:229]     Train net output #0: loss = 3972.59 (* 1 = 3972.59 loss)
I0318 10:40:33.382771 29479 solver.cpp:610] Iteration 107500, lr = 4.99575e-09
I0318 10:40:33.382786 29479 solver.cpp:613] Iteration 107500, avg_grad_norm = 479686
I0318 10:43:01.767575 29479 solver.cpp:214] Iteration 107520, loss = 5170.74
I0318 10:43:01.767686 29479 solver.cpp:229]     Train net output #0: loss = 10107.1 (* 1 = 10107.1 loss)
I0318 10:43:01.942555 29479 solver.cpp:610] Iteration 107520, lr = 4.99478e-09
I0318 10:43:01.942569 29479 solver.cpp:613] Iteration 107520, avg_grad_norm = 462426
I0318 10:45:30.474021 29479 solver.cpp:214] Iteration 107540, loss = 5697.71
I0318 10:45:30.474217 29479 solver.cpp:229]     Train net output #0: loss = 7224.62 (* 1 = 7224.62 loss)
I0318 10:45:31.519513 29479 solver.cpp:610] Iteration 107540, lr = 4.9938e-09
I0318 10:45:31.519528 29479 solver.cpp:613] Iteration 107540, avg_grad_norm = 492894
I0318 10:47:08.081430 29479 solver.cpp:214] Iteration 107560, loss = 5526.51
I0318 10:47:08.081564 29479 solver.cpp:229]     Train net output #0: loss = 7022.4 (* 1 = 7022.4 loss)
I0318 10:47:08.186347 29479 solver.cpp:610] Iteration 107560, lr = 4.99283e-09
I0318 10:47:08.186383 29479 solver.cpp:613] Iteration 107560, avg_grad_norm = 491981
I0318 10:49:43.857442 29479 solver.cpp:214] Iteration 107580, loss = 5479.24
I0318 10:49:43.857596 29479 solver.cpp:229]     Train net output #0: loss = 2825.14 (* 1 = 2825.14 loss)
I0318 10:49:44.018828 29479 solver.cpp:610] Iteration 107580, lr = 4.99186e-09
I0318 10:49:44.018843 29479 solver.cpp:613] Iteration 107580, avg_grad_norm = 469928
I0318 10:52:12.566210 29479 solver.cpp:214] Iteration 107600, loss = 5754.32
I0318 10:52:12.566350 29479 solver.cpp:229]     Train net output #0: loss = 4702.96 (* 1 = 4702.96 loss)
I0318 10:52:13.643273 29479 solver.cpp:610] Iteration 107600, lr = 4.99089e-09
I0318 10:52:13.643290 29479 solver.cpp:613] Iteration 107600, avg_grad_norm = 477951
I0318 10:54:43.093379 29479 solver.cpp:214] Iteration 107620, loss = 5609.83
I0318 10:54:43.093504 29479 solver.cpp:229]     Train net output #0: loss = 5589.87 (* 1 = 5589.87 loss)
I0318 10:54:43.254573 29479 solver.cpp:610] Iteration 107620, lr = 4.98992e-09
I0318 10:54:43.254586 29479 solver.cpp:613] Iteration 107620, avg_grad_norm = 502890
I0318 10:57:12.738271 29479 solver.cpp:214] Iteration 107640, loss = 5635.8
I0318 10:57:12.738412 29479 solver.cpp:229]     Train net output #0: loss = 3329.83 (* 1 = 3329.83 loss)
I0318 10:57:13.773381 29479 solver.cpp:610] Iteration 107640, lr = 4.98894e-09
I0318 10:57:13.773396 29479 solver.cpp:613] Iteration 107640, avg_grad_norm = 558731
I0318 10:59:42.348253 29479 solver.cpp:214] Iteration 107660, loss = 5466.58
I0318 10:59:42.348436 29479 solver.cpp:229]     Train net output #0: loss = 2899.88 (* 1 = 2899.88 loss)
I0318 10:59:43.380261 29479 solver.cpp:610] Iteration 107660, lr = 4.98797e-09
I0318 10:59:43.380275 29479 solver.cpp:613] Iteration 107660, avg_grad_norm = 576836
I0318 11:02:10.994338 29479 solver.cpp:214] Iteration 107680, loss = 5778.93
I0318 11:02:10.994484 29479 solver.cpp:229]     Train net output #0: loss = 4766.9 (* 1 = 4766.9 loss)
I0318 11:02:12.033377 29479 solver.cpp:610] Iteration 107680, lr = 4.987e-09
I0318 11:02:12.033391 29479 solver.cpp:613] Iteration 107680, avg_grad_norm = 569895
I0318 11:04:55.624099 29479 solver.cpp:214] Iteration 107700, loss = 5422.96
I0318 11:04:55.624236 29479 solver.cpp:229]     Train net output #0: loss = 6469.03 (* 1 = 6469.03 loss)
I0318 11:04:56.669327 29479 solver.cpp:610] Iteration 107700, lr = 4.98603e-09
I0318 11:04:56.669342 29479 solver.cpp:613] Iteration 107700, avg_grad_norm = 476770
I0318 11:07:25.182576 29479 solver.cpp:214] Iteration 107720, loss = 5554.63
I0318 11:07:25.182715 29479 solver.cpp:229]     Train net output #0: loss = 9500.7 (* 1 = 9500.7 loss)
I0318 11:07:25.338407 29479 solver.cpp:610] Iteration 107720, lr = 4.98505e-09
I0318 11:07:25.338420 29479 solver.cpp:613] Iteration 107720, avg_grad_norm = 518748
I0318 11:08:43.712915 29479 solver.cpp:214] Iteration 107740, loss = 5668.51
I0318 11:08:43.713240 29479 solver.cpp:229]     Train net output #0: loss = 4456.76 (* 1 = 4456.76 loss)
I0318 11:08:43.876364 29479 solver.cpp:610] Iteration 107740, lr = 4.98408e-09
I0318 11:08:43.876379 29479 solver.cpp:613] Iteration 107740, avg_grad_norm = 464810
I0318 11:11:11.399801 29479 solver.cpp:214] Iteration 107760, loss = 5649.4
I0318 11:11:11.400002 29479 solver.cpp:229]     Train net output #0: loss = 4303.09 (* 1 = 4303.09 loss)
I0318 11:11:12.478086 29479 solver.cpp:610] Iteration 107760, lr = 4.98311e-09
I0318 11:11:12.478101 29479 solver.cpp:613] Iteration 107760, avg_grad_norm = 481505
I0318 11:13:40.930697 29479 solver.cpp:214] Iteration 107780, loss = 5431.22
I0318 11:13:40.930836 29479 solver.cpp:229]     Train net output #0: loss = 5173.61 (* 1 = 5173.61 loss)
I0318 11:13:41.083852 29479 solver.cpp:610] Iteration 107780, lr = 4.98214e-09
I0318 11:13:41.083868 29479 solver.cpp:613] Iteration 107780, avg_grad_norm = 466271
I0318 11:16:10.542575 29479 solver.cpp:214] Iteration 107800, loss = 5329.23
I0318 11:16:10.542701 29479 solver.cpp:229]     Train net output #0: loss = 3967.1 (* 1 = 3967.1 loss)
I0318 11:16:10.697636 29479 solver.cpp:610] Iteration 107800, lr = 4.98116e-09
I0318 11:16:10.697650 29479 solver.cpp:613] Iteration 107800, avg_grad_norm = 478546
I0318 11:19:14.224503 29479 solver.cpp:214] Iteration 107820, loss = 5229.82
I0318 11:19:14.224645 29479 solver.cpp:229]     Train net output #0: loss = 3296.89 (* 1 = 3296.89 loss)
I0318 11:19:15.263258 29479 solver.cpp:610] Iteration 107820, lr = 4.98019e-09
I0318 11:19:15.263273 29479 solver.cpp:613] Iteration 107820, avg_grad_norm = 464777
I0318 11:21:42.829438 29479 solver.cpp:214] Iteration 107840, loss = 5479.26
I0318 11:21:42.829557 29479 solver.cpp:229]     Train net output #0: loss = 5413.64 (* 1 = 5413.64 loss)
I0318 11:21:42.984405 29479 solver.cpp:610] Iteration 107840, lr = 4.97922e-09
I0318 11:21:42.984418 29479 solver.cpp:613] Iteration 107840, avg_grad_norm = 471959
I0318 11:24:10.498306 29479 solver.cpp:214] Iteration 107860, loss = 5452.71
I0318 11:24:10.498412 29479 solver.cpp:229]     Train net output #0: loss = 3251.99 (* 1 = 3251.99 loss)
I0318 11:24:10.658059 29479 solver.cpp:610] Iteration 107860, lr = 4.97825e-09
I0318 11:24:10.658072 29479 solver.cpp:613] Iteration 107860, avg_grad_norm = 484615
I0318 11:26:40.090121 29479 solver.cpp:214] Iteration 107880, loss = 5509.04
I0318 11:26:40.090239 29479 solver.cpp:229]     Train net output #0: loss = 6582.02 (* 1 = 6582.02 loss)
I0318 11:26:40.243657 29479 solver.cpp:610] Iteration 107880, lr = 4.97727e-09
I0318 11:26:40.243670 29479 solver.cpp:613] Iteration 107880, avg_grad_norm = 514145
I0318 11:27:57.662050 29479 solver.cpp:214] Iteration 107900, loss = 5393.85
I0318 11:27:57.662184 29479 solver.cpp:229]     Train net output #0: loss = 5043.29 (* 1 = 5043.29 loss)
I0318 11:27:57.766254 29479 solver.cpp:610] Iteration 107900, lr = 4.9763e-09
I0318 11:27:57.766291 29479 solver.cpp:613] Iteration 107900, avg_grad_norm = 504335
I0318 11:30:03.225744 29479 solver.cpp:214] Iteration 107920, loss = 5235.83
I0318 11:30:03.225889 29479 solver.cpp:229]     Train net output #0: loss = 5946.72 (* 1 = 5946.72 loss)
I0318 11:30:04.274657 29479 solver.cpp:610] Iteration 107920, lr = 4.97533e-09
I0318 11:30:04.274672 29479 solver.cpp:613] Iteration 107920, avg_grad_norm = 508828
I0318 11:32:32.813771 29479 solver.cpp:214] Iteration 107940, loss = 5449.96
I0318 11:32:32.813925 29479 solver.cpp:229]     Train net output #0: loss = 8960.88 (* 1 = 8960.88 loss)
I0318 11:32:32.970300 29479 solver.cpp:610] Iteration 107940, lr = 4.97436e-09
I0318 11:32:32.970314 29479 solver.cpp:613] Iteration 107940, avg_grad_norm = 493519
I0318 11:35:18.425017 29479 solver.cpp:214] Iteration 107960, loss = 5461.72
I0318 11:35:18.425148 29479 solver.cpp:229]     Train net output #0: loss = 5075.19 (* 1 = 5075.19 loss)
I0318 11:35:19.475961 29479 solver.cpp:610] Iteration 107960, lr = 4.97338e-09
I0318 11:35:19.475975 29479 solver.cpp:613] Iteration 107960, avg_grad_norm = 494934
I0318 11:37:47.056862 29479 solver.cpp:214] Iteration 107980, loss = 5575.58
I0318 11:37:47.057111 29479 solver.cpp:229]     Train net output #0: loss = 3321.22 (* 1 = 3321.22 loss)
I0318 11:37:48.098129 29479 solver.cpp:610] Iteration 107980, lr = 4.97241e-09
I0318 11:37:48.098151 29479 solver.cpp:613] Iteration 107980, avg_grad_norm = 484153
I0318 11:40:03.692201 29479 solver.cpp:214] Iteration 108000, loss = 5352.41
I0318 11:40:03.692296 29479 solver.cpp:229]     Train net output #0: loss = 8173.65 (* 1 = 8173.65 loss)
I0318 11:40:04.768548 29479 solver.cpp:610] Iteration 108000, lr = 4.97144e-09
I0318 11:40:04.768565 29479 solver.cpp:613] Iteration 108000, avg_grad_norm = 512200
I0318 11:42:32.261044 29479 solver.cpp:214] Iteration 108020, loss = 5591.67
I0318 11:42:32.261237 29479 solver.cpp:229]     Train net output #0: loss = 3169.47 (* 1 = 3169.47 loss)
I0318 11:42:33.342454 29479 solver.cpp:610] Iteration 108020, lr = 4.97047e-09
I0318 11:42:33.342484 29479 solver.cpp:613] Iteration 108020, avg_grad_norm = 509259
I0318 11:45:01.884824 29479 solver.cpp:214] Iteration 108040, loss = 5300.72
I0318 11:45:01.884990 29479 solver.cpp:229]     Train net output #0: loss = 5977.07 (* 1 = 5977.07 loss)
I0318 11:45:02.045470 29479 solver.cpp:610] Iteration 108040, lr = 4.96949e-09
I0318 11:45:02.045486 29479 solver.cpp:613] Iteration 108040, avg_grad_norm = 508305
I0318 11:47:31.471910 29479 solver.cpp:214] Iteration 108060, loss = 5393.46
I0318 11:47:31.472014 29479 solver.cpp:229]     Train net output #0: loss = 8048.74 (* 1 = 8048.74 loss)
I0318 11:47:31.625145 29479 solver.cpp:610] Iteration 108060, lr = 4.96852e-09
I0318 11:47:31.625159 29479 solver.cpp:613] Iteration 108060, avg_grad_norm = 508865
I0318 11:49:51.978431 29479 solver.cpp:214] Iteration 108080, loss = 5317.53
I0318 11:49:51.978518 29479 solver.cpp:229]     Train net output #0: loss = 2822.24 (* 1 = 2822.24 loss)
I0318 11:49:53.062297 29479 solver.cpp:610] Iteration 108080, lr = 4.96755e-09
I0318 11:49:53.062312 29479 solver.cpp:613] Iteration 108080, avg_grad_norm = 541504
I0318 11:52:21.466912 29479 solver.cpp:214] Iteration 108100, loss = 5535.35
I0318 11:52:21.467054 29479 solver.cpp:229]     Train net output #0: loss = 7464.86 (* 1 = 7464.86 loss)
I0318 11:52:21.620611 29479 solver.cpp:610] Iteration 108100, lr = 4.96657e-09
I0318 11:52:21.620625 29479 solver.cpp:613] Iteration 108100, avg_grad_norm = 605907
I0318 11:54:50.097321 29479 solver.cpp:214] Iteration 108120, loss = 5799.47
I0318 11:54:50.097539 29479 solver.cpp:229]     Train net output #0: loss = 4080.42 (* 1 = 4080.42 loss)
I0318 11:54:51.169391 29479 solver.cpp:610] Iteration 108120, lr = 4.9656e-09
I0318 11:54:51.169417 29479 solver.cpp:613] Iteration 108120, avg_grad_norm = 504132
I0318 11:57:19.750330 29479 solver.cpp:214] Iteration 108140, loss = 5287.35
I0318 11:57:19.750469 29479 solver.cpp:229]     Train net output #0: loss = 7270.44 (* 1 = 7270.44 loss)
I0318 11:57:20.820444 29479 solver.cpp:610] Iteration 108140, lr = 4.96463e-09
I0318 11:57:20.820459 29479 solver.cpp:613] Iteration 108140, avg_grad_norm = 447213
I0318 11:59:49.295048 29479 solver.cpp:214] Iteration 108160, loss = 5478.52
I0318 11:59:49.295189 29479 solver.cpp:229]     Train net output #0: loss = 5052.07 (* 1 = 5052.07 loss)
I0318 11:59:49.448660 29479 solver.cpp:610] Iteration 108160, lr = 4.96366e-09
I0318 11:59:49.448674 29479 solver.cpp:613] Iteration 108160, avg_grad_norm = 453161
I0318 12:02:18.042508 29479 solver.cpp:214] Iteration 108180, loss = 5787.22
I0318 12:02:18.042613 29479 solver.cpp:229]     Train net output #0: loss = 6768.17 (* 1 = 6768.17 loss)
I0318 12:02:19.116981 29479 solver.cpp:610] Iteration 108180, lr = 4.96268e-09
I0318 12:02:19.116997 29479 solver.cpp:613] Iteration 108180, avg_grad_norm = 480289
I0318 12:05:13.576604 29479 solver.cpp:214] Iteration 108200, loss = 5625.05
I0318 12:05:13.576863 29479 solver.cpp:229]     Train net output #0: loss = 6466.38 (* 1 = 6466.38 loss)
I0318 12:05:13.799420 29479 solver.cpp:610] Iteration 108200, lr = 4.96171e-09
I0318 12:05:13.799434 29479 solver.cpp:613] Iteration 108200, avg_grad_norm = 565071
I0318 12:07:42.280247 29479 solver.cpp:214] Iteration 108220, loss = 5483.29
I0318 12:07:42.280405 29479 solver.cpp:229]     Train net output #0: loss = 8453.85 (* 1 = 8453.85 loss)
I0318 12:07:42.433706 29479 solver.cpp:610] Iteration 108220, lr = 4.96074e-09
I0318 12:07:42.433719 29479 solver.cpp:613] Iteration 108220, avg_grad_norm = 492586
I0318 12:08:59.848525 29479 solver.cpp:214] Iteration 108240, loss = 5436.73
I0318 12:08:59.848639 29479 solver.cpp:229]     Train net output #0: loss = 4417.1 (* 1 = 4417.1 loss)
I0318 12:09:00.009713 29479 solver.cpp:610] Iteration 108240, lr = 4.95977e-09
I0318 12:09:00.009727 29479 solver.cpp:613] Iteration 108240, avg_grad_norm = 491360
I0318 12:11:29.511188 29479 solver.cpp:214] Iteration 108260, loss = 5513.44
I0318 12:11:29.511338 29479 solver.cpp:229]     Train net output #0: loss = 8458.76 (* 1 = 8458.76 loss)
I0318 12:11:30.539887 29479 solver.cpp:610] Iteration 108260, lr = 4.95879e-09
I0318 12:11:30.539902 29479 solver.cpp:613] Iteration 108260, avg_grad_norm = 507245
I0318 12:13:58.203997 29479 solver.cpp:214] Iteration 108280, loss = 5587.99
I0318 12:13:58.204118 29479 solver.cpp:229]     Train net output #0: loss = 4436.51 (* 1 = 4436.51 loss)
I0318 12:13:59.287624 29479 solver.cpp:610] Iteration 108280, lr = 4.95782e-09
I0318 12:13:59.287639 29479 solver.cpp:613] Iteration 108280, avg_grad_norm = 482054
I0318 12:16:28.743304 29479 solver.cpp:214] Iteration 108300, loss = 5407.17
I0318 12:16:28.743438 29479 solver.cpp:229]     Train net output #0: loss = 2789.29 (* 1 = 2789.29 loss)
I0318 12:16:28.901381 29479 solver.cpp:610] Iteration 108300, lr = 4.95685e-09
I0318 12:16:28.901393 29479 solver.cpp:613] Iteration 108300, avg_grad_norm = 453616
I0318 12:19:05.399974 29479 solver.cpp:214] Iteration 108320, loss = 5686.42
I0318 12:19:05.400104 29479 solver.cpp:229]     Train net output #0: loss = 3390.3 (* 1 = 3390.3 loss)
I0318 12:19:06.414484 29479 solver.cpp:610] Iteration 108320, lr = 4.95587e-09
I0318 12:19:06.414499 29479 solver.cpp:613] Iteration 108320, avg_grad_norm = 529997
I0318 12:21:48.024762 29479 solver.cpp:214] Iteration 108340, loss = 5570.18
I0318 12:21:48.024847 29479 solver.cpp:229]     Train net output #0: loss = 4117.32 (* 1 = 4117.32 loss)
I0318 12:21:49.099102 29479 solver.cpp:610] Iteration 108340, lr = 4.9549e-09
I0318 12:21:49.099117 29479 solver.cpp:613] Iteration 108340, avg_grad_norm = 507624
I0318 12:24:16.587591 29479 solver.cpp:214] Iteration 108360, loss = 5506.36
I0318 12:24:16.587740 29479 solver.cpp:229]     Train net output #0: loss = 3890.72 (* 1 = 3890.72 loss)
I0318 12:24:17.632200 29479 solver.cpp:610] Iteration 108360, lr = 4.95393e-09
I0318 12:24:17.632215 29479 solver.cpp:613] Iteration 108360, avg_grad_norm = 527792
I0318 12:26:46.124785 29479 solver.cpp:214] Iteration 108380, loss = 5624.7
I0318 12:26:46.124941 29479 solver.cpp:229]     Train net output #0: loss = 5442.76 (* 1 = 5442.76 loss)
I0318 12:26:46.278143 29479 solver.cpp:610] Iteration 108380, lr = 4.95295e-09
I0318 12:26:46.278164 29479 solver.cpp:613] Iteration 108380, avg_grad_norm = 472838
I0318 12:29:00.800710 29479 solver.cpp:214] Iteration 108400, loss = 5898.62
I0318 12:29:00.800845 29479 solver.cpp:229]     Train net output #0: loss = 4668.85 (* 1 = 4668.85 loss)
I0318 12:29:00.905472 29479 solver.cpp:610] Iteration 108400, lr = 4.95198e-09
I0318 12:29:00.905522 29479 solver.cpp:613] Iteration 108400, avg_grad_norm = 499131
I0318 12:30:34.381816 29479 solver.cpp:214] Iteration 108420, loss = 5524.03
I0318 12:30:34.381929 29479 solver.cpp:229]     Train net output #0: loss = 5009.01 (* 1 = 5009.01 loss)
I0318 12:30:34.535671 29479 solver.cpp:610] Iteration 108420, lr = 4.95101e-09
I0318 12:30:34.535684 29479 solver.cpp:613] Iteration 108420, avg_grad_norm = 485771
I0318 12:33:03.990262 29479 solver.cpp:214] Iteration 108440, loss = 5600.46
I0318 12:33:03.990489 29479 solver.cpp:229]     Train net output #0: loss = 6550.77 (* 1 = 6550.77 loss)
I0318 12:33:05.060578 29479 solver.cpp:610] Iteration 108440, lr = 4.95003e-09
I0318 12:33:05.060593 29479 solver.cpp:613] Iteration 108440, avg_grad_norm = 496846
I0318 12:35:51.581145 29479 solver.cpp:214] Iteration 108460, loss = 5777.76
I0318 12:35:51.581394 29479 solver.cpp:229]     Train net output #0: loss = 3628.88 (* 1 = 3628.88 loss)
I0318 12:35:51.738087 29479 solver.cpp:610] Iteration 108460, lr = 4.94906e-09
I0318 12:35:51.738101 29479 solver.cpp:613] Iteration 108460, avg_grad_norm = 524924
I0318 12:38:16.199343 29479 solver.cpp:214] Iteration 108480, loss = 5236.84
I0318 12:38:16.199491 29479 solver.cpp:229]     Train net output #0: loss = 2953.19 (* 1 = 2953.19 loss)
I0318 12:38:16.353042 29479 solver.cpp:610] Iteration 108480, lr = 4.94809e-09
I0318 12:38:16.353055 29479 solver.cpp:613] Iteration 108480, avg_grad_norm = 463803
I0318 12:40:44.829754 29479 solver.cpp:214] Iteration 108500, loss = 5359.21
I0318 12:40:44.829885 29479 solver.cpp:229]     Train net output #0: loss = 3664.64 (* 1 = 3664.64 loss)
I0318 12:40:45.906936 29479 solver.cpp:610] Iteration 108500, lr = 4.94711e-09
I0318 12:40:45.906950 29479 solver.cpp:613] Iteration 108500, avg_grad_norm = 517148
I0318 12:43:13.421826 29479 solver.cpp:214] Iteration 108520, loss = 5775.89
I0318 12:43:13.421972 29479 solver.cpp:229]     Train net output #0: loss = 9483.1 (* 1 = 9483.1 loss)
I0318 12:43:13.577884 29479 solver.cpp:610] Iteration 108520, lr = 4.94614e-09
I0318 12:43:13.577899 29479 solver.cpp:613] Iteration 108520, avg_grad_norm = 522498
I0318 12:45:41.914774 29479 solver.cpp:214] Iteration 108540, loss = 5813.15
I0318 12:45:41.914954 29479 solver.cpp:229]     Train net output #0: loss = 4380.27 (* 1 = 4380.27 loss)
I0318 12:45:42.136557 29479 solver.cpp:610] Iteration 108540, lr = 4.94517e-09
I0318 12:45:42.136572 29479 solver.cpp:613] Iteration 108540, avg_grad_norm = 519564
I0318 12:48:11.650066 29479 solver.cpp:214] Iteration 108560, loss = 5656.92
I0318 12:48:11.650204 29479 solver.cpp:229]     Train net output #0: loss = 6236.06 (* 1 = 6236.06 loss)
I0318 12:48:12.721971 29479 solver.cpp:610] Iteration 108560, lr = 4.9442e-09
I0318 12:48:12.721984 29479 solver.cpp:613] Iteration 108560, avg_grad_norm = 506767
I0318 12:49:51.680272 29479 solver.cpp:214] Iteration 108580, loss = 5283.76
I0318 12:49:51.680414 29479 solver.cpp:229]     Train net output #0: loss = 3486.49 (* 1 = 3486.49 loss)
I0318 12:49:51.846885 29479 solver.cpp:610] Iteration 108580, lr = 4.94322e-09
I0318 12:49:51.846899 29479 solver.cpp:613] Iteration 108580, avg_grad_norm = 455542
I0318 12:52:20.347612 29479 solver.cpp:214] Iteration 108600, loss = 5407.22
I0318 12:52:20.347719 29479 solver.cpp:229]     Train net output #0: loss = 2034.42 (* 1 = 2034.42 loss)
I0318 12:52:21.394716 29479 solver.cpp:610] Iteration 108600, lr = 4.94225e-09
I0318 12:52:21.394728 29479 solver.cpp:613] Iteration 108600, avg_grad_norm = 526179
I0318 12:54:49.942139 29479 solver.cpp:214] Iteration 108620, loss = 5451.1
I0318 12:54:49.942257 29479 solver.cpp:229]     Train net output #0: loss = 5649.03 (* 1 = 5649.03 loss)
I0318 12:54:51.029536 29479 solver.cpp:610] Iteration 108620, lr = 4.94128e-09
I0318 12:54:51.029559 29479 solver.cpp:613] Iteration 108620, avg_grad_norm = 455849
I0318 12:57:19.580445 29479 solver.cpp:214] Iteration 108640, loss = 5394.85
I0318 12:57:19.580659 29479 solver.cpp:229]     Train net output #0: loss = 5567.56 (* 1 = 5567.56 loss)
I0318 12:57:20.648282 29479 solver.cpp:610] Iteration 108640, lr = 4.9403e-09
I0318 12:57:20.648295 29479 solver.cpp:613] Iteration 108640, avg_grad_norm = 460742
I0318 12:59:49.150238 29479 solver.cpp:214] Iteration 108660, loss = 5647.37
I0318 12:59:49.150338 29479 solver.cpp:229]     Train net output #0: loss = 5839.73 (* 1 = 5839.73 loss)
I0318 12:59:49.311962 29479 solver.cpp:610] Iteration 108660, lr = 4.93933e-09
I0318 12:59:49.311975 29479 solver.cpp:613] Iteration 108660, avg_grad_norm = 541637
I0318 13:02:18.887773 29479 solver.cpp:214] Iteration 108680, loss = 5551.43
I0318 13:02:18.888039 29479 solver.cpp:229]     Train net output #0: loss = 3306.3 (* 1 = 3306.3 loss)
I0318 13:02:19.957900 29479 solver.cpp:610] Iteration 108680, lr = 4.93836e-09
I0318 13:02:19.957914 29479 solver.cpp:613] Iteration 108680, avg_grad_norm = 471224
I0318 13:04:50.403523 29479 solver.cpp:214] Iteration 108700, loss = 5648.9
I0318 13:04:50.403671 29479 solver.cpp:229]     Train net output #0: loss = 4384.19 (* 1 = 4384.19 loss)
I0318 13:04:51.451938 29479 solver.cpp:610] Iteration 108700, lr = 4.93738e-09
I0318 13:04:51.451953 29479 solver.cpp:613] Iteration 108700, avg_grad_norm = 510062
I0318 13:07:38.061215 29479 solver.cpp:214] Iteration 108720, loss = 5551.79
I0318 13:07:38.061301 29479 solver.cpp:229]     Train net output #0: loss = 7818.73 (* 1 = 7818.73 loss)
I0318 13:07:38.231004 29479 solver.cpp:610] Iteration 108720, lr = 4.93641e-09
I0318 13:07:38.231017 29479 solver.cpp:613] Iteration 108720, avg_grad_norm = 475654
I0318 13:09:34.670550 29479 solver.cpp:214] Iteration 108740, loss = 5421.65
I0318 13:09:34.670691 29479 solver.cpp:229]     Train net output #0: loss = 5596.9 (* 1 = 5596.9 loss)
I0318 13:09:34.775110 29479 solver.cpp:610] Iteration 108740, lr = 4.93544e-09
I0318 13:09:34.775161 29479 solver.cpp:613] Iteration 108740, avg_grad_norm = 458621
I0318 13:11:25.249269 29479 solver.cpp:214] Iteration 108760, loss = 5561.11
I0318 13:11:25.249385 29479 solver.cpp:229]     Train net output #0: loss = 5160.38 (* 1 = 5160.38 loss)
I0318 13:11:25.404045 29479 solver.cpp:610] Iteration 108760, lr = 4.93446e-09
I0318 13:11:25.404058 29479 solver.cpp:613] Iteration 108760, avg_grad_norm = 508406
I0318 13:13:53.893424 29479 solver.cpp:214] Iteration 108780, loss = 5533.88
I0318 13:13:53.893570 29479 solver.cpp:229]     Train net output #0: loss = 7225.37 (* 1 = 7225.37 loss)
I0318 13:13:54.935933 29479 solver.cpp:610] Iteration 108780, lr = 4.93349e-09
I0318 13:13:54.935948 29479 solver.cpp:613] Iteration 108780, avg_grad_norm = 517111
I0318 13:16:23.546540 29479 solver.cpp:214] Iteration 108800, loss = 5695.97
I0318 13:16:23.546654 29479 solver.cpp:229]     Train net output #0: loss = 9536.29 (* 1 = 9536.29 loss)
I0318 13:16:23.704216 29479 solver.cpp:610] Iteration 108800, lr = 4.93251e-09
I0318 13:16:23.704228 29479 solver.cpp:613] Iteration 108800, avg_grad_norm = 563464
I0318 13:18:53.190718 29479 solver.cpp:214] Iteration 108820, loss = 5384.27
I0318 13:18:53.190927 29479 solver.cpp:229]     Train net output #0: loss = 2984.22 (* 1 = 2984.22 loss)
I0318 13:18:54.229348 29479 solver.cpp:610] Iteration 108820, lr = 4.93154e-09
I0318 13:18:54.229369 29479 solver.cpp:613] Iteration 108820, avg_grad_norm = 529159
I0318 13:21:37.763679 29479 solver.cpp:214] Iteration 108840, loss = 5376.74
I0318 13:21:37.763813 29479 solver.cpp:229]     Train net output #0: loss = 3958.97 (* 1 = 3958.97 loss)
I0318 13:21:37.924626 29479 solver.cpp:610] Iteration 108840, lr = 4.93057e-09
I0318 13:21:37.924640 29479 solver.cpp:613] Iteration 108840, avg_grad_norm = 493442
I0318 13:24:05.386245 29479 solver.cpp:214] Iteration 108860, loss = 5622.32
I0318 13:24:05.386382 29479 solver.cpp:229]     Train net output #0: loss = 6404.54 (* 1 = 6404.54 loss)
I0318 13:24:05.540024 29479 solver.cpp:610] Iteration 108860, lr = 4.92959e-09
I0318 13:24:05.540036 29479 solver.cpp:613] Iteration 108860, avg_grad_norm = 501078
I0318 13:26:35.052211 29479 solver.cpp:214] Iteration 108880, loss = 5253.69
I0318 13:26:35.052361 29479 solver.cpp:229]     Train net output #0: loss = 7027.1 (* 1 = 7027.1 loss)
I0318 13:26:35.205435 29479 solver.cpp:610] Iteration 108880, lr = 4.92862e-09
I0318 13:26:35.205449 29479 solver.cpp:613] Iteration 108880, avg_grad_norm = 488607
I0318 13:29:01.744508 29479 solver.cpp:214] Iteration 108900, loss = 5659.31
I0318 13:29:01.744616 29479 solver.cpp:229]     Train net output #0: loss = 3923.39 (* 1 = 3923.39 loss)
I0318 13:29:02.820338 29479 solver.cpp:610] Iteration 108900, lr = 4.92765e-09
I0318 13:29:02.820353 29479 solver.cpp:613] Iteration 108900, avg_grad_norm = 476541
I0318 13:30:21.329130 29479 solver.cpp:214] Iteration 108920, loss = 5489.73
I0318 13:30:21.329334 29479 solver.cpp:229]     Train net output #0: loss = 5258.58 (* 1 = 5258.58 loss)
I0318 13:30:22.404700 29479 solver.cpp:610] Iteration 108920, lr = 4.92667e-09
I0318 13:30:22.404716 29479 solver.cpp:613] Iteration 108920, avg_grad_norm = 469520
I0318 13:32:55.954397 29479 solver.cpp:214] Iteration 108940, loss = 5475.21
I0318 13:32:55.954545 29479 solver.cpp:229]     Train net output #0: loss = 5062.51 (* 1 = 5062.51 loss)
I0318 13:32:56.997300 29479 solver.cpp:610] Iteration 108940, lr = 4.9257e-09
I0318 13:32:56.997319 29479 solver.cpp:613] Iteration 108940, avg_grad_norm = 511528
I0318 13:35:40.646864 29479 solver.cpp:214] Iteration 108960, loss = 5589.37
I0318 13:35:40.647014 29479 solver.cpp:229]     Train net output #0: loss = 3561.47 (* 1 = 3561.47 loss)
I0318 13:35:41.727921 29479 solver.cpp:610] Iteration 108960, lr = 4.92473e-09
I0318 13:35:41.727938 29479 solver.cpp:613] Iteration 108960, avg_grad_norm = 476160
I0318 13:38:09.299985 29479 solver.cpp:214] Iteration 108980, loss = 5853.07
I0318 13:38:09.300109 29479 solver.cpp:229]     Train net output #0: loss = 4352.64 (* 1 = 4352.64 loss)
I0318 13:38:10.390769 29479 solver.cpp:610] Iteration 108980, lr = 4.92375e-09
I0318 13:38:10.390810 29479 solver.cpp:613] Iteration 108980, avg_grad_norm = 476809
I0318 13:40:38.960533 29479 solver.cpp:214] Iteration 109000, loss = 5651.9
I0318 13:40:38.960655 29479 solver.cpp:229]     Train net output #0: loss = 3546.61 (* 1 = 3546.61 loss)
I0318 13:40:40.037925 29479 solver.cpp:610] Iteration 109000, lr = 4.92278e-09
I0318 13:40:40.037940 29479 solver.cpp:613] Iteration 109000, avg_grad_norm = 491155
I0318 13:43:08.622431 29479 solver.cpp:214] Iteration 109020, loss = 5636.72
I0318 13:43:08.622568 29479 solver.cpp:229]     Train net output #0: loss = 3599.21 (* 1 = 3599.21 loss)
I0318 13:43:09.707299 29479 solver.cpp:610] Iteration 109020, lr = 4.9218e-09
I0318 13:43:09.707314 29479 solver.cpp:613] Iteration 109020, avg_grad_norm = 475196
I0318 13:45:38.237772 29479 solver.cpp:214] Iteration 109040, loss = 5679.18
I0318 13:45:38.237910 29479 solver.cpp:229]     Train net output #0: loss = 4457.34 (* 1 = 4457.34 loss)
I0318 13:45:39.277964 29479 solver.cpp:610] Iteration 109040, lr = 4.92083e-09
I0318 13:45:39.278007 29479 solver.cpp:613] Iteration 109040, avg_grad_norm = 495460
I0318 13:48:05.903911 29479 solver.cpp:214] Iteration 109060, loss = 5437.25
I0318 13:48:05.904103 29479 solver.cpp:229]     Train net output #0: loss = 8969.03 (* 1 = 8969.03 loss)
I0318 13:48:06.981159 29479 solver.cpp:610] Iteration 109060, lr = 4.91986e-09
I0318 13:48:06.981197 29479 solver.cpp:613] Iteration 109060, avg_grad_norm = 453960
I0318 13:50:08.504240 29479 solver.cpp:214] Iteration 109080, loss = 5628.74
I0318 13:50:08.504432 29479 solver.cpp:229]     Train net output #0: loss = 4987.61 (* 1 = 4987.61 loss)
I0318 13:50:08.609757 29479 solver.cpp:610] Iteration 109080, lr = 4.91888e-09
I0318 13:50:08.609771 29479 solver.cpp:613] Iteration 109080, avg_grad_norm = 507207
I0318 13:52:09.130951 29479 solver.cpp:214] Iteration 109100, loss = 5478.56
I0318 13:52:09.131057 29479 solver.cpp:229]     Train net output #0: loss = 7095.52 (* 1 = 7095.52 loss)
I0318 13:52:10.215198 29479 solver.cpp:610] Iteration 109100, lr = 4.91791e-09
I0318 13:52:10.215214 29479 solver.cpp:613] Iteration 109100, avg_grad_norm = 523402
I0318 13:54:39.702217 29479 solver.cpp:214] Iteration 109120, loss = 5596.94
I0318 13:54:39.702349 29479 solver.cpp:229]     Train net output #0: loss = 6023.69 (* 1 = 6023.69 loss)
I0318 13:54:39.863530 29479 solver.cpp:610] Iteration 109120, lr = 4.91694e-09
I0318 13:54:39.863544 29479 solver.cpp:613] Iteration 109120, avg_grad_norm = 473821
I0318 13:57:08.315130 29479 solver.cpp:214] Iteration 109140, loss = 5725.06
I0318 13:57:08.315261 29479 solver.cpp:229]     Train net output #0: loss = 6656.85 (* 1 = 6656.85 loss)
I0318 13:57:08.473193 29479 solver.cpp:610] Iteration 109140, lr = 4.91596e-09
I0318 13:57:08.473224 29479 solver.cpp:613] Iteration 109140, avg_grad_norm = 490090
I0318 13:59:36.921062 29479 solver.cpp:214] Iteration 109160, loss = 5453.8
I0318 13:59:36.921252 29479 solver.cpp:229]     Train net output #0: loss = 2172.43 (* 1 = 2172.43 loss)
I0318 13:59:37.079141 29479 solver.cpp:610] Iteration 109160, lr = 4.91499e-09
I0318 13:59:37.079156 29479 solver.cpp:613] Iteration 109160, avg_grad_norm = 494676
I0318 14:02:05.562470 29479 solver.cpp:214] Iteration 109180, loss = 5509.23
I0318 14:02:05.562613 29479 solver.cpp:229]     Train net output #0: loss = 5974.88 (* 1 = 5974.88 loss)
I0318 14:02:05.718128 29479 solver.cpp:610] Iteration 109180, lr = 4.91401e-09
I0318 14:02:05.718143 29479 solver.cpp:613] Iteration 109180, avg_grad_norm = 499357
I0318 14:04:36.153646 29479 solver.cpp:214] Iteration 109200, loss = 5347.47
I0318 14:04:36.153806 29479 solver.cpp:229]     Train net output #0: loss = 6208.88 (* 1 = 6208.88 loss)
I0318 14:04:36.349062 29479 solver.cpp:610] Iteration 109200, lr = 4.91304e-09
I0318 14:04:36.349081 29479 solver.cpp:613] Iteration 109200, avg_grad_norm = 518968
I0318 14:07:34.874698 29479 solver.cpp:214] Iteration 109220, loss = 5359.68
I0318 14:07:34.874825 29479 solver.cpp:229]     Train net output #0: loss = 5039.24 (* 1 = 5039.24 loss)
I0318 14:07:35.916404 29479 solver.cpp:610] Iteration 109220, lr = 4.91207e-09
I0318 14:07:35.916419 29479 solver.cpp:613] Iteration 109220, avg_grad_norm = 558028
I0318 14:10:04.380964 29479 solver.cpp:214] Iteration 109240, loss = 5336.33
I0318 14:10:04.381098 29479 solver.cpp:229]     Train net output #0: loss = 4855.78 (* 1 = 4855.78 loss)
I0318 14:10:04.603952 29479 solver.cpp:610] Iteration 109240, lr = 4.91109e-09
I0318 14:10:04.604013 29479 solver.cpp:613] Iteration 109240, avg_grad_norm = 572072
I0318 14:11:23.093686 29479 solver.cpp:214] Iteration 109260, loss = 5414.56
I0318 14:11:23.093827 29479 solver.cpp:229]     Train net output #0: loss = 5487.83 (* 1 = 5487.83 loss)
I0318 14:11:24.130012 29479 solver.cpp:610] Iteration 109260, lr = 4.91012e-09
I0318 14:11:24.130025 29479 solver.cpp:613] Iteration 109260, avg_grad_norm = 534954
I0318 14:13:53.702872 29479 solver.cpp:214] Iteration 109280, loss = 5531.5
I0318 14:13:53.702998 29479 solver.cpp:229]     Train net output #0: loss = 7878.58 (* 1 = 7878.58 loss)
I0318 14:13:53.877801 29479 solver.cpp:610] Iteration 109280, lr = 4.90914e-09
I0318 14:13:53.877815 29479 solver.cpp:613] Iteration 109280, avg_grad_norm = 533425
I0318 14:16:23.217237 29479 solver.cpp:214] Iteration 109300, loss = 5467.78
I0318 14:16:23.217437 29479 solver.cpp:229]     Train net output #0: loss = 7629.67 (* 1 = 7629.67 loss)
I0318 14:16:23.439848 29479 solver.cpp:610] Iteration 109300, lr = 4.90817e-09
I0318 14:16:23.439862 29479 solver.cpp:613] Iteration 109300, avg_grad_norm = 600966
I0318 14:18:53.901396 29479 solver.cpp:214] Iteration 109320, loss = 5254.9
I0318 14:18:53.901532 29479 solver.cpp:229]     Train net output #0: loss = 4687.43 (* 1 = 4687.43 loss)
I0318 14:18:54.062311 29479 solver.cpp:610] Iteration 109320, lr = 4.9072e-09
I0318 14:18:54.062325 29479 solver.cpp:613] Iteration 109320, avg_grad_norm = 601814
I0318 14:21:22.570061 29479 solver.cpp:214] Iteration 109340, loss = 5481.83
I0318 14:21:22.570168 29479 solver.cpp:229]     Train net output #0: loss = 3486.95 (* 1 = 3486.95 loss)
I0318 14:21:22.737260 29479 solver.cpp:610] Iteration 109340, lr = 4.90622e-09
I0318 14:21:22.737273 29479 solver.cpp:613] Iteration 109340, avg_grad_norm = 529436
I0318 14:24:03.214784 29479 solver.cpp:214] Iteration 109360, loss = 5420.13
I0318 14:24:03.214948 29479 solver.cpp:229]     Train net output #0: loss = 4995.95 (* 1 = 4995.95 loss)
I0318 14:24:03.437878 29479 solver.cpp:610] Iteration 109360, lr = 4.90525e-09
I0318 14:24:03.437892 29479 solver.cpp:613] Iteration 109360, avg_grad_norm = 519432
I0318 14:26:31.918149 29479 solver.cpp:214] Iteration 109380, loss = 5402.81
I0318 14:26:31.918318 29479 solver.cpp:229]     Train net output #0: loss = 4862.23 (* 1 = 4862.23 loss)
I0318 14:26:32.085000 29479 solver.cpp:610] Iteration 109380, lr = 4.90427e-09
I0318 14:26:32.085014 29479 solver.cpp:613] Iteration 109380, avg_grad_norm = 474839
I0318 14:29:01.510803 29479 solver.cpp:214] Iteration 109400, loss = 5317.39
I0318 14:29:01.510941 29479 solver.cpp:229]     Train net output #0: loss = 2052.55 (* 1 = 2052.55 loss)
I0318 14:29:01.664180 29479 solver.cpp:610] Iteration 109400, lr = 4.9033e-09
I0318 14:29:01.664194 29479 solver.cpp:613] Iteration 109400, avg_grad_norm = 495282
I0318 14:30:42.175209 29479 solver.cpp:214] Iteration 109420, loss = 5551.9
I0318 14:30:42.175345 29479 solver.cpp:229]     Train net output #0: loss = 7966.84 (* 1 = 7966.84 loss)
I0318 14:30:42.279417 29479 solver.cpp:610] Iteration 109420, lr = 4.90232e-09
I0318 14:30:42.279453 29479 solver.cpp:613] Iteration 109420, avg_grad_norm = 477707
I0318 14:32:28.791328 29479 solver.cpp:214] Iteration 109440, loss = 5721.97
I0318 14:32:28.791410 29479 solver.cpp:229]     Train net output #0: loss = 6951.83 (* 1 = 6951.83 loss)
I0318 14:32:29.839287 29479 solver.cpp:610] Iteration 109440, lr = 4.90135e-09
I0318 14:32:29.839300 29479 solver.cpp:613] Iteration 109440, avg_grad_norm = 547278
I0318 14:35:00.366632 29479 solver.cpp:214] Iteration 109460, loss = 5472.17
I0318 14:35:00.366792 29479 solver.cpp:229]     Train net output #0: loss = 5402.19 (* 1 = 5402.19 loss)
I0318 14:35:00.542804 29479 solver.cpp:610] Iteration 109460, lr = 4.90038e-09
I0318 14:35:00.542817 29479 solver.cpp:613] Iteration 109460, avg_grad_norm = 572759
I0318 14:37:38.997934 29479 solver.cpp:214] Iteration 109480, loss = 5439.55
I0318 14:37:38.998117 29479 solver.cpp:229]     Train net output #0: loss = 4082.27 (* 1 = 4082.27 loss)
I0318 14:37:39.167621 29479 solver.cpp:610] Iteration 109480, lr = 4.8994e-09
I0318 14:37:39.167634 29479 solver.cpp:613] Iteration 109480, avg_grad_norm = 502573
I0318 14:40:06.798809 29479 solver.cpp:214] Iteration 109500, loss = 5378.07
I0318 14:40:06.798930 29479 solver.cpp:229]     Train net output #0: loss = 8006.92 (* 1 = 8006.92 loss)
I0318 14:40:07.879009 29479 solver.cpp:610] Iteration 109500, lr = 4.89843e-09
I0318 14:40:07.879024 29479 solver.cpp:613] Iteration 109500, avg_grad_norm = 475644
I0318 14:42:36.357342 29479 solver.cpp:214] Iteration 109520, loss = 5890.31
I0318 14:42:36.357507 29479 solver.cpp:229]     Train net output #0: loss = 3500.01 (* 1 = 3500.01 loss)
I0318 14:42:36.513733 29479 solver.cpp:610] Iteration 109520, lr = 4.89745e-09
I0318 14:42:36.513747 29479 solver.cpp:613] Iteration 109520, avg_grad_norm = 504158
I0318 14:45:05.046195 29479 solver.cpp:214] Iteration 109540, loss = 5522.98
I0318 14:45:05.046326 29479 solver.cpp:229]     Train net output #0: loss = 2491.61 (* 1 = 2491.61 loss)
I0318 14:45:06.085824 29479 solver.cpp:610] Iteration 109540, lr = 4.89648e-09
I0318 14:45:06.085844 29479 solver.cpp:613] Iteration 109540, avg_grad_norm = 526756
I0318 14:47:33.656853 29479 solver.cpp:214] Iteration 109560, loss = 5396.1
I0318 14:47:33.656991 29479 solver.cpp:229]     Train net output #0: loss = 5208.64 (* 1 = 5208.64 loss)
I0318 14:47:33.817358 29479 solver.cpp:610] Iteration 109560, lr = 4.8955e-09
I0318 14:47:33.817371 29479 solver.cpp:613] Iteration 109560, avg_grad_norm = 547899
I0318 14:50:01.291123 29479 solver.cpp:214] Iteration 109580, loss = 5509.6
I0318 14:50:01.291303 29479 solver.cpp:229]     Train net output #0: loss = 5335.1 (* 1 = 5335.1 loss)
I0318 14:50:01.454887 29479 solver.cpp:610] Iteration 109580, lr = 4.89453e-09
I0318 14:50:01.454900 29479 solver.cpp:613] Iteration 109580, avg_grad_norm = 539839
I0318 14:51:13.783306 29479 solver.cpp:214] Iteration 109600, loss = 5321.79
I0318 14:51:13.783483 29479 solver.cpp:229]     Train net output #0: loss = 3455.73 (* 1 = 3455.73 loss)
I0318 14:51:13.888955 29479 solver.cpp:610] Iteration 109600, lr = 4.89356e-09
I0318 14:51:13.888978 29479 solver.cpp:613] Iteration 109600, avg_grad_norm = 573110
I0318 14:53:28.351670 29479 solver.cpp:214] Iteration 109620, loss = 5684.58
I0318 14:53:28.351877 29479 solver.cpp:229]     Train net output #0: loss = 5087.41 (* 1 = 5087.41 loss)
I0318 14:53:28.504897 29479 solver.cpp:610] Iteration 109620, lr = 4.89258e-09
I0318 14:53:28.504911 29479 solver.cpp:613] Iteration 109620, avg_grad_norm = 527984
I0318 14:55:58.007755 29479 solver.cpp:214] Iteration 109640, loss = 5434.03
I0318 14:55:58.007892 29479 solver.cpp:229]     Train net output #0: loss = 4415.3 (* 1 = 4415.3 loss)
I0318 14:55:58.169327 29479 solver.cpp:610] Iteration 109640, lr = 4.89161e-09
I0318 14:55:58.169340 29479 solver.cpp:613] Iteration 109640, avg_grad_norm = 464012
I0318 14:58:24.682476 29479 solver.cpp:214] Iteration 109660, loss = 5216.79
I0318 14:58:24.682647 29479 solver.cpp:229]     Train net output #0: loss = 5211.76 (* 1 = 5211.76 loss)
I0318 14:58:25.727654 29479 solver.cpp:610] Iteration 109660, lr = 4.89063e-09
I0318 14:58:25.727669 29479 solver.cpp:613] Iteration 109660, avg_grad_norm = 486813
I0318 15:00:43.289453 29479 solver.cpp:214] Iteration 109680, loss = 5370.43
I0318 15:00:43.289630 29479 solver.cpp:229]     Train net output #0: loss = 6850.18 (* 1 = 6850.18 loss)
I0318 15:00:44.331353 29479 solver.cpp:610] Iteration 109680, lr = 4.88966e-09
I0318 15:00:44.331370 29479 solver.cpp:613] Iteration 109680, avg_grad_norm = 457871
I0318 15:03:10.932986 29479 solver.cpp:214] Iteration 109700, loss = 5433.29
I0318 15:03:10.933195 29479 solver.cpp:229]     Train net output #0: loss = 4968.89 (* 1 = 4968.89 loss)
I0318 15:03:12.006693 29479 solver.cpp:610] Iteration 109700, lr = 4.88868e-09
I0318 15:03:12.006716 29479 solver.cpp:613] Iteration 109700, avg_grad_norm = 473056
I0318 15:05:43.531358 29479 solver.cpp:214] Iteration 109720, loss = 5252.46
I0318 15:05:43.531474 29479 solver.cpp:229]     Train net output #0: loss = 4309.63 (* 1 = 4309.63 loss)
I0318 15:05:44.612201 29479 solver.cpp:610] Iteration 109720, lr = 4.88771e-09
I0318 15:05:44.612215 29479 solver.cpp:613] Iteration 109720, avg_grad_norm = 503201
I0318 15:08:11.091368 29479 solver.cpp:214] Iteration 109740, loss = 5538.19
I0318 15:08:11.091547 29479 solver.cpp:229]     Train net output #0: loss = 6444.85 (* 1 = 6444.85 loss)
I0318 15:08:11.262188 29479 solver.cpp:610] Iteration 109740, lr = 4.88674e-09
I0318 15:08:11.262203 29479 solver.cpp:613] Iteration 109740, avg_grad_norm = 491644
I0318 15:10:38.704825 29479 solver.cpp:214] Iteration 109760, loss = 5360.69
I0318 15:10:38.705034 29479 solver.cpp:229]     Train net output #0: loss = 4752.39 (* 1 = 4752.39 loss)
I0318 15:10:38.887168 29479 solver.cpp:610] Iteration 109760, lr = 4.88576e-09
I0318 15:10:38.887188 29479 solver.cpp:613] Iteration 109760, avg_grad_norm = 496179
I0318 15:11:53.389865 29479 solver.cpp:214] Iteration 109780, loss = 5454.79
I0318 15:11:53.389972 29479 solver.cpp:229]     Train net output #0: loss = 3628.03 (* 1 = 3628.03 loss)
I0318 15:11:54.481254 29479 solver.cpp:610] Iteration 109780, lr = 4.88479e-09
I0318 15:11:54.481268 29479 solver.cpp:613] Iteration 109780, avg_grad_norm = 481067
I0318 15:14:17.976104 29479 solver.cpp:214] Iteration 109800, loss = 5591.17
I0318 15:14:17.976219 29479 solver.cpp:229]     Train net output #0: loss = 4325.05 (* 1 = 4325.05 loss)
I0318 15:14:19.005240 29479 solver.cpp:610] Iteration 109800, lr = 4.88381e-09
I0318 15:14:19.005259 29479 solver.cpp:613] Iteration 109800, avg_grad_norm = 500611
I0318 15:16:43.485973 29479 solver.cpp:214] Iteration 109820, loss = 5546.42
I0318 15:16:43.486119 29479 solver.cpp:229]     Train net output #0: loss = 8886.51 (* 1 = 8886.51 loss)
I0318 15:16:43.647456 29479 solver.cpp:610] Iteration 109820, lr = 4.88284e-09
I0318 15:16:43.647471 29479 solver.cpp:613] Iteration 109820, avg_grad_norm = 489693
I0318 15:19:13.201302 29479 solver.cpp:214] Iteration 109840, loss = 5513.18
I0318 15:19:13.201491 29479 solver.cpp:229]     Train net output #0: loss = 6631.33 (* 1 = 6631.33 loss)
I0318 15:19:14.274837 29479 solver.cpp:610] Iteration 109840, lr = 4.88186e-09
I0318 15:19:14.274855 29479 solver.cpp:613] Iteration 109840, avg_grad_norm = 525257
I0318 15:21:41.745640 29479 solver.cpp:214] Iteration 109860, loss = 5430.03
I0318 15:21:41.745808 29479 solver.cpp:229]     Train net output #0: loss = 3318.94 (* 1 = 3318.94 loss)
I0318 15:21:41.921139 29479 solver.cpp:610] Iteration 109860, lr = 4.88089e-09
I0318 15:21:41.921151 29479 solver.cpp:613] Iteration 109860, avg_grad_norm = 572406
I0318 15:24:06.301936 29479 solver.cpp:214] Iteration 109880, loss = 5687.3
I0318 15:24:06.302043 29479 solver.cpp:229]     Train net output #0: loss = 5361.47 (* 1 = 5361.47 loss)
I0318 15:24:06.486821 29479 solver.cpp:610] Iteration 109880, lr = 4.87991e-09
I0318 15:24:06.486834 29479 solver.cpp:613] Iteration 109880, avg_grad_norm = 571356
I0318 15:26:30.970139 29479 solver.cpp:214] Iteration 109900, loss = 5406.87
I0318 15:26:30.970338 29479 solver.cpp:229]     Train net output #0: loss = 4324.18 (* 1 = 4324.18 loss)
I0318 15:26:31.141772 29479 solver.cpp:610] Iteration 109900, lr = 4.87894e-09
I0318 15:26:31.141784 29479 solver.cpp:613] Iteration 109900, avg_grad_norm = 502206
I0318 15:28:54.705050 29479 solver.cpp:214] Iteration 109920, loss = 5507.98
I0318 15:28:54.705190 29479 solver.cpp:229]     Train net output #0: loss = 9893.7 (* 1 = 9893.7 loss)
I0318 15:28:55.772708 29479 solver.cpp:610] Iteration 109920, lr = 4.87796e-09
I0318 15:28:55.772752 29479 solver.cpp:613] Iteration 109920, avg_grad_norm = 490669
I0318 15:31:19.231209 29479 solver.cpp:214] Iteration 109940, loss = 5734.52
I0318 15:31:19.231334 29479 solver.cpp:229]     Train net output #0: loss = 8396.73 (* 1 = 8396.73 loss)
I0318 15:31:19.400593 29479 solver.cpp:610] Iteration 109940, lr = 4.87699e-09
I0318 15:31:19.400606 29479 solver.cpp:613] Iteration 109940, avg_grad_norm = 489206
I0318 15:32:10.866395 29479 solver.cpp:214] Iteration 109960, loss = 5564.27
I0318 15:32:10.866602 29479 solver.cpp:229]     Train net output #0: loss = 4200.54 (* 1 = 4200.54 loss)
I0318 15:32:10.971036 29479 solver.cpp:610] Iteration 109960, lr = 4.87601e-09
I0318 15:32:10.971052 29479 solver.cpp:613] Iteration 109960, avg_grad_norm = 499068
I0318 15:34:14.424372 29479 solver.cpp:214] Iteration 109980, loss = 5543.1
I0318 15:34:14.424525 29479 solver.cpp:229]     Train net output #0: loss = 5753.08 (* 1 = 5753.08 loss)
I0318 15:34:14.599325 29479 solver.cpp:610] Iteration 109980, lr = 4.87504e-09
I0318 15:34:14.599340 29479 solver.cpp:613] Iteration 109980, avg_grad_norm = 614279
I0318 15:36:31.129829 29479 solver.cpp:458] Snapshotting to models/pnet/VGG_VOC2012ext_iter_110000.caffemodel
I0318 15:36:32.089335 29479 solver.cpp:466] Snapshotting solver state to models/pnet/VGG_VOC2012ext_iter_110000.solverstate
I0318 15:36:39.123180 29479 solver.cpp:214] Iteration 110000, loss = 5667.31
I0318 15:36:39.123257 29479 solver.cpp:229]     Train net output #0: loss = 6516.34 (* 1 = 6516.34 loss)
I0318 15:36:40.157620 29479 solver.cpp:610] Iteration 110000, lr = 4.87406e-09
I0318 15:36:40.157636 29479 solver.cpp:613] Iteration 110000, avg_grad_norm = 523937
I0318 15:39:03.737701 29479 solver.cpp:214] Iteration 110020, loss = 5514.86
I0318 15:39:03.737853 29479 solver.cpp:229]     Train net output #0: loss = 6286.44 (* 1 = 6286.44 loss)
I0318 15:39:03.904595 29479 solver.cpp:610] Iteration 110020, lr = 4.87309e-09
I0318 15:39:03.904609 29479 solver.cpp:613] Iteration 110020, avg_grad_norm = 570859
I0318 15:41:33.356756 29479 solver.cpp:214] Iteration 110040, loss = 5518.08
I0318 15:41:33.356899 29479 solver.cpp:229]     Train net output #0: loss = 4855.69 (* 1 = 4855.69 loss)
I0318 15:41:33.519259 29479 solver.cpp:610] Iteration 110040, lr = 4.87211e-09
I0318 15:41:33.519274 29479 solver.cpp:613] Iteration 110040, avg_grad_norm = 559367
I0318 15:44:02.951131 29479 solver.cpp:214] Iteration 110060, loss = 5538.57
I0318 15:44:02.951285 29479 solver.cpp:229]     Train net output #0: loss = 4704.32 (* 1 = 4704.32 loss)
I0318 15:44:03.973857 29479 solver.cpp:610] Iteration 110060, lr = 4.87114e-09
I0318 15:44:03.973872 29479 solver.cpp:613] Iteration 110060, avg_grad_norm = 501369
I0318 15:46:34.662713 29479 solver.cpp:214] Iteration 110080, loss = 5569.23
I0318 15:46:34.662844 29479 solver.cpp:229]     Train net output #0: loss = 6131.7 (* 1 = 6131.7 loss)
I0318 15:46:35.734716 29479 solver.cpp:610] Iteration 110080, lr = 4.87016e-09
I0318 15:46:35.734731 29479 solver.cpp:613] Iteration 110080, avg_grad_norm = 470504
I0318 15:49:07.262419 29479 solver.cpp:214] Iteration 110100, loss = 5611.56
I0318 15:49:07.262562 29479 solver.cpp:229]     Train net output #0: loss = 3750.45 (* 1 = 3750.45 loss)
I0318 15:49:07.416072 29479 solver.cpp:610] Iteration 110100, lr = 4.86919e-09
I0318 15:49:07.416085 29479 solver.cpp:613] Iteration 110100, avg_grad_norm = 506120
I0318 15:51:36.916890 29479 solver.cpp:214] Iteration 110120, loss = 5331.13
I0318 15:51:36.917018 29479 solver.cpp:229]     Train net output #0: loss = 7870.85 (* 1 = 7870.85 loss)
I0318 15:51:38.000244 29479 solver.cpp:610] Iteration 110120, lr = 4.86822e-09
I0318 15:51:38.000260 29479 solver.cpp:613] Iteration 110120, avg_grad_norm = 493384
I0318 15:52:54.472338 29479 solver.cpp:214] Iteration 110140, loss = 5119.46
I0318 15:52:54.472501 29479 solver.cpp:229]     Train net output #0: loss = 6766.11 (* 1 = 6766.11 loss)
I0318 15:52:55.548549 29479 solver.cpp:610] Iteration 110140, lr = 4.86724e-09
I0318 15:52:55.548609 29479 solver.cpp:613] Iteration 110140, avg_grad_norm = 458528
I0318 15:55:24.036458 29479 solver.cpp:214] Iteration 110160, loss = 5278.12
I0318 15:55:24.036661 29479 solver.cpp:229]     Train net output #0: loss = 4262.94 (* 1 = 4262.94 loss)
I0318 15:55:24.193805 29479 solver.cpp:610] Iteration 110160, lr = 4.86627e-09
I0318 15:55:24.193820 29479 solver.cpp:613] Iteration 110160, avg_grad_norm = 510392
I0318 15:57:53.682050 29479 solver.cpp:214] Iteration 110180, loss = 5712.79
I0318 15:57:53.682193 29479 solver.cpp:229]     Train net output #0: loss = 8829.81 (* 1 = 8829.81 loss)
I0318 15:57:53.843453 29479 solver.cpp:610] Iteration 110180, lr = 4.86529e-09
I0318 15:57:53.843467 29479 solver.cpp:613] Iteration 110180, avg_grad_norm = 543806
I0318 16:00:23.225414 29479 solver.cpp:214] Iteration 110200, loss = 5512.11
I0318 16:00:23.225623 29479 solver.cpp:229]     Train net output #0: loss = 2087.08 (* 1 = 2087.08 loss)
I0318 16:00:23.448134 29479 solver.cpp:610] Iteration 110200, lr = 4.86432e-09
I0318 16:00:23.448148 29479 solver.cpp:613] Iteration 110200, avg_grad_norm = 488944
I0318 16:02:53.004075 29479 solver.cpp:214] Iteration 110220, loss = 5416.4
I0318 16:02:53.004175 29479 solver.cpp:229]     Train net output #0: loss = 5090.42 (* 1 = 5090.42 loss)
I0318 16:02:54.074776 29479 solver.cpp:610] Iteration 110220, lr = 4.86334e-09
I0318 16:02:54.074790 29479 solver.cpp:613] Iteration 110220, avg_grad_norm = 417699
I0318 16:05:24.606351 29479 solver.cpp:214] Iteration 110240, loss = 5659.72
I0318 16:05:24.606515 29479 solver.cpp:229]     Train net output #0: loss = 3429.29 (* 1 = 3429.29 loss)
I0318 16:05:25.690369 29479 solver.cpp:610] Iteration 110240, lr = 4.86237e-09
I0318 16:05:25.690383 29479 solver.cpp:613] Iteration 110240, avg_grad_norm = 479085
I0318 16:07:54.189090 29479 solver.cpp:214] Iteration 110260, loss = 5648.09
I0318 16:07:54.189213 29479 solver.cpp:229]     Train net output #0: loss = 4208.18 (* 1 = 4208.18 loss)
I0318 16:07:54.342532 29479 solver.cpp:610] Iteration 110260, lr = 4.86139e-09
I0318 16:07:54.342545 29479 solver.cpp:613] Iteration 110260, avg_grad_norm = 537633
I0318 16:10:22.885311 29479 solver.cpp:214] Iteration 110280, loss = 5454.7
I0318 16:10:22.885527 29479 solver.cpp:229]     Train net output #0: loss = 3882.06 (* 1 = 3882.06 loss)
I0318 16:10:23.926408 29479 solver.cpp:610] Iteration 110280, lr = 4.86041e-09
I0318 16:10:23.926434 29479 solver.cpp:613] Iteration 110280, avg_grad_norm = 511541
